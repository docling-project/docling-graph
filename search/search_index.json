{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Docling Graph Documentation","text":""},{"location":"#what-is-docling-graph","title":"What is Docling Graph?","text":"<p>Docling-Graph turns documents into validated Pydantic objects, then builds a directed knowledge graph with explicit semantic relationships.</p> <p>This transformation enables high-precision use cases in chemistry, finance, and legal domains, where AI must capture exact entity connections (compounds and reactions, instruments and dependencies, properties and measurements) rather than rely on approximate text embeddings.</p> <p>This toolkit supports two extraction paths: local VLM extraction via Docling, and LLM-based extraction using either local runtimes (vLLM, Ollama) or API providers (Mistral, OpenAI, Gemini, IBM WatsonX), all orchestrated through a flexible, config-driven pipeline.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\u270d\ud83c\udffb Multi-Format Input: Ingest PDFs, images, URLs, raw text, Markdown and more.</li> <li>\ud83e\udde0 Flexible Extraction: VLM or LLM-based (vLLM, Ollama, Mistral, Gemini, WatsonX, etc.)</li> <li>\ud83d\udd28 Smart Graphs: Convert Pydantic models to NetworkX graphs with stable node IDs</li> <li>\ud83d\udce6 Multiple Export: CSV (Neo4j-compatible), Cypher scripts, JSON, Markdown</li> <li>\ud83d\udcca Rich Visualizations: Interactive HTML and detailed Markdown reports</li> <li>\u2699\ufe0f Type-Safe Configuration: Pydantic-based validation</li> </ul>"},{"location":"#quick-navigation","title":"Quick Navigation","text":""},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<ul> <li> <p>Installation \u2192</p> <p>Set up your environment with uv package manager</p> </li> <li> <p>Quick Start \u2192</p> <p>Run your first extraction in 5 minutes</p> </li> <li> <p>Architecture \u2192</p> <p>Understand the pipeline stages and components</p> </li> <li> <p>Key Concepts \u2192</p> <p>Learn how documents flow through the system</p> </li> </ul>"},{"location":"#core-documentation","title":"\ud83d\udcda Core Documentation","text":"<ul> <li> <p>Introduction</p> <p>Overview, architecture, and core concepts</p> </li> <li> <p>Fundamentals</p> <p>Installation, schema definition, pipeline configuration, extraction, and more</p> </li> <li> <p>Usage</p> <p>CLI reference, Python API, examples, and advanced topics</p> </li> <li> <p>Reference</p> <p>Detailed API documentation</p> </li> <li> <p>Community</p> <p>Contributing and development guide</p> </li> </ul>"},{"location":"#quick-start-example","title":"Quick Start Example","text":""},{"location":"#python-api","title":"Python API","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Create configuration\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\",\n    output_dir=\"outputs/invoice\"\n)\n\n# Run pipeline\nconfig.run()\n</code></pre>"},{"location":"#cli","title":"CLI","text":"<pre><code># Initialize configuration\nuv run docling-graph init\n\n# Convert document\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"outputs/invoice\"\n\n# Visualize results\nuv run docling-graph inspect outputs/invoice\n</code></pre>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<p>The documentation is organized into 5 main sections for a streamlined learning experience:</p>"},{"location":"#1-introduction","title":"1. Introduction","text":"<p>Learn what Docling Graph is, how it works, and its architecture.</p> <p>\u2192 Go to Introduction</p>"},{"location":"#2-fundamentals","title":"2. Fundamentals","text":"<p>Master the core concepts: installation, schema definition, pipeline configuration, extraction, and graph management.</p> <p>\u2192 Go to Fundamentals</p>"},{"location":"#3-usage","title":"3. Usage","text":"<p>Learn to use Docling Graph through CLI, Python API, examples, and advanced techniques.</p> <p>\u2192 Go to Usage</p>"},{"location":"#4-reference","title":"4. Reference","text":"<p>Detailed API documentation for all modules and components.</p> <p>\u2192 Go to Reference</p>"},{"location":"#5-community","title":"5. Community","text":"<p>Contribute to the project and understand the development workflow.</p> <p>\u2192 Go to Community</p>"},{"location":"#common-use-cases","title":"Common Use Cases","text":""},{"location":"#extract-invoice-data","title":"Extract Invoice Data","text":"<pre><code>from docling_graph import PipelineConfig\nfrom templates import Invoice\n\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=Invoice,\n    backend=\"llm\",\n    inference=\"remote\"\n)\nconfig.run()\n</code></pre> <p>\u2192 See Invoice Template</p>"},{"location":"#process-research-papers","title":"Process Research Papers","text":"<pre><code>config = PipelineConfig(\n    source=\"research.pdf\",\n    template=ResearchPaper,\n    backend=\"llm\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True\n)\nconfig.run()\n</code></pre> <p>\u2192 See Research Template</p>"},{"location":"#extract-id-card-information","title":"Extract ID Card Information","text":"<pre><code>config = PipelineConfig(\n    source=\"id_card.jpg\",\n    template=IDCard,\n    backend=\"vlm\",\n    inference=\"local\"\n)\nconfig.run()\n</code></pre> <p>\u2192 See ID Card Template</p>"},{"location":"#key-concepts","title":"Key Concepts","text":""},{"location":"#pydantic-templates","title":"Pydantic Templates","text":"<p>Templates define both the extraction schema and the graph structure:</p> <pre><code>from pydantic import BaseModel, Field\nfrom docling_graph.utils import edge\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['last_name', 'date_of_birth']\n    }\n\n    first_name: str = Field(description=\"First name\")\n    last_name: str = Field(description=\"Last name\")\n    date_of_birth: str = Field(description=\"Date of birth (YYYY-MM-DD)\")\n\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = {'is_entity': True}\n\n    name: str = Field(description=\"Organization name\")\n    employees: list[Person] = edge(\"EMPLOYS\", description=\"Employees\")\n</code></pre> <p>\u2192 Learn More About Templates</p>"},{"location":"#pipeline-stages","title":"Pipeline Stages","text":"<ol> <li>Template Loading: Load and validate Pydantic templates</li> <li>Document Conversion: Convert documents using Docling</li> <li>Chunking: Split content into manageable pieces (optional)</li> <li>Extraction: Extract structured data using VLM or LLM</li> <li>Consolidation: Merge results (optional)</li> <li>Graph Construction: Build NetworkX graph from Pydantic models</li> <li>Export: Generate CSV, Cypher, JSON outputs</li> <li>Visualization: Create interactive HTML and Markdown reports</li> </ol> <p>\u2192 Learn More About Key Concepts</p>"},{"location":"#extraction-backends","title":"Extraction Backends","text":"<ul> <li>VLM (Vision-Language Model): Local extraction using Docling's NuExtract</li> <li>LLM (Language Model): Text-based extraction using local (vLLM, Ollama) or remote APIs (Mistral, OpenAI, Gemini, WatsonX)</li> <li>Model Capabilities: Automatic classification into SIMPLE/STANDARD/ADVANCED tiers for optimized extraction</li> </ul> <p>\u2192 Learn More About Backends \u2192 Learn More About Model Capabilities</p>"},{"location":"#resources","title":"Resources","text":""},{"location":"#documentation","title":"Documentation","text":"<ul> <li>GitHub Repository - Source code and issues</li> <li>PyPI Package - Install via pip/uv</li> <li>Contributing Guidelines - How to contribute</li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>GitHub Issues - Report bugs and request features</li> <li>GitHub Discussions - Ask questions and share ideas</li> </ul>"},{"location":"#related-projects","title":"Related Projects","text":"<ul> <li>Docling - Document processing engine</li> <li>Pydantic - Data validation library</li> <li>NetworkX - Graph library</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ol> <li>Install Docling Graph \u2192</li> <li>Follow the Quick Start \u2192</li> <li>Create Your First Template \u2192</li> <li>Explore Examples \u2192</li> </ol>"},{"location":"#need-help","title":"Need Help?","text":"<ul> <li>Installation Issues: See Installation Guide</li> <li>Template Questions: See Schema Definition</li> <li>Configuration Help: See Pipeline Configuration</li> <li>Error Messages: See Error Handling</li> </ul> <p> Ready to get started? Install Docling Graph \u2192 </p>"},{"location":"assets/flowcharts/architecture/","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Source Input\" }\n    n2@{ shape: terminal, label: \"Config\" }\n    n3@{ shape: terminal, label: \"Pydantic Template\" }\n\n    n4@{ shape: procs, label: \"Docling Graph Pipeline\" }\n    n35@{ shape: lin-proc, label: \"Input Validator\" }\n    n37@{ shape: tag-proc, label: \"Multi-Input Handler\" }\n    n39@{ shape: tag-proc, label: \"DoclingDoc Loader\" }\n    n5@{ shape: tag-proc, label: \"Extraction Factory\" }\n\n    n6@{ shape: procs, label: \"Docling Pipeline\" }\n    %% Defined first to prioritize placement\n    n25@{ shape: lin-proc, label: \"Extract\" } \n    n7@{ shape: lin-proc, label: \"OCR\" }\n    n8@{ shape: lin-proc, label: \"Vision\" }\n    n9@{ shape: tag-proc, label: \"Markdown Processor\" }\n\n    n16@{ shape: terminal, label: \"Prompt\" }\n    n13@{ shape: procs, label: \"Extraction Backend\" }\n    n14@{ shape: lin-proc, label: \"LLM\" }\n    n15@{ shape: lin-proc, label: \"VLM\" }\n    n17@{ shape: terminal, label: \"Extracted Content\" }\n\n    n10@{ shape: procs, label: \"Conversion Strategy\" }\n    n11@{ shape: lin-proc, label: \"One To One\" }\n    n12@{ shape: lin-proc, label: \"Many To One\" }\n    n18@{ shape: tag-proc, label: \"Smart Template Merger\" }\n    n20@{ shape: terminal, label: \"Populated Pydantic Model(s)\" }\n\n    n21@{ shape: tag-proc, label: \"Graph Converter\" }\n    n22@{ shape: terminal, label: \"Knowledge Graph\" }\n\n    n23@{ shape: tag-proc, label: \"Exporter\" }\n    n29@{ shape: terminal, label: \"CSV\" }\n    n30@{ shape: terminal, label: \"Cypher\" }\n    n31@{ shape: terminal, label: \"JSON\" }\n    n34@{ shape: tag-proc, label: \"Batch Loader\" }\n    n33@{ shape: db, label: \"Knowledge Base\" }\n\n    n24@{ shape: tag-proc, label: \"Visualizer\" }\n    n28@{ shape: terminal, label: \"Images\" }\n    n27@{ shape: terminal, label: \"HTML\" }\n    n26@{ shape: terminal, label: \"Markdown\" }\n\n    %% 3. Define Connections\n    A &amp; n2 &amp; n3 --&gt; n4\n    n4 --&gt; n35\n    n35 --&gt; n37 &amp; n39\n\n    n37 --&gt; n5\n    n39 --&gt; n6\n\n    n5 --&gt; n6\n\n    %% n25 first to encourage left placement\n    n6 --&gt; n25 &amp; n7 &amp; n8\n\n    n7 &amp; n8 --&gt; n9\n    n9 --&gt; n16\n    n16 --&gt; n13\n\n    n13 --&gt; n14 &amp; n15\n    n14 &amp; n15 --&gt; n17\n    n17 --&gt; n10\n\n    n10 --&gt; n11 &amp; n12\n    n12 --&gt; n18\n    n11 &amp; n18 &amp; n25 --&gt; n20\n\n    n20 --&gt; n21\n    n21 --&gt; n22\n    n22 --&gt; n23 &amp; n24\n\n    n23 --&gt; n29 &amp; n30 &amp; n31 &amp; n33\n    n29 &amp; n30 &amp; n31 --&gt; n34\n    n34 --&gt; n33\n\n    n24 --&gt; n28 &amp; n27 &amp; n26\n\n    %% 4. Apply Classes\n    class A,n3 input\n    class n2,n16 config\n    class n4,n35,n6,n7,n8,n25,n13,n14,n15,n10,n11,n12,n33 process\n    class n37,n39,n5,n9,n18,n21,n23,n34,n24 operator\n    class n17,n20,n22,n29,n30,n31,n28,n27,n26 output</code></pre>"},{"location":"assets/flowcharts/chunk_batcher/","title":"Chunk batcher","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"10 Chunks\" }\n\n    B@{ shape: procs, label: \"Greedy Packing\" }\n    C@{ shape: doc, label: \"5 Candidate Batches\" }\n\n    D@{ shape: lin-proc, label: \"Merge Undersized\" }\n    E@{ shape: doc, label: \"3 Final Batches\" }\n\n    F@{ shape: tag-proc, label: \"3 API Calls\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,D process\n    class C,E data\n    class F output</code></pre>"},{"location":"assets/flowcharts/config_flow/","title":"Config flow","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% Subgraph Styling (Transparent with dashed border for visibility)\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5,color:#969696\n\n    %% 2. Define Nodes &amp; Subgraphs\n    A@{ shape: procs, label: \"PipelineConfig\" }\n\n    subgraph Backends [\"Backend Configuration\"]\n        B@{ shape: lin-proc, label: \"Backend Selection\" }\n        F@{ shape: tag-proc, label: \"LLM Backend\" }\n        G@{ shape: tag-proc, label: \"VLM Backend\" }\n    end\n\n    subgraph Models [\"Inference Settings\"]\n        C@{ shape: lin-proc, label: \"Model Selection\" }\n        H@{ shape: tag-proc, label: \"Local Inference\" }\n        I@{ shape: tag-proc, label: \"Remote Inference\" }\n    end\n\n    subgraph Strategy [\"Processing Mode\"]\n        D@{ shape: lin-proc, label: \"Processing Mode\" }\n        J@{ shape: tag-proc, label: \"One-to-One\" }\n        K@{ shape: tag-proc, label: \"Many-to-One\" }\n    end\n\n    subgraph Exports [\"Output Settings\"]\n        E@{ shape: lin-proc, label: \"Export Settings\" }\n        L@{ shape: tag-proc, label: \"CSV Export\" }\n        M@{ shape: tag-proc, label: \"Cypher Export\" }\n    end\n\n    %% 3. Define Connections\n    A --&gt; B &amp; C &amp; D &amp; E\n\n    B --&gt; F &amp; G\n    C --&gt; H &amp; I\n    D --&gt; J &amp; K\n    E --&gt; L &amp; M\n\n    %% 4. Apply Classes\n    class A config\n    class B,C,D,E process\n    class F,G,H,I,J,K operator\n    class L,M output\n    class Backends,Models,Strategy,Exports subgraph_style</code></pre>"},{"location":"assets/flowcharts/conversion_process/","title":"Conversion process","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Pydantic Models\" }\n\n    B@{ shape: lin-proc, label: \"Pre-register Models\" }\n    C@{ shape: procs, label: \"Create Nodes\" }\n    D@{ shape: procs, label: \"Create Edges\" }\n\n    E@{ shape: tag-proc, label: \"Auto Cleanup\" }\n    F@{ shape: tag-proc, label: \"Validate Graph\" }\n    G@{ shape: tag-proc, label: \"Calculate Stats\" }\n\n    H@{ shape: doc, label: \"NetworkX Graph\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n    F --&gt; G\n    G --&gt; H\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D process\n    class E,F,G operator\n    class H output</code></pre>"},{"location":"assets/flowcharts/doc_chunker/","title":"Doc chunker","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Full Document\" }\n\n    B@{ shape: procs, label: \"Docling&lt;br/&gt;Segmentation\" }\n    C@{ shape: lin-proc, label: \"Semantic&lt;br/&gt;Boundaries\" }\n    D@{ shape: tag-proc, label: \"Token-Aware&lt;br/&gt;Splitting\" }\n\n    E(\"Chunks with&lt;br/&gt;Context\")\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B,C process\n    class D operator\n    class E output</code></pre>"},{"location":"assets/flowcharts/exporters/","title":"Exporters","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5,color:#969696\n\n    %% 2. Define Nodes &amp; Subgraphs\n    A@{ shape: terminal, label: \"NetworkX Graph\" }\n\n    subgraph subGraph0[\"Export Modules\"]\n        B@{ shape: tag-proc, label: \"CSV Exporter\" }\n        C@{ shape: tag-proc, label: \"Cypher Exporter\" }\n        D@{ shape: tag-proc, label: \"JSON Exporter\" }\n        E@{ shape: tag-proc, label: \"Docling Exporter\" }\n    end\n\n    %% Output Files\n    F@{ shape: doc, label: \"nodes.csv\" }\n    n1@{ shape: doc, label: \"edges.csv\" }\n    G@{ shape: doc, label: \"graph.cypher\" }\n    H@{ shape: doc, label: \"graph.json\" }\n    I@{ shape: doc, label: \"docling.json\" }\n    n2@{ shape: doc, label: \"document.md\" }\n\n    %% 3. Define Connections\n    A --&gt; B &amp; C &amp; D &amp; E\n\n    B --&gt; F &amp; n1\n    C --&gt; G\n    D --&gt; H\n    E --&gt; I &amp; n2\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D,E operator\n    class F,n1,G,H,I,n2 output\n    class subGraph0 subgraph_style</code></pre>"},{"location":"assets/flowcharts/extension_points/","title":"Extension points","text":"<p>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%% flowchart TB     %% 1. Define Classes     classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1     classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037     classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20     classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100     classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0     classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A     classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238</p> <pre><code>%% 2. Define Nodes\nA@{ shape: terminal, label: \"Input Source\" }\n\nB@{ shape: lin-proc, label: \"Custom Stage 1\" }\nC@{ shape: procs, label: \"Docling Conversion\" }\nD@{ shape: tag-proc, label: \"Custom Backend\" }\nE@{ shape: procs, label: \"Extraction\" }\nF@{ shape: lin-proc, label: \"Custom Stage 2\" }\nG@{ shape: procs, label: \"Graph Conversion\" }\nH@{ shape: tag-proc, label: \"Custom Exporter\" }\n\nI@{ shape: doc, label: \"Output\" }\n\n%% 3. Define Connections\nA --&gt; B\nB --&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; F\nF --&gt; G\nG --&gt; H\nH --&gt; I\n\n%% 4. Apply Classes\nclass A input\nclass B,F config\nclass C,E,G process\nclass D,H operator\nclass I output\n</code></pre> <p>```</p>"},{"location":"assets/flowcharts/extraction_flow/","title":"Extraction flow","text":"<p>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%% flowchart TD     %% 1. Define Classes     classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1     classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037     classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20     classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100     classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0     classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A     classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238</p> <pre><code>%% 2. Define Nodes\nStart@{ shape: terminal, label: \"Input Source\" }\n\nNormalize@{ shape: procs, label: \"Input Normalization\" }\nCheckInput{\"Input Type\"}\n\nConvert@{ shape: procs, label: \"Document Conversion&lt;br/&gt;PDF/Image\" }\nTextProc@{ shape: lin-proc, label: \"Text Processing&lt;br/&gt;Text/Markdown\" }\nLoadDoc@{ shape: lin-proc, label: \"Load DoclingDocument&lt;br/&gt;Skip to Graph\" }\n\nCheckMode{\"Process. Mode\"}\nCheckChunk{\"Chunking?\"}\n\nPageExtract@{ shape: lin-proc, label: \"Page-by-Page Extraction\" }\nFullDoc@{ shape: lin-proc, label: \"Full Document Extraction\" }\n\nChunk@{ shape: tag-proc, label: \"Structure-Aware Chunking\" }\nBatch@{ shape: tag-proc, label: \"Batch Chunks\" }\n\nExtract@{ shape: procs, label: \"Extract from Batches\" }\n\nCheckMerge{\"Multiple Models?\"}\n\nMerge@{ shape: lin-proc, label: \"Programmatic Merge\" }\nSingle@{ shape: doc, label: \"Single Model\" }\n\nCheckConsol{\"Consolidation?\"}\nConsol@{ shape: procs, label: \"LLM Consolidation\" }\n\nFinal@{ shape: doc, label: \"Final Model\" }\nGraph@{ shape: db, label: \"Knowledge Graph\" }\n\n%% 3. Define Connections\nStart --&gt; Normalize\nNormalize --&gt; CheckInput\n\nCheckInput -- \"PDF/Image\" --&gt; Convert\nCheckInput -- \"Text/Markdown\" --&gt; TextProc\nCheckInput -- \"DoclingDocument\" --&gt; LoadDoc\n\nConvert --&gt; CheckMode\nTextProc --&gt; CheckMode\n\nLoadDoc --&gt; Graph\n\nCheckMode -- Many-to-One --&gt; CheckChunk\nCheckMode -- One-to-One --&gt; PageExtract\n\nCheckChunk -- Yes --&gt; Chunk\nCheckChunk -- No --&gt; FullDoc\n\nChunk --&gt; Batch\nBatch --&gt; Extract\n\nFullDoc --&gt; Extract\nPageExtract --&gt; Extract\n\nExtract --&gt; CheckMerge\nCheckMerge -- Yes --&gt; Merge\nCheckMerge -- No --&gt; Single\n\nMerge --&gt; CheckConsol\nCheckConsol -- Yes --&gt; Consol\nCheckConsol -- No --&gt; Final\n\nConsol --&gt; Final\nSingle --&gt; Final\nFinal --&gt; Graph\n\n%% 4. Apply Classes\nclass Start input\nclass Normalize,Convert,Extract,Consol process\nclass TextProc,LoadDoc,PageExtract,FullDoc,Merge process\nclass Chunk,Batch operator\nclass CheckInput,CheckMode,CheckChunk,CheckMerge,CheckConsol decision\nclass Single data\nclass Final,Graph output\n</code></pre> <p>```</p>"},{"location":"assets/flowcharts/four_stage_pipeline/","title":"Four stage pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Input Source\" }\n\n    A1@{ shape: tag-proc, label: \"Input Normalization\" }\n    B@{ shape: procs, label: \"Conversion\" }\n    C@{ shape: tag-proc, label: \"Chunking\" }\n    D@{ shape: procs, label: \"Extraction\" }\n    E@{ shape: lin-proc, label: \"Merging\" }\n\n    F@{ shape: db, label: \"Knowledge Graph\" }\n\n    %% 3. Define Connections\n    A --&gt; A1\n    A1 --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class A1,C operator\n    class B,D,E process\n    class F output</code></pre>"},{"location":"assets/flowcharts/graph_converter/","title":"Graph converter","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Pydantic Models\" }\n\n    B@{ shape: lin-proc, label: \"Node ID&lt;br/&gt;Generation\" }\n    C@{ shape: lin-proc, label: \"Node&lt;br/&gt;Creation\" }\n    D@{ shape: lin-proc, label: \"Edge&lt;br/&gt;Creation\" }\n    E@{ shape: tag-proc, label: \"Graph&lt;br/&gt;Validation\" }\n\n    F(\"NetworkX&lt;br/&gt;DiGraph\")\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D process\n    class E operator\n    class F output</code></pre>"},{"location":"assets/flowcharts/graph_pipeline/","title":"Graph pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Pydantic Models\" }\n\n    B@{ shape: procs, label: \"Graph Conversion\" }\n    C@{ shape: doc, label: \"NetworkX Graph\" }\n\n    D@{ shape: tag-proc, label: \"Export\" }\n    F@{ shape: tag-proc, label: \"Visualization\" }\n\n    E1@{ shape: doc, label: \"CSV Files\" }\n    E2@{ shape: doc, label: \"Cypher Script\" }\n    E3@{ shape: doc, label: \"JSON\" }\n\n    G@{ shape: doc, label: \"Interactive HTML\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n\n    C --&gt; D\n    C --&gt; F\n\n    D --&gt; E1\n    D --&gt; E2\n    D --&gt; E3\n\n    F --&gt; G\n\n    %% 4. Apply Classes\n    class A input\n    class B process\n    class C data\n    class D,F operator\n    class E1,E2,E3,G output</code></pre>"},{"location":"assets/flowcharts/input_normalization/","title":"Input normalization","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    Start@{ shape: terminal, label: \"Input Source\" }\n    Detect@{ shape: procs, label: \"Input Type Detection\" }\n\n    %% Validators\n    ValPDF@{ shape: lin-proc, label: \"Validate PDF\" }\n    ValImg@{ shape: lin-proc, label: \"Validate Image\" }\n    ValText@{ shape: lin-proc, label: \"Validate Text\" }\n    ValMD@{ shape: lin-proc, label: \"Validate MD\" }\n    ValDoc@{ shape: lin-proc, label: \"Validate Docling\" }\n\n    %% URL Specifics\n    ValURL@{ shape: lin-proc, label: \"Validate &amp; Download URL\" }\n    CheckDL{\"Type?\"}\n\n    %% Handlers\n    HandVisual@{ shape: tag-proc, label: \"Visual Handler\" }\n    HandText@{ shape: tag-proc, label: \"Text Handler\" }\n    HandDoc@{ shape: tag-proc, label: \"Object Handler\" }\n\n    %% Outcomes\n    SetFlags@{ shape: procs, label: \"Set Processing Flags\" }\n    Output@{ shape: doc, label: \"Normalized Context\" }\n\n    %% 3. Define Connections\n    Start --&gt; Detect\n\n    %% Input Detection Routing\n    Detect -- PDF --&gt; ValPDF\n    Detect -- Image --&gt; ValImg\n    Detect -- Text --&gt; ValText\n    Detect -- MD --&gt; ValMD\n    Detect -- Docling --&gt; ValDoc\n    Detect -- URL --&gt; ValURL\n\n    %% URL Routing (Feeds back into validators)\n    ValURL --&gt; CheckDL\n    CheckDL -- PDF --&gt; ValPDF\n    CheckDL -- Image --&gt; ValImg\n    CheckDL -- Text --&gt; ValText\n    CheckDL -- MD --&gt; ValMD\n\n    %% Validation to Handlers (The \"Happy Path\")\n    ValPDF &amp; ValImg --&gt; HandVisual\n    ValText &amp; ValMD --&gt; HandText\n    ValDoc --&gt; HandDoc\n\n    %% Converge Handlers to Output\n    HandVisual &amp; HandText &amp; HandDoc --&gt; SetFlags --&gt; Output\n\n    %% 4. Apply Classes\n    class Start input\n    class Detect,SetFlags process\n    class ValPDF,ValImg,ValText,ValMD,ValURL,ValDoc process\n    class HandVisual,HandText,HandDoc operator\n    class CheckDL decision\n    class Output output</code></pre>"},{"location":"assets/flowcharts/llm_backend/","title":"Llm backend","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: procs, label: \"Docling Conversion\" }\n    C@{ shape: doc, label: \"Markdown Text\" }\n    D@{ shape: tag-proc, label: \"Chunking Optional\" }\n    E@{ shape: procs, label: \"LLM Extraction\" }\n\n    F@{ shape: doc, label: \"Structured Data\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,E process\n    class C data\n    class D operator\n    class F output</code></pre>"},{"location":"assets/flowcharts/llm_clients/","title":"Llm clients","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% Custom Subgraph Style (Transparent with dashed border)\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5,color:#969696\n\n    %% 2. Define Nodes\n    A@{ shape: procs, label: \"BaseLlmClient&lt;br&gt;Template Method Pattern\" }\n\n    subgraph subGraph0[\"Client Implementations\"]\n        B@{ shape: lin-proc, label: \"VLLMClient\" }\n        C@{ shape: lin-proc, label: \"OllamaClient\" }\n        D@{ shape: lin-proc, label: \"MistralClient\" }\n        E@{ shape: lin-proc, label: \"OpenAIClient\" }\n        F@{ shape: lin-proc, label: \"GeminiClient\" }\n        G@{ shape: lin-proc, label: \"WatsonXClient\" }\n    end\n\n    H@{ shape: tag-proc, label: \"ResponseHandler&lt;br&gt;JSON Parsing\" }\n    I(\"Config&lt;br&gt;models.yaml\")\n\n    %% 3. Define Connections\n    A --&gt; B\n    A --&gt; C\n    A --&gt; D\n    A --&gt; E\n    A --&gt; F\n    A --&gt; G\n    subGraph0 --&gt; H\n    subGraph0 --&gt; I\n\n    %% 4. Apply Classes\n    class A,B,C,D,E,F,G process\n    class H operator\n    class I config\n    class subGraph0 subgraph_style</code></pre>"},{"location":"assets/flowcharts/llm_consolidation/","title":"Llm consolidation","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Raw Models\" }\n\n    B@{ shape: lin-proc, label: \"Programmatic Merge\" }\n    C@{ shape: doc, label: \"Draft Model\" }\n\n    D@{ shape: procs, label: \"LLM Consolidation\" }\n    E@{ shape: doc, label: \"Final Model\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n\n    A --&gt; D\n    C --&gt; D\n\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A,C data\n    class B,D process\n    class E output</code></pre>"},{"location":"assets/flowcharts/many_to_one_mode/","title":"Many to one mode","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: doc, label: \"All Pages\" }\n    C@{ shape: tag-proc, label: \"Chunking\" }\n    D@{ shape: procs, label: \"Extract Chunks\" }\n    E@{ shape: lin-proc, label: \"Merge Results\" }\n\n    F@{ shape: procs, label: \"Single Model\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B data\n    class C operator\n    class D,E process\n    class F output</code></pre>"},{"location":"assets/flowcharts/model_decision_tree/","title":"Model decision tree","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"New Model\" }\n\n    B{\"Should this be&lt;br/&gt;tracked individually?\"}\n    C{\"Does it have a&lt;br/&gt;natural unique ID?\"}\n    F{\"Can you create&lt;br/&gt;a composite ID?\"}\n    G{\"Is it a value&lt;br/&gt;that's shared?\"}\n\n    %% Outcomes\n    D@{ shape: tag-proc, label: \"Component&lt;br/&gt;is_entity=False\" }\n    E@{ shape: procs, label: \"Entity&lt;br/&gt;graph_id_fields\" }\n    H@{ shape: lin-proc, label: \"Consider redesigning&lt;br/&gt;or use content-based ID\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B -- Yes --&gt; C\n    B -- No --&gt; D\n\n    C -- Yes --&gt; E\n    C -- No --&gt; F\n\n    F -- Yes --&gt; E\n    F -- No --&gt; G\n\n    G -- Yes --&gt; D\n    G -- No --&gt; H\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,F,G decision\n    class E output\n    class D data\n    class H config</code></pre>"},{"location":"assets/flowcharts/ocr_pipeline/","title":"Ocr pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Image / PDF Document\" }\n\n    B@{ shape: procs, label: \"OCR Engine\" }\n    C@{ shape: lin-proc, label: \"Text Extraction\" }\n    D@{ shape: lin-proc, label: \"Layout Analysis\" }\n\n    E@{ shape: doc, label: \"Markdown\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D process\n    class E output</code></pre>"},{"location":"assets/flowcharts/one_to_one_mode/","title":"One to one mode","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: doc, label: \"Page 1\" }\n    C@{ shape: doc, label: \"Page 2\" }\n    D@{ shape: doc, label: \"Page 3\" }\n\n    E@{ shape: tag-proc, label: \"Extract 1\" }\n    F@{ shape: tag-proc, label: \"Extract 2\" }\n    G@{ shape: tag-proc, label: \"Extract 3\" }\n\n    H@{ shape: procs, label: \"Model 1\" }\n    I@{ shape: procs, label: \"Model 2\" }\n    J@{ shape: procs, label: \"Model 3\" }\n\n    %% 3. Define Connections\n    A --&gt; B &amp; C &amp; D\n\n    B --&gt; E\n    C --&gt; F\n    D --&gt; G\n\n    E --&gt; H\n    F --&gt; I\n    G --&gt; J\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D data\n    class E,F,G operator\n    class H,I,J output</code></pre>"},{"location":"assets/flowcharts/pipeline_flow/","title":"Pipeline flow","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Input Source\" }\n    A1@{ shape: procs, label: \"1. Input Normalization&lt;br/&gt;Type Detection &amp; Validation\" }\n\n    A2{\"Input Type\"}\n\n    B@{ shape: procs, label: \"2. Docling Conversion&lt;br/&gt;OCR or Vision\" }\n    B2@{ shape: lin-proc, label: \"2b. Text Processing&lt;br/&gt;Direct to Markdown\" }\n    B3@{ shape: lin-proc, label: \"2c. Load DoclingDocument&lt;br/&gt;Skip Conversion\" }\n\n    C{\"3. Backend\"}\n\n    D@{ shape: lin-proc, label: \"4a. VLM Extraction&lt;br/&gt;Direct from Document\" }\n    E@{ shape: lin-proc, label: \"4b. Markdown Extraction\" }\n\n    F{\"5. Chunking\"}\n\n    G@{ shape: tag-proc, label: \"6a. Hybrid Chunking&lt;br/&gt;Semantic + Token-Aware\" }\n    H@{ shape: tag-proc, label: \"6b. Full Document\" }\n\n    I@{ shape: procs, label: \"7. Batch Extraction&lt;br/&gt;Process Each Chunk\" }\n    J@{ shape: tag-proc, label: \"8. Pydantic Validation&lt;br/&gt;Type Checking\" }\n\n    K{\"9. Consolidation\"}\n\n    L@{ shape: lin-proc, label: \"10a. Smart Merge&lt;br/&gt;Rule-Based\" }\n    M@{ shape: lin-proc, label: \"10b. LLM Consolidation&lt;br/&gt;Intelligent\" }\n\n    N@{ shape: procs, label: \"11. Graph Conversion&lt;br/&gt;Pydantic \u2192 NetworkX\" }\n    O@{ shape: tag-proc, label: \"12. Node ID Generation&lt;br/&gt;Stable Identifiers\" }\n\n    P@{ shape: tag-proc, label: \"13. Export&lt;br/&gt;CSV/Cypher/JSON\" }\n    Q@{ shape: tag-proc, label: \"14. Visualization&lt;br/&gt;HTML + Reports\" }\n\n    %% 3. Define Connections\n    A --&gt; A1\n    A1 --&gt; A2\n\n    A2 -- \"PDF/Image\" --&gt; B\n    A2 -- \"Text/Markdown\" --&gt; B2\n    A2 -- \"DoclingDocument\" --&gt; B3\n\n    B --&gt; C\n    B2 --&gt; C\n\n    B3 --&gt; E\n\n    C -- VLM --&gt; D\n    C -- LLM --&gt; E\n\n    E --&gt; F\n    F -- Yes --&gt; G\n    F -- No --&gt; H\n\n    G --&gt; I\n    H --&gt; I\n\n    D --&gt; J\n    I --&gt; J\n    J --&gt; K\n\n    K -- Programmatic --&gt; L\n    K -- LLM --&gt; M\n\n    L --&gt; N\n    M --&gt; N\n\n    N --&gt; O\n    O --&gt; P\n    P --&gt; Q\n\n    %% 4. Apply Classes\n    class A input\n    class A1,B,I,N process\n    class B2,B3,D,E,L,M process\n    class A2,C,F,K decision\n    class G,H,J,O operator\n    class P,Q output</code></pre>"},{"location":"assets/flowcharts/pipeline_stages/","title":"Pipeline stages","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A(\"1. Install\")\n\n    B@{ shape: lin-proc, label: \"2. Define Schema\" }\n    C@{ shape: lin-proc, label: \"3. Configure Pipeline\" }\n\n    D@{ shape: procs, label: \"4. Extract Data\" }\n    E@{ shape: procs, label: \"5. Build Graph\" }\n\n    F@{ shape: tag-proc, label: \"6. Export &amp; Visualize\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,C config\n    class D,E process\n    class F output</code></pre>"},{"location":"assets/flowcharts/processing_mode_tree/","title":"Processing mode tree","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A(\"Start\")\n\n    B{\"Are pages&lt;br/&gt;independent?\"}\n    D{\"Single entity&lt;br/&gt;across pages?\"}\n    F{\"Need page-level&lt;br/&gt;tracking?\"}\n\n    C@{ shape: tag-proc, label: \"One-to-One\" }\n    E@{ shape: tag-proc, label: \"Many-to-One\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n\n    B -- Yes --&gt; C\n    B -- No --&gt; D\n\n    D -- Yes --&gt; E\n    D -- No --&gt; F\n\n    F -- Yes --&gt; C\n    F -- No --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B,D,F decision\n    class C,E output</code></pre>"},{"location":"assets/flowcharts/programmatic_merge/","title":"Programmatic merge","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Model 1\" }\n    B@{ shape: terminal, label: \"Model 2\" }\n    C@{ shape: terminal, label: \"Model 3\" }\n\n    D@{ shape: lin-proc, label: \"Deep Merge\" }\n    E@{ shape: tag-proc, label: \"Deduplicate\" }\n    F@{ shape: tag-proc, label: \"Validate\" }\n\n    G@{ shape: doc, label: \"Final Model\" }\n\n    %% 3. Define Connections\n    A &amp; B &amp; C --&gt; D\n\n    D --&gt; E\n    E --&gt; F\n    F --&gt; G\n\n    %% 4. Apply Classes\n    class A,B,C data\n    class D process\n    class E,F operator\n    class G output</code></pre>"},{"location":"assets/flowcharts/vision_pipeline/","title":"Vision pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Images / PDF Document\" }\n\n    B@{ shape: doc, label: \"Page Images\" }\n    C@{ shape: procs, label: \"VLM Processing\" }\n    D@{ shape: lin-proc, label: \"Visual Understanding\" }\n\n    E@{ shape: doc, label: \"Structured Output\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B data\n    class C,D process\n    class E output</code></pre>"},{"location":"assets/flowcharts/vlm_backend/","title":"Vlm backend","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    InputPDF@{ shape: terminal, label: \"PDF Document\" }\n    InputImg@{ shape: terminal, label: \"Images\" }\n\n    Convert@{ shape: procs, label: \"PDF to Image&lt;br&gt;Conversion\" }\n    PageImgs@{ shape: doc, label: \"Page Images\" }\n\n    VLM@{ shape: procs, label: \"VLM Processing\" }\n    Understand@{ shape: lin-proc, label: \"Visual Understanding\" }\n    Extract@{ shape: tag-proc, label: \"Direct Extraction\" }\n\n    Output@{ shape: doc, label: \"Pydantic Models\" }\n\n    %% 3. Define Connections\n    %% Path A: PDF requires conversion\n    InputPDF --&gt; Convert\n    Convert --&gt; PageImgs\n    PageImgs --&gt; VLM\n\n    %% Path B: Direct Image Input (Merges here)\n    InputImg --&gt; VLM\n\n    %% Shared Processing Chain\n    VLM --&gt; Understand\n    Understand --&gt; Extract\n    Extract --&gt; Output\n\n    %% 4. Apply Classes\n    class InputPDF,InputImg input\n    class Convert,VLM,Understand process\n    class PageImgs data\n    class Extract operator\n    class Output output</code></pre>"},{"location":"community/","title":"Development Guide","text":""},{"location":"community/#overview","title":"Overview","text":"<p>Guide for contributing to docling-graph development.</p> <p>What's Included: - Contributing guidelines - Development setup - Code standards - Testing requirements - GitHub workflow - Release process</p>"},{"location":"community/#quick-start","title":"Quick Start","text":""},{"location":"community/#1-fork-and-clone","title":"1. Fork and Clone","text":"<pre><code># Fork on GitHub, then clone\ngit clone https://github.com/YOUR_USERNAME/docling-graph.git\ncd docling-graph\n</code></pre>"},{"location":"community/#2-setup-development-environment","title":"2. Setup Development Environment","text":"<pre><code># Install with all dependencies\nuv sync --extra all --extra dev\n\n# Verify installation\nuv run python -c \"import docling_graph; print(docling_graph.__version__)\"\n</code></pre>"},{"location":"community/#3-create-branch","title":"3. Create Branch","text":"<pre><code># Create feature branch\ngit checkout -b feature/my-feature\n\n# Or bug fix branch\ngit checkout -b fix/issue-123\n</code></pre>"},{"location":"community/#4-make-changes","title":"4. Make Changes","text":"<pre><code># Edit code\n# Add tests\n# Update documentation\n</code></pre>"},{"location":"community/#5-run-tests","title":"5. Run Tests","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov=docling_graph --cov-report=html\n</code></pre>"},{"location":"community/#6-submit-pull-request","title":"6. Submit Pull Request","text":"<pre><code># Commit changes\ngit add .\ngit commit -s -m \"feat: add new feature\"\n\n# Push to your fork\ngit push origin feature/my-feature\n\n# Create PR on GitHub\n</code></pre>"},{"location":"community/#development-topics","title":"Development Topics","text":""},{"location":"community/#contributing","title":"\ud83d\udcdd Contributing","text":"<p>Contributing Guidelines Official contribution guidelines for the project.</p> <ul> <li>Code of conduct</li> <li>Contribution workflow</li> <li>Issue reporting</li> <li>Pull request process</li> <li>Legal requirements (DCO)</li> </ul>"},{"location":"community/#github-workflow","title":"\ud83d\udd27 GitHub Workflow","text":"<p>GitHub Workflow Working with GitHub and CI/CD.</p> <ul> <li>Branch strategy</li> <li>Commit conventions</li> <li>CI/CD pipeline</li> <li>Automated testing</li> <li>Code quality checks</li> </ul>"},{"location":"community/#release-process","title":"\ud83d\ude80 Release Process","text":"<p>Release Process How releases are managed.</p> <ul> <li>Version numbering</li> <li>Release checklist</li> <li>Changelog management</li> <li>Publishing process</li> <li>Documentation updates</li> </ul>"},{"location":"community/#development-setup","title":"Development Setup","text":""},{"location":"community/#system-requirements","title":"System Requirements","text":"<ul> <li>Python 3.10+</li> <li>Git</li> <li>uv package manager</li> <li>(Optional) GPU with CUDA for local inference</li> </ul>"},{"location":"community/#install-development-dependencies","title":"Install Development Dependencies","text":"<pre><code># Full development setup\nuv sync --extra all --extra dev\n\n# This installs:\n# - Core dependencies\n# - Local inference (vLLM, transformers)\n# - Remote API clients\n# - Development tools (pytest, ruff, mypy)\n# - Documentation tools (mkdocs)\n</code></pre>"},{"location":"community/#verify-setup","title":"Verify Setup","text":"<pre><code># Check Python version\npython --version  # Should be 3.10+\n\n# Check uv\nuv --version\n\n# Run tests\nuv run pytest\n\n# Check code quality\nuv run ruff check .\nuv run mypy docling_graph\n</code></pre>"},{"location":"community/#code-standards","title":"Code Standards","text":""},{"location":"community/#style-guide","title":"Style Guide","text":"<p>We follow PEP 8 with some modifications:</p> <ul> <li>Line length: 100 characters</li> <li>Use type hints for all functions</li> <li>Docstrings for all public APIs</li> <li>Format with <code>ruff format</code></li> </ul>"},{"location":"community/#type-checking","title":"Type Checking","text":"<p>All code must pass mypy:</p> <pre><code>uv run mypy docling_graph\n</code></pre>"},{"location":"community/#linting","title":"Linting","text":"<p>Code must pass ruff checks:</p> <pre><code># Check code\nuv run ruff check .\n\n# Auto-fix issues\nuv run ruff check --fix .\n\n# Format code\nuv run ruff format .\n</code></pre>"},{"location":"community/#testing-requirements","title":"Testing Requirements","text":""},{"location":"community/#test-coverage","title":"Test Coverage","text":"<ul> <li>Minimum 80% code coverage</li> <li>All new features must have tests</li> <li>Bug fixes must include regression tests</li> </ul>"},{"location":"community/#running-tests","title":"Running Tests","text":"<pre><code># All tests\nuv run pytest\n\n# Specific test file\nuv run pytest tests/unit/test_config.py\n\n# Specific test\nuv run pytest tests/unit/test_config.py::test_pipeline_config\n\n# With coverage\nuv run pytest --cov=docling_graph --cov-report=html\n\n# Fast tests only (skip slow)\nuv run pytest -m \"not slow\"\n</code></pre>"},{"location":"community/#writing-tests","title":"Writing Tests","text":"<pre><code>\"\"\"Test example.\"\"\"\n\nimport pytest\nfrom docling_graph import PipelineConfig\n\ndef test_pipeline_config_creation():\n    \"\"\"Test PipelineConfig can be created.\"\"\"\n    config = PipelineConfig(\n        source=\"test.pdf\",\n        template=\"templates.Test\"\n    )\n    assert config.source == \"test.pdf\"\n    assert config.backend == \"llm\"  # Default\n\ndef test_pipeline_config_validation():\n    \"\"\"Test PipelineConfig validates inputs.\"\"\"\n    with pytest.raises(ValueError):\n        PipelineConfig(\n            source=\"test.pdf\",\n            template=\"templates.Test\",\n            backend=\"invalid\"  # Should fail\n        )\n</code></pre>"},{"location":"community/#documentation","title":"Documentation","text":""},{"location":"community/#building-documentation","title":"Building Documentation","text":"<pre><code># Install mkdocs\nuv add --dev mkdocs mkdocs-material\n\n# Serve locally\nuv run mkdocs serve\n\n# Build static site\nuv run mkdocs build\n</code></pre>"},{"location":"community/#documentation-standards","title":"Documentation Standards","text":"<ul> <li>All public APIs must be documented</li> <li>Include code examples</li> <li>Use clear, concise language</li> <li>Cross-reference related docs</li> <li>Keep examples up to date</li> </ul>"},{"location":"community/#project-structure","title":"Project Structure","text":"<pre><code>docling-graph/\n\u251c\u2500\u2500 docling_graph/           # Source code\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 pipeline.py\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u251c\u2500\u2500 protocols.py\n\u2502   \u251c\u2500\u2500 exceptions.py\n\u2502   \u251c\u2500\u2500 core/               # Core modules\n\u2502   \u251c\u2500\u2500 llm_clients/        # LLM integrations\n\u2502   \u251c\u2500\u2500 pipeline/           # Pipeline orchestration\n\u2502   \u2514\u2500\u2500 cli/                # CLI commands\n\u2502\n\u251c\u2500\u2500 tests/                  # Test suite\n\u2502   \u251c\u2500\u2500 unit/              # Unit tests\n\u2502   \u251c\u2500\u2500 integration/       # Integration tests\n\u2502   \u251c\u2500\u2500 fixtures/          # Test fixtures\n\u2502   \u2514\u2500\u2500 mocks/             # Mock objects\n\u2502\n\u251c\u2500\u2500 docs/                   # Documentation\n\u2502   \u251c\u2500\u2500 01-introduction/\n\u2502   \u251c\u2500\u2500 installation/\n\u2502   \u2514\u2500\u2500 ...\n\u2502\n\u251c\u2500\u2500 examples/               # Example code\n\u2502   \u251c\u2500\u2500 scripts/\n\u2502   \u2514\u2500\u2500 templates/\n\u2502\n\u251c\u2500\u2500 .github/               # GitHub configuration\n\u2502\n\u251c\u2500\u2500 pyproject.toml         # Project configuration\n\u251c\u2500\u2500 README.md              # Project README\n\u251c\u2500\u2500 CHANGELOG.md           # Version history\n\u2514\u2500\u2500 LICENSE                # License file\n</code></pre>"},{"location":"community/#common-tasks","title":"Common Tasks","text":""},{"location":"community/#add-new-feature","title":"Add New Feature","text":"<ol> <li>Create issue describing feature</li> <li>Create feature branch</li> <li>Implement feature with tests</li> <li>Update documentation</li> <li>Submit pull request</li> </ol>"},{"location":"community/#fix-bug","title":"Fix Bug","text":"<ol> <li>Create issue describing bug</li> <li>Create fix branch</li> <li>Write failing test</li> <li>Fix bug</li> <li>Verify test passes</li> <li>Submit pull request</li> </ol>"},{"location":"community/#update-documentation","title":"Update Documentation","text":"<ol> <li>Edit markdown files in <code>docs/</code></li> <li>Test locally with <code>mkdocs serve</code></li> <li>Submit pull request</li> </ol>"},{"location":"community/#add-new-llm-client","title":"Add New LLM Client","text":"<ol> <li>Implement <code>LLMClientProtocol</code></li> <li>Add to <code>llm_clients/</code></li> <li>Add tests</li> <li>Update documentation</li> <li>Submit pull request</li> </ol>"},{"location":"community/#getting-help","title":"Getting Help","text":""},{"location":"community/#resources","title":"Resources","text":"<ul> <li>GitHub Issues - Report bugs, request features</li> <li>GitHub Discussions - Ask questions</li> <li>GitHub Repository - Source code and issues</li> </ul>"},{"location":"community/#communication","title":"Communication","text":"<ul> <li>Be respectful and constructive</li> <li>Provide clear, detailed information</li> <li>Include code examples when relevant</li> <li>Follow up on feedback</li> </ul>"},{"location":"community/#next-steps","title":"Next Steps","text":"<ol> <li>GitHub Workflow \u2192 - Understand the workflow</li> <li>Release Process \u2192 - Learn about releases</li> <li>GitHub Workflow \u2192 - Development workflow</li> </ol>"},{"location":"community/github-workflow/","title":"GitHub Workflow","text":""},{"location":"community/github-workflow/#overview","title":"Overview","text":"<p>Guide to working with GitHub for docling-graph development.</p>"},{"location":"community/github-workflow/#branch-strategy","title":"Branch Strategy","text":""},{"location":"community/github-workflow/#main-branches","title":"Main Branches","text":"Branch Purpose Protected <code>main</code> Stable releases \u2705 Yes <code>develop</code> Development integration \u2705 Yes"},{"location":"community/github-workflow/#feature-branches","title":"Feature Branches","text":"<p>Create from <code>develop</code>:</p> <pre><code># Feature\ngit checkout -b feature/add-custom-backend\n\n# Bug fix\ngit checkout -b fix/extraction-error\n\n# Documentation\ngit checkout -b docs/update-api-reference\n</code></pre>"},{"location":"community/github-workflow/#branch-naming","title":"Branch Naming","text":"Type Pattern Example Feature <code>feature/&lt;description&gt;</code> <code>feature/add-vlm-support</code> Bug Fix <code>fix/&lt;description&gt;</code> <code>fix/config-validation</code> Documentation <code>docs/&lt;description&gt;</code> <code>docs/update-examples</code> Refactor <code>refactor/&lt;description&gt;</code> <code>refactor/pipeline-stages</code>"},{"location":"community/github-workflow/#workflow-steps","title":"Workflow Steps","text":""},{"location":"community/github-workflow/#1-create-issue","title":"1. Create Issue","text":"<p>Before starting work:</p> <pre><code>**Title**: Add custom backend support\n\n**Description**:\nAllow users to create custom extraction backends by implementing protocols.\n\n**Acceptance Criteria**:\n- [ ] Protocol defined\n- [ ] Example implementation\n- [ ] Tests added\n- [ ] Documentation updated\n</code></pre>"},{"location":"community/github-workflow/#2-create-branch","title":"2. Create Branch","text":"<pre><code># From develop\ngit checkout develop\ngit pull origin develop\n\n# Create feature branch\ngit checkout -b feature/custom-backends\n</code></pre>"},{"location":"community/github-workflow/#3-develop","title":"3. Develop","text":"<pre><code># Make changes\nvim docling_graph/protocols.py\n\n# Add tests\nvim tests/unit/test_protocols.py\n\n# Test locally\nuv run pytest\nuv run ruff check .\nuv run mypy docling_graph\n</code></pre>"},{"location":"community/github-workflow/#4-commit","title":"4. Commit","text":"<pre><code># Stage changes\ngit add .\n\n# Commit with conventional message\ngit commit -m \"feat(protocols): add custom backend protocol\n\n- Define ExtractionBackendProtocol\n- Add example implementation\n- Include comprehensive tests\"\n</code></pre>"},{"location":"community/github-workflow/#5-push","title":"5. Push","text":"<pre><code># Push to your fork\ngit push origin feature/custom-backends\n</code></pre>"},{"location":"community/github-workflow/#6-create-pull-request","title":"6. Create Pull Request","text":"<p>On GitHub:</p> <ol> <li>Click \"New Pull Request\"</li> <li>Select <code>develop</code> as base branch</li> <li>Fill in PR template</li> <li>Link related issue</li> <li>Request review</li> </ol>"},{"location":"community/github-workflow/#pull-request-template","title":"Pull Request Template","text":"<pre><code>## Description\nBrief description of changes\n\nFixes #123\n\n## Type of Change\n- [ ] Bug fix (non-breaking change fixing an issue)\n- [ ] New feature (non-breaking change adding functionality)\n- [ ] Breaking change (fix or feature causing existing functionality to change)\n- [ ] Documentation update\n\n## How Has This Been Tested?\nDescribe the tests you ran:\n- [ ] Unit tests\n- [ ] Integration tests\n- [ ] Manual testing\n\n## Checklist\n- [ ] My code follows the style guidelines\n- [ ] I have performed a self-review\n- [ ] I have commented my code where needed\n- [ ] I have updated the documentation\n- [ ] My changes generate no new warnings\n- [ ] I have added tests that prove my fix/feature works\n- [ ] New and existing unit tests pass locally\n- [ ] I have updated CHANGELOG.md\n\n## Screenshots (if applicable)\nAdd screenshots to help explain your changes\n</code></pre>"},{"location":"community/github-workflow/#cicd-pipeline","title":"CI/CD Pipeline","text":""},{"location":"community/github-workflow/#automated-checks","title":"Automated Checks","text":"<p>On every push and PR:</p> <pre><code># .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Install uv\n        run: curl -LsSf https://astral.sh/uv/install.sh | sh\n\n      - name: Install dependencies\n        run: uv sync --extra all --extra dev\n\n      - name: Run tests\n        run: uv run pytest --cov --cov-report=xml\n\n      - name: Lint\n        run: uv run ruff check .\n\n      - name: Type check\n        run: uv run mypy docling_graph\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n</code></pre>"},{"location":"community/github-workflow/#status-checks","title":"Status Checks","text":"<p>Required checks before merge:</p> <p>\u2705 Tests pass \u2705 Code coverage \u2265 80% \u2705 Linting passes \u2705 Type checking passes \u2705 Documentation builds</p>"},{"location":"community/github-workflow/#code-review-process","title":"Code Review Process","text":""},{"location":"community/github-workflow/#for-contributors","title":"For Contributors","text":"<p>After submitting PR:</p> <ol> <li>Wait for automated checks</li> <li>Address any failures</li> <li>Respond to reviewer feedback</li> <li>Make requested changes</li> <li>Re-request review</li> </ol> <p>Responding to feedback:</p> <pre><code>&gt; Can you add a test for the error case?\n\nGood point! Added test in commit abc123.\n\n&gt; This could be simplified\n\nRefactored in commit def456. Let me know if this is clearer.\n</code></pre>"},{"location":"community/github-workflow/#for-reviewers","title":"For Reviewers","text":"<p>Review checklist:</p> <ul> <li> Code follows style guide</li> <li> Tests are comprehensive</li> <li> Documentation is updated</li> <li> No breaking changes (or properly documented)</li> <li> Performance considerations addressed</li> <li> Security implications considered</li> </ul> <p>Providing feedback:</p> <pre><code># \u2705 Good feedback\nThe logic here is correct, but could be simplified:\n\n\\`\\`\\`python\n# Instead of:\nif condition:\n    return True\nelse:\n    return False\n\n# Consider:\nreturn condition\n\\`\\`\\`\n\n# \u274c Avoid\nThis is wrong. Fix it.\n</code></pre>"},{"location":"community/github-workflow/#merge-strategy","title":"Merge Strategy","text":""},{"location":"community/github-workflow/#squash-and-merge","title":"Squash and Merge","text":"<p>We use squash merging:</p> <pre><code># Multiple commits:\nfeat: add feature part 1\nfeat: add feature part 2\nfix: typo\ndocs: update\n\n# Become single commit:\nfeat: add custom backend support (#123)\n</code></pre>"},{"location":"community/github-workflow/#merge-requirements","title":"Merge Requirements","text":"<p>Before merging:</p> <p>\u2705 All checks pass \u2705 At least one approval \u2705 No unresolved conversations \u2705 Branch is up to date</p>"},{"location":"community/github-workflow/#issue-management","title":"Issue Management","text":""},{"location":"community/github-workflow/#labels","title":"Labels","text":"Label Purpose <code>bug</code> Something isn't working <code>enhancement</code> New feature or request <code>documentation</code> Documentation improvements <code>good first issue</code> Good for newcomers <code>help wanted</code> Extra attention needed <code>question</code> Further information requested"},{"location":"community/github-workflow/#issue-templates","title":"Issue Templates","text":"<p>Bug Report:</p> <pre><code>**Describe the bug**\nA clear description of the bug.\n\n**To Reproduce**\nSteps to reproduce the behavior.\n\n**Expected behavior**\nWhat you expected to happen.\n\n**Environment**\n- OS: [e.g., Ubuntu 22.04]\n- Python: [e.g., 3.10.12]\n- docling-graph: [e.g., 0.3.0]\n</code></pre> <p>Feature Request:</p> <pre><code>**Is your feature request related to a problem?**\nA clear description of the problem.\n\n**Describe the solution you'd like**\nA clear description of what you want to happen.\n\n**Describe alternatives you've considered**\nAlternative solutions or features you've considered.\n</code></pre>"},{"location":"community/github-workflow/#release-workflow","title":"Release Workflow","text":""},{"location":"community/github-workflow/#version-bumping","title":"Version Bumping","text":"<pre><code># Update version in pyproject.toml\n# Update CHANGELOG.md\n# Commit changes\ngit commit -m \"chore: bump version to 0.4.0\"\n\n# Tag release\ngit tag -a v0.4.0 -m \"Release v0.4.0\"\n\n# Push\ngit push origin main --tags\n</code></pre>"},{"location":"community/github-workflow/#automated-release","title":"Automated Release","text":"<p>GitHub Actions automatically:</p> <ol> <li>Runs tests</li> <li>Builds package</li> <li>Publishes to PyPI</li> <li>Creates GitHub release</li> <li>Updates documentation</li> </ol>"},{"location":"community/github-workflow/#best-practices","title":"Best Practices","text":""},{"location":"community/github-workflow/#commit-messages","title":"Commit Messages","text":"<pre><code># \u2705 Good\nfeat(extractors): add support for custom chunking\n\nAllows users to provide custom chunking strategies\nvia the ChunkerProtocol interface.\n\nCloses #123\n\n# \u274c Avoid\nupdate code\nfix stuff\nwip\n</code></pre>"},{"location":"community/github-workflow/#pr-size","title":"PR Size","text":"<ul> <li>Keep PRs focused and small</li> <li>One feature/fix per PR</li> <li>Split large changes into multiple PRs</li> </ul>"},{"location":"community/github-workflow/#communication","title":"Communication","text":"<ul> <li>Be responsive to feedback</li> <li>Ask questions if unclear</li> <li>Update PR description if scope changes</li> <li>Close stale PRs</li> </ul>"},{"location":"community/github-workflow/#troubleshooting","title":"Troubleshooting","text":""},{"location":"community/github-workflow/#ci-failures","title":"CI Failures","text":"<p>Tests fail:</p> <pre><code># Run tests locally\nuv run pytest -v\n\n# Check specific failure\nuv run pytest tests/unit/test_config.py::test_validation -v\n</code></pre> <p>Linting fails:</p> <pre><code># Check issues\nuv run ruff check .\n\n# Auto-fix\nuv run ruff check --fix .\n</code></pre> <p>Type checking fails:</p> <pre><code># Check types\nuv run mypy docling_graph\n\n# Check specific file\nuv run mypy docling_graph/config.py\n</code></pre>"},{"location":"community/github-workflow/#merge-conflicts","title":"Merge Conflicts","text":"<pre><code># Update your branch\ngit checkout feature/my-feature\ngit fetch origin\ngit rebase origin/develop\n\n# Resolve conflicts\n# Edit conflicted files\ngit add .\ngit rebase --continue\n\n# Force push\ngit push origin feature/my-feature --force\n</code></pre>"},{"location":"community/github-workflow/#next-steps","title":"Next Steps","text":"<ol> <li>Release Process \u2192 - Learn about releases</li> <li>Development Guide - Back to overview</li> <li>Testing Guide - Testing practices</li> </ol>"},{"location":"community/release-process/","title":"Release Process","text":""},{"location":"community/release-process/#overview","title":"Overview","text":"<p>Guide to the docling-graph release process.</p>"},{"location":"community/release-process/#version-numbering","title":"Version Numbering","text":"<p>We follow Semantic Versioning:</p> <pre><code>MAJOR.MINOR.PATCH\n\nExample: 1.0.0\n</code></pre>"},{"location":"community/release-process/#version-components","title":"Version Components","text":"Component When to Increment MAJOR Breaking changes (manual only) MINOR New features (backward compatible) PATCH Bug fixes (backward compatible)"},{"location":"community/release-process/#examples","title":"Examples","text":"<pre><code>1.0.0 \u2192 1.0.1  # Bug fix\n1.0.1 \u2192 1.1.0  # New feature\n1.1.0 \u2192 2.0.0  # Breaking change (manual tag required)\n</code></pre>"},{"location":"community/release-process/#automated-vs-manual-releases","title":"Automated vs Manual Releases","text":""},{"location":"community/release-process/#automated-releases-semantic-release","title":"Automated Releases (Semantic Release)","text":"<p>Our CI/CD automatically handles routine releases:</p> Commit Type Version Bump Example <code>fix:</code> Patch (1.0.0 \u2192 1.0.1) <code>fix: handle null values</code> <code>feat:</code> Minor (1.0.0 \u2192 1.1.0) <code>feat: add CSV export</code> <code>refactor:</code> Minor (1.0.0 \u2192 1.1.0) <code>refactor: improve parser</code> <code>perf:</code> Patch (1.0.0 \u2192 1.0.1) <code>perf: optimize graph build</code> <code>BREAKING CHANGE:</code> Minor (1.0.0 \u2192 1.1.0) Capped at minor, not major <p>Note: BREAKING CHANGE commits will trigger minor releases, not major. This allows you to accumulate breaking changes and release them together as a planned major version.</p>"},{"location":"community/release-process/#manual-releases-git-tags","title":"Manual Releases (Git Tags)","text":"<p>Major version bumps require manual Git tags:</p> <ul> <li>Major releases (1.x.x \u2192 2.0.0): Manual Git tags only</li> <li>Requires deliberate decision and planning</li> <li>Includes migration guides and announcements</li> <li>Prevents accidental major bumps from commit messages</li> </ul>"},{"location":"community/release-process/#why-manual-major-releases","title":"Why Manual Major Releases?","text":"<p>Following industry best practices:</p> <ol> <li>Strategic Milestones: Major versions signal significant changes requiring coordination</li> <li>Communication: Need time for announcements, migration guides, and user preparation</li> <li>Prevent Accidents: Developers can't accidentally trigger major bumps with commit messages</li> <li>Stability Perception: Controlled major releases signal project maturity</li> <li>Accumulate Changes: Collect multiple breaking changes for a single coordinated release</li> </ol>"},{"location":"community/release-process/#release-types","title":"Release Types","text":""},{"location":"community/release-process/#patch-release-030-031","title":"Patch Release (0.3.0 \u2192 0.3.1)","text":"<p>When: - Bug fixes - Documentation updates - Performance improvements (no API changes)</p> <p>Example: <pre><code># Fix extraction error\ngit commit -m \"fix(extractors): handle empty markdown\"\n\n# Release\ngit tag v0.3.1\n</code></pre></p>"},{"location":"community/release-process/#minor-release-030-040","title":"Minor Release (0.3.0 \u2192 0.4.0)","text":"<p>When: - New features - New backends/exporters - Deprecations (with warnings)</p> <p>Example: <pre><code># Add new feature\ngit commit -m \"feat(exporters): add GraphML exporter\"\n\n# Release\ngit tag v0.4.0\n</code></pre></p>"},{"location":"community/release-process/#major-release-1xx-200-manual-only","title":"Major Release (1.x.x \u2192 2.0.0) - Manual Only","text":"<p>When: - Breaking API changes - Removed deprecated features - Major architectural refactoring - Multiple accumulated breaking changes</p> <p>Important: Major releases require manual Git tags and cannot be triggered by commits.</p> <p>Process:</p> <ol> <li>Prepare breaking changes on a release branch</li> <li>Update version manually in <code>pyproject.toml</code> and <code>__init__.py</code></li> <li>Create comprehensive CHANGELOG with migration guide</li> <li>Merge to main via PR</li> <li>Create and push Git tag:</li> </ol> <pre><code>git checkout main\ngit pull origin main\n\n# Create annotated tag with detailed message\ngit tag -a v2.0.0 -m \"Major release v2.0.0\n\nBreaking changes:\n- Changed run_pipeline signature to require PipelineConfig\n- Removed deprecated old_function() (use new_function instead)\n- Refactored graph converter API\n\nSee CHANGELOG.md for full details and migration guide.\"\n\n# Push tag to trigger release workflow\ngit push origin v2.0.0\n</code></pre> <p>Note: Even if you use <code>BREAKING CHANGE:</code> in commits, semantic-release will only bump to the next minor version. Major bumps require manual tags.</p>"},{"location":"community/release-process/#creating-a-major-release-detailed-guide","title":"Creating a Major Release (Detailed Guide)","text":"<p>Major releases are strategic milestones that require careful planning and execution. Follow this comprehensive guide:</p>"},{"location":"community/release-process/#prerequisites","title":"Prerequisites","text":"<p>Before starting a major release:</p> <ul> <li> All breaking changes are documented</li> <li> Migration guide is prepared</li> <li> Deprecation warnings were in place in previous versions</li> <li> Team consensus on timing and scope</li> <li> Communication plan is ready (announcements, blog posts, etc.)</li> <li> All tests pass with breaking changes</li> <li> Documentation is updated for new APIs</li> </ul>"},{"location":"community/release-process/#step-by-step-process","title":"Step-by-Step Process","text":""},{"location":"community/release-process/#1-create-release-branch","title":"1. Create Release Branch","text":"<pre><code># Start from main\ngit checkout main\ngit pull origin main\n\n# Create release branch\ngit checkout -b release/2.0.0\n</code></pre>"},{"location":"community/release-process/#2-implement-breaking-changes","title":"2. Implement Breaking Changes","text":"<p>Make all necessary breaking changes on this branch:</p> <pre><code># Make changes\nvim docling_graph/pipeline.py\n\n# Commit with clear messages\ngit commit -m \"feat!: change run_pipeline signature\n\nBREAKING CHANGE: run_pipeline now requires PipelineConfig object\ninstead of individual parameters. This provides better type safety\nand makes the API more maintainable.\n\nMigration:\n  Before: run_pipeline(source, template, backend='llm')\n  After:  config = PipelineConfig(source=source, template=template)\n          run_pipeline(config)\"\n</code></pre>"},{"location":"community/release-process/#3-update-version-numbers-manually","title":"3. Update Version Numbers Manually","text":"<p>pyproject.toml: <pre><code>[project]\nname = \"docling-graph\"\nversion = \"2.0.0\"  # Update to new major version\n</code></pre></p> <p>docling_graph/init.py: <pre><code>__version__ = \"2.0.0\"  # Update to new major version\n</code></pre></p>"},{"location":"community/release-process/#4-create-comprehensive-changelog","title":"4. Create Comprehensive CHANGELOG","text":"<p>CHANGELOG.md: <pre><code># Changelog\n\n## [2.0.0] - 2024-XX-XX\n\n### BREAKING CHANGES\n\n#### Changed run_pipeline API\n\n**Before:**\n\\`\\`\\`python\nfrom docling_graph import run_pipeline\n\nresult = run_pipeline(\n    source=\"document.pdf\",\n    template=MyTemplate,\n    backend=\"llm\"\n)\n\\`\\`\\`\n\n**After:**\n\\`\\`\\`python\nfrom docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=MyTemplate,\n    backend=\"llm\"\n)\nresult = run_pipeline(config)\n\\`\\`\\`\n\n**Migration:** Update all `run_pipeline` calls to use `PipelineConfig`.\n\n#### Removed deprecated functions\n\n- Removed `old_function()` (deprecated in v1.5.0)\n  - **Migration:** Use `new_function()` instead\n\n### Added\n- New graph validation features\n- Enhanced error messages\n\n### Fixed\n- Various bug fixes\n</code></pre></p>"},{"location":"community/release-process/#5-update-documentation","title":"5. Update Documentation","text":"<p>Update all documentation to reflect breaking changes:</p> <pre><code># Update examples\nvim docs/introduction/quickstart.md\n\n# Update API documentation\nvim docs/api/run-pipeline.md\n\n# Create migration guide\nvim docs/12-development/migration-v2.md\n</code></pre>"},{"location":"community/release-process/#6-commit-version-updates","title":"6. Commit Version Updates","text":"<pre><code>git add pyproject.toml docling_graph/__init__.py CHANGELOG.md docs/\ngit commit -m \"chore: prepare version 2.0.0 release\"\n</code></pre>"},{"location":"community/release-process/#7-final-testing","title":"7. Final Testing","text":"<pre><code># Run full test suite\nuv run pytest\n\n# Check code quality\nuv run ruff check .\nuv run mypy docling_graph\n\n# Build and test package\nuv build\nuv run pip install dist/docling_graph-2.0.0-*.whl\n</code></pre>"},{"location":"community/release-process/#8-create-pull-request","title":"8. Create Pull Request","text":"<pre><code># Push release branch\ngit push origin release/2.0.0\n\n# Create PR to main\n# Title: \"Release v2.0.0\"\n# Description: Include summary of breaking changes\n# Get team approval\n</code></pre>"},{"location":"community/release-process/#9-merge-to-main","title":"9. Merge to Main","text":"<p>After PR approval: <pre><code># Merge PR (via GitHub UI or command line)\n# DO NOT create a tag yet - this is done manually next\n</code></pre></p>"},{"location":"community/release-process/#10-create-and-push-git-tag","title":"10. Create and Push Git Tag","text":"<p>This is the critical step that triggers the major release:</p> <pre><code># Checkout and update main\ngit checkout main\ngit pull origin main\n\n# Create annotated tag with comprehensive message\ngit tag -a v2.0.0 -m \"Major release v2.0.0\n\nBreaking changes:\n- Changed run_pipeline API to use PipelineConfig\n- Removed old_function() (use new_function instead)\n- Refactored graph converter for better performance\n\nNew features:\n- Enhanced graph validation\n- Improved error messages\n\nSee CHANGELOG.md for complete details and migration guide.\nSee docs/12-development/migration-v2.md for migration instructions.\"\n\n# Push tag to trigger release workflow\ngit push origin v2.0.0\n</code></pre>"},{"location":"community/release-process/#11-monitor-release","title":"11. Monitor Release","text":"<p>Watch the GitHub Actions workflow: - Build completes successfully - Tests pass - Package published to PyPI - GitHub release created</p>"},{"location":"community/release-process/#12-post-release-tasks","title":"12. Post-Release Tasks","text":"<pre><code># Verify PyPI release\npip install docling-graph==2.0.0\n\n# Update documentation site\n# Publish announcement\n# Monitor for issues\n</code></pre>"},{"location":"community/release-process/#communication-checklist","title":"Communication Checklist","text":"<ul> <li> GitHub release notes published</li> <li> Migration guide available</li> <li> Announcement in GitHub Discussions</li> <li> Update README badges if needed</li> <li> Social media announcement (if applicable)</li> <li> Email to major users (if applicable)</li> </ul>"},{"location":"community/release-process/#rollback-plan","title":"Rollback Plan","text":"<p>If critical issues are discovered:</p> <ol> <li>Quick fix: Release v2.0.1 hotfix</li> <li>Major issues: Yank v2.0.0 from PyPI, recommend v1.x.x</li> </ol>"},{"location":"community/release-process/#release-checklist","title":"Release Checklist","text":""},{"location":"community/release-process/#pre-release","title":"Pre-Release","text":"<ul> <li> All tests pass</li> <li> Documentation is updated</li> <li> CHANGELOG.md is updated</li> <li> Version bumped in <code>pyproject.toml</code></li> <li> No open critical bugs</li> <li> Breaking changes documented</li> </ul>"},{"location":"community/release-process/#release","title":"Release","text":"<ul> <li> Create release branch</li> <li> Final testing</li> <li> Tag release</li> <li> Push to GitHub</li> <li> Automated build and publish</li> <li> Verify PyPI upload</li> </ul>"},{"location":"community/release-process/#post-release","title":"Post-Release","text":"<ul> <li> Create GitHub release notes</li> <li> Announce release</li> <li> Update documentation site</li> <li> Close milestone</li> <li> Merge back to develop</li> </ul>"},{"location":"community/release-process/#step-by-step-process_1","title":"Step-by-Step Process","text":""},{"location":"community/release-process/#1-prepare-release","title":"1. Prepare Release","text":"<pre><code># Checkout develop\ngit checkout develop\ngit pull origin develop\n\n# Create release branch\ngit checkout -b release/0.4.0\n</code></pre>"},{"location":"community/release-process/#2-update-version","title":"2. Update Version","text":"<p>pyproject.toml:</p> <pre><code>[project]\nname = \"docling-graph\"\nversion = \"0.4.0\"  # Update version\n</code></pre> <p>docling_graph/__init__.py:</p> <pre><code>__version__ = \"0.4.0\"  # Update version\n</code></pre>"},{"location":"community/release-process/#3-update-changelog","title":"3. Update CHANGELOG","text":"<p>CHANGELOG.md:</p> <pre><code># Changelog\n\n## [0.4.0] - 2024-01-22\n\n### Added\n- GraphML exporter for graph visualization tools\n- Support for custom chunking strategies\n- New examples for insurance policy extraction\n\n### Changed\n- Improved error messages in extraction pipeline\n- Updated documentation structure\n\n### Fixed\n- Fixed VLM backend memory leak\n- Corrected date parsing in templates\n\n### Deprecated\n- Old configuration format (use PipelineConfig)\n\n## [0.3.0] - 2024-01-15\n...\n</code></pre>"},{"location":"community/release-process/#4-commit-changes","title":"4. Commit Changes","text":"<pre><code>git add pyproject.toml docling_graph/__init__.py CHANGELOG.md\ngit commit -m \"chore: bump version to 0.4.0\"\n</code></pre>"},{"location":"community/release-process/#5-final-testing","title":"5. Final Testing","text":"<pre><code># Run full test suite\nuv run pytest\n\n# Check code quality\nuv run ruff check .\nuv run mypy docling_graph\n\n# Build documentation\nuv run mkdocs build\n\n# Test package build\nuv build\n</code></pre>"},{"location":"community/release-process/#6-merge-to-main","title":"6. Merge to Main","text":"<pre><code># Push release branch\ngit push origin release/0.4.0\n\n# Create PR to main\n# Get approval\n# Merge PR\n</code></pre>"},{"location":"community/release-process/#7-tag-release","title":"7. Tag Release","text":"<pre><code># Checkout main\ngit checkout main\ngit pull origin main\n\n# Create tag\ngit tag -a v0.4.0 -m \"Release v0.4.0\n\n- Add GraphML exporter\n- Support custom chunking\n- Improve error messages\n- Fix VLM memory leak\"\n\n# Push tag\ngit push origin v0.4.0\n</code></pre>"},{"location":"community/release-process/#8-automated-build","title":"8. Automated Build","text":"<p>GitHub Actions automatically:</p> <pre><code># .github/workflows/release.yml\nname: Release\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Install uv\n        run: curl -LsSf https://astral.sh/uv/install.sh | sh\n\n      - name: Build package\n        run: uv build\n\n      - name: Publish to PyPI\n        run: uv publish\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_TOKEN }}\n\n      - name: Create GitHub Release\n        uses: actions/create-release@v1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          body_path: CHANGELOG.md\n</code></pre>"},{"location":"community/release-process/#9-verify-release","title":"9. Verify Release","text":"<pre><code># Check PyPI\npip install docling-graph==0.4.0\n\n# Verify version\npython -c \"import docling_graph; print(docling_graph.__version__)\"\n</code></pre>"},{"location":"community/release-process/#10-create-release-notes","title":"10. Create Release Notes","text":"<p>On GitHub:</p> <ol> <li>Go to Releases</li> <li>Click \"Draft a new release\"</li> <li>Select tag v0.4.0</li> <li>Title: \"Release 0.4.0\"</li> <li>Description from CHANGELOG</li> <li>Publish release</li> </ol>"},{"location":"community/release-process/#11-announce-release","title":"11. Announce Release","text":"<ul> <li>GitHub Discussions</li> <li>Project README</li> <li>Social media (if applicable)</li> </ul>"},{"location":"community/release-process/#12-merge-back","title":"12. Merge Back","text":"<pre><code># Merge main back to develop\ngit checkout develop\ngit merge main\ngit push origin develop\n</code></pre>"},{"location":"community/release-process/#changelog-format","title":"CHANGELOG Format","text":"<p>Follow Keep a Changelog:</p> <pre><code># Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/),\nand this project adheres to [Semantic Versioning](https://semver.org/).\n\n## [Unreleased]\n\n### Added\n- New features in development\n\n### Changed\n- Changes to existing features\n\n### Deprecated\n- Features to be removed\n\n### Removed\n- Removed features\n\n### Fixed\n- Bug fixes\n\n### Security\n- Security fixes\n\n## [0.4.0] - 2024-01-22\n\n### Added\n- GraphML exporter (#123)\n- Custom chunking support (#124)\n\n### Fixed\n- VLM memory leak (#125)\n\n## [0.3.0] - 2024-01-15\n...\n</code></pre>"},{"location":"community/release-process/#breaking-changes","title":"Breaking Changes","text":""},{"location":"community/release-process/#documentation","title":"Documentation","text":"<p>Document breaking changes clearly:</p> <pre><code>## [1.0.0] - 2024-02-01\n\n### BREAKING CHANGES\n\n#### run_pipeline signature changed\n\n**Before:**\n\\`\\`\\`python\nrun_pipeline(source, template, backend=\"llm\")\n\\`\\`\\`\n\n**After:**\n\\`\\`\\`python\nconfig = PipelineConfig(source=source, template=template)\nrun_pipeline(config)\n\\`\\`\\`\n\n**Migration:**\nUpdate all calls to use PipelineConfig.\n\n#### Removed deprecated features\n\n- Removed `old_function()` (deprecated in 0.8.0)\n- Use `new_function()` instead\n</code></pre>"},{"location":"community/release-process/#deprecation-period","title":"Deprecation Period","text":"<ol> <li>Version N: Add deprecation warning</li> <li>Version N+1: Keep with warning</li> <li>Version N+2: Remove feature</li> </ol> <p>Example:</p> <pre><code># Version 0.8.0 - Add warning\ndef old_function():\n    warnings.warn(\n        \"old_function is deprecated, use new_function\",\n        DeprecationWarning,\n        stacklevel=2\n    )\n    return new_function()\n\n# Version 0.9.0 - Keep warning\n\n# Version 1.0.0 - Remove\n# old_function() removed\n</code></pre>"},{"location":"community/release-process/#hotfix-process","title":"Hotfix Process","text":"<p>For critical bugs in production:</p>"},{"location":"community/release-process/#1-create-hotfix-branch","title":"1. Create Hotfix Branch","text":"<pre><code># From main\ngit checkout main\ngit checkout -b hotfix/0.3.1\n</code></pre>"},{"location":"community/release-process/#2-fix-bug","title":"2. Fix Bug","text":"<pre><code># Fix the bug\nvim docling_graph/module.py\n\n# Add test\nvim tests/unit/test_module.py\n\n# Commit\ngit commit -m \"fix: critical extraction bug\"\n</code></pre>"},{"location":"community/release-process/#3-update-version","title":"3. Update Version","text":"<pre><code># Bump patch version\n# Update CHANGELOG\n\ngit commit -m \"chore: bump version to 0.3.1\"\n</code></pre>"},{"location":"community/release-process/#4-release","title":"4. Release","text":"<pre><code># Merge to main\ngit checkout main\ngit merge hotfix/0.3.1\n\n# Tag\ngit tag v0.3.1\n\n# Push\ngit push origin main --tags\n\n# Merge back to develop\ngit checkout develop\ngit merge hotfix/0.3.1\ngit push origin develop\n</code></pre>"},{"location":"community/release-process/#release-schedule","title":"Release Schedule","text":""},{"location":"community/release-process/#regular-releases","title":"Regular Releases","text":"<ul> <li>Minor releases: Monthly (if features ready)</li> <li>Patch releases: As needed (bug fixes)</li> <li>Major releases: When breaking changes accumulated</li> </ul>"},{"location":"community/release-process/#release-windows","title":"Release Windows","text":"<ul> <li>Avoid releases on Fridays</li> <li>Avoid holiday periods</li> <li>Allow time for testing</li> </ul>"},{"location":"community/release-process/#rollback-procedure","title":"Rollback Procedure","text":"<p>If a release has critical issues:</p>"},{"location":"community/release-process/#1-identify-issue","title":"1. Identify Issue","text":"<pre><code># Check reports\n# Verify bug\n# Assess severity\n</code></pre>"},{"location":"community/release-process/#2-quick-fix-or-rollback","title":"2. Quick Fix or Rollback","text":"<p>Option A: Quick hotfix</p> <pre><code># If fix is simple\ngit checkout -b hotfix/0.4.1\n# Fix bug\n# Release 0.4.1\n</code></pre> <p>Option B: Rollback</p> <pre><code># If fix is complex\n# Yank from PyPI (if possible)\n# Announce rollback\n# Recommend previous version\n</code></pre>"},{"location":"community/release-process/#3-communicate","title":"3. Communicate","text":"<ul> <li>Update GitHub release</li> <li>Post in Discussions</li> <li>Update documentation</li> </ul>"},{"location":"community/release-process/#post-release-tasks","title":"Post-Release Tasks","text":""},{"location":"community/release-process/#documentation_1","title":"Documentation","text":"<ul> <li> Update docs site</li> <li> Update examples</li> <li> Update tutorials</li> </ul>"},{"location":"community/release-process/#communication","title":"Communication","text":"<ul> <li> Announce on GitHub</li> <li> Update README badges</li> <li> Social media posts</li> </ul>"},{"location":"community/release-process/#monitoring","title":"Monitoring","text":"<ul> <li> Watch for issues</li> <li> Monitor PyPI downloads</li> <li> Check user feedback</li> </ul>"},{"location":"community/release-process/#tools","title":"Tools","text":""},{"location":"community/release-process/#version-management","title":"Version Management","text":"<pre><code># Check current version\ngrep version pyproject.toml\n\n# Update version\nsed -i 's/version = \"0.3.0\"/version = \"0.4.0\"/' pyproject.toml\n</code></pre>"},{"location":"community/release-process/#build-and-publish","title":"Build and Publish","text":"<pre><code># Build package\nuv build\n\n# Check package\nuv run twine check dist/*\n\n# Publish to TestPyPI (testing)\nuv publish --repository testpypi\n\n# Publish to PyPI (production)\nuv publish\n</code></pre>"},{"location":"community/release-process/#next-steps","title":"Next Steps","text":"<ol> <li>Development Guide - Back to overview</li> <li>GitHub Workflow - Development workflow</li> <li>Testing Guide - Testing practices</li> </ol>"},{"location":"examples/","title":"Docling Graph Examples","text":"<p>Welcome to the <code>docling-graph</code> examples. This directory contains all the resources you need to get started.</p>"},{"location":"examples/#project-structure","title":"Project Structure","text":"<ul> <li><code>/examples/scripts/</code>: Python script examples and the CLI recipes.</li> <li><code>/examples/data/</code>: Sample PDF and image files used by the scripts.</li> <li><code>/examples/templates/</code>: The Pydantic schemas (e.g., <code>invoice.py</code>) that define what data to extract.</li> </ul>"},{"location":"examples/#10-core-recipes","title":"10 Core Recipes","text":"<p>All Python scripts are located in the <code>/examples/scripts/</code> folder and are designed to be run from the project's root directory.</p> <ol> <li><code>01_vlm_from_image.py</code>: The \"Hello World.\" Extracts from a single image using the VLM.</li> <li><code>02_vlm_from_pdf_page.py</code>: Shows the VLM backend on a single-page PDF.</li> <li><code>03_llm_remote_api.py</code>: Standard LLM workflow using a remote API (Mistral) on a multi-page PDF.</li> <li><code>04_llm_local_ollama.py</code>: Uses a local LLM (Ollama) on the same PDF.</li> <li><code>05_llm_with_consolidation.py</code>: Advanced merging strategy using an LLM to consolidate results.</li> <li><code>06_llm_one_to_one.py</code>: Processes each page individually (<code>one-to-one</code>) and combines them into one graph.</li> <li><code>07_llm_no_chunking.py</code>: Processes a short document in a single pass (disables chunking).</li> <li><code>08_llm_with_vision_config.py</code>: Hybrid mode: uses the <code>vision</code> config for layout-aware chunks for the LLM.</li> <li><code>09_export_to_cypher.py</code>: Shows how to change the output format to a Cypher script for Neo4j.</li> <li><code>10_cli_recipes.md</code>: A markdown file showing the CLI (command-line) equivalents for all the examples above.</li> </ol>"},{"location":"examples/scripts/10_cli_recipes/","title":"Example 10: CLI Recipes","text":"<p>These recipes show how to run the <code>docling-graph convert</code> command from your project's root directory.</p> <p>All paths (<code>--template</code>, source file, <code>--output-dir</code>) are relative to the root.</p>"},{"location":"examples/scripts/10_cli_recipes/#recipe-1-vlm-from-image","title":"Recipe 1: VLM from Image","text":"<p>(Python: <code>01_vlm_from_image.py</code>)</p> <pre><code>uv run docling-graph convert \"docs/examples/data/invoice/sample_invoice.jpg\" \\\n    --template \"docs.examples.templates.invoice.Invoice\" \\\n    --output-dir \"outputs/cli_01\" \\\n    --backend \"vlm\" \\\n    --processing-mode \"one-to-one\" \\\n    --docling-pipeline \"vision\"\n````\n\n-----\n\n### Recipe 3: Remote LLM (Mistral)\n\n(Python: `03_llm_remote_api.py`)\n\n*(Requires `MISTRAL_API_KEY` env var)*\n\n```bash\nuv run docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.Research\" \\\n    --output-dir \"outputs/cli_03\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"mistral\" \\\n    --model \"mistral-large-latest\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking \\\n    --no-llm-consolidation\n</code></pre>"},{"location":"examples/scripts/10_cli_recipes/#recipe-4-local-llm-ollama","title":"Recipe 4: Local LLM (Ollama)","text":"<p>(Python: <code>04_llm_local_ollama.py</code>)</p> <p>(Requires Ollama server to be running)</p> <pre><code>uv run docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.Research\" \\\n    --output-dir \"outputs/cli_04\" \\\n    --backend \"llm\" \\\n    --inference \"local\" \\\n    --provider \"ollama\" \\\n    --model \"llama3:8b\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking \\\n    --no-llm-consolidation\n</code></pre>"},{"location":"examples/scripts/10_cli_recipes/#recipe-5-llm-with-consolidation","title":"Recipe 5: LLM with Consolidation","text":"<p>(Python: <code>05_llm_with_consolidation.py</code>)</p> <pre><code>uv run docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.Research\" \\\n    --output-dir \"outputs/cli_05\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"mistral\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking \\\n    --llm-consolidation\n</code></pre>"},{"location":"examples/scripts/10_cli_recipes/#recipe-8-llm-with-vision-config-hybrid","title":"Recipe 8: LLM with 'vision' Config (Hybrid)","text":"<p>(Python: <code>08_llm_with_vision_config.py</code>)</p> <pre><code>uv run docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.Research\" \\\n    --output-dir \"outputs/cli_08\" \\\n    --backend \"llm\" \\\n    --inference \"local\" \\\n    --provider \"ollama\" \\\n    --model \"llama3:8b\" \\\n    --docling-pipeline \"vision\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking\n</code></pre>"},{"location":"examples/scripts/10_cli_recipes/#recipe-9-export-to-cypher","title":"Recipe 9: Export to Cypher","text":"<p>(Python: <code>09_export_to_cypher.py</code>)</p> <pre><code>uv run docling-graph convert \"docs/examples/data/invoice/sample_invoice.jpg\" \\\n    --template \"docs.examples.templates.invoice.Invoice\" \\\n    --output-dir \"outputs/cli_09\" \\\n    --backend \"vlm\" \\\n    --docling-pipeline \"vision\" \\\n    --export-format \"cypher\"\n</code></pre>"},{"location":"fundamentals/","title":"Fundamentals","text":"<p>Welcome to the Fundamentals section! This section covers the core concepts and essential setup needed to work with Docling Graph.</p>"},{"location":"fundamentals/#what-youll-learn","title":"What You'll Learn","text":"<p>This section guides you through the foundational knowledge required to effectively use Docling Graph:</p> <ol> <li>Installation - Set up your environment with dependencies and GPU support</li> <li>Schema Definition - Create Pydantic templates that define extraction schemas and graph structures</li> <li>Pipeline Configuration - Configure backends, models, and processing modes</li> <li>Extraction Process - Convert documents and extract structured data</li> <li>Graph Management - Export and visualize knowledge graphs</li> </ol>"},{"location":"fundamentals/#quick-links","title":"Quick Links","text":"<ul> <li> <p>Installation \u2192</p> <p>Set up your environment with uv package manager and configure GPU support</p> </li> <li> <p>Schema Definition \u2192</p> <p>Learn how to create Pydantic templates for extraction</p> </li> <li> <p>Pipeline Configuration \u2192</p> <p>Configure backends, models, and processing options</p> </li> <li> <p>Extraction Process \u2192</p> <p>Understand document conversion and extraction workflows</p> </li> <li> <p>Graph Management \u2192</p> <p>Export graphs and create visualizations</p> </li> </ul>"},{"location":"fundamentals/#learning-path","title":"Learning Path","text":"<p>We recommend following this order:</p> <ol> <li>Start with Installation to set up your environment</li> <li>Learn Schema Definition to understand how templates work</li> <li>Configure Your Pipeline to select backends and models</li> <li>Run Extractions to process documents</li> <li>Manage Graphs to export and visualize results</li> </ol>"},{"location":"fundamentals/#next-steps","title":"Next Steps","text":"<p>Ready to begin? Start with the Installation Guide to set up your environment.</p>"},{"location":"fundamentals/extraction-process/","title":"The Extraction Process","text":""},{"location":"fundamentals/extraction-process/#overview","title":"Overview","text":"<p>The Extraction Process is the core of Docling Graph, transforming raw documents into structured knowledge graphs through a multi-stage pipeline. This section explains each stage in detail.</p> <p>What you'll learn: - How documents are converted to structured format - Intelligent chunking strategies - Extraction backends (LLM vs VLM) - Model merging and consolidation - Pipeline orchestration</p>"},{"location":"fundamentals/extraction-process/#the-four-stage-pipeline","title":"The Four-Stage Pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Input Source\" }\n\n    A1@{ shape: tag-proc, label: \"Input Normalization\" }\n    B@{ shape: procs, label: \"Conversion\" }\n    C@{ shape: tag-proc, label: \"Chunking\" }\n    D@{ shape: procs, label: \"Extraction\" }\n    E@{ shape: lin-proc, label: \"Merging\" }\n\n    F@{ shape: db, label: \"Knowledge Graph\" }\n\n    %% 3. Define Connections\n    A --&gt; A1\n    A1 --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class A1,C operator\n    class B,D,E process\n    class F output</code></pre>"},{"location":"fundamentals/extraction-process/#stage-1-document-conversion","title":"Stage 1: Document Conversion","text":"<p>Purpose: Convert PDF/images to structured Docling format</p> <p>Process: - OCR or Vision pipeline - Layout analysis - Table extraction - Text extraction</p> <p>Output: DoclingDocument with structure</p> <p>Learn more: Document Conversion \u2192</p>"},{"location":"fundamentals/extraction-process/#stage-2-chunking","title":"Stage 2: Chunking","text":"<p>Purpose: Split document into optimal chunks for LLM processing</p> <p>Process: - Structure-aware splitting - Token counting - Semantic boundaries - Context preservation</p> <p>Output: List of contextualized chunks</p> <p>Learn more: Chunking Strategies \u2192</p>"},{"location":"fundamentals/extraction-process/#stage-3-extraction","title":"Stage 3: Extraction","text":"<p>Purpose: Extract structured data using LLM/VLM</p> <p>Process: - Backend selection (LLM/VLM) - Batch processing - Schema validation - Error handling</p> <p>Output: List of Pydantic models</p> <p>Learn more: Extraction Backends \u2192</p>"},{"location":"fundamentals/extraction-process/#stage-4-merging","title":"Stage 4: Merging","text":"<p>Purpose: Consolidate multiple extractions into single model</p> <p>Process: - Programmatic merging - LLM consolidation (optional) - Conflict resolution - Validation</p> <p>Output: Single consolidated model</p> <p>Learn more: Model Merging \u2192</p>"},{"location":"fundamentals/extraction-process/#processing-modes","title":"Processing Modes","text":""},{"location":"fundamentals/extraction-process/#many-to-one-default","title":"Many-to-One (Default)","text":"<p>Best for: Most documents</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"many-to-one\"  # Default\n)\n</code></pre> <p>Process: 1. Convert entire document 2. Chunk intelligently 3. Extract from each chunk 4. Merge into single model</p> <p>Output: 1 consolidated model</p>"},{"location":"fundamentals/extraction-process/#one-to-one","title":"One-to-One","text":"<p>Best for: Multi-page forms, page-specific data</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"one-to-one\"\n)\n</code></pre> <p>Process: 1. Convert entire document 2. Extract from each page 3. Return separate models</p> <p>Output: N models (one per page)</p>"},{"location":"fundamentals/extraction-process/#backend-comparison","title":"Backend Comparison","text":"Feature LLM Backend VLM Backend Input Markdown text Images/PDFs Accuracy High for text High for visuals Speed Fast Slower Cost Low (local) Medium Best For Text documents Complex layouts"},{"location":"fundamentals/extraction-process/#pipeline-stages-in-code","title":"Pipeline Stages in Code","text":""},{"location":"fundamentals/extraction-process/#stage-overview","title":"Stage Overview","text":"<pre><code>from docling_graph.pipeline.stages import (\n    TemplateLoadingStage,    # Load Pydantic template\n    ExtractionStage,         # Extract data\n    DoclingExportStage,      # Export Docling outputs\n    GraphConversionStage,    # Convert to graph\n    ExportStage,             # Export graph\n    VisualizationStage       # Generate visualizations\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/#orchestration","title":"Orchestration","text":"<pre><code>from docling_graph.pipeline.orchestrator import PipelineOrchestrator\n\norchestrator = PipelineOrchestrator(config)\ncontext = orchestrator.run()\n\n# Access results\nprint(f\"Extracted {len(context.extracted_models)} models\")\nprint(f\"Graph has {context.graph_metadata.node_count} nodes\")\n</code></pre>"},{"location":"fundamentals/extraction-process/#extraction-flow","title":"Extraction Flow","text":""},{"location":"fundamentals/extraction-process/#complete-flow-diagram","title":"Complete Flow Diagram","text":"<p>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%% flowchart TD     %% 1. Define Classes     classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1     classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037     classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20     classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100     classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0     classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A     classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238</p> <pre><code>%% 2. Define Nodes\nStart@{ shape: terminal, label: \"Input Source\" }\n\nNormalize@{ shape: procs, label: \"Input Normalization\" }\nCheckInput{\"Input Type\"}\n\nConvert@{ shape: procs, label: \"Document Conversion&lt;br/&gt;PDF/Image\" }\nTextProc@{ shape: lin-proc, label: \"Text Processing&lt;br/&gt;Text/Markdown\" }\nLoadDoc@{ shape: lin-proc, label: \"Load DoclingDocument&lt;br/&gt;Skip to Graph\" }\n\nCheckMode{\"Process. Mode\"}\nCheckChunk{\"Chunking?\"}\n\nPageExtract@{ shape: lin-proc, label: \"Page-by-Page Extraction\" }\nFullDoc@{ shape: lin-proc, label: \"Full Document Extraction\" }\n\nChunk@{ shape: tag-proc, label: \"Structure-Aware Chunking\" }\nBatch@{ shape: tag-proc, label: \"Batch Chunks\" }\n\nExtract@{ shape: procs, label: \"Extract from Batches\" }\n\nCheckMerge{\"Multiple Models?\"}\n\nMerge@{ shape: lin-proc, label: \"Programmatic Merge\" }\nSingle@{ shape: doc, label: \"Single Model\" }\n\nCheckConsol{\"Consolidation?\"}\nConsol@{ shape: procs, label: \"LLM Consolidation\" }\n\nFinal@{ shape: doc, label: \"Final Model\" }\nGraph@{ shape: db, label: \"Knowledge Graph\" }\n\n%% 3. Define Connections\nStart --&gt; Normalize\nNormalize --&gt; CheckInput\n\nCheckInput -- \"PDF/Image\" --&gt; Convert\nCheckInput -- \"Text/Markdown\" --&gt; TextProc\nCheckInput -- \"DoclingDocument\" --&gt; LoadDoc\n\nConvert --&gt; CheckMode\nTextProc --&gt; CheckMode\n\nLoadDoc --&gt; Graph\n\nCheckMode -- Many-to-One --&gt; CheckChunk\nCheckMode -- One-to-One --&gt; PageExtract\n\nCheckChunk -- Yes --&gt; Chunk\nCheckChunk -- No --&gt; FullDoc\n\nChunk --&gt; Batch\nBatch --&gt; Extract\n\nFullDoc --&gt; Extract\nPageExtract --&gt; Extract\n\nExtract --&gt; CheckMerge\nCheckMerge -- Yes --&gt; Merge\nCheckMerge -- No --&gt; Single\n\nMerge --&gt; CheckConsol\nCheckConsol -- Yes --&gt; Consol\nCheckConsol -- No --&gt; Final\n\nConsol --&gt; Final\nSingle --&gt; Final\nFinal --&gt; Graph\n\n%% 4. Apply Classes\nclass Start input\nclass Normalize,Convert,Extract,Consol process\nclass TextProc,LoadDoc,PageExtract,FullDoc,Merge process\nclass Chunk,Batch operator\nclass CheckInput,CheckMode,CheckChunk,CheckMerge,CheckConsol decision\nclass Single data\nclass Final,Graph output\n</code></pre> <p>```</p>"},{"location":"fundamentals/extraction-process/#key-concepts","title":"Key Concepts","text":""},{"location":"fundamentals/extraction-process/#1-document-conversion","title":"1. Document Conversion","text":"<p>Transform raw documents into structured format:  <code>python from docling_graph.core.extractors import DocumentProcessor  processor = DocumentProcessor(docling_config=\"ocr\") document = processor.convert_to_docling_doc(\"document.pdf\")</code></p> <p>Learn more: Document Conversion \u2192</p>"},{"location":"fundamentals/extraction-process/#2-chunking","title":"2. Chunking","text":"<p>Split documents intelligently:</p> <pre><code>from docling_graph.core.extractors import DocumentChunker\n\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096\n)\nchunks = chunker.chunk_document(document)\n</code></pre> <p>Learn more: Chunking Strategies \u2192</p>"},{"location":"fundamentals/extraction-process/#3-extraction","title":"3. Extraction","text":"<p>Extract structured data:</p> <pre><code>from docling_graph.core.extractors import ExtractorFactory\n\nextractor = ExtractorFactory.create_extractor(\n    processing_mode=\"many-to-one\",\n    backend_name=\"llm\",\n    llm_client=client\n)\nmodels, doc = extractor.extract(source, template)\n</code></pre> <p>Learn more: Extraction Backends \u2192</p>"},{"location":"fundamentals/extraction-process/#4-merging","title":"4. Merging","text":"<p>Consolidate multiple models:</p> <pre><code>from docling_graph.core.utils import merge_pydantic_models\n\nmerged = merge_pydantic_models(models, template)\n</code></pre> <p>Learn more: Model Merging \u2192</p>"},{"location":"fundamentals/extraction-process/#performance-optimization","title":"Performance Optimization","text":""},{"location":"fundamentals/extraction-process/#chunking-vs-no-chunking","title":"Chunking vs No Chunking","text":"Approach Speed Accuracy Memory Best For Chunking Fast High Low Large docs No Chunking Slow Medium High Small docs"},{"location":"fundamentals/extraction-process/#batch-processing","title":"Batch Processing","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    use_chunking=True,      # Enable chunking\n    max_batch_size=5        # Process 5 chunks at once\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/#error-handling","title":"Error Handling","text":""},{"location":"fundamentals/extraction-process/#extraction-errors","title":"Extraction Errors","text":"<pre><code>from docling_graph.exceptions import ExtractionError\n\ntry:\n    config.run()\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n    print(f\"Details: {e.details}\")\n</code></pre>"},{"location":"fundamentals/extraction-process/#pipeline-errors","title":"Pipeline Errors","text":"<pre><code>from docling_graph.exceptions import PipelineError\n\ntry:\n    config.run()\nexcept PipelineError as e:\n    print(f\"Pipeline failed at stage: {e.details['stage']}\")\n</code></pre>"},{"location":"fundamentals/extraction-process/#section-contents","title":"Section Contents","text":""},{"location":"fundamentals/extraction-process/#1-document-conversion_1","title":"1. Document Conversion","text":"<p>Learn how documents are converted to structured format using Docling pipelines.</p> <p>Topics: - OCR vs Vision pipelines - Layout analysis - Table extraction - Multi-language support</p>"},{"location":"fundamentals/extraction-process/#2-chunking-strategies","title":"2. Chunking Strategies","text":"<p>Understand intelligent document chunking for optimal LLM processing.</p> <p>Topics: - Structure-aware chunking - Token management - Semantic boundaries - Provider-specific optimization</p>"},{"location":"fundamentals/extraction-process/#3-extraction-backends","title":"3. Extraction Backends","text":"<p>Deep dive into LLM and VLM extraction backends.</p> <p>Topics: - LLM backend (text-based) - VLM backend (vision-based) - Backend selection - Performance comparison</p>"},{"location":"fundamentals/extraction-process/#4-model-merging","title":"4. Model Merging","text":"<p>Learn how multiple extractions are consolidated into single models.</p> <p>Topics: - Programmatic merging - LLM consolidation - Conflict resolution - Validation strategies</p>"},{"location":"fundamentals/extraction-process/#5-batch-processing","title":"5. Batch Processing","text":"<p>Optimize extraction with intelligent batching.</p> <p>Topics: - Chunk batching - Context window management - Adaptive batch sizing - Performance tuning</p>"},{"location":"fundamentals/extraction-process/#6-pipeline-orchestration","title":"6. Pipeline Orchestration","text":"<p>Understand how pipeline stages are coordinated through the extraction process.</p> <p>Topics: - Stage execution - Context management - Error handling - Resource cleanup</p>"},{"location":"fundamentals/extraction-process/#quick-examples","title":"Quick Examples","text":""},{"location":"fundamentals/extraction-process/#example-1-basic-extraction","title":"Example 1: Basic Extraction","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/#example-2-high-accuracy-extraction","title":"Example 2: High-Accuracy Extraction","text":"<pre><code>config = PipelineConfig(\n    source=\"complex_document.pdf\",\n    template=\"my_templates.ResearchPaper\",\n    backend=\"vlm\",              # Vision backend\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\"     # Vision pipeline\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/#example-3-optimized-for-large-documents","title":"Example 3: Optimized for Large Documents","text":"<pre><code>config = PipelineConfig(\n    source=\"large_document.pdf\",\n    template=\"my_templates.Contract\",\n    backend=\"llm\",\n    use_chunking=True,          # Enable chunking\n    llm_consolidation=True,     # Extra accuracy\n    max_batch_size=3            # Smaller batches\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/#1-choose-the-right-backend","title":"1. Choose the Right Backend","text":"<pre><code># \u2705 Good - Match backend to document type\nif document_has_complex_layout:\n    backend = \"vlm\"\nelse:\n    backend = \"llm\"\n</code></pre>"},{"location":"fundamentals/extraction-process/#2-enable-chunking-for-large-documents","title":"2. Enable Chunking for Large Documents","text":"<pre><code># \u2705 Good - Use chunking for efficiency\nconfig = PipelineConfig(\n    source=\"large_doc.pdf\",\n    template=\"my_templates.Invoice\",\n    use_chunking=True  # Recommended\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/#3-use-llm-consolidation-for-accuracy","title":"3. Use LLM Consolidation for Accuracy","text":"<pre><code># \u2705 Good - Extra accuracy for critical data\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"my_templates.Contract\",\n    llm_consolidation=True  # Higher accuracy\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/#issue-extraction-returns-empty-results","title":"Issue: Extraction Returns Empty Results","text":"<p>Solution: <pre><code># Check document conversion\nprocessor = DocumentProcessor()\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\nmarkdown = processor.extract_full_markdown(document)\n\nif not markdown.strip():\n    print(\"Document conversion failed\")\n</code></pre></p>"},{"location":"fundamentals/extraction-process/#issue-out-of-memory","title":"Issue: Out of Memory","text":"<p>Solution: <pre><code># Enable chunking and reduce batch size\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    use_chunking=True,\n    max_batch_size=1  # Smaller batches\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/#issue-slow-extraction","title":"Issue: Slow Extraction","text":"<p>Solution: <pre><code># Use local backend or disable consolidation\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\",      # Faster\n    llm_consolidation=False  # Skip extra pass\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/#next-steps","title":"Next Steps","text":"<p>Ready to dive deeper? Start with:</p> <ol> <li>Document Conversion \u2192 - Learn about Docling pipelines</li> <li>Chunking Strategies \u2192 - Optimize document splitting</li> <li>Extraction Backends \u2192 - Choose the right backend</li> </ol>"},{"location":"fundamentals/extraction-process/batch-processing/","title":"Batch Processing","text":""},{"location":"fundamentals/extraction-process/batch-processing/#overview","title":"Overview","text":"<p>Batch processing optimizes extraction by grouping multiple chunks into single LLM calls, reducing API overhead while maximizing context window utilization.</p> <p>In this guide: - Why batching matters - Adaptive batching algorithm - Context window optimization - Performance tuning - Best practices</p>"},{"location":"fundamentals/extraction-process/batch-processing/#why-batching-matters","title":"Why Batching Matters","text":""},{"location":"fundamentals/extraction-process/batch-processing/#the-api-call-problem","title":"The API Call Problem","text":"<p>Without batching:</p> <pre><code># 10 chunks = 10 API calls\nfor chunk in chunks:  # 10 iterations\n    model = llm.extract(chunk)  # 10 API calls\n    models.append(model)\n\n# Cost: 10 \u00d7 API_COST\n# Time: 10 \u00d7 LATENCY\n</code></pre> <p>With batching:</p> <pre><code># 10 chunks = 3 batches = 3 API calls\nbatches = batcher.batch_chunks(chunks)  # Group into 3 batches\nfor batch in batches:  # 3 iterations\n    model = llm.extract(batch.combined_text)  # 3 API calls\n    models.append(model)\n\n# Cost: 3 \u00d7 API_COST (70% savings)\n# Time: 3 \u00d7 LATENCY (70% faster)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#chunkbatcher","title":"ChunkBatcher","text":""},{"location":"fundamentals/extraction-process/batch-processing/#what-is-chunkbatcher","title":"What is ChunkBatcher?","text":"<p>ChunkBatcher intelligently groups chunks to fit within context windows, minimizing API calls while preserving semantic boundaries.</p>"},{"location":"fundamentals/extraction-process/batch-processing/#architecture","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"10 Chunks\" }\n\n    B@{ shape: procs, label: \"Greedy Packing\" }\n    C@{ shape: doc, label: \"5 Candidate Batches\" }\n\n    D@{ shape: lin-proc, label: \"Merge Undersized\" }\n    E@{ shape: doc, label: \"3 Final Batches\" }\n\n    F@{ shape: tag-proc, label: \"3 API Calls\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,D process\n    class C,E data\n    class F output</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#basic-usage","title":"Basic Usage","text":""},{"location":"fundamentals/extraction-process/batch-processing/#initialize-batcher","title":"Initialize Batcher","text":"<pre><code>from docling_graph.core.extractors import ChunkBatcher\n\n# Create batcher with context constraints\nbatcher = ChunkBatcher(\n    context_limit=8000,          # Total context window\n    system_prompt_tokens=500,    # System prompt overhead\n    response_buffer_tokens=500,  # Response space\n    merge_threshold=0.85         # Merge if &lt;85% utilized\n)\n\n# Available for content: 8000 - 500 - 500 = 7000 tokens\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#batch-chunks","title":"Batch Chunks","text":"<pre><code># Batch your chunks\nbatches = batcher.batch_chunks(chunks)\n\nprint(f\"Reduced {len(chunks)} chunks to {len(batches)} batches\")\n\n# Process batches\nfor batch in batches:\n    print(f\"Batch {batch.batch_id}: {batch.chunk_count} chunks\")\n    print(f\"  Tokens: {batch.total_tokens}\")\n    print(f\"  Utilization: {batch.total_tokens / 7000 * 100:.1f}%\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#batching-algorithm","title":"Batching Algorithm","text":""},{"location":"fundamentals/extraction-process/batch-processing/#phase-1-greedy-packing","title":"Phase 1: Greedy Packing","text":"<p>Strategy: Pack chunks sequentially until context limit reached</p> <pre><code>current_batch = []\ncurrent_tokens = 0\n\nfor chunk in chunks:\n    chunk_tokens = estimate_tokens(chunk) + OVERHEAD\n\n    if current_tokens + chunk_tokens &gt; available_tokens:\n        # Start new batch\n        batches.append(current_batch)\n        current_batch = [chunk]\n        current_tokens = chunk_tokens\n    else:\n        # Add to current batch\n        current_batch.append(chunk)\n        current_tokens += chunk_tokens\n</code></pre> <p>Result: Candidate batches that fit context window</p>"},{"location":"fundamentals/extraction-process/batch-processing/#phase-2-merge-undersized","title":"Phase 2: Merge Undersized","text":"<p>Strategy: Combine small batches to improve utilization</p> <pre><code>threshold = available_tokens * merge_threshold  # e.g., 85%\n\nfor batch in batches:\n    if batch.total_tokens &lt; threshold:\n        # Try to merge with next batch\n        if can_merge_with_next(batch):\n            merge_batches(batch, next_batch)\n</code></pre> <p>Result: Optimized batches with high utilization</p>"},{"location":"fundamentals/extraction-process/batch-processing/#chunkbatch-object","title":"ChunkBatch Object","text":""},{"location":"fundamentals/extraction-process/batch-processing/#structure","title":"Structure","text":"<pre><code>@dataclass\nclass ChunkBatch:\n    batch_id: int              # Batch sequence number\n    chunks: List[str]          # Chunk texts\n    total_tokens: int          # Estimated tokens\n    chunk_indices: List[int]   # Original indices\n\n    @property\n    def chunk_count(self) -&gt; int:\n        return len(self.chunks)\n\n    @property\n    def combined_text(self) -&gt; str:\n        # Chunks with separators\n        return \"\\n\\n---CHUNK BOUNDARY---\\n\\n\".join(chunks)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#usage","title":"Usage","text":"<pre><code>batch = batches[0]\n\nprint(f\"Batch ID: {batch.batch_id}\")\nprint(f\"Chunks: {batch.chunk_count}\")\nprint(f\"Tokens: {batch.total_tokens}\")\nprint(f\"Indices: {batch.chunk_indices}\")\n\n# Get combined text for LLM\ncombined = batch.combined_text\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#token-estimation","title":"Token Estimation","text":""},{"location":"fundamentals/extraction-process/batch-processing/#estimation-methods","title":"Estimation Methods","text":""},{"location":"fundamentals/extraction-process/batch-processing/#1-heuristic-default","title":"1. Heuristic (Default)","text":"<pre><code># Fast but approximate\ntokens = len(text) // 4  # ~4 chars per token\n</code></pre> <p>Pros: Fast, no dependencies Cons: Approximate (\u00b120% error)</p>"},{"location":"fundamentals/extraction-process/batch-processing/#2-custom-tokenizer","title":"2. Custom Tokenizer","text":"<pre><code>from transformers import AutoTokenizer\n\n# Accurate token counting\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n\ndef count_tokens(text: str) -&gt; int:\n    return len(tokenizer.encode(text))\n\n# Use with batcher\nbatches = batcher.batch_chunks(chunks, tokenizer_fn=count_tokens)\n</code></pre> <p>Pros: Accurate Cons: Slower, requires tokenizer</p>"},{"location":"fundamentals/extraction-process/batch-processing/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"fundamentals/extraction-process/batch-processing/#context-limit","title":"Context Limit","text":"<p>Definition: Total context window size</p> <pre><code>batcher = ChunkBatcher(\n    context_limit=8000  # Mistral: 32K, GPT-4: 128K, Llama: 8K\n)\n</code></pre> <p>How to choose: - Use model's actual context limit - Be conservative (leave buffer) - Account for prompt overhead</p>"},{"location":"fundamentals/extraction-process/batch-processing/#system-prompt-tokens","title":"System Prompt Tokens","text":"<p>Definition: Tokens used by system prompt</p> <pre><code>batcher = ChunkBatcher(\n    context_limit=8000,\n    system_prompt_tokens=500  # Typical: 300-700\n)\n</code></pre> <p>Includes: - Extraction instructions - Schema definition - Example format</p>"},{"location":"fundamentals/extraction-process/batch-processing/#response-buffer-tokens","title":"Response Buffer Tokens","text":"<p>Definition: Space reserved for LLM response</p> <pre><code>batcher = ChunkBatcher(\n    context_limit=8000,\n    response_buffer_tokens=500  # Typical: 500-1000\n)\n</code></pre> <p>Depends on: - Schema complexity - Expected output size - Safety margin</p>"},{"location":"fundamentals/extraction-process/batch-processing/#merge-threshold","title":"Merge Threshold","text":"<p>Definition: Minimum utilization before merging</p> <pre><code>batcher = ChunkBatcher(\n    context_limit=8000,\n    merge_threshold=0.85  # Merge if &lt;85% utilized\n)\n</code></pre> <p>Effects: - Higher (0.9): More batches, better fit - Lower (0.7): Fewer batches, more merging</p>"},{"location":"fundamentals/extraction-process/batch-processing/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/extraction-process/batch-processing/#example-1-basic-batching","title":"Example 1: Basic Batching","text":"<pre><code>from docling_graph.core.extractors import ChunkBatcher, DocumentChunker, DocumentProcessor\n\n# Convert and chunk document\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"large_document.pdf\")\n\nchunker = DocumentChunker(provider=\"mistral\")\nchunks = chunker.chunk_document(document)\n\nprint(f\"Created {len(chunks)} chunks\")\n\n# Batch chunks\nbatcher = ChunkBatcher(\n    context_limit=32000,  # Mistral Large\n    system_prompt_tokens=500,\n    response_buffer_tokens=500,\n    merge_threshold=0.85\n)\n\nbatches = batcher.batch_chunks(chunks)\n\nprint(f\"Reduced to {len(batches)} batches\")\nprint(f\"API call reduction: {(1 - len(batches)/len(chunks)) * 100:.0f}%\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#example-2-with-custom-tokenizer","title":"Example 2: With Custom Tokenizer","text":"<pre><code>from docling_graph.core.extractors import ChunkBatcher\nfrom transformers import AutoTokenizer\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n\ndef count_tokens(text: str) -&gt; int:\n    return len(tokenizer.encode(text))\n\n# Batch with accurate token counting\nbatcher = ChunkBatcher(context_limit=8000)\nbatches = batcher.batch_chunks(chunks, tokenizer_fn=count_tokens)\n\nprint(f\"Accurate batching: {len(batches)} batches\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#example-3-integration-with-extraction","title":"Example 3: Integration with Extraction","text":"<pre><code>from docling_graph.core.extractors.backends import LlmBackend\nfrom docling_graph.llm_clients import MistralClient\n\n# Initialize backend\nclient = MistralClient(model=\"mistral-large-latest\")\nbackend = LlmBackend(llm_client=client)\n\n# Batch chunks\nbatcher = ChunkBatcher(context_limit=32000)\nbatches = batcher.batch_chunks(chunks)\n\n# Extract from batches\nmodels = []\nfor batch in batches:\n    print(f\"Processing batch {batch.batch_id} ({batch.chunk_count} chunks)\")\n\n    model = backend.extract_from_markdown(\n        markdown=batch.combined_text,\n        template=InvoiceTemplate,\n        context=f\"batch {batch.batch_id}\",\n        is_partial=True\n    )\n\n    if model:\n        models.append(model)\n\nprint(f\"Extracted {len(models)} models from {len(batches)} batches\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#example-4-automatic-batching-in-pipeline","title":"Example 4: Automatic Batching in Pipeline","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Batching happens automatically\nconfig = PipelineConfig(\n    source=\"large_document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    use_chunking=True  # Enables automatic batching\n)\n\nconfig.run()\n\n# ChunkBatcher is used internally to optimize API calls\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#performance-optimization","title":"Performance Optimization","text":""},{"location":"fundamentals/extraction-process/batch-processing/#batch-size-vs-api-calls","title":"Batch Size vs API Calls","text":"Chunks No Batching With Batching Reduction 10 10 calls 3 calls 70% 20 20 calls 5 calls 75% 50 50 calls 12 calls 76% 100 100 calls 23 calls 77%"},{"location":"fundamentals/extraction-process/batch-processing/#cost-savings","title":"Cost Savings","text":"<pre><code># Example: Mistral Large API\nAPI_COST_PER_CALL = $0.002  # Input tokens\n\n# Without batching: 50 chunks\ncost_without = 50 * API_COST_PER_CALL = $0.10\n\n# With batching: 12 batches\ncost_with = 12 * API_COST_PER_CALL = $0.024\n\n# Savings: 76%\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#context-utilization","title":"Context Utilization","text":""},{"location":"fundamentals/extraction-process/batch-processing/#measuring-utilization","title":"Measuring Utilization","text":"<pre><code>batches = batcher.batch_chunks(chunks)\n\nfor batch in batches:\n    utilization = batch.total_tokens / batcher.available_tokens * 100\n    print(f\"Batch {batch.batch_id}: {utilization:.1f}% utilized\")\n\n# Average utilization\navg_util = sum(b.total_tokens for b in batches) / (len(batches) * batcher.available_tokens) * 100\nprint(f\"Average utilization: {avg_util:.1f}%\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#optimization-tips","title":"Optimization Tips","text":"<pre><code># \u2705 Good - High utilization (85-95%)\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    merge_threshold=0.85  # Merge undersized batches\n)\n\n# \u274c Bad - Low utilization (&lt;70%)\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    merge_threshold=0.5  # Too aggressive merging\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/batch-processing/#1-match-context-limit-to-model","title":"1. Match Context Limit to Model","text":"<pre><code># \u2705 Good - Use actual model limits\nif model == \"mistral-large\":\n    context_limit = 32000\nelif model == \"gpt-4-turbo\":\n    context_limit = 128000\nelif model == \"llama3.1:8b\":\n    context_limit = 8000\n\nbatcher = ChunkBatcher(context_limit=context_limit)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#2-leave-adequate-buffer","title":"2. Leave Adequate Buffer","text":"<pre><code># \u2705 Good - Conservative buffers\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    system_prompt_tokens=500,  # Adequate\n    response_buffer_tokens=500  # Safe margin\n)\n\n# \u274c Bad - Insufficient buffer\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    system_prompt_tokens=100,  # Too small\n    response_buffer_tokens=100  # Risky\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#3-use-merge-threshold-wisely","title":"3. Use Merge Threshold Wisely","text":"<pre><code># \u2705 Good - Balance efficiency and fit\nbatcher = ChunkBatcher(\n    merge_threshold=0.85  # 85% - good balance\n)\n\n# For many small chunks\nbatcher = ChunkBatcher(\n    merge_threshold=0.80  # More aggressive merging\n)\n\n# For few large chunks\nbatcher = ChunkBatcher(\n    merge_threshold=0.90  # Less merging\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#4-monitor-batch-statistics","title":"4. Monitor Batch Statistics","text":"<pre><code># \u2705 Good - Check batching effectiveness\nbatches = batcher.batch_chunks(chunks)\n\nreduction = (1 - len(batches) / len(chunks)) * 100\nprint(f\"API call reduction: {reduction:.0f}%\")\n\nif reduction &lt; 50:\n    print(\"Warning: Low batching efficiency\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/batch-processing/#issue-too-many-batches","title":"Issue: Too Many Batches","text":"<p>Problem: Batching not reducing API calls enough</p> <p>Solution: <pre><code># Increase merge threshold\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    merge_threshold=0.80  # More aggressive (was 0.85)\n)\n\n# Or increase context limit if model supports it\nbatcher = ChunkBatcher(\n    context_limit=16000  # Use larger context\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/batch-processing/#issue-batches-too-large","title":"Issue: Batches Too Large","text":"<p>Problem: Batches exceeding context limit</p> <p>Solution: <pre><code># Increase buffer sizes\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    system_prompt_tokens=700,  # More buffer (was 500)\n    response_buffer_tokens=700  # More buffer (was 500)\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/batch-processing/#issue-low-utilization","title":"Issue: Low Utilization","text":"<p>Problem: Batches not filling context window</p> <p>Solution: <pre><code># Lower merge threshold\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    merge_threshold=0.90  # Less merging (was 0.85)\n)\n\n# Or use smaller chunks\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=3000  # Smaller chunks (was 4096)\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/batch-processing/#advanced-techniques","title":"Advanced Techniques","text":""},{"location":"fundamentals/extraction-process/batch-processing/#custom-batch-processing","title":"Custom Batch Processing","text":"<pre><code>from docling_graph.core.extractors import ChunkBatcher\n\ndef process_with_retry(batches, backend, template):\n    \"\"\"Process batches with retry logic.\"\"\"\n    models = []\n\n    for batch in batches:\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                model = backend.extract_from_markdown(\n                    markdown=batch.combined_text,\n                    template=template,\n                    context=f\"batch {batch.batch_id}\",\n                    is_partial=True\n                )\n\n                if model:\n                    models.append(model)\n                    break\n\n            except Exception as e:\n                if attempt == max_retries - 1:\n                    print(f\"Failed batch {batch.batch_id} after {max_retries} attempts\")\n                else:\n                    print(f\"Retry {attempt + 1} for batch {batch.batch_id}\")\n\n    return models\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#next-steps","title":"Next Steps","text":"<p>Now that you understand batch processing:</p> <ol> <li>Graph Management \u2192 - Work with knowledge graphs</li> <li>Export Formats \u2192 - Export graphs</li> <li>Visualization \u2192 - Visualize graphs</li> </ol>"},{"location":"fundamentals/extraction-process/batch-processing/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/extraction-process/batch-processing/#basic-batching","title":"Basic Batching","text":"<pre><code>from docling_graph.core.extractors import ChunkBatcher\n\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    system_prompt_tokens=500,\n    response_buffer_tokens=500,\n    merge_threshold=0.85\n)\n\nbatches = batcher.batch_chunks(chunks)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#with-custom-tokenizer","title":"With Custom Tokenizer","text":"<pre><code>batches = batcher.batch_chunks(chunks, tokenizer_fn=count_tokens)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#process-batches","title":"Process Batches","text":"<pre><code>for batch in batches:\n    model = backend.extract_from_markdown(\n        markdown=batch.combined_text,\n        template=template,\n        context=f\"batch {batch.batch_id}\",\n        is_partial=True\n    )\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/","title":"Chunking Strategies","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#overview","title":"Overview","text":"<p>Chunking is the process of intelligently splitting documents into optimal pieces for LLM processing. Docling Graph uses structure-aware chunking that preserves document semantics, tables, and hierarchies.</p> <p>In this guide: - Why chunking matters - Structure-aware vs naive chunking - Real tokenizer integration - Token management with safety margins - Schema-aware chunking - Provider-specific optimization - Performance tuning</p> <p>New: Real Tokenizer Integration</p> <p>Docling Graph now uses real tokenizers for accurate token counting instead of character-based heuristics. This prevents context window overflows and enables more efficient chunk packing with a 20% safety margin.</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#why-chunking-matters","title":"Why Chunking Matters","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#the-context-window-problem","title":"The Context Window Problem","text":"<p>LLMs have limited context windows:</p> Provider Model Context Limit OpenAI GPT-4 Turbo 128K tokens Mistral Mistral Large 32K tokens Ollama Llama 3.1 8B 8K tokens IBM Granite 4.0 8K tokens <p>Problem: Most documents exceed these limits.</p> <p>Solution: Intelligent chunking.</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#chunking-approaches","title":"Chunking Approaches","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#naive-chunking","title":"\u274c Naive Chunking","text":"<pre><code># \u274c Bad - Breaks tables and structure\ndef naive_chunk(text, max_chars=1000):\n    return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]\n</code></pre> <p>Problems: - Breaks tables mid-row - Splits lists - Ignores semantic boundaries - Loses context</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#structure-aware-chunking","title":"\u2705 Structure-Aware Chunking","text":"<pre><code># \u2705 Good - Preserves structure\nfrom docling_graph.core.extractors import DocumentChunker\n\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096\n)\n\nchunks = chunker.chunk_document(document)\n</code></pre> <p>Benefits: - Preserves tables - Keeps lists intact - Respects sections - Maintains context</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#documentchunker","title":"DocumentChunker","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker, DocumentProcessor\n\n# Initialize processor\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n\n# Initialize chunker\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096\n)\n\n# Chunk document\nchunks = chunker.chunk_document(document)\n\nprint(f\"Created {len(chunks)} chunks\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#configuration-options","title":"Configuration Options","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#by-provider","title":"By Provider","text":"<pre><code># Automatic configuration for provider\nchunker = DocumentChunker(\n    provider=\"mistral\",  # Auto-configures for Mistral\n    merge_peers=True\n)\n</code></pre> <p>Supported providers: - <code>mistral</code> - Mistral AI models - <code>openai</code> - OpenAI models - <code>ollama</code> - Ollama local models - <code>watsonx</code> - IBM watsonx models - <code>google</code> - Google Gemini models</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#custom-tokenizer","title":"Custom Tokenizer","text":"<pre><code># Use specific tokenizer\nchunker = DocumentChunker(\n    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n    max_tokens=4096,\n    merge_peers=True\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#custom-max-tokens","title":"Custom Max Tokens","text":"<pre><code># Override max tokens\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=8000,  # Custom limit\n    merge_peers=True\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#structure-preservation","title":"Structure Preservation","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#what-gets-preserved","title":"What Gets Preserved?","text":"<p>The HybridChunker preserves:</p> <ol> <li>Tables - Never split across chunks</li> <li>Lists - Kept intact</li> <li>Sections - With headers</li> <li>Hierarchies - Parent-child relationships</li> <li>Semantic boundaries - Natural breaks</li> </ol>"},{"location":"fundamentals/extraction-process/chunking-strategies/#example-table-preservation","title":"Example: Table Preservation","text":"<p>Input document: <pre><code># Sales Report\n\n| Product | Q1 | Q2 | Q3 | Q4 |\n|---------|----|----|----|----|\n| A       | 10 | 15 | 20 | 25 |\n| B       | 5  | 10 | 15 | 20 |\n</code></pre></p> <p>Chunking result: <pre><code># \u2705 Table stays together in one chunk\nchunks = [\n    \"# Sales Report\\n\\n| Product | Q1 | Q2 | Q3 | Q4 |\\n...\"\n]\n</code></pre></p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#context-enrichment","title":"Context Enrichment","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#what-is-context-enrichment","title":"What is Context Enrichment?","text":"<p>Chunks are contextualized with metadata: - Section headers - Parent sections - Document structure - Page numbers</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#example","title":"Example","text":"<p>Original text: <pre><code>Product A costs $50.\n</code></pre></p> <p>Contextualized chunk: <pre><code># Invoice INV-001\n## Line Items\n### Product Details\n\nProduct A costs $50.\n</code></pre></p> <p>Why it matters: LLM understands context better.</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#real-tokenizer-integration","title":"Real Tokenizer Integration","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#accurate-token-counting","title":"Accurate Token Counting","text":"<p>Docling Graph uses real tokenizers instead of character-based heuristics:</p> <pre><code>from docling_graph.core.extractors import DocumentChunker\n\n# \u2705 Good - Real tokenizer (accurate)\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096\n)\n# Uses Mistral's actual tokenizer for precise counting\n\n# \u274c Old approach - Character heuristic (inaccurate)\n# estimated_tokens = len(text) / 4  # Rough approximation\n</code></pre> <p>Benefits:</p> Feature Character Heuristic Real Tokenizer Accuracy ~70% 95%+ Context Overflows Occasional Rare Chunk Efficiency 60-70% 80-90% Provider-Specific No Yes"},{"location":"fundamentals/extraction-process/chunking-strategies/#how-it-works","title":"How It Works","text":"<pre><code># Behind the scenes:\n# 1. Load provider-specific tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n\n# 2. Count tokens accurately\ntokens = tokenizer.encode(text)\ntoken_count = len(tokens)\n\n# 3. Apply safety margin (20%)\nsafe_limit = int(max_tokens * 0.8)\n\n# 4. Chunk based on actual token count\nif token_count &gt; safe_limit:\n    # Split into multiple chunks\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#safety-margins","title":"Safety Margins","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#why-safety-margins","title":"Why Safety Margins?","text":"<p>Even with real tokenizers, we apply a 20% safety margin:</p> <pre><code># Example: Model with 8192 token context\nmax_tokens = 8192\n\n# Effective limit with 20% safety margin\nsafe_limit = int(max_tokens * 0.8)  # 6553 tokens\n\n# Why?\n# - Schema takes tokens (~500-2000)\n# - System prompts take tokens (~200-500)\n# - Response buffer needed (~500-1000)\n# - Edge cases and variations\n</code></pre> <p>Safety Margin Breakdown:</p> Component Token Usage Example (8K context) Document chunk 80% 6553 tokens Schema 10-15% 819-1228 tokens System prompt 3-5% 245-409 tokens Response buffer 5-10% 409-819 tokens"},{"location":"fundamentals/extraction-process/chunking-strategies/#configuring-safety-margins","title":"Configuring Safety Margins","text":"<pre><code># Default: 20% safety margin (recommended)\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096  # Effective: ~3276 tokens per chunk\n)\n\n# For aggressive batching (not recommended):\n# Modify ChunkBatcher.batch_chunks merge_threshold\n# But this increases risk of context overflows\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#token-management","title":"Token Management","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#token-counting-with-statistics","title":"Token Counting with Statistics","text":"<pre><code># Get detailed token statistics\nchunks, stats = chunker.chunk_document_with_stats(document)\n\nprint(f\"Total chunks: {stats['total_chunks']}\")\nprint(f\"Average tokens: {stats['avg_tokens']:.0f}\")\nprint(f\"Max tokens: {stats['max_tokens_in_chunk']}\")\nprint(f\"Total tokens: {stats['total_tokens']}\")\nprint(f\"Safety margin: {(1 - stats['max_tokens_in_chunk']/max_tokens)*100:.1f}%\")\n</code></pre> <p>Output: <pre><code>Total chunks: 5\nAverage tokens: 3200\nMax tokens: 3950\nTotal tokens: 16000\nSafety margin: 3.5%\n</code></pre></p> <p>Monitor Safety Margins</p> <p>If <code>max_tokens_in_chunk</code> is &gt; 95% of <code>max_tokens</code>, consider:</p> <ul> <li>Reducing <code>max_tokens</code> parameter</li> <li>Increasing schema efficiency</li> <li>Splitting large tables</li> </ul>"},{"location":"fundamentals/extraction-process/chunking-strategies/#schema-aware-chunking","title":"Schema-Aware Chunking","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#dynamic-adjustment-based-on-schema","title":"Dynamic Adjustment Based on Schema","text":"<p>Chunk size automatically adjusts based on schema complexity:</p> <pre><code>from my_templates import ComplexTemplate\n\n# Schema-aware chunking\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    schema_size=len(ComplexTemplate.model_json_schema())\n)\n\n# Behind the scenes:\n# 1. Calculate schema token usage\nschema_tokens = schema_size / 4  # Rough estimate\n\n# 2. Adjust max_tokens for chunks\nadjusted_max = max_tokens - schema_tokens - buffer\n\n# 3. Chunk with adjusted limit\nchunks = chunker.chunk_document(document)\n</code></pre> <p>Schema Size Impact:</p> Schema Size Schema Tokens Chunk Tokens (8K context) Small (&lt; 2KB) ~500 ~6000 Medium (2-5KB) ~1000 ~5500 Large (5-10KB) ~2000 ~4500 Very Large (&gt; 10KB) ~3000+ ~3500"},{"location":"fundamentals/extraction-process/chunking-strategies/#update-schema-configuration","title":"Update Schema Configuration","text":"<pre><code># Update schema size after initialization\nchunker = DocumentChunker(provider=\"mistral\")\n\n# Later, update for different template\nfrom my_templates import LargeTemplate\n\nchunker.update_schema_config(\n    schema_size=len(LargeTemplate.model_json_schema())\n)\n\n# Chunker now uses adjusted limits\nchunks = chunker.chunk_document(document)\n</code></pre> <p>Schema Optimization</p> <p>To maximize chunk size:</p> <ul> <li>Keep schemas focused and minimal</li> <li>Use field descriptions sparingly</li> <li>Avoid deeply nested structures</li> <li>Consider splitting large schemas</li> </ul>"},{"location":"fundamentals/extraction-process/chunking-strategies/#merge-peers-option","title":"Merge Peers Option","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#what-is-merge-peers","title":"What is Merge Peers?","text":"<p>Merge peers combines sibling sections when they fit together:</p> <pre><code># Enable merge peers (default)\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    merge_peers=True  # Combine related sections\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#example_1","title":"Example","text":"<p>Without merge_peers: <pre><code>chunks = [\n    \"## Section 1\\nContent 1\",\n    \"## Section 2\\nContent 2\",\n    \"## Section 3\\nContent 3\"\n]\n</code></pre></p> <p>With merge_peers: <pre><code>chunks = [\n    \"## Section 1\\nContent 1\\n\\n## Section 2\\nContent 2\",\n    \"## Section 3\\nContent 3\"\n]\n</code></pre></p> <p>Benefit: Fewer chunks, better context.</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#integration-with-pipeline","title":"Integration with Pipeline","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#automatic-chunking","title":"Automatic Chunking","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    use_chunking=True  # Automatic chunking (default)\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#disable-chunking","title":"Disable Chunking","text":"<pre><code>config = PipelineConfig(\n    source=\"small_document.pdf\",\n    template=\"my_templates.Invoice\",\n    use_chunking=False  # Process full document\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#example-1-basic-chunking","title":"Example 1: Basic Chunking","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker, DocumentProcessor\n\n# Convert document\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n\n# Chunk with Mistral settings\nchunker = DocumentChunker(provider=\"mistral\")\nchunks = chunker.chunk_document(document)\n\nprint(f\"Created {len(chunks)} chunks\")\nfor i, chunk in enumerate(chunks, 1):\n    print(f\"Chunk {i}: {len(chunk)} characters\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#example-2-with-statistics","title":"Example 2: With Statistics","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker, DocumentProcessor\n\n# Convert and chunk\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"large_document.pdf\")\n\n# Get detailed statistics\nchunker = DocumentChunker(provider=\"openai\", max_tokens=8000)\nchunks, stats = chunker.chunk_document_with_stats(document)\n\nprint(f\"Chunking Statistics:\")\nprint(f\"  Total chunks: {stats['total_chunks']}\")\nprint(f\"  Average tokens: {stats['avg_tokens']:.0f}\")\nprint(f\"  Max tokens: {stats['max_tokens_in_chunk']}\")\nprint(f\"  Total tokens: {stats['total_tokens']}\")\n\n# Check if any chunk exceeds limit\nif stats['max_tokens_in_chunk'] &gt; 8000:\n    print(\"Warning: Some chunks exceed token limit!\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#example-3-custom-configuration","title":"Example 3: Custom Configuration","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker, DocumentProcessor\n\n# Custom chunker for specific use case\nchunker = DocumentChunker(\n    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n    max_tokens=6000,  # Conservative limit\n    merge_peers=True,\n    schema_size=5000  # Large schema\n)\n\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"contract.pdf\")\n\nchunks = chunker.chunk_document(document)\nprint(f\"Created {len(chunks)} optimized chunks\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#example-4-fallback-text-chunking","title":"Example 4: Fallback Text Chunking","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker\n\n# For raw text (when DoclingDocument unavailable)\nchunker = DocumentChunker(provider=\"mistral\")\n\nraw_text = \"\"\"\nLong text content that needs to be chunked...\n\"\"\"\n\nchunks = chunker.chunk_text_fallback(raw_text)\nprint(f\"Created {len(chunks)} text chunks\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#provider-specific-optimization","title":"Provider-Specific Optimization","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#mistral-ai","title":"Mistral AI","text":"<pre><code>chunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096  # Optimized for Mistral Large\n)\n</code></pre> <p>Context limit: 32K tokens Recommended chunk size: 4096 tokens (with 20% safety margin) Effective chunk size: ~3276 tokens Tokenizer: Mistral-7B-Instruct-v0.2 (real tokenizer)</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#openai","title":"OpenAI","text":"<pre><code>chunker = DocumentChunker(\n    provider=\"openai\",\n    max_tokens=8000  # Optimized for GPT-4\n)\n</code></pre> <p>Context limit: 128K tokens Recommended chunk size: 8000 tokens (with 20% safety margin) Effective chunk size: ~6400 tokens Tokenizer: tiktoken (GPT-4) (real tokenizer)</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#ollama-local","title":"Ollama (Local)","text":"<pre><code>chunker = DocumentChunker(\n    provider=\"ollama\",\n    max_tokens=3500  # Conservative for 8K context\n)\n</code></pre> <p>Context limit: 8K tokens (typical) Recommended chunk size: 3500 tokens (with 20% safety margin) Effective chunk size: ~2800 tokens Tokenizer: Model-specific (real tokenizer when available)</p> <p>Ollama Tokenizer Fallback</p> <p>If model-specific tokenizer is unavailable, falls back to character heuristic with extra safety margin (75% instead of 80%).</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#ibm-watsonx","title":"IBM watsonx","text":"<pre><code>chunker = DocumentChunker(\n    provider=\"watsonx\",\n    max_tokens=3500  # Optimized for Granite\n)\n</code></pre> <p>Context limit: 8K tokens Recommended chunk size: 3500 tokens (with 20% safety margin) Effective chunk size: ~2800 tokens Tokenizer: Granite-specific (real tokenizer)</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#google-gemini","title":"Google Gemini","text":"<pre><code>chunker = DocumentChunker(\n    provider=\"google\",\n    max_tokens=6000  # Optimized for Gemini\n)\n</code></pre> <p>Context limit: 32K-128K tokens (model-dependent) Recommended chunk size: 6000 tokens (with 20% safety margin) Effective chunk size: ~4800 tokens Tokenizer: Gemini-specific (real tokenizer)</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#performance-tuning","title":"Performance Tuning","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#chunk-size-vs-accuracy","title":"Chunk Size vs Accuracy","text":"Chunk Size Accuracy Speed Memory Small (2K) Lower Fast Low Medium (4K) Good Medium Medium Large (8K) Best Slow High"},{"location":"fundamentals/extraction-process/chunking-strategies/#recommendations","title":"Recommendations","text":"<pre><code># \u2705 Good - Balance accuracy and speed\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096  # Sweet spot\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#issue-chunks-too-large","title":"Issue: Chunks Too Large","text":"<p>Solution: <pre><code># Reduce max_tokens\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=3000  # Smaller chunks\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#issue-too-many-chunks","title":"Issue: Too Many Chunks","text":"<p>Solution: <pre><code># Increase max_tokens and enable merge_peers\nchunker = DocumentChunker(\n    provider=\"openai\",\n    max_tokens=8000,  # Larger chunks\n    merge_peers=True  # Combine sections\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#issue-tables-split-across-chunks","title":"Issue: Tables Split Across Chunks","text":"<p>Solution: <pre><code># This shouldn't happen with HybridChunker\n# If it does, increase max_tokens\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=6000  # Larger to fit tables\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#issue-out-of-memory","title":"Issue: Out of Memory","text":"<p>Solution: <pre><code># Use smaller chunks\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=2000,  # Smaller chunks\n    merge_peers=False  # Don't combine\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#1-match-provider","title":"1. Match Provider","text":"<pre><code># \u2705 Good - Match chunker to LLM provider\nif using_mistral:\n    chunker = DocumentChunker(provider=\"mistral\")\nelif using_openai:\n    chunker = DocumentChunker(provider=\"openai\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#2-enable-merge-peers","title":"2. Enable Merge Peers","text":"<pre><code># \u2705 Good - Better context\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    merge_peers=True  # Recommended\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#3-monitor-statistics","title":"3. Monitor Statistics","text":"<pre><code># \u2705 Good - Check chunk distribution\nchunks, stats = chunker.chunk_document_with_stats(document)\n\nif stats['max_tokens_in_chunk'] &gt; max_tokens * 0.95:\n    print(\"Warning: Chunks near limit\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#4-adjust-for-schema-complexity","title":"4. Adjust for Schema Complexity","text":"<pre><code># \u2705 Good - Account for schema size\nschema_size = len(template.model_json_schema())\n\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    schema_size=schema_size  # Dynamic adjustment\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#advanced-features","title":"Advanced Features","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#custom-tokenizer_1","title":"Custom Tokenizer","text":"<pre><code>from transformers import AutoTokenizer\nfrom docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n\n# Load custom tokenizer\nhf_tokenizer = AutoTokenizer.from_pretrained(\"custom/model\")\ncustom_tokenizer = HuggingFaceTokenizer(\n    tokenizer=hf_tokenizer,\n    max_tokens=4096\n)\n\n# Use with HybridChunker\nfrom docling.chunking import HybridChunker\n\nchunker = HybridChunker(\n    tokenizer=custom_tokenizer,\n    merge_peers=True\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#recommended-chunk-size-calculation","title":"Recommended Chunk Size Calculation","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker\n\n# Calculate recommended size\nrecommended = DocumentChunker.calculate_recommended_max_tokens(\n    context_limit=32000,  # Mistral Large\n    system_prompt_tokens=500,\n    response_buffer_tokens=500\n)\n\nprint(f\"Recommended max_tokens: {recommended}\")\n# Output: Recommended max_tokens: 24800\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#performance-impact","title":"Performance Impact","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#real-tokenizer-vs-heuristic","title":"Real Tokenizer vs Heuristic","text":"<p>Benchmark Results (100-page document):</p> Method Chunks Created Context Overflows Processing Time API Calls Character Heuristic 45 3 (6.7%) 180s 48 (3 retries) Real Tokenizer 38 0 (0%) 152s 38 (no retries) <p>Improvements: - \u2705 15% fewer chunks (better packing) - \u2705 Zero context overflows (vs 6.7%) - \u2705 15% faster processing (no retries) - \u2705 21% fewer API calls (no retries)</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#safety-margin-impact","title":"Safety Margin Impact","text":"Safety Margin Chunk Efficiency Context Overflows Recommended For 10% 90% Occasional Aggressive batching 20% (default) 80% Rare General use 30% 70% Very rare Complex schemas"},{"location":"fundamentals/extraction-process/chunking-strategies/#next-steps","title":"Next Steps","text":"<p>Now that you understand chunking:</p> <ol> <li>Model Capabilities \u2192 - Learn about adaptive prompting</li> <li>Extraction Backends \u2192 - Learn about LLM and VLM backends</li> <li>Batch Processing \u2192 - Optimize chunk processing</li> <li>Model Merging \u2192 - Consolidate chunk extractions</li> <li>Performance Tuning \u2192 - Advanced optimization</li> </ol>"},{"location":"fundamentals/extraction-process/chunking-strategies/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#basic-chunking","title":"Basic Chunking","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker\n\nchunker = DocumentChunker(provider=\"mistral\")\nchunks = chunker.chunk_document(document)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#with-statistics","title":"With Statistics","text":"<pre><code>chunks, stats = chunker.chunk_document_with_stats(document)\nprint(f\"Created {stats['total_chunks']} chunks\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#custom-configuration","title":"Custom Configuration","text":"<pre><code>chunker = DocumentChunker(\n    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n    max_tokens=4096,\n    merge_peers=True,\n    schema_size=5000\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#fallback-text-chunking","title":"Fallback Text Chunking","text":"<pre><code>chunks = chunker.chunk_text_fallback(raw_text)\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/","title":"Document Conversion","text":""},{"location":"fundamentals/extraction-process/document-conversion/#overview","title":"Overview","text":"<p>Document Conversion is the first stage of the extraction pipeline, transforming raw PDFs and images into structured DoclingDocument format. This stage uses the Docling library to perform OCR, layout analysis, and content extraction.</p> <p>In this guide: - OCR vs Vision pipelines - Layout analysis - Table extraction - Multi-language support - Performance optimization</p>"},{"location":"fundamentals/extraction-process/document-conversion/#docling-pipelines","title":"Docling Pipelines","text":""},{"location":"fundamentals/extraction-process/document-conversion/#quick-comparison","title":"Quick Comparison","text":"Pipeline Best For Speed Accuracy GPU Required OCR Standard documents Fast High No Vision Complex layouts Slower Very High Recommended"},{"location":"fundamentals/extraction-process/document-conversion/#ocr-pipeline-default","title":"OCR Pipeline (Default)","text":""},{"location":"fundamentals/extraction-process/document-conversion/#what-is-ocr-pipeline","title":"What is OCR Pipeline?","text":"<p>The OCR (Optical Character Recognition) pipeline is the default and most accurate for standard documents. It uses traditional OCR engines combined with layout analysis.</p>"},{"location":"fundamentals/extraction-process/document-conversion/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"ocr\"  # Default\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#features","title":"Features","text":"<p>\u2705 Strengths: - Fast processing - High accuracy for text - Excellent table extraction - Multi-language support - No GPU required</p> <p>\u274c Limitations: - May struggle with complex layouts - Less effective for handwriting - Requires clear text</p>"},{"location":"fundamentals/extraction-process/document-conversion/#when-to-use-ocr","title":"When to Use OCR","text":"<p>Use OCR pipeline for: - Standard business documents - Invoices and forms - Reports and contracts - Documents with clear text - Batch processing (faster)</p>"},{"location":"fundamentals/extraction-process/document-conversion/#vision-pipeline","title":"Vision Pipeline","text":""},{"location":"fundamentals/extraction-process/document-conversion/#what-is-vision-pipeline","title":"What is Vision Pipeline?","text":"<p>The Vision pipeline uses Vision-Language Models (VLMs) to understand document layout and content visually, similar to how humans read documents.</p>"},{"location":"fundamentals/extraction-process/document-conversion/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"vision\"  # Vision pipeline\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#features_1","title":"Features","text":"<p>\u2705 Strengths: - Excellent for complex layouts - Handles handwriting better - Understands visual context - Better for images - Robust to noise</p> <p>\u274c Limitations: - Slower processing - Requires more memory - GPU recommended - Higher resource usage</p>"},{"location":"fundamentals/extraction-process/document-conversion/#when-to-use-vision","title":"When to Use Vision","text":"<p>Use Vision pipeline for: - Complex layouts (magazines, brochures) - Handwritten documents - Low-quality scans - Documents with images - Visual-heavy content</p>"},{"location":"fundamentals/extraction-process/document-conversion/#document-processor","title":"Document Processor","text":""},{"location":"fundamentals/extraction-process/document-conversion/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph.core.extractors import DocumentProcessor\n\n# Initialize with OCR pipeline\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\n# Convert document\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n\nprint(f\"Converted {document.num_pages()} pages\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#with-vision-pipeline","title":"With Vision Pipeline","text":"<pre><code># Initialize with Vision pipeline\nprocessor = DocumentProcessor(docling_config=\"vision\")\n\n# Convert document\ndocument = processor.convert_to_docling_doc(\"complex_document.pdf\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#doclingdocument-structure","title":"DoclingDocument Structure","text":""},{"location":"fundamentals/extraction-process/document-conversion/#what-is-doclingdocument","title":"What is DoclingDocument?","text":"<p>A DoclingDocument is a structured representation of your document containing: - Page information - Layout elements - Text content - Tables - Images - Metadata</p>"},{"location":"fundamentals/extraction-process/document-conversion/#accessing-document-data","title":"Accessing Document Data","text":"<pre><code># Get number of pages\nnum_pages = document.num_pages()\n\n# Get page keys\npage_keys = sorted(document.pages.keys())\n\n# Access specific page\npage = document.pages[page_keys[0]]\n\n# Get document metadata\nmetadata = document.metadata\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#markdown-extraction","title":"Markdown Extraction","text":""},{"location":"fundamentals/extraction-process/document-conversion/#full-document-markdown","title":"Full Document Markdown","text":"<pre><code># Extract complete document as markdown\nfull_markdown = processor.extract_full_markdown(document)\n\nprint(f\"Document length: {len(full_markdown)} characters\")\n</code></pre> <p>Output example: <pre><code># Invoice\n\n**Invoice Number:** INV-001\n**Date:** 2024-01-15\n\n## Items\n\n| Description | Quantity | Price |\n|-------------|----------|-------|\n| Product A   | 2        | $50   |\n| Product B   | 1        | $100  |\n\n**Total:** $200\n</code></pre></p>"},{"location":"fundamentals/extraction-process/document-conversion/#per-page-markdown","title":"Per-Page Markdown","text":"<pre><code># Extract markdown for each page\npage_markdowns = processor.extract_page_markdowns(document)\n\nfor i, page_md in enumerate(page_markdowns, 1):\n    print(f\"Page {i}: {len(page_md)} characters\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#layout-analysis","title":"Layout Analysis","text":""},{"location":"fundamentals/extraction-process/document-conversion/#what-is-layout-analysis","title":"What is Layout Analysis?","text":"<p>Layout analysis identifies document structure: - Headers and footers - Sections and paragraphs - Tables and lists - Images and figures - Captions and footnotes</p>"},{"location":"fundamentals/extraction-process/document-conversion/#accessing-layout-information","title":"Accessing Layout Information","text":"<pre><code># Get document structure\nfor page_no, page in document.pages.items():\n    print(f\"Page {page_no}:\")\n\n    # Access layout elements\n    for element in page.elements:\n        print(f\"  - {element.type}: {element.text[:50]}\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#table-extraction","title":"Table Extraction","text":""},{"location":"fundamentals/extraction-process/document-conversion/#automatic-table-detection","title":"Automatic Table Detection","text":"<p>The OCR pipeline automatically detects and extracts tables:</p> <pre><code># Tables are preserved in markdown\nmarkdown = processor.extract_full_markdown(document)\n\n# Tables appear as markdown tables\n# | Column 1 | Column 2 |\n# |----------|----------|\n# | Value 1  | Value 2  |\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#table-structure","title":"Table Structure","text":"<p>Tables are extracted with: - Column headers - Row data - Cell alignment - Merged cells (when possible)</p>"},{"location":"fundamentals/extraction-process/document-conversion/#multi-language-support","title":"Multi-Language Support","text":""},{"location":"fundamentals/extraction-process/document-conversion/#supported-languages","title":"Supported Languages","text":"<p>The OCR pipeline supports multiple languages:</p> <pre><code>from docling_graph.core.extractors import DocumentProcessor\n\n# Default: English and French\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\n# Document will be processed with both languages\ndocument = processor.convert_to_docling_doc(\"multilingual.pdf\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#language-configuration","title":"Language Configuration","text":"<p>Currently configured for: - English (en) - French (fr)</p> <p>Note: Language configuration is set in the DocumentProcessor initialization and can be extended by modifying the source code.</p>"},{"location":"fundamentals/extraction-process/document-conversion/#performance-optimization","title":"Performance Optimization","text":""},{"location":"fundamentals/extraction-process/document-conversion/#ocr-pipeline-optimization","title":"OCR Pipeline Optimization","text":"<pre><code>from docling.datamodel.accelerator_options import AcceleratorDevice\n\n# The OCR pipeline is pre-configured with:\n# - 4 threads for parallel processing\n# - Auto device selection (GPU if available)\n# - Optimized table structure matching\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#vision-pipeline-optimization","title":"Vision Pipeline Optimization","text":"<pre><code># Vision pipeline automatically uses:\n# - GPU acceleration (if available)\n# - Optimized batch processing\n# - Memory-efficient processing\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/extraction-process/document-conversion/#example-1-basic-ocr-conversion","title":"Example 1: Basic OCR Conversion","text":"<pre><code>from docling_graph.core.extractors import DocumentProcessor\n\n# Initialize processor\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\n# Convert document\ndocument = processor.convert_to_docling_doc(\"invoice.pdf\")\n\n# Extract markdown\nmarkdown = processor.extract_full_markdown(document)\n\nprint(f\"Converted {document.num_pages()} pages\")\nprint(f\"Markdown length: {len(markdown)} characters\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#example-2-vision-pipeline-for-complex-layout","title":"Example 2: Vision Pipeline for Complex Layout","text":"<pre><code>from docling_graph.core.extractors import DocumentProcessor\n\n# Initialize with vision pipeline\nprocessor = DocumentProcessor(docling_config=\"vision\")\n\n# Convert complex document\ndocument = processor.convert_to_docling_doc(\"magazine.pdf\")\n\n# Extract per-page markdown\npages = processor.extract_page_markdowns(document)\n\nfor i, page in enumerate(pages, 1):\n    print(f\"Page {i}: {len(page)} characters\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#example-3-batch-processing","title":"Example 3: Batch Processing","text":"<pre><code>from docling_graph.core.extractors import DocumentProcessor\nfrom pathlib import Path\n\n# Initialize processor once\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\n# Process multiple documents\nfor pdf_file in Path(\"documents\").glob(\"*.pdf\"):\n    print(f\"Processing {pdf_file.name}\")\n\n    document = processor.convert_to_docling_doc(str(pdf_file))\n    markdown = processor.extract_full_markdown(document)\n\n    # Save markdown\n    output_file = pdf_file.with_suffix(\".md\")\n    output_file.write_text(markdown)\n\n# Cleanup resources\nprocessor.cleanup()\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#integration-with-pipeline","title":"Integration with Pipeline","text":""},{"location":"fundamentals/extraction-process/document-conversion/#automatic-conversion","title":"Automatic Conversion","text":"<p>When using PipelineConfig, conversion happens automatically:</p> <pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"ocr\"  # Conversion happens automatically\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#manual-conversion","title":"Manual Conversion","text":"<p>For more control, use DocumentProcessor directly:</p> <pre><code>from docling_graph.core.extractors import DocumentProcessor\n\n# Manual conversion\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n\n# Now use document for extraction\n# ... extraction code ...\n\n# Cleanup\nprocessor.cleanup()\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#export-options","title":"Export Options","text":""},{"location":"fundamentals/extraction-process/document-conversion/#export-docling-json","title":"Export Docling JSON","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_docling_json=True  # Export DoclingDocument as JSON\n)\n</code></pre> <p>Output: <code>outputs/document.json</code></p>"},{"location":"fundamentals/extraction-process/document-conversion/#export-markdown","title":"Export Markdown","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_markdown=True  # Export as markdown\n)\n</code></pre> <p>Output: <code>outputs/document.md</code></p>"},{"location":"fundamentals/extraction-process/document-conversion/#export-per-page-markdown","title":"Export Per-Page Markdown","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_per_page_markdown=True  # Export each page\n)\n</code></pre> <p>Output: <code>outputs/pages/page_001.md</code>, <code>page_002.md</code>, etc.</p>"},{"location":"fundamentals/extraction-process/document-conversion/#advanced-features","title":"Advanced Features","text":""},{"location":"fundamentals/extraction-process/document-conversion/#custom-pipeline-options","title":"Custom Pipeline Options","text":"<p>For advanced use cases, you can customize the pipeline:</p> <pre><code>from docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.datamodel.accelerator_options import AcceleratorOptions, AcceleratorDevice\n\n# Create custom options\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.do_table_structure = True\npipeline_options.ocr_options.lang = [\"en\", \"de\", \"fr\"]  # Multiple languages\n\n# Set accelerator options\npipeline_options.accelerator_options = AcceleratorOptions(\n    num_threads=8,  # More threads\n    device=AcceleratorDevice.CUDA  # Force GPU\n)\n\n# Note: This requires modifying DocumentProcessor source code\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/document-conversion/#issue-conversion-fails","title":"Issue: Conversion Fails","text":"<p>Solution: <pre><code>try:\n    document = processor.convert_to_docling_doc(\"document.pdf\")\nexcept Exception as e:\n    print(f\"Conversion failed: {e}\")\n    # Check if file exists\n    # Check if file is valid PDF\n    # Try with different pipeline\n</code></pre></p>"},{"location":"fundamentals/extraction-process/document-conversion/#issue-poor-ocr-quality","title":"Issue: Poor OCR Quality","text":"<p>Solution: <pre><code># Try Vision pipeline instead\nprocessor = DocumentProcessor(docling_config=\"vision\")\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n</code></pre></p>"},{"location":"fundamentals/extraction-process/document-conversion/#issue-slow-conversion","title":"Issue: Slow Conversion","text":"<p>Solution: <pre><code># Use OCR pipeline (faster)\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\n# Or process in batches\n# ... batch processing code ...\n</code></pre></p>"},{"location":"fundamentals/extraction-process/document-conversion/#issue-out-of-memory","title":"Issue: Out of Memory","text":"<p>Solution: <pre><code># Process pages individually\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"large_doc.pdf\")\n\n# Extract per-page to reduce memory\npages = processor.extract_page_markdowns(document)\n\n# Process each page separately\nfor page in pages:\n    # ... process page ...\n    pass\n\n# Cleanup\nprocessor.cleanup()\n</code></pre></p>"},{"location":"fundamentals/extraction-process/document-conversion/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/document-conversion/#1-choose-the-right-pipeline","title":"1. Choose the Right Pipeline","text":"<pre><code># \u2705 Good - Match pipeline to document type\nif document_is_standard:\n    docling_config = \"ocr\"  # Faster\nelse:\n    docling_config = \"vision\"  # More accurate\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#2-cleanup-resources","title":"2. Cleanup Resources","text":"<pre><code># \u2705 Good - Always cleanup\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ntry:\n    document = processor.convert_to_docling_doc(\"document.pdf\")\n    # ... process document ...\nfinally:\n    processor.cleanup()\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#3-reuse-processor-for-batch-processing","title":"3. Reuse Processor for Batch Processing","text":"<pre><code># \u2705 Good - Reuse processor\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\nfor pdf_file in pdf_files:\n    document = processor.convert_to_docling_doc(pdf_file)\n    # ... process ...\n\nprocessor.cleanup()\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#4-export-for-debugging","title":"4. Export for Debugging","text":"<pre><code># \u2705 Good - Export markdown for inspection\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_markdown=True,  # Check conversion quality\n    export_per_page_markdown=True  # Debug per page\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#next-steps","title":"Next Steps","text":"<p>Now that you understand document conversion:</p> <ol> <li>Chunking Strategies \u2192 - Learn intelligent document splitting</li> <li>Extraction Backends \u2192 - Choose LLM or VLM backend</li> <li>Model Merging \u2192 - Consolidate extractions</li> </ol>"},{"location":"fundamentals/extraction-process/document-conversion/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/extraction-process/document-conversion/#ocr-pipeline-default_1","title":"OCR Pipeline (Default)","text":"<pre><code>processor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#vision-pipeline_1","title":"Vision Pipeline","text":"<pre><code>processor = DocumentProcessor(docling_config=\"vision\")\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#extract-markdown","title":"Extract Markdown","text":"<pre><code># Full document\nmarkdown = processor.extract_full_markdown(document)\n\n# Per page\npages = processor.extract_page_markdowns(document)\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#cleanup","title":"Cleanup","text":"<pre><code>processor.cleanup()\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/","title":"Extraction Backends","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#overview","title":"Overview","text":"<p>Extraction backends are the engines that extract structured data from documents. Docling Graph supports two types: LLM backends (text-based) and VLM backends (vision-based).</p> <p>In this guide: - LLM vs VLM comparison - Backend selection criteria - Configuration and usage - Model capability tiers - Performance optimization - Error handling</p> <p>New: Model Capability Detection</p> <p>Docling Graph now automatically detects model capabilities and adapts prompts and consolidation strategies based on model size. See Model Capabilities for details.</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#backend-types","title":"Backend Types","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#quick-comparison","title":"Quick Comparison","text":"Feature LLM Backend VLM Backend Input Markdown text Images/PDFs directly Processing Text-based Vision-based Accuracy High for text High for visuals Speed Fast Slower Cost Low (local) / Medium (API) Medium GPU Optional Recommended Best For Standard documents Complex layouts"},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend","title":"LLM Backend","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#what-is-llm-backend","title":"What is LLM Backend?","text":"<p>The LLM (Language Model) backend processes documents as text, using markdown extracted from PDFs. It supports both local and remote models.</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#architecture","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: procs, label: \"Docling Conversion\" }\n    C@{ shape: doc, label: \"Markdown Text\" }\n    D@{ shape: tag-proc, label: \"Chunking Optional\" }\n    E@{ shape: procs, label: \"LLM Extraction\" }\n\n    F@{ shape: doc, label: \"Structured Data\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,E process\n    class C data\n    class D operator\n    class F output</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",           # LLM backend\n    inference=\"local\",       # or \"remote\"\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\"\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#model-capability-detection","title":"Model Capability Detection","text":"<p>Docling Graph automatically detects model capabilities based on parameter count and adapts its behavior:</p> <pre><code>from docling_graph import PipelineConfig\n\n# Small model (1B-7B) - Uses SIMPLE tier\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.2:3b\"  # Automatically detected as SIMPLE\n)\n\n# Medium model (7B-13B) - Uses STANDARD tier\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\"  # Automatically detected as STANDARD\n)\n\n# Large model (13B+) - Uses ADVANCED tier\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\"  # Automatically detected as ADVANCED\n)\n</code></pre> <p>Capability Tiers:</p> Tier Model Size Prompt Style Consolidation SIMPLE 1B-7B Minimal instructions Basic merge STANDARD 7B-13B Balanced instructions Standard merge ADVANCED 13B+ Detailed instructions Chain of Density <p>See Model Capabilities for complete details.</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend-features","title":"LLM Backend Features","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#strengths","title":"\u2705 Strengths","text":"<ol> <li>Fast Processing</li> <li>Quick text extraction</li> <li>Efficient chunking</li> <li> <p>Parallel processing</p> </li> <li> <p>Cost Effective</p> </li> <li>Local models are free</li> <li>Remote APIs are affordable</li> <li> <p>No GPU required (local)</p> </li> <li> <p>Flexible</p> </li> <li>Multiple providers</li> <li>Easy to switch models</li> <li> <p>API or local</p> </li> <li> <p>Accurate for Text</p> </li> <li>Excellent for standard documents</li> <li>Good table understanding</li> <li>Strong reasoning</li> </ol>"},{"location":"fundamentals/extraction-process/extraction-backends/#limitations","title":"\u274c Limitations","text":"<ol> <li>Text-Only</li> <li>No visual understanding</li> <li>Relies on OCR quality</li> <li> <p>May miss layout cues</p> </li> <li> <p>Context Limits</p> </li> <li>Requires chunking for large docs</li> <li>May lose cross-page context</li> <li>Needs merging</li> </ol>"},{"location":"fundamentals/extraction-process/extraction-backends/#supported-providers","title":"Supported Providers","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#local-providers","title":"Local Providers","text":"<p>Ollama: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\"\n)\n</code></pre></p> <p>vLLM: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"vllm\",\n    model_override=\"ibm-granite/granite-4.0-1b\"\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#remote-providers","title":"Remote Providers","text":"<p>Mistral AI: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\"\n)\n</code></pre></p> <p>OpenAI: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\"\n)\n</code></pre></p> <p>Google Gemini: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"gemini\",\n    model_override=\"gemini-2.5-flash\"\n)\n</code></pre></p> <p>IBM watsonx: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"watsonx\",\n    model_override=\"ibm/granite-13b-chat-v2\"\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend-usage","title":"LLM Backend Usage","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#basic-extraction","title":"Basic Extraction","text":"<pre><code>from docling_graph.core.extractors.backends import LlmBackend\nfrom docling_graph.llm_clients import OllamaClient\n\n# Initialize client\nclient = OllamaClient(model=\"llama3.1:8b\")\n\n# Create backend\nbackend = LlmBackend(llm_client=client)\n\n# Extract from markdown\nmodel = backend.extract_from_markdown(\n    markdown=\"# Invoice\\n\\nInvoice Number: INV-001\\nTotal: $1000\",\n    template=InvoiceTemplate,\n    context=\"full document\",\n    is_partial=False\n)\n\nprint(model)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#with-consolidation","title":"With Consolidation","text":"<pre><code># Extract from multiple chunks\nmodels = []\nfor chunk in chunks:\n    model = backend.extract_from_markdown(\n        markdown=chunk,\n        template=InvoiceTemplate,\n        context=f\"chunk {i}\",\n        is_partial=True\n    )\n    if model:\n        models.append(model)\n\n# Consolidate with LLM\nfrom docling_graph.core.utils import merge_pydantic_models\n\nprogrammatic_merge = merge_pydantic_models(models, InvoiceTemplate)\n\nfinal_model = backend.consolidate_from_pydantic_models(\n    raw_models=models,\n    programmatic_model=programmatic_merge,\n    template=InvoiceTemplate\n)\n</code></pre> <p>Chain of Density Consolidation</p> <p>For ADVANCED tier models (13B+), consolidation uses a multi-turn \"Chain of Density\" approach:</p> <ol> <li>Initial Merge: Create first consolidated version</li> <li>Refinement: Identify and resolve conflicts</li> <li>Final Polish: Ensure completeness and accuracy</li> </ol> <p>This produces higher quality results but uses more tokens. See Model Capabilities.</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-backend","title":"VLM Backend","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#what-is-vlm-backend","title":"What is VLM Backend?","text":"<p>The VLM (Vision-Language Model) backend processes documents visually, understanding layout, images, and text together like a human would.</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#architecture_1","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    InputPDF@{ shape: terminal, label: \"PDF Document\" }\n    InputImg@{ shape: terminal, label: \"Images\" }\n\n    Convert@{ shape: procs, label: \"PDF to Image&lt;br&gt;Conversion\" }\n    PageImgs@{ shape: doc, label: \"Page Images\" }\n\n    VLM@{ shape: procs, label: \"VLM Processing\" }\n    Understand@{ shape: lin-proc, label: \"Visual Understanding\" }\n    Extract@{ shape: tag-proc, label: \"Direct Extraction\" }\n\n    Output@{ shape: doc, label: \"Pydantic Models\" }\n\n    %% 3. Define Connections\n    %% Path A: PDF requires conversion\n    InputPDF --&gt; Convert\n    Convert --&gt; PageImgs\n    PageImgs --&gt; VLM\n\n    %% Path B: Direct Image Input (Merges here)\n    InputImg --&gt; VLM\n\n    %% Shared Processing Chain\n    VLM --&gt; Understand\n    Understand --&gt; Extract\n    Extract --&gt; Output\n\n    %% 4. Apply Classes\n    class InputPDF,InputImg input\n    class Convert,VLM,Understand process\n    class PageImgs data\n    class Extract operator\n    class Output output</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",                      # VLM backend\n    inference=\"local\",                  # Only local supported\n    model_override=\"numind/NuExtract-2.0-8B\"\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-backend-features","title":"VLM Backend Features","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#strengths_1","title":"\u2705 Strengths","text":"<ol> <li>Visual Understanding</li> <li>Sees layout and structure</li> <li>Understands images</li> <li> <p>Handles complex formats</p> </li> <li> <p>No Chunking Needed</p> </li> <li>Processes pages directly</li> <li>No context window limits</li> <li> <p>Simpler pipeline</p> </li> <li> <p>Robust to OCR Issues</p> </li> <li>Doesn't rely on OCR</li> <li>Handles poor quality</li> <li> <p>Better for handwriting</p> </li> <li> <p>Layout Aware</p> </li> <li>Understands visual hierarchy</li> <li>Recognizes forms</li> <li>Detects tables visually</li> </ol>"},{"location":"fundamentals/extraction-process/extraction-backends/#limitations_1","title":"\u274c Limitations","text":"<ol> <li>Slower</li> <li>More computation</li> <li>GPU recommended</li> <li> <p>Longer processing time</p> </li> <li> <p>Local Only</p> </li> <li>No remote API support</li> <li>Requires local GPU</li> <li> <p>Higher resource usage</p> </li> <li> <p>Model Size</p> </li> <li>Large models (2B-8B params)</li> <li>More memory needed</li> <li>Longer startup time</li> </ol>"},{"location":"fundamentals/extraction-process/extraction-backends/#supported-models","title":"Supported Models","text":"<p>NuExtract 2.0 (Recommended): <pre><code># 2B model (faster, less accurate)\nmodel_override=\"numind/NuExtract-2.0-2B\"\n\n# 8B model (slower, more accurate)\nmodel_override=\"numind/NuExtract-2.0-8B\"\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-backend-usage","title":"VLM Backend Usage","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#basic-extraction_1","title":"Basic Extraction","text":"<pre><code>from docling_graph.core.extractors.backends import VlmBackend\n\n# Initialize backend\nbackend = VlmBackend(model_name=\"numind/NuExtract-2.0-8B\")\n\n# Extract from document\nmodels = backend.extract_from_document(\n    source=\"document.pdf\",\n    template=InvoiceTemplate\n)\n\nprint(f\"Extracted {len(models)} models\")\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#with-pipeline","title":"With Pipeline","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"complex_form.pdf\",\n    template=\"my_templates.ApplicationForm\",\n    backend=\"vlm\",\n    inference=\"local\",\n    processing_mode=\"one-to-one\"  # One model per page\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#backend-selection","title":"Backend Selection","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#decision-matrix","title":"Decision Matrix","text":"Document Type Recommended Backend Reason Standard invoices LLM Fast, accurate for text Complex forms VLM Better layout understanding Research papers LLM Good for text-heavy docs Handwritten forms VLM Handles handwriting better Scanned documents VLM Robust to poor quality Multi-page contracts LLM Efficient chunking Image-heavy docs VLM Visual understanding Batch processing LLM Faster throughput"},{"location":"fundamentals/extraction-process/extraction-backends/#selection-criteria","title":"Selection Criteria","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#choose-llm-backend-when","title":"Choose LLM Backend When:","text":"<p>\u2705 Document is text-heavy \u2705 Need fast processing \u2705 Want to use remote APIs \u2705 Processing many documents \u2705 Standard layout \u2705 Good OCR quality  </p>"},{"location":"fundamentals/extraction-process/extraction-backends/#choose-vlm-backend-when","title":"Choose VLM Backend When:","text":"<p>\u2705 Complex visual layout \u2705 Poor OCR quality \u2705 Handwritten content \u2705 Image-heavy documents \u2705 Form-based extraction \u2705 Have GPU available  </p>"},{"location":"fundamentals/extraction-process/extraction-backends/#performance-comparison","title":"Performance Comparison","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#speed-benchmark","title":"Speed Benchmark","text":"Backend Document Type Pages Time Throughput LLM (Local) Invoice 1 2s 30 docs/min LLM (Remote) Invoice 1 3s 20 docs/min VLM (Local) Invoice 1 8s 7 docs/min LLM (Local) Contract 10 15s 4 docs/min VLM (Local) Contract 10 60s 1 doc/min <p>Note: Times are approximate and vary by hardware.</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#accuracy-comparison","title":"Accuracy Comparison","text":"Document Type LLM Accuracy VLM Accuracy Winner Standard invoice 95% 93% LLM Complex form 85% 95% VLM Handwritten 70% 90% VLM Research paper 92% 88% LLM Poor scan 75% 88% VLM"},{"location":"fundamentals/extraction-process/extraction-backends/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#example-1-llm-backend-local","title":"Example 1: LLM Backend (Local)","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"my_templates.Invoice\",\n\n    # LLM backend with Ollama\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n\n    # Optimized settings\n    use_chunking=True,\n    processing_mode=\"many-to-one\",\n\n    output_dir=\"outputs/llm_local\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#example-2-llm-backend-remote","title":"Example 2: LLM Backend (Remote)","text":"<pre><code>from docling_graph import PipelineConfig\nimport os\n\n# Set API key\nos.environ[\"MISTRAL_API_KEY\"] = \"your_api_key\"\n\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"my_templates.Contract\",\n\n    # LLM backend with Mistral API\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n\n    # High accuracy settings\n    use_chunking=True,\n    llm_consolidation=True,\n    processing_mode=\"many-to-one\",\n\n    output_dir=\"outputs/llm_remote\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#example-3-vlm-backend","title":"Example 3: VLM Backend","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"complex_form.pdf\",\n    template=\"my_templates.ApplicationForm\",\n\n    # VLM backend\n    backend=\"vlm\",\n    inference=\"local\",\n    model_override=\"numind/NuExtract-2.0-8B\",\n\n    # VLM settings\n    processing_mode=\"one-to-one\",  # One model per page\n    docling_config=\"vision\",       # Vision pipeline\n    use_chunking=False,            # VLM doesn't need chunking\n\n    output_dir=\"outputs/vlm\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#example-4-hybrid-approach","title":"Example 4: Hybrid Approach","text":"<pre><code>from docling_graph import PipelineConfig\n\ndef process_document(doc_path: str, doc_type: str):\n    \"\"\"Process document with appropriate backend.\"\"\"\n\n    if doc_type == \"form\":\n        # Use VLM for forms\n        backend = \"vlm\"\n        inference = \"local\"\n        processing_mode = \"one-to-one\"\n    else:\n        # Use LLM for standard docs\n        backend = \"llm\"\n        inference = \"remote\"\n        processing_mode = \"many-to-one\"\n\n    config = PipelineConfig(\n        source=doc_path,\n        template=f\"my_templates.{doc_type.capitalize()}\",\n        backend=backend,\n        inference=inference,\n        processing_mode=processing_mode\n    )\n\n    config.run()\n\n# Process different document types\nprocess_document(\"invoice.pdf\", \"invoice\")  # LLM\nprocess_document(\"form.pdf\", \"form\")        # VLM\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#error-handling","title":"Error Handling","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend-errors","title":"LLM Backend Errors","text":"<pre><code>from docling_graph.exceptions import ExtractionError\n\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"my_templates.Invoice\",\n        backend=\"llm\",\n        inference=\"remote\"\n    )\n    config.run()\n\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n    print(f\"Details: {e.details}\")\n\n    # Fallback to local\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"my_templates.Invoice\",\n        backend=\"llm\",\n        inference=\"local\"\n    )\n    config.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-backend-errors","title":"VLM Backend Errors","text":"<pre><code>from docling_graph.exceptions import ExtractionError\n\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"my_templates.Invoice\",\n        backend=\"vlm\"\n    )\n    config.run()\n\nexcept ExtractionError as e:\n    print(f\"VLM extraction failed: {e.message}\")\n\n    # Fallback to LLM\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"my_templates.Invoice\",\n        backend=\"llm\",\n        inference=\"local\"\n    )\n    config.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#1-match-backend-to-document-type","title":"1. Match Backend to Document Type","text":"<pre><code># \u2705 Good - Choose based on document\nif document_is_form:\n    backend = \"vlm\"\nelif document_is_standard:\n    backend = \"llm\"\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#2-use-local-for-development","title":"2. Use Local for Development","text":"<pre><code># \u2705 Good - Fast iteration\nconfig = PipelineConfig(\n    source=\"test.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\"  # Fast for testing\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#3-use-remote-for-production","title":"3. Use Remote for Production","text":"<pre><code># \u2705 Good - Reliable and scalable\nconfig = PipelineConfig(\n    source=\"production.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\"  # Reliable\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#4-cleanup-resources","title":"4. Cleanup Resources","text":"<pre><code># \u2705 Good - Always cleanup\nfrom docling_graph.core.extractors.backends import VlmBackend\n\nbackend = VlmBackend(model_name=\"numind/NuExtract-2.0-8B\")\ntry:\n    models = backend.extract_from_document(source, template)\nfinally:\n    backend.cleanup()  # Free GPU memory\n</code></pre> <p>Enhanced GPU Cleanup</p> <p>VLM backend now includes enhanced GPU memory management:</p> <ul> <li>Model-to-CPU Transfer: Moves model to CPU before deletion</li> <li>CUDA Cache Clearing: Explicitly clears GPU cache</li> <li>Memory Tracking: Logs memory usage before/after cleanup</li> <li>Multi-GPU Support: Handles multiple GPU devices</li> </ul> <p>This ensures GPU memory is properly released, especially important for long-running processes.</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#5-use-real-tokenizers","title":"5. Use Real Tokenizers","text":"<pre><code># \u2705 Good - Accurate token counting\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n    use_chunking=True  # Uses real tokenizer with 20% safety margin\n)\n</code></pre> <p>Benefits: - Prevents context window overflows - More efficient chunk packing - Better resource utilization</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#issue-llm-returns-empty-results","title":"Issue: LLM Returns Empty Results","text":"<p>Solution: <pre><code># Check markdown extraction\nfrom docling_graph.core.extractors import DocumentProcessor\n\nprocessor = DocumentProcessor()\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\nmarkdown = processor.extract_full_markdown(document)\n\nif not markdown.strip():\n    print(\"Markdown extraction failed\")\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#issue-vlm-out-of-memory","title":"Issue: VLM Out of Memory","text":"<p>Solution: <pre><code># Use smaller model\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",\n    model_override=\"numind/NuExtract-2.0-2B\"  # Smaller model\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#issue-slow-vlm-processing","title":"Issue: Slow VLM Processing","text":"<p>Solution: <pre><code># Switch to LLM for speed\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",  # Faster\n    inference=\"local\"\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#advanced-features","title":"Advanced Features","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#provider-specific-batching","title":"Provider-Specific Batching","text":"<p>Different LLM providers have different optimal batching strategies:</p> <pre><code>from docling_graph import PipelineConfig\n\n# OpenAI - Aggressive batching (90% merge threshold)\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",\n    use_chunking=True  # Automatically uses 90% threshold\n)\n\n# Anthropic - Conservative batching (85% threshold)\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"anthropic\",\n    model_override=\"claude-3-opus\",\n    use_chunking=True  # Automatically uses 85% threshold\n)\n\n# Ollama - Very conservative (75% threshold)\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n    use_chunking=True  # Automatically uses 75% threshold\n)\n</code></pre> <p>Why Different Thresholds? - OpenAI/Google: Robust to near-limit contexts \u2192 aggressive batching - Anthropic: More conservative \u2192 moderate batching - Ollama/Local: Variable performance \u2192 conservative batching</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#next-steps","title":"Next Steps","text":"<p>Now that you understand extraction backends:</p> <ol> <li>Model Capabilities \u2192 - Learn about adaptive prompting</li> <li>Model Merging \u2192 - Learn how to consolidate extractions</li> <li>Batch Processing \u2192 - Optimize chunk processing</li> <li>Performance Tuning \u2192 - Advanced optimization</li> </ol>"},{"location":"fundamentals/extraction-process/extraction-backends/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend-local","title":"LLM Backend (Local)","text":"<pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\"\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend-remote","title":"LLM Backend (Remote)","text":"<pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\"\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-backend_1","title":"VLM Backend","text":"<pre><code>config = PipelineConfig(\n    backend=\"vlm\",\n    inference=\"local\",\n    model_override=\"numind/NuExtract-2.0-8B\"\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-capabilities/","title":"Model Capabilities","text":""},{"location":"fundamentals/extraction-process/model-capabilities/#overview","title":"Overview","text":"<p>Docling-Graph automatically classifies models into three capability tiers to optimize extraction quality and performance. This intelligent system adapts prompts, consolidation strategies, and processing approaches based on model size and capabilities.</p> <p>What You'll Learn: - Model capability tier system - Automatic model detection - Adaptive behavior per tier - Performance implications - Supported models by tier</p>"},{"location":"fundamentals/extraction-process/model-capabilities/#model-capability-tiers","title":"Model Capability Tiers","text":""},{"location":"fundamentals/extraction-process/model-capabilities/#tier-classification","title":"Tier Classification","text":"Tier Model Size Characteristics Use Cases SIMPLE 1B-7B params Fast, basic understanding Simple forms, invoices, quick extraction STANDARD 7B-13B params Balanced speed/accuracy General documents, contracts ADVANCED 13B+ params High accuracy, complex reasoning Research papers, legal documents, complex analysis"},{"location":"fundamentals/extraction-process/model-capabilities/#automatic-detection","title":"Automatic Detection","text":"<p>Models are automatically classified based on their name and known characteristics:</p> <pre><code>from docling_graph.llm_clients.config import detect_model_capability, ModelCapability\n\n# Automatic detection examples\ncapability = detect_model_capability(\"llama-3.1-8b\")\nprint(capability)  # ModelCapability.STANDARD\n\ncapability = detect_model_capability(\"gpt-4-turbo\")\nprint(capability)  # ModelCapability.ADVANCED\n\ncapability = detect_model_capability(\"granite-4.0-1b\")\nprint(capability)  # ModelCapability.SIMPLE\n</code></pre>"},{"location":"fundamentals/extraction-process/model-capabilities/#detection-logic","title":"Detection Logic","text":"<p>The system uses pattern matching on model names:</p> <ol> <li>Size-based detection: Extracts parameter count from model name (e.g., \"8b\", \"13b\")</li> <li>Known model mapping: Uses pre-classified list of 40+ popular models</li> <li>Fallback heuristics: Conservative defaults for unknown models</li> </ol>"},{"location":"fundamentals/extraction-process/model-capabilities/#adaptive-behavior","title":"Adaptive Behavior","text":"<p>The extraction system automatically adapts based on model capability:</p>"},{"location":"fundamentals/extraction-process/model-capabilities/#simple-models-1b-7b","title":"SIMPLE Models (1B-7B)","text":"<p>Optimized for Speed</p> <ul> <li>\u2705 Minimal Instructions: Focused, concise prompts</li> <li>\u2705 Basic Consolidation: Simple programmatic merging</li> <li>\u2705 Fast Processing: Optimized for throughput</li> <li>\u2705 Lower Memory: Efficient resource usage</li> </ul> <p>Best For: - Simple forms and invoices - Structured data extraction - High-volume processing - Resource-constrained environments</p> <p>Example Models: - <code>ibm-granite/granite-4.0-1b</code> - <code>meta-llama/Llama-3.2-1B</code> - <code>numind/NuExtract-2.0-2B</code></p> <pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\"  # SIMPLE tier\n)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/model-capabilities/#standard-models-7b-13b","title":"STANDARD Models (7B-13B)","text":"<p>Balanced Performance</p> <ul> <li>\u2705 Balanced Instructions: Moderate detail level</li> <li>\u2705 Standard Consolidation: Programmatic + optional LLM</li> <li>\u2705 Good Accuracy: Reliable for most documents</li> <li>\u2705 Reasonable Speed: Good throughput</li> </ul> <p>Best For: - General business documents - Multi-page contracts - Standard extraction tasks - Production workloads</p> <p>Example Models: - <code>meta-llama/Llama-3.1-8B</code> - <code>mistralai/Mistral-7B-v0.1</code> - <code>numind/NuExtract-2.0-8B</code></p> <pre><code>config = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"templates.Contract\",\n    backend=\"llm\",\n    inference=\"local\",\n    model_override=\"meta-llama/Llama-3.1-8B\"  # STANDARD tier\n)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/model-capabilities/#advanced-models-13b","title":"ADVANCED Models (13B+)","text":"<p>Maximum Accuracy</p> <ul> <li>\u2705 Detailed Instructions: Comprehensive prompts</li> <li>\u2705 Chain of Density: Multi-turn consolidation</li> <li>\u2705 High Accuracy: Best extraction quality</li> <li>\u2705 Complex Reasoning: Handles nuanced content</li> </ul> <p>Best For: - Research papers - Legal documents - Complex technical content - High-accuracy requirements</p> <p>Example Models: - <code>gpt-4-turbo</code> (OpenAI) - <code>claude-3.5-sonnet</code> (Anthropic) - <code>gemini-2.5-flash</code> (Google) - <code>mistral-large-latest</code> (Mistral)</p> <pre><code>config = PipelineConfig(\n    source=\"research_paper.pdf\",\n    template=\"templates.ResearchPaper\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",  # ADVANCED tier\n    llm_consolidation=True  # Enable Chain of Density\n)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/model-capabilities/#chain-of-density-consolidation","title":"Chain of Density Consolidation","text":"<p>ADVANCED models automatically use Chain of Density consolidation when <code>llm_consolidation=True</code>:</p>"},{"location":"fundamentals/extraction-process/model-capabilities/#three-step-refinement","title":"Three-Step Refinement","text":"<ol> <li>Initial Extraction: Extract from raw document chunks</li> <li>Refinement: Merge with programmatic consolidation</li> <li>Final Polish: LLM refines for consistency and completeness</li> </ol> <pre><code># Chain of Density is automatic for ADVANCED models\nconfig = PipelineConfig(\n    source=\"complex_document.pdf\",\n    template=\"templates.ComplexTemplate\",\n    backend=\"llm\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",  # ADVANCED tier\n    llm_consolidation=True,  # Enables Chain of Density\n    processing_mode=\"many-to-one\"\n)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/model-capabilities/#when-to-use-chain-of-density","title":"When to Use Chain of Density","text":"<p>\u2705 Use When: - Document has conflicting information - Need highest accuracy - Complex narrative content - Using ADVANCED tier models</p> <p>\u274c Skip When: - Simple structured data - Speed is critical - Using SIMPLE/STANDARD models - Budget constraints</p>"},{"location":"fundamentals/extraction-process/model-capabilities/#supported-models","title":"Supported Models","text":""},{"location":"fundamentals/extraction-process/model-capabilities/#complete-model-list","title":"Complete Model List","text":"<p>See the full list of classified models in <code>models.yaml</code>.</p>"},{"location":"fundamentals/extraction-process/model-capabilities/#simple-tier-1b-7b","title":"SIMPLE Tier (1B-7B)","text":"<p>Local Models: - <code>ibm-granite/granite-4.0-1b</code> - <code>meta-llama/Llama-3.2-1B</code> - <code>meta-llama/Llama-3.2-3B</code> - <code>numind/NuExtract-2.0-2B</code> - <code>Qwen/Qwen2.5-1.5B</code></p>"},{"location":"fundamentals/extraction-process/model-capabilities/#standard-tier-7b-13b","title":"STANDARD Tier (7B-13B)","text":"<p>Local Models: - <code>meta-llama/Llama-3.1-8B</code> - <code>mistralai/Mistral-7B-v0.1</code> - <code>numind/NuExtract-2.0-8B</code> - <code>Qwen/Qwen2.5-7B</code></p> <p>Remote APIs: - <code>mistral-small-latest</code> (Mistral) - <code>gemini-1.5-flash</code> (Google)</p>"},{"location":"fundamentals/extraction-process/model-capabilities/#advanced-tier-13b","title":"ADVANCED Tier (13B+)","text":"<p>Remote APIs: - <code>gpt-4-turbo</code> (OpenAI) - <code>gpt-4o</code> (OpenAI) - <code>claude-3.5-sonnet</code> (Anthropic) - <code>claude-3-opus</code> (Anthropic) - <code>gemini-2.5-flash</code> (Google) - <code>gemini-2.5-pro</code> (Google) - <code>mistral-large-latest</code> (Mistral) - <code>mistral-medium-latest</code> (Mistral)</p> <p>IBM WatsonX: - <code>ibm/granite-13b-chat-v2</code> - <code>meta-llama/llama-3-1-70b-instruct</code></p>"},{"location":"fundamentals/extraction-process/model-capabilities/#performance-implications","title":"Performance Implications","text":""},{"location":"fundamentals/extraction-process/model-capabilities/#speed-vs-accuracy-trade-off","title":"Speed vs Accuracy Trade-off","text":"Tier Speed Accuracy Memory Cost SIMPLE \u26a1\u26a1\u26a1 Very Fast \ud83d\udfe1 Moderate 2-4 GB $ Low STANDARD \u26a1\u26a1 Fast \ud83d\udfe2 Good 8-16 GB $$ Medium ADVANCED \u26a1 Moderate \ud83d\udc8e Excellent 16-32 GB $$$ High"},{"location":"fundamentals/extraction-process/model-capabilities/#benchmark-results","title":"Benchmark Results","text":"<p>Document: 10-page contract</p> Model Tier Time Accuracy Tokens Used SIMPLE (1B) 15s 85% 2,500 STANDARD (8B) 45s 92% 3,200 ADVANCED (GPT-4) 90s 97% 4,100"},{"location":"fundamentals/extraction-process/model-capabilities/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/model-capabilities/#1-match-tier-to-task-complexity","title":"1. Match Tier to Task Complexity","text":"<pre><code># \u2705 Good - Simple task, simple model\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.Invoice\",\n    model_override=\"granite-4.0-1b\"  # SIMPLE tier\n)\n\n# \u2705 Good - Complex task, advanced model\nconfig = PipelineConfig(\n    source=\"research_paper.pdf\",\n    template=\"templates.ResearchPaper\",\n    model_override=\"gpt-4-turbo\"  # ADVANCED tier\n)\n\n# \u274c Avoid - Overkill\nconfig = PipelineConfig(\n    source=\"simple_form.pdf\",\n    template=\"templates.SimpleForm\",\n    model_override=\"gpt-4-turbo\"  # Unnecessary\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-capabilities/#2-start-small-scale-up","title":"2. Start Small, Scale Up","text":"<pre><code># Start with SIMPLE tier\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    model_override=\"granite-4.0-1b\"\n)\nresult = config.run()\n\n# If accuracy insufficient, upgrade to STANDARD\nif accuracy_check(result) &lt; 0.90:\n    config.model_override = \"llama-3.1-8b\"\n    result = config.run()\n\n# If still insufficient, upgrade to ADVANCED\nif accuracy_check(result) &lt; 0.95:\n    config.model_override = \"gpt-4-turbo\"\n    config.llm_consolidation = True\n    result = config.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/model-capabilities/#3-use-chain-of-density-wisely","title":"3. Use Chain of Density Wisely","text":"<pre><code># \u2705 Good - Complex document with ADVANCED model\nconfig = PipelineConfig(\n    source=\"complex_legal.pdf\",\n    template=\"templates.LegalDocument\",\n    model_override=\"gpt-4-turbo\",  # ADVANCED\n    llm_consolidation=True  # Enable Chain of Density\n)\n\n# \u274c Avoid - Chain of Density with SIMPLE model\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.Invoice\",\n    model_override=\"granite-4.0-1b\",  # SIMPLE\n    llm_consolidation=True  # Won't use Chain of Density\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-capabilities/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/model-capabilities/#issue-model-not-detected-correctly","title":"Issue: Model Not Detected Correctly","text":"<p>Solution: <pre><code># Override automatic detection\nfrom docling_graph.llm_clients.config import ModelCapability\n\n# Force specific capability\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    model_override=\"custom-model-7b\",\n    # Note: Capability override not directly exposed\n    # Model will be detected based on name patterns\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-capabilities/#issue-poor-accuracy-with-simple-model","title":"Issue: Poor Accuracy with SIMPLE Model","text":"<p>Solution: <pre><code># Upgrade to STANDARD or ADVANCED tier\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    model_override=\"llama-3.1-8b\"  # STANDARD tier\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-capabilities/#issue-slow-processing-with-advanced-model","title":"Issue: Slow Processing with ADVANCED Model","text":"<p>Solution: <pre><code># Try STANDARD tier first\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    model_override=\"mistral-small-latest\"  # STANDARD tier\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-capabilities/#next-steps","title":"Next Steps","text":"<p>Now that you understand model capabilities:</p> <ol> <li>Extraction Backends \u2192 - Learn about LLM and VLM backends</li> <li>Model Configuration \u2192 - Configure model settings</li> <li>Performance Tuning \u2192 - Optimize for your use case</li> </ol>"},{"location":"fundamentals/extraction-process/model-capabilities/#related-documentation","title":"Related Documentation","text":"<ul> <li>Model Configuration - Detailed model settings</li> <li>Extraction Backends - Backend selection guide</li> <li>Performance Tuning - Optimization strategies</li> <li>Model Merging - Consolidation strategies</li> </ul>"},{"location":"fundamentals/extraction-process/model-merging/","title":"Model Merging","text":""},{"location":"fundamentals/extraction-process/model-merging/#overview","title":"Overview","text":"<p>Model merging is the process of consolidating multiple Pydantic model instances into a single unified model. This is essential when extracting from multiple chunks or pages.</p> <p>In this guide: - Why merging is needed - Programmatic vs LLM merging - Chain of Density consolidation - Zero data loss strategies - Deduplication strategies - Conflict resolution - Best practices</p> <p>New: Chain of Density Consolidation</p> <p>For ADVANCED tier models (13B+), LLM consolidation now uses a multi-turn \"Chain of Density\" approach for higher quality results. See Model Capabilities for details.</p>"},{"location":"fundamentals/extraction-process/model-merging/#why-merging-matters","title":"Why Merging Matters","text":""},{"location":"fundamentals/extraction-process/model-merging/#the-multi-extraction-problem","title":"The Multi-Extraction Problem","text":"<p>When processing large documents:</p> <pre><code># Document split into 3 chunks\nchunk_1 = \"Invoice INV-001, Issued by: Acme Corp\"\nchunk_2 = \"Line items: Product A ($50), Product B ($100)\"\nchunk_3 = \"Total: $150, Due date: 2024-01-31\"\n\n# Each chunk produces a partial model\nmodel_1 = Invoice(invoice_number=\"INV-001\", issued_by=Organization(name=\"Acme Corp\"))\nmodel_2 = Invoice(line_items=[LineItem(...), LineItem(...)])\nmodel_3 = Invoice(total=150, due_date=\"2024-01-31\")\n\n# Need to merge into one complete model\nfinal_model = merge(model_1, model_2, model_3)\n</code></pre> <p>Without merging: Incomplete, fragmented data With merging: Complete, unified model</p>"},{"location":"fundamentals/extraction-process/model-merging/#merging-strategies","title":"Merging Strategies","text":""},{"location":"fundamentals/extraction-process/model-merging/#quick-comparison","title":"Quick Comparison","text":"Strategy Speed Accuracy Cost Use Case Programmatic \u26a1 Fast \ud83d\udfe1 Good (90%) Free Default, simple merging LLM (Standard) \ud83d\udc22 Slow \ud83d\udfe2 Better (95%) $ API cost High accuracy needs LLM (Chain of Density) \ud83d\udc0c Very Slow \ud83d\udc8e Best (98%) $$$ 3x API cost Critical documents <p>Zero Data Loss</p> <p>All merging strategies now implement zero data loss - if merging fails, the system returns partial models instead of empty results.</p>"},{"location":"fundamentals/extraction-process/model-merging/#programmatic-merging","title":"Programmatic Merging","text":""},{"location":"fundamentals/extraction-process/model-merging/#what-is-programmatic-merging","title":"What is Programmatic Merging?","text":"<p>Programmatic merging uses rule-based algorithms to combine models without LLM calls. It's fast, free, and works well for most cases.</p>"},{"location":"fundamentals/extraction-process/model-merging/#how-it-works","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Model 1\" }\n    B@{ shape: terminal, label: \"Model 2\" }\n    C@{ shape: terminal, label: \"Model 3\" }\n\n    D@{ shape: lin-proc, label: \"Deep Merge\" }\n    E@{ shape: tag-proc, label: \"Deduplicate\" }\n    F@{ shape: tag-proc, label: \"Validate\" }\n\n    G@{ shape: doc, label: \"Final Model\" }\n\n    %% 3. Define Connections\n    A &amp; B &amp; C --&gt; D\n\n    D --&gt; E\n    E --&gt; F\n    F --&gt; G\n\n    %% 4. Apply Classes\n    class A,B,C data\n    class D process\n    class E,F operator\n    class G output</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph.core.utils import merge_pydantic_models\n\n# Multiple partial models\nmodels = [\n    Invoice(invoice_number=\"INV-001\", issued_by=Organization(name=\"Acme\")),\n    Invoice(line_items=[LineItem(description=\"Product A\", total=50)]),\n    Invoice(total=150, due_date=\"2024-01-31\")\n]\n\n# Merge programmatically\nmerged = merge_pydantic_models(models, Invoice)\n\nprint(merged)\n# Invoice(\n#     invoice_number=\"INV-001\",\n#     issued_by=Organization(name=\"Acme\"),\n#     line_items=[LineItem(description=\"Product A\", total=50)],\n#     total=150,\n#     due_date=\"2024-01-31\"\n# )\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#merge-rules","title":"Merge Rules","text":""},{"location":"fundamentals/extraction-process/model-merging/#1-field-overwriting","title":"1. Field Overwriting","text":"<p>Rule: Non-empty values overwrite empty ones</p> <pre><code># Model 1\nInvoice(invoice_number=\"INV-001\", total=None)\n\n# Model 2\nInvoice(invoice_number=None, total=150)\n\n# Merged\nInvoice(invoice_number=\"INV-001\", total=150)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#2-list-concatenation","title":"2. List Concatenation","text":"<p>Rule: Lists are concatenated and deduplicated</p> <pre><code># Model 1\nInvoice(line_items=[LineItem(description=\"Product A\")])\n\n# Model 2\nInvoice(line_items=[LineItem(description=\"Product B\")])\n\n# Merged\nInvoice(line_items=[\n    LineItem(description=\"Product A\"),\n    LineItem(description=\"Product B\")\n])\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#3-nested-object-merging","title":"3. Nested Object Merging","text":"<p>Rule: Nested objects are recursively merged</p> <pre><code># Model 1\nInvoice(issued_by=Organization(name=\"Acme\"))\n\n# Model 2\nInvoice(issued_by=Organization(address=Address(city=\"Paris\")))\n\n# Merged\nInvoice(issued_by=Organization(\n    name=\"Acme\",\n    address=Address(city=\"Paris\")\n))\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#4-entity-deduplication","title":"4. Entity Deduplication","text":"<p>Rule: Duplicate entities are detected and removed</p> <pre><code># Model 1\nInvoice(line_items=[LineItem(description=\"Product A\", total=50)])\n\n# Model 2 (duplicate)\nInvoice(line_items=[LineItem(description=\"Product A\", total=50)])\n\n# Merged (deduplicated)\nInvoice(line_items=[LineItem(description=\"Product A\", total=50)])\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#deduplication-algorithm","title":"Deduplication Algorithm","text":""},{"location":"fundamentals/extraction-process/model-merging/#content-based-hashing","title":"Content-Based Hashing","text":"<p>Entities are deduplicated using content hashing:</p> <pre><code>def entity_hash(entity: dict) -&gt; str:\n    \"\"\"Compute content hash for entity.\"\"\"\n    # Use stable fields (exclude id, __class__)\n    stable_fields = {\n        k: v for k, v in entity.items() \n        if k not in {\"id\", \"__class__\"} and v is not None\n    }\n\n    # Create stable JSON representation\n    content = json.dumps(stable_fields, sort_keys=True)\n\n    # Hash content\n    return hashlib.blake2b(content.encode()).hexdigest()[:16]\n</code></pre> <p>Example: <pre><code># These are considered duplicates\nentity_1 = {\"name\": \"Acme Corp\", \"city\": \"Paris\"}\nentity_2 = {\"name\": \"Acme Corp\", \"city\": \"Paris\"}\n\n# These are different\nentity_3 = {\"name\": \"Acme Corp\", \"city\": \"London\"}\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#llm-consolidation","title":"LLM Consolidation","text":""},{"location":"fundamentals/extraction-process/model-merging/#what-is-llm-consolidation","title":"What is LLM Consolidation?","text":"<p>LLM consolidation uses an LLM to intelligently merge models, resolving conflicts and improving accuracy. For ADVANCED tier models (13B+), it uses a multi-turn \"Chain of Density\" approach.</p>"},{"location":"fundamentals/extraction-process/model-merging/#consolidation-modes","title":"Consolidation Modes","text":""},{"location":"fundamentals/extraction-process/model-merging/#standard-consolidation-simplestandard-tiers","title":"Standard Consolidation (SIMPLE/STANDARD tiers)","text":"<p>Single-turn consolidation for models &lt; 13B parameters:</p> <pre><code># Automatic for SIMPLE/STANDARD tier models\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",  # STANDARD tier\n    llm_consolidation=True  # Single-turn consolidation\n)\n</code></pre> <p>Process: 1. Receive raw models and programmatic merge 2. Create consolidated model in one LLM call 3. Validate and return</p> <p>Performance: - Speed: ~3-5 seconds - Token usage: ~1000-2000 tokens - Accuracy: 95%</p>"},{"location":"fundamentals/extraction-process/model-merging/#chain-of-density-consolidation-advanced-tier","title":"Chain of Density Consolidation (ADVANCED tier)","text":"<p>Multi-turn consolidation for models \u2265 13B parameters:</p> <pre><code># Automatic for ADVANCED tier models\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"my_templates.Contract\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",  # ADVANCED tier\n    llm_consolidation=True  # Chain of Density (3 turns)\n)\n</code></pre> <p>Process: 1. Initial Merge (Turn 1): Create first consolidated version 2. Refinement (Turn 2): Identify and resolve conflicts 3. Final Polish (Turn 3): Ensure completeness and accuracy</p> <p>Performance: - Speed: ~10-15 seconds (3x slower) - Token usage: ~3000-6000 tokens (3x more) - Accuracy: 98%</p>"},{"location":"fundamentals/extraction-process/model-merging/#when-to-use","title":"When to Use","text":"<p>\u2705 Use Standard LLM consolidation when: - High accuracy is needed (95%) - Complex conflict resolution required - Using SIMPLE/STANDARD tier models - Budget allows API calls</p> <p>\u2705 Use Chain of Density when: - Critical accuracy required (98%) - Legal or financial documents - Using ADVANCED tier models (13B+) - Budget allows 3x API costs</p> <p>\u274c Don't use LLM consolidation when: - Speed is priority - Cost is primary concern - Simple merging sufficient - Processing high volume (&gt;1000 docs)</p>"},{"location":"fundamentals/extraction-process/model-merging/#how-it-works_1","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: procs, label: \"Docling Conversion\" }\n    C@{ shape: doc, label: \"Markdown Text\" }\n    D@{ shape: tag-proc, label: \"Chunking Optional\" }\n    E@{ shape: procs, label: \"LLM Extraction\" }\n\n    F@{ shape: doc, label: \"Structured Data\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,E process\n    class C data\n    class D operator\n    class F output</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    llm_consolidation=True  # Enable LLM consolidation\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#llm-consolidation-process","title":"LLM Consolidation Process","text":""},{"location":"fundamentals/extraction-process/model-merging/#step-1-programmatic-merge","title":"Step 1: Programmatic Merge","text":"<pre><code># First, merge programmatically\nprogrammatic_model = merge_pydantic_models(raw_models, template)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#step-2-llm-review","title":"Step 2: LLM Review","text":"<pre><code># Then, LLM reviews and improves\nfinal_model = backend.consolidate_from_pydantic_models(\n    raw_models=raw_models,\n    programmatic_model=programmatic_model,\n    template=template\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#step-3-validation","title":"Step 3: Validation","text":"<pre><code># LLM output is validated against schema\nvalidated_model = template.model_validate(llm_output)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#chain-of-density-process","title":"Chain of Density Process","text":"<p>For ADVANCED tier models, consolidation uses three turns:</p>"},{"location":"fundamentals/extraction-process/model-merging/#turn-1-initial-merge","title":"Turn 1: Initial Merge","text":"<pre><code># Prompt includes:\n# - Schema definition\n# - All raw models\n# - Programmatic merge result\n\n# LLM creates initial consolidated version\ninitial_model = llm.consolidate(\n    schema=schema,\n    raw_models=raw_models,\n    draft=programmatic_merge\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#turn-2-refinement","title":"Turn 2: Refinement","text":"<pre><code># Prompt includes:\n# - Initial model from Turn 1\n# - Identified conflicts\n# - Missing information\n\n# LLM refines and resolves conflicts\nrefined_model = llm.refine(\n    initial=initial_model,\n    conflicts=identified_conflicts,\n    raw_models=raw_models\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#turn-3-final-polish","title":"Turn 3: Final Polish","text":"<pre><code># Prompt includes:\n# - Refined model from Turn 2\n# - Completeness checklist\n# - Accuracy verification\n\n# LLM ensures completeness and accuracy\nfinal_model = llm.polish(\n    refined=refined_model,\n    schema=schema,\n    raw_models=raw_models\n)\n</code></pre> <p>Benefits: - \ud83d\udc8e Highest accuracy (98% vs 95%) - \ud83d\udd0d Better conflict resolution - \u2705 More complete data extraction - \ud83c\udfaf Fewer validation errors</p> <p>Trade-offs: - \ud83d\udc0c 3x slower processing - \ud83d\udcb0 3x higher API costs - \ud83d\udcca 3x more token usage</p> <p>See Model Capabilities: Chain of Density for complete details.</p>"},{"location":"fundamentals/extraction-process/model-merging/#llm-consolidation-prompt","title":"LLM Consolidation Prompt","text":"<p>The LLM receives:</p> <ol> <li>Schema: Pydantic model structure</li> <li>Raw models: All partial extractions</li> <li>Draft model: Programmatic merge result</li> </ol> <p>Task: Create the best possible consolidated model</p> <p>For Chain of Density (ADVANCED tier): - Turn 1: Initial consolidation - Turn 2: Conflict resolution - Turn 3: Completeness verification</p>"},{"location":"fundamentals/extraction-process/model-merging/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/extraction-process/model-merging/#example-1-basic-programmatic-merge","title":"Example 1: Basic Programmatic Merge","text":"<pre><code>from docling_graph.core.utils import merge_pydantic_models\nfrom my_templates import Invoice, Organization, LineItem\n\n# Partial models from chunks\nmodels = [\n    Invoice(\n        invoice_number=\"INV-001\",\n        issued_by=Organization(name=\"Acme Corp\")\n    ),\n    Invoice(\n        line_items=[\n            LineItem(description=\"Product A\", quantity=2, unit_price=50, total=100),\n            LineItem(description=\"Product B\", quantity=1, unit_price=150, total=150)\n        ]\n    ),\n    Invoice(\n        subtotal=250,\n        tax=25,\n        total=275,\n        due_date=\"2024-01-31\"\n    )\n]\n\n# Merge\nmerged = merge_pydantic_models(models, Invoice)\n\nprint(f\"Invoice: {merged.invoice_number}\")\nprint(f\"Issued by: {merged.issued_by.name}\")\nprint(f\"Line items: {len(merged.line_items)}\")\nprint(f\"Total: ${merged.total}\")\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#example-2-with-llm-consolidation","title":"Example 2: With LLM Consolidation","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"my_templates.Contract\",\n\n    # Enable LLM consolidation\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    llm_consolidation=True,  # Extra accuracy\n\n    # Chunking settings\n    use_chunking=True,\n    processing_mode=\"many-to-one\",\n\n    output_dir=\"outputs/consolidated\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#example-3-manual-consolidation","title":"Example 3: Manual Consolidation","text":"<pre><code>from docling_graph.core.extractors.backends import LlmBackend\nfrom docling_graph.core.utils import merge_pydantic_models\nfrom docling_graph.llm_clients import MistralClient\n\n# Extract from chunks\nmodels = []\nfor chunk in chunks:\n    model = backend.extract_from_markdown(chunk, template, is_partial=True)\n    if model:\n        models.append(model)\n\n# Programmatic merge\nprogrammatic = merge_pydantic_models(models, template)\n\n# LLM consolidation\nclient = MistralClient(model=\"mistral-large-latest\")\nbackend = LlmBackend(llm_client=client)\n\nfinal = backend.consolidate_from_pydantic_models(\n    raw_models=models,\n    programmatic_model=programmatic,\n    template=template\n)\n\nprint(f\"Consolidated {len(models)} models into 1\")\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#example-4-handling-merge-failures","title":"Example 4: Handling Merge Failures","text":"<pre><code>from docling_graph.core.utils import merge_pydantic_models\n\ntry:\n    merged = merge_pydantic_models(models, template)\n    print(\"\u2713 Merge successful\")\n\nexcept Exception as e:\n    print(f\"\u2717 Merge failed: {e}\")\n\n    # Fallback: use first model\n    merged = models[0] if models else template()\n    print(\"Using first model as fallback\")\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#zero-data-loss","title":"Zero Data Loss","text":""},{"location":"fundamentals/extraction-process/model-merging/#what-is-zero-data-loss","title":"What is Zero Data Loss?","text":"<p>Zero data loss ensures that extraction failures never result in completely empty results. Instead, the system returns partial models with whatever data was successfully extracted.</p>"},{"location":"fundamentals/extraction-process/model-merging/#how-it-works_2","title":"How It Works","text":""},{"location":"fundamentals/extraction-process/model-merging/#before-old-behavior","title":"Before (Old Behavior)","text":"<pre><code># If merging failed\ntry:\n    merged = merge_pydantic_models(models, template)\nexcept Exception:\n    return []  # \u274c All data lost!\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#after-zero-data-loss","title":"After (Zero Data Loss)","text":"<pre><code># If merging fails, return partial models\ntry:\n    merged = merge_pydantic_models(models, template)\n    return [merged]\nexcept Exception:\n    # \u2705 Return partial models instead of empty list\n    return models if models else [template()]\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#benefits","title":"Benefits","text":"<p>Data Preservation: <pre><code># Even if consolidation fails, you get partial data\nmodels = [\n    Invoice(invoice_number=\"INV-001\"),  # From chunk 1\n    Invoice(line_items=[...]),          # From chunk 2\n    Invoice(total=150)                  # From chunk 3\n]\n\n# If merge fails, you still have all 3 partial models\n# Better than nothing!\n</code></pre></p> <p>Graceful Degradation: <pre><code># System continues processing even with errors\nfor document in documents:\n    try:\n        result = process_document(document)\n        # May return merged model or partial models\n        print(f\"Extracted {len(result)} model(s)\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n        # But still got partial data\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#configuration_1","title":"Configuration","text":"<p>Zero data loss is automatic - no configuration needed:</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"many-to-one\"\n    # Zero data loss is always enabled\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#example-handling-partial-results","title":"Example: Handling Partial Results","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"many-to-one\"\n)\n\nresults = config.run()\n\n# Check if we got merged or partial models\nif len(results) == 1:\n    print(\"\u2713 Successfully merged into single model\")\n    merged = results[0]\nelse:\n    print(f\"\u26a0 Got {len(results)} partial models\")\n    # Still useful! Can manually merge or use as-is\n    for i, model in enumerate(results, 1):\n        print(f\"  Model {i}: {model.invoice_number or 'N/A'}\")\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#conflict-resolution","title":"Conflict Resolution","text":""},{"location":"fundamentals/extraction-process/model-merging/#common-conflicts","title":"Common Conflicts","text":""},{"location":"fundamentals/extraction-process/model-merging/#1-duplicate-entities","title":"1. Duplicate Entities","text":"<p>Problem: Same entity appears multiple times</p> <pre><code># Chunk 1\nOrganization(name=\"Acme Corp\", city=\"Paris\")\n\n# Chunk 2\nOrganization(name=\"Acme Corp\", city=\"Paris\")\n\n# Solution: Deduplicated automatically\nOrganization(name=\"Acme Corp\", city=\"Paris\")  # Only one\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#2-conflicting-values","title":"2. Conflicting Values","text":"<p>Problem: Different values for same field</p> <pre><code># Chunk 1\nInvoice(total=150)\n\n# Chunk 2\nInvoice(total=275)\n\n# Programmatic: Last value wins\nInvoice(total=275)\n\n# LLM: Intelligent resolution\nInvoice(total=275)  # LLM chooses correct value\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#3-partial-information","title":"3. Partial Information","text":"<p>Problem: Information spread across chunks</p> <pre><code># Chunk 1\nOrganization(name=\"Acme Corp\")\n\n# Chunk 2\nOrganization(address=Address(city=\"Paris\"))\n\n# Solution: Merged recursively\nOrganization(\n    name=\"Acme Corp\",\n    address=Address(city=\"Paris\")\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#performance-comparison","title":"Performance Comparison","text":""},{"location":"fundamentals/extraction-process/model-merging/#speed-benchmark","title":"Speed Benchmark","text":"Strategy Models Time Throughput Programmatic 5 0.01s 500 merges/s LLM Consolidation 5 3s 0.3 merges/s Programmatic 20 0.05s 400 merges/s LLM Consolidation 20 8s 0.1 merges/s"},{"location":"fundamentals/extraction-process/model-merging/#accuracy-comparison","title":"Accuracy Comparison","text":"Document Type Programmatic LLM Consolidation Improvement Simple invoice 95% 96% +1% Complex contract 88% 94% +6% Multi-page form 90% 95% +5% Research paper 85% 92% +7%"},{"location":"fundamentals/extraction-process/model-merging/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/model-merging/#1-use-programmatic-by-default","title":"1. Use Programmatic by Default","text":"<pre><code># \u2705 Good - Fast and free\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    llm_consolidation=False  # Default (90% accuracy)\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#2-enable-standard-llm-for-high-accuracy","title":"2. Enable Standard LLM for High Accuracy","text":"<pre><code># \u2705 Good - Better accuracy for important documents\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"my_templates.Contract\",\n    backend=\"llm\",\n    inference=\"local\",\n    model_override=\"llama3.1:8b\",  # STANDARD tier\n    llm_consolidation=True  # 95% accuracy\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#3-use-chain-of-density-for-critical-documents","title":"3. Use Chain of Density for Critical Documents","text":"<pre><code># \u2705 Good - Highest accuracy for critical data\nconfig = PipelineConfig(\n    source=\"legal_contract.pdf\",\n    template=\"my_templates.LegalContract\",\n    backend=\"llm\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",  # ADVANCED tier\n    llm_consolidation=True  # Chain of Density (98% accuracy)\n)\n</code></pre> <p>Cost Consideration</p> <p>Chain of Density uses 3x more tokens than standard consolidation. For 100 documents:</p> <ul> <li>Standard LLM: ~$10-20</li> <li>Chain of Density: ~$30-60</li> </ul> <p>Use only when accuracy justifies the cost.</p>"},{"location":"fundamentals/extraction-process/model-merging/#3-validate-merged-results","title":"3. Validate Merged Results","text":"<pre><code># \u2705 Good - Always validate\nmerged = merge_pydantic_models(models, template)\n\n# Check completeness\nif not merged.invoice_number:\n    print(\"Warning: Missing invoice number\")\n\nif not merged.line_items:\n    print(\"Warning: No line items\")\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#4-handle-empty-model-lists","title":"4. Handle Empty Model Lists","text":"<pre><code># \u2705 Good - Handle edge cases\nif not models:\n    print(\"No models to merge\")\n    merged = template()  # Empty model\nelse:\n    merged = merge_pydantic_models(models, template)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/model-merging/#issue-duplicate-entities","title":"Issue: Duplicate Entities","text":"<p>Solution: <pre><code># Deduplication is automatic\n# If duplicates persist, check entity fields\n\n# Ensure entities have stable identifiers\nclass Organization(BaseModel):\n    name: str  # Used for deduplication\n    address: Address | None = None\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#issue-lost-information","title":"Issue: Lost Information","text":"<p>Solution: <pre><code># Check if fields are being overwritten\n# Use LLM consolidation for better merging\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    llm_consolidation=True  # Better preservation\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#issue-merge-validation-fails","title":"Issue: Merge Validation Fails","text":"<p>Solution: <pre><code># Check merged data structure\ntry:\n    merged = merge_pydantic_models(models, template)\nexcept ValidationError as e:\n    print(f\"Validation errors: {e.errors()}\")\n\n    # Inspect raw merged data\n    dicts = [m.model_dump() for m in models]\n    print(f\"Raw data: {dicts}\")\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#issue-slow-consolidation","title":"Issue: Slow Consolidation","text":"<p>Solution: <pre><code># Disable LLM consolidation for speed\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    llm_consolidation=False  # Faster\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#advanced-techniques","title":"Advanced Techniques","text":""},{"location":"fundamentals/extraction-process/model-merging/#custom-merge-logic","title":"Custom Merge Logic","text":"<p>For special cases, implement custom merging:</p> <pre><code>from docling_graph.core.utils import merge_pydantic_models\n\ndef custom_merge(models, template):\n    \"\"\"Custom merge with special rules.\"\"\"\n\n    # Start with programmatic merge\n    base = merge_pydantic_models(models, template)\n\n    # Apply custom logic\n    if base.total is None and base.line_items:\n        # Calculate total from line items\n        base.total = sum(item.total for item in base.line_items)\n\n    return base\n\n# Use custom merge\nmerged = custom_merge(models, Invoice)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#performance-comparison_1","title":"Performance Comparison","text":""},{"location":"fundamentals/extraction-process/model-merging/#consolidation-strategy-comparison","title":"Consolidation Strategy Comparison","text":"Strategy Time Tokens Accuracy Cost (100 docs) Best For Programmatic 0.01s 0 90% $0 Default, high volume LLM Standard 3s 1500 95% $15 Important documents Chain of Density 10s 4500 98% $45 Critical documents"},{"location":"fundamentals/extraction-process/model-merging/#when-to-use-each","title":"When to Use Each","text":"<pre><code># High volume, good accuracy needed\nif document_count &gt; 1000:\n    llm_consolidation = False  # Programmatic\n\n# Important documents, high accuracy needed\nelif document_importance == \"high\":\n    llm_consolidation = True  # Standard LLM\n    model_override = \"llama3.1:8b\"  # STANDARD tier\n\n# Critical documents, maximum accuracy needed\nelif document_importance == \"critical\":\n    llm_consolidation = True  # Chain of Density\n    model_override = \"gpt-4-turbo\"  # ADVANCED tier\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#next-steps","title":"Next Steps","text":"<p>Now that you understand model merging:</p> <ol> <li>Model Capabilities \u2192 - Learn about Chain of Density</li> <li>Batch Processing \u2192 - Optimize chunk processing</li> <li>Extraction Backends \u2192 - Understand backends</li> <li>Performance Tuning \u2192 - Optimize consolidation</li> <li>Graph Management \u2192 - Work with knowledge graphs</li> </ol>"},{"location":"fundamentals/extraction-process/model-merging/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/extraction-process/model-merging/#programmatic-merge","title":"Programmatic Merge","text":"<pre><code>from docling_graph.core.utils import merge_pydantic_models\n\nmerged = merge_pydantic_models(models, template)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#with-llm-consolidation","title":"With LLM Consolidation","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    llm_consolidation=True\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#manual-llm-consolidation","title":"Manual LLM Consolidation","text":"<pre><code>final = backend.consolidate_from_pydantic_models(\n    raw_models=models,\n    programmatic_model=programmatic,\n    template=template\n)\n</code></pre>"},{"location":"fundamentals/graph-management/","title":"Knowledge Graph Management","text":""},{"location":"fundamentals/graph-management/#overview","title":"Overview","text":"<p>Knowledge Graph Management covers converting extracted Pydantic models into graph structures, exporting to various formats, and visualizing the results.</p> <p>What you'll learn: - Graph conversion from Pydantic models - Export formats (CSV, Cypher, JSON) - Visualization techniques - Graph analysis and statistics - Neo4j integration</p>"},{"location":"fundamentals/graph-management/#the-graph-pipeline","title":"The Graph Pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Pydantic Models\" }\n\n    B@{ shape: procs, label: \"Graph Conversion\" }\n    C@{ shape: doc, label: \"NetworkX Graph\" }\n\n    D@{ shape: tag-proc, label: \"Export\" }\n    F@{ shape: tag-proc, label: \"Visualization\" }\n\n    E1@{ shape: doc, label: \"CSV Files\" }\n    E2@{ shape: doc, label: \"Cypher Script\" }\n    E3@{ shape: doc, label: \"JSON\" }\n\n    G@{ shape: doc, label: \"Interactive HTML\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n\n    C --&gt; D\n    C --&gt; F\n\n    D --&gt; E1\n    D --&gt; E2\n    D --&gt; E3\n\n    F --&gt; G\n\n    %% 4. Apply Classes\n    class A input\n    class B process\n    class C data\n    class D,F operator\n    class E1,E2,E3,G output</code></pre>"},{"location":"fundamentals/graph-management/#key-concepts","title":"Key Concepts","text":""},{"location":"fundamentals/graph-management/#1-graph-conversion","title":"1. Graph Conversion","text":"<p>Transform Pydantic models into graph structure:</p> <pre><code>from docling_graph.core.converters import GraphConverter\n\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\nprint(f\"Nodes: {metadata.node_count}\")\nprint(f\"Edges: {metadata.edge_count}\")\n</code></pre> <p>Learn more: Graph Conversion \u2192</p>"},{"location":"fundamentals/graph-management/#2-export-formats","title":"2. Export Formats","text":"<p>Export graphs in multiple formats:</p> <pre><code>from docling_graph.core.exporters import CSVExporter, CypherExporter\n\n# CSV export\nCSVExporter().export(graph, output_dir)\n\n# Cypher export\nCypherExporter().export(graph, output_file)\n</code></pre> <p>Learn more: Export Formats \u2192</p>"},{"location":"fundamentals/graph-management/#3-visualization","title":"3. Visualization","text":"<p>Generate interactive visualizations:</p> <pre><code>from docling_graph.core.visualizers import InteractiveVisualizer\n\nvisualizer = InteractiveVisualizer()\nvisualizer.save_cytoscape_graph(graph, \"graph.html\")\n</code></pre> <p>Learn more: Visualization \u2192</p>"},{"location":"fundamentals/graph-management/#4-neo4j-integration","title":"4. Neo4j Integration","text":"<p>Import graphs into Neo4j:</p> <pre><code># Import Cypher script\ncat graph.cypher | cypher-shell -u neo4j -p password\n</code></pre> <p>Learn more: Neo4j Integration \u2192</p>"},{"location":"fundamentals/graph-management/#quick-start","title":"Quick Start","text":""},{"location":"fundamentals/graph-management/#complete-pipeline","title":"Complete Pipeline","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Run complete pipeline\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\",\n    export_format=\"csv\",  # or \"cypher\"\n    output_dir=\"outputs\"\n)\n\nconfig.run()\n\n# Outputs:\n# - outputs/nodes.csv\n# - outputs/edges.csv\n# - outputs/graph_stats.json\n# - outputs/visualization.html\n</code></pre>"},{"location":"fundamentals/graph-management/#graph-structure","title":"Graph Structure","text":""},{"location":"fundamentals/graph-management/#nodes","title":"Nodes","text":"<p>Nodes represent entities from your Pydantic models:</p> <pre><code># Node structure\n{\n    \"id\": \"invoice_001\",\n    \"label\": \"Invoice\",\n    \"type\": \"entity\",\n    \"invoice_number\": \"INV-001\",\n    \"total\": 1000\n}\n</code></pre>"},{"location":"fundamentals/graph-management/#edges","title":"Edges","text":"<p>Edges represent relationships between entities:</p> <pre><code># Edge structure\n{\n    \"source\": \"invoice_001\",\n    \"target\": \"org_acme\",\n    \"label\": \"ISSUED_BY\"\n}\n</code></pre>"},{"location":"fundamentals/graph-management/#export-formats-comparison","title":"Export Formats Comparison","text":"Format Best For File Type Use Case CSV Analysis, spreadsheets <code>.csv</code> Data analysis, Excel Cypher Neo4j import <code>.cypher</code> Graph database JSON APIs, processing <code>.json</code> Programmatic access"},{"location":"fundamentals/graph-management/#section-contents","title":"Section Contents","text":""},{"location":"fundamentals/graph-management/#1-graph-conversion_1","title":"1. Graph Conversion","text":"<p>Learn how Pydantic models are converted to NetworkX graphs.</p> <p>Topics: - Node creation - Edge generation - Node ID registry - Graph validation - Automatic cleanup</p>"},{"location":"fundamentals/graph-management/#2-export-formats_1","title":"2. Export Formats","text":"<p>Understand different export formats and when to use them.</p> <p>Topics: - CSV export (nodes and edges) - Cypher export (Neo4j) - JSON export (programmatic) - Format selection</p>"},{"location":"fundamentals/graph-management/#3-visualization_1","title":"3. Visualization","text":"<p>Generate interactive visualizations of your knowledge graphs.</p> <p>Topics: - Interactive HTML graphs - Markdown reports - Graph statistics - Customization options</p>"},{"location":"fundamentals/graph-management/#4-neo4j-integration_1","title":"4. Neo4j Integration","text":"<p>Import and query graphs in Neo4j database.</p> <p>Topics: - Cypher import - Neo4j setup - Query examples - Best practices</p>"},{"location":"fundamentals/graph-management/#5-graph-analysis","title":"5. Graph Analysis","text":"<p>Analyze graph structure and statistics.</p> <p>Topics: - Node and edge counts - Graph metrics - Connectivity analysis - Quality checks</p>"},{"location":"fundamentals/graph-management/#6-advanced-topics","title":"6. Advanced Topics","text":"<p>Advanced graph management techniques covered in other sections.</p> <p>See also: - Custom Exporters - Performance Tuning - Graph Analysis</p>"},{"location":"fundamentals/graph-management/#common-workflows","title":"Common Workflows","text":""},{"location":"fundamentals/graph-management/#workflow-1-csv-analysis","title":"Workflow 1: CSV Analysis","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Extract and export to CSV\nconfig = PipelineConfig(\n    source=\"invoices.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\",\n    output_dir=\"analysis\"\n)\n\nconfig.run()\n\n# Analyze in Python\nimport pandas as pd\n\nnodes = pd.read_csv(\"analysis/nodes.csv\")\nedges = pd.read_csv(\"analysis/edges.csv\")\n\nprint(f\"Total invoices: {len(nodes[nodes['label'] == 'Invoice'])}\")\n</code></pre>"},{"location":"fundamentals/graph-management/#workflow-2-neo4j-import","title":"Workflow 2: Neo4j Import","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Extract and export to Cypher\nconfig = PipelineConfig(\n    source=\"contracts.pdf\",\n    template=\"my_templates.Contract\",\n    export_format=\"cypher\",\n    output_dir=\"neo4j_import\"\n)\n\nconfig.run()\n\n# Import to Neo4j\n# cat neo4j_import/graph.cypher | cypher-shell\n</code></pre>"},{"location":"fundamentals/graph-management/#workflow-3-programmatic-access","title":"Workflow 3: Programmatic Access","text":"<pre><code>from docling_graph import PipelineConfig\nimport json\n\n# Extract and access programmatically\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    output_dir=\"data\"\n)\n\nconfig.run()\n\n# Load graph data\nwith open(\"data/graph_data.json\") as f:\n    graph_data = json.load(f)\n\n# Process nodes\nfor node in graph_data[\"nodes\"]:\n    print(f\"{node['type']}: {node['id']}\")\n</code></pre>"},{"location":"fundamentals/graph-management/#graph-statistics","title":"Graph Statistics","text":""},{"location":"fundamentals/graph-management/#automatic-statistics","title":"Automatic Statistics","text":"<p>Every pipeline run generates statistics:</p> <pre><code>{\n  \"node_count\": 15,\n  \"edge_count\": 18,\n  \"node_types\": {\n    \"Invoice\": 1,\n    \"Organization\": 2,\n    \"Address\": 3,\n    \"LineItem\": 9\n  },\n  \"edge_types\": {\n    \"ISSUED_BY\": 1,\n    \"SENT_TO\": 1,\n    \"LOCATED_AT\": 5,\n    \"CONTAINS_ITEM\": 9\n  },\n  \"avg_degree\": 2.4,\n  \"density\": 0.17\n}\n</code></pre>"},{"location":"fundamentals/graph-management/#using-statistics","title":"Using Statistics","text":"<pre><code>import json\n\n# Load statistics\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nprint(f\"Graph has {stats['node_count']} nodes\")\nprint(f\"Most common node type: {max(stats['node_types'], key=stats['node_types'].get)}\")\n</code></pre>"},{"location":"fundamentals/graph-management/#visualization-preview","title":"Visualization Preview","text":""},{"location":"fundamentals/graph-management/#interactive-html","title":"Interactive HTML","text":"<p>Every pipeline run generates an interactive visualization:</p> <pre><code>outputs/\n\u2514\u2500\u2500 visualization.html  # Open in browser\n</code></pre> <p>Features: - Zoom and pan - Node inspection - Search functionality - Export to image</p>"},{"location":"fundamentals/graph-management/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/#1-choose-the-right-format","title":"1. Choose the Right Format","text":"<pre><code># \u2705 Good - Match format to use case\nif use_case == \"neo4j\":\n    export_format = \"cypher\"\nelif use_case == \"analysis\":\n    export_format = \"csv\"\nelse:\n    export_format = \"csv\"  # Default\n</code></pre>"},{"location":"fundamentals/graph-management/#2-validate-graph-structure","title":"2. Validate Graph Structure","text":"<pre><code># \u2705 Good - Enable validation\nconverter = GraphConverter(validate_graph=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/#3-use-automatic-cleanup","title":"3. Use Automatic Cleanup","text":"<pre><code># \u2705 Good - Enable cleanup\nconverter = GraphConverter(auto_cleanup=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/#4-check-statistics","title":"4. Check Statistics","text":"<pre><code># \u2705 Good - Verify graph quality\nif metadata.node_count == 0:\n    print(\"Warning: Empty graph\")\n\nif metadata.edge_count == 0:\n    print(\"Warning: No relationships\")\n</code></pre>"},{"location":"fundamentals/graph-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/#issue-empty-graph","title":"Issue: Empty Graph","text":"<p>Solution: <pre><code># Check if models were extracted\nif not models:\n    print(\"No models extracted\")\n\n# Check if models have relationships\nfor model in models:\n    print(f\"Model: {model}\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/#issue-missing-relationships","title":"Issue: Missing Relationships","text":"<p>Solution: <pre><code># Ensure entities are properly defined\nclass Organization(BaseModel):\n    name: str\n    # Must be entity to create nodes\n    model_config = {\"is_entity\": True}\n</code></pre></p>"},{"location":"fundamentals/graph-management/#issue-export-fails","title":"Issue: Export Fails","text":"<p>Solution: <pre><code># Check output directory exists\nimport os\nos.makedirs(\"outputs\", exist_ok=True)\n\n# Check graph is not empty\nif graph.number_of_nodes() == 0:\n    print(\"Cannot export empty graph\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/#next-steps","title":"Next Steps","text":"<p>Ready to dive deeper? Start with:</p> <ol> <li>Graph Conversion \u2192 - Learn graph conversion</li> <li>Export Formats \u2192 - Choose export format</li> <li>Visualization \u2192 - Visualize your graphs</li> </ol>"},{"location":"fundamentals/graph-management/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/graph-management/#run-complete-pipeline","title":"Run Complete Pipeline","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\",\n    output_dir=\"outputs\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/graph-management/#manual-graph-conversion","title":"Manual Graph Conversion","text":"<pre><code>from docling_graph.core.converters import GraphConverter\n\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/#export-graph","title":"Export Graph","text":"<pre><code>from docling_graph.core.exporters import CSVExporter, CypherExporter\n\n# CSV\nCSVExporter().export(graph, output_dir)\n\n# Cypher\nCypherExporter().export(graph, output_file)\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/","title":"Export Formats","text":""},{"location":"fundamentals/graph-management/export-formats/#overview","title":"Overview","text":"<p>Export formats determine how your knowledge graph is saved and shared. Docling Graph supports CSV, Cypher, and JSON formats, each optimized for different use cases.</p> <p>In this guide: - CSV format (spreadsheets, analysis) - Cypher format (Neo4j import) - JSON format (programmatic access) - Format selection criteria - Integration examples</p>"},{"location":"fundamentals/graph-management/export-formats/#format-comparison","title":"Format Comparison","text":"Format Best For Output Use Case CSV Analysis, spreadsheets <code>nodes.csv</code>, <code>edges.csv</code> Excel, Pandas, SQL Cypher Graph databases <code>graph.cypher</code> Neo4j import JSON APIs, processing <code>graph.json</code> Python, JavaScript"},{"location":"fundamentals/graph-management/export-formats/#csv-export","title":"CSV Export","text":""},{"location":"fundamentals/graph-management/export-formats/#what-is-csv-export","title":"What is CSV Export?","text":"<p>CSV export creates separate files for nodes and edges in comma-separated format, perfect for spreadsheet analysis and SQL databases.</p>"},{"location":"fundamentals/graph-management/export-formats/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\",  # CSV export (default)\n    output_dir=\"outputs\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#output-files","title":"Output Files","text":"<pre><code>outputs/\n\u251c\u2500\u2500 nodes.csv          # All nodes with properties\n\u251c\u2500\u2500 edges.csv          # All edges with relationships\n\u251c\u2500\u2500 graph_stats.json   # Graph statistics\n\u2514\u2500\u2500 visualization.html # Interactive visualization\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#nodescsv-format","title":"nodes.csv Format","text":"<pre><code>id,label,type,__class__,invoice_number,total,name,street,city\ninvoice_001,Invoice,entity,Invoice,INV-001,1000,,,\norg_acme,Organization,entity,Organization,,,Acme Corp,,\naddr_123,Address,entity,Address,,,,123 Main St,Paris\n</code></pre> <p>Columns: - <code>id</code>: Unique node identifier - <code>label</code>: Node type/class - <code>type</code>: Always \"entity\" - <code>__class__</code>: Python class name - Additional columns for each property</p>"},{"location":"fundamentals/graph-management/export-formats/#edgescsv-format","title":"edges.csv Format","text":"<pre><code>source,target,label\ninvoice_001,org_acme,issued_by\norg_acme,addr_123,located_at\ninvoice_001,item_001,contains_item\n</code></pre> <p>Columns: - <code>source</code>: Source node ID - <code>target</code>: Target node ID - <code>label</code>: Relationship type</p>"},{"location":"fundamentals/graph-management/export-formats/#manual-csv-export","title":"Manual CSV Export","text":"<pre><code>from docling_graph.core.exporters import CSVExporter\nfrom docling_graph.core.converters import GraphConverter\n\n# Convert models to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Export to CSV\nexporter = CSVExporter()\nexporter.export(graph, output_dir=\"csv_output\")\n\nprint(\"Exported to csv_output/nodes.csv and csv_output/edges.csv\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#using-csv-with-pandas","title":"Using CSV with Pandas","text":"<pre><code>import pandas as pd\n\n# Load CSV files\nnodes = pd.read_csv(\"outputs/nodes.csv\")\nedges = pd.read_csv(\"outputs/edges.csv\")\n\n# Analyze nodes\nprint(f\"Total nodes: {len(nodes)}\")\nprint(f\"Node types:\\n{nodes['label'].value_counts()}\")\n\n# Analyze edges\nprint(f\"Total edges: {len(edges)}\")\nprint(f\"Edge types:\\n{edges['label'].value_counts()}\")\n\n# Filter specific node type\ninvoices = nodes[nodes['label'] == 'Invoice']\nprint(f\"Found {len(invoices)} invoices\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#using-csv-with-sql","title":"Using CSV with SQL","text":"<pre><code>import sqlite3\nimport pandas as pd\n\n# Load CSV\nnodes = pd.read_csv(\"outputs/nodes.csv\")\nedges = pd.read_csv(\"outputs/edges.csv\")\n\n# Create database\nconn = sqlite3.connect(\"graph.db\")\n\n# Import to SQL\nnodes.to_sql(\"nodes\", conn, if_exists=\"replace\", index=False)\nedges.to_sql(\"edges\", conn, if_exists=\"replace\", index=False)\n\n# Query\nresult = pd.read_sql(\"\"\"\n    SELECT n.label, COUNT(*) as count\n    FROM nodes n\n    GROUP BY n.label\n\"\"\", conn)\n\nprint(result)\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#cypher-export","title":"Cypher Export","text":""},{"location":"fundamentals/graph-management/export-formats/#what-is-cypher-export","title":"What is Cypher Export?","text":"<p>Cypher export generates Cypher statements for direct import into Neo4j graph databases.</p>"},{"location":"fundamentals/graph-management/export-formats/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"cypher\",  # Cypher export\n    output_dir=\"outputs\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#output-files_1","title":"Output Files","text":"<pre><code>outputs/\n\u251c\u2500\u2500 graph.cypher       # Cypher statements\n\u251c\u2500\u2500 graph_stats.json   # Graph statistics\n\u2514\u2500\u2500 visualization.html # Interactive visualization\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#graphcypher-format","title":"graph.cypher Format","text":"<pre><code>// Cypher script generated by docling-graph\n// Import this into Neo4j\n\n// --- Create Nodes ---\nCREATE (invoice_001:Invoice {invoice_number: \"INV-001\", total: 1000, node_id: \"invoice_001\"})\nCREATE (org_acme:Organization {name: \"Acme Corp\", node_id: \"org_acme\"})\nCREATE (addr_123:Address {street: \"123 Main St\", city: \"Paris\", node_id: \"addr_123\"})\n\n// --- Create Relationships ---\nMATCH (invoice_001), (org_acme)\nCREATE (invoice_001)-[:ISSUED_BY]-&gt;(org_acme)\n\nMATCH (org_acme), (addr_123)\nCREATE (org_acme)-[:LOCATED_AT]-&gt;(addr_123)\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#manual-cypher-export","title":"Manual Cypher Export","text":"<pre><code>from docling_graph.core.exporters import CypherExporter\nfrom docling_graph.core.converters import GraphConverter\nfrom pathlib import Path\n\n# Convert models to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Export to Cypher\nexporter = CypherExporter()\nexporter.export(graph, Path(\"outputs/graph.cypher\"))\n\nprint(\"Exported to outputs/graph.cypher\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#importing-to-neo4j","title":"Importing to Neo4j","text":""},{"location":"fundamentals/graph-management/export-formats/#method-1-cypher-shell","title":"Method 1: cypher-shell","text":"<pre><code># Import using cypher-shell\ncat outputs/graph.cypher | cypher-shell -u neo4j -p password\n\n# Or with file\ncypher-shell -u neo4j -p password -f outputs/graph.cypher\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#method-2-neo4j-browser","title":"Method 2: Neo4j Browser","text":"<ol> <li>Open Neo4j Browser (http://localhost:7474)</li> <li>Copy contents of <code>graph.cypher</code></li> <li>Paste into query editor</li> <li>Execute</li> </ol>"},{"location":"fundamentals/graph-management/export-formats/#method-3-python-driver","title":"Method 3: Python Driver","text":"<pre><code>from neo4j import GraphDatabase\n\n# Connect to Neo4j\ndriver = GraphDatabase.driver(\n    \"bolt://localhost:7687\",\n    auth=(\"neo4j\", \"password\")\n)\n\n# Read Cypher file\nwith open(\"outputs/graph.cypher\") as f:\n    cypher_script = f.read()\n\n# Execute\nwith driver.session() as session:\n    session.run(cypher_script)\n\ndriver.close()\nprint(\"Imported to Neo4j\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#json-export","title":"JSON Export","text":""},{"location":"fundamentals/graph-management/export-formats/#what-is-json-export","title":"What is JSON Export?","text":"<p>JSON export is automatically generated alongside CSV or Cypher, providing structured data for programmatic access.</p>"},{"location":"fundamentals/graph-management/export-formats/#output-files_2","title":"Output Files","text":"<pre><code>outputs/\n\u251c\u2500\u2500 extracted_data.json  # Pydantic models\n\u251c\u2500\u2500 graph_data.json      # Graph structure\n\u251c\u2500\u2500 graph_stats.json     # Statistics\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#extracted_datajson-format","title":"extracted_data.json Format","text":"<pre><code>{\n  \"models\": [\n    {\n      \"invoice_number\": \"INV-001\",\n      \"total\": 1000,\n      \"issued_by\": {\n        \"name\": \"Acme Corp\",\n        \"located_at\": {\n          \"street\": \"123 Main St\",\n          \"city\": \"Paris\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#graph_datajson-format","title":"graph_data.json Format","text":"<pre><code>{\n  \"nodes\": [\n    {\n      \"id\": \"invoice_001\",\n      \"label\": \"Invoice\",\n      \"type\": \"entity\",\n      \"properties\": {\n        \"invoice_number\": \"INV-001\",\n        \"total\": 1000\n      }\n    },\n    {\n      \"id\": \"org_acme\",\n      \"label\": \"Organization\",\n      \"type\": \"entity\",\n      \"properties\": {\n        \"name\": \"Acme Corp\"\n      }\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"invoice_001\",\n      \"target\": \"org_acme\",\n      \"label\": \"issued_by\"\n    }\n  ]\n}\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#manual-json-export","title":"Manual JSON Export","text":"<pre><code>from docling_graph.core.exporters import JSONExporter\nfrom docling_graph.core.converters import GraphConverter\nfrom pathlib import Path\n\n# Convert models to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Export to JSON\nexporter = JSONExporter()\nexporter.export(graph, Path(\"outputs/graph.json\"))\n\nprint(\"Exported to outputs/graph.json\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#using-json-in-python","title":"Using JSON in Python","text":"<pre><code>import json\n\n# Load graph data\nwith open(\"outputs/graph_data.json\") as f:\n    graph_data = json.load(f)\n\n# Access nodes\nfor node in graph_data[\"nodes\"]:\n    print(f\"{node['label']}: {node['id']}\")\n\n# Access edges\nfor edge in graph_data[\"edges\"]:\n    print(f\"{edge['source']} --[{edge['label']}]--&gt; {edge['target']}\")\n\n# Filter by type\ninvoices = [n for n in graph_data[\"nodes\"] if n[\"label\"] == \"Invoice\"]\nprint(f\"Found {len(invoices)} invoices\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#format-selection","title":"Format Selection","text":""},{"location":"fundamentals/graph-management/export-formats/#decision-matrix","title":"Decision Matrix","text":"Use Case Recommended Format Reason Excel analysis CSV Direct import to Excel Neo4j database Cypher Direct import Python processing JSON Easy to parse SQL database CSV Standard import Data science CSV Pandas compatible API integration JSON Standard format Graph queries Cypher Neo4j native"},{"location":"fundamentals/graph-management/export-formats/#by-tool","title":"By Tool","text":"Tool Format Import Method Excel CSV File \u2192 Open Neo4j Cypher cypher-shell Python JSON json.load() Pandas CSV pd.read_csv() SQL CSV COPY/LOAD DATA Power BI CSV Get Data Tableau CSV Connect to File"},{"location":"fundamentals/graph-management/export-formats/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/graph-management/export-formats/#example-1-csv-for-analysis","title":"Example 1: CSV for Analysis","text":"<pre><code>from docling_graph import PipelineConfig\nimport pandas as pd\n\n# Extract and export to CSV\nconfig = PipelineConfig(\n    source=\"invoices.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\",\n    output_dir=\"analysis\"\n)\n\nconfig.run()\n\n# Analyze with Pandas\nnodes = pd.read_csv(\"analysis/nodes.csv\")\nedges = pd.read_csv(\"analysis/edges.csv\")\n\n# Calculate statistics\nprint(f\"Total invoices: {len(nodes[nodes['label'] == 'Invoice'])}\")\nprint(f\"Total organizations: {len(nodes[nodes['label'] == 'Organization'])}\")\nprint(f\"Total relationships: {len(edges)}\")\n\n# Export summary\nsummary = nodes.groupby('label').size()\nsummary.to_csv(\"analysis/summary.csv\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#example-2-cypher-for-neo4j","title":"Example 2: Cypher for Neo4j","text":"<pre><code>from docling_graph import PipelineConfig\nimport subprocess\n\n# Extract and export to Cypher\nconfig = PipelineConfig(\n    source=\"contracts.pdf\",\n    template=\"my_templates.Contract\",\n    export_format=\"cypher\",\n    output_dir=\"neo4j_import\"\n)\n\nconfig.run()\n\n# Import to Neo4j\nresult = subprocess.run([\n    \"cypher-shell\",\n    \"-u\", \"neo4j\",\n    \"-p\", \"password\",\n    \"-f\", \"neo4j_import/graph.cypher\"\n], capture_output=True, text=True)\n\nif result.returncode == 0:\n    print(\"\u2713 Successfully imported to Neo4j\")\nelse:\n    print(f\"\u2717 Import failed: {result.stderr}\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#example-3-json-for-api","title":"Example 3: JSON for API","text":"<pre><code>from docling_graph import PipelineConfig\nimport json\nimport requests\n\n# Extract and export\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\",  # JSON always generated\n    output_dir=\"api_data\"\n)\n\nconfig.run()\n\n# Load JSON\nwith open(\"api_data/extracted_data.json\") as f:\n    data = json.load(f)\n\n# Send to API\nresponse = requests.post(\n    \"https://api.example.com/invoices\",\n    json=data,\n    headers={\"Content-Type\": \"application/json\"}\n)\n\nprint(f\"API response: {response.status_code}\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/export-formats/#1-choose-format-by-use-case","title":"1. Choose Format by Use Case","text":"<pre><code># \u2705 Good - Match format to use case\nif use_case == \"neo4j\":\n    export_format = \"cypher\"\nelif use_case == \"analysis\":\n    export_format = \"csv\"\nelse:\n    export_format = \"csv\"  # Default\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#2-organize-output-directories","title":"2. Organize Output Directories","text":"<pre><code># \u2705 Good - Structured outputs\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\noutput_dir = f\"exports/{export_format}/{timestamp}\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=export_format,\n    output_dir=output_dir\n)\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#3-validate-exports","title":"3. Validate Exports","text":"<pre><code># \u2705 Good - Check exports exist\nimport os\n\nconfig.run()\n\nif export_format == \"csv\":\n    assert os.path.exists(f\"{output_dir}/nodes.csv\")\n    assert os.path.exists(f\"{output_dir}/edges.csv\")\nelif export_format == \"cypher\":\n    assert os.path.exists(f\"{output_dir}/graph.cypher\")\n\nprint(\"\u2713 Exports validated\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/export-formats/#issue-empty-csv-files","title":"Issue: Empty CSV Files","text":"<p>Solution: <pre><code># Check if graph has nodes\nimport json\n\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nif stats[\"node_count\"] == 0:\n    print(\"No nodes in graph - check extraction\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/export-formats/#issue-cypher-import-fails","title":"Issue: Cypher Import Fails","text":"<p>Solution: <pre><code># Check Cypher syntax\nhead -20 outputs/graph.cypher\n\n# Test connection\ncypher-shell -u neo4j -p password \"RETURN 1\"\n\n# Import with error logging\ncat outputs/graph.cypher | cypher-shell -u neo4j -p password 2&gt;&amp;1 | tee import.log\n</code></pre></p>"},{"location":"fundamentals/graph-management/export-formats/#issue-json-parsing-error","title":"Issue: JSON Parsing Error","text":"<p>Solution: <pre><code># Validate JSON\nimport json\n\ntry:\n    with open(\"outputs/graph_data.json\") as f:\n        data = json.load(f)\n    print(\"\u2713 Valid JSON\")\nexcept json.JSONDecodeError as e:\n    print(f\"\u2717 Invalid JSON: {e}\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/export-formats/#next-steps","title":"Next Steps","text":"<p>Now that you understand export formats:</p> <ol> <li>Visualization \u2192 - Visualize your graphs</li> <li>Neo4j Integration \u2192 - Deep dive into Neo4j</li> <li>Graph Analysis \u2192 - Analyze graph structure</li> </ol>"},{"location":"fundamentals/graph-management/export-formats/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/graph-management/export-formats/#csv-export_1","title":"CSV Export","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\"\n)\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#cypher-export_1","title":"Cypher Export","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"cypher\"\n)\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#load-csv","title":"Load CSV","text":"<pre><code>import pandas as pd\nnodes = pd.read_csv(\"outputs/nodes.csv\")\nedges = pd.read_csv(\"outputs/edges.csv\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#import-cypher","title":"Import Cypher","text":"<pre><code>cat outputs/graph.cypher | cypher-shell -u neo4j -p password\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/","title":"Graph Analysis","text":""},{"location":"fundamentals/graph-management/graph-analysis/#overview","title":"Overview","text":"<p>Graph analysis helps you understand the structure, quality, and characteristics of your knowledge graphs through metrics, statistics, and validation.</p> <p>In this guide: - Graph metrics - Quality checks - Connectivity analysis - Performance optimization - Validation techniques</p>"},{"location":"fundamentals/graph-management/graph-analysis/#graph-metrics","title":"Graph Metrics","text":""},{"location":"fundamentals/graph-management/graph-analysis/#basic-metrics","title":"Basic Metrics","text":"<pre><code>from docling_graph.core.converters import GraphConverter\n\n# Create graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Basic metrics\nprint(f\"Nodes: {metadata.node_count}\")\nprint(f\"Edges: {metadata.edge_count}\")\nprint(f\"Density: {metadata.density:.3f}\")\nprint(f\"Avg degree: {metadata.avg_degree:.2f}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#node-metrics","title":"Node Metrics","text":""},{"location":"fundamentals/graph-management/graph-analysis/#node-count-by-type","title":"Node Count by Type","text":"<pre><code># Node type distribution\nfor node_type, count in metadata.node_types.items():\n    percentage = (count / metadata.node_count) * 100\n    print(f\"{node_type}: {count} ({percentage:.1f}%)\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#node-degree","title":"Node Degree","text":"<pre><code>import networkx as nx\n\n# Calculate node degrees\ndegrees = dict(graph.degree())\n\n# Statistics\navg_degree = sum(degrees.values()) / len(degrees)\nmax_degree = max(degrees.values())\nmin_degree = min(degrees.values())\n\nprint(f\"Average degree: {avg_degree:.2f}\")\nprint(f\"Max degree: {max_degree}\")\nprint(f\"Min degree: {min_degree}\")\n\n# Find high-degree nodes (hubs)\nhubs = [(node, deg) for node, deg in degrees.items() if deg &gt; avg_degree * 2]\nprint(f\"Hub nodes: {len(hubs)}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#edge-metrics","title":"Edge Metrics","text":""},{"location":"fundamentals/graph-management/graph-analysis/#edge-count-by-type","title":"Edge Count by Type","text":"<pre><code># Edge type distribution\nfor edge_type, count in metadata.edge_types.items():\n    percentage = (count / metadata.edge_count) * 100\n    print(f\"{edge_type}: {count} ({percentage:.1f}%)\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#edge-density","title":"Edge Density","text":"<pre><code># Graph density (actual edges / possible edges)\ndensity = metadata.density\n\nif density &lt; 0.1:\n    print(\"Sparse graph\")\nelif density &lt; 0.5:\n    print(\"Medium density graph\")\nelse:\n    print(\"Dense graph\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#connectivity-analysis","title":"Connectivity Analysis","text":""},{"location":"fundamentals/graph-management/graph-analysis/#connected-components","title":"Connected Components","text":"<pre><code>import networkx as nx\n\n# Find connected components\ncomponents = list(nx.weakly_connected_components(graph))\n\nprint(f\"Connected components: {len(components)}\")\nprint(f\"Largest component: {len(max(components, key=len))} nodes\")\n\n# Check if graph is connected\nis_connected = nx.is_weakly_connected(graph)\nprint(f\"Graph is connected: {is_connected}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#isolated-nodes","title":"Isolated Nodes","text":"<pre><code># Find isolated nodes (no connections)\nisolated = [node for node, degree in graph.degree() if degree == 0]\n\nprint(f\"Isolated nodes: {len(isolated)}\")\nif isolated:\n    print(\"Warning: Graph has isolated nodes\")\n    for node in isolated[:5]:\n        print(f\"  - {node}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#quality-checks","title":"Quality Checks","text":""},{"location":"fundamentals/graph-management/graph-analysis/#validation","title":"Validation","text":"<pre><code>from docling_graph.core.utils import validate_graph_structure\n\ntry:\n    validate_graph_structure(graph, raise_on_error=True)\n    print(\"\u2713 Graph structure valid\")\nexcept ValueError as e:\n    print(f\"\u2717 Validation failed: {e}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#completeness-check","title":"Completeness Check","text":"<pre><code>def check_completeness(graph, metadata):\n    \"\"\"Check graph completeness.\"\"\"\n    issues = []\n\n    # Check for nodes\n    if metadata.node_count == 0:\n        issues.append(\"No nodes in graph\")\n\n    # Check for edges\n    if metadata.edge_count == 0:\n        issues.append(\"No edges in graph\")\n\n    # Check for isolated nodes\n    isolated = [n for n, d in graph.degree() if d == 0]\n    if isolated:\n        issues.append(f\"{len(isolated)} isolated nodes\")\n\n    # Check node attributes\n    nodes_without_label = [\n        n for n, data in graph.nodes(data=True)\n        if 'label' not in data\n    ]\n    if nodes_without_label:\n        issues.append(f\"{len(nodes_without_label)} nodes without labels\")\n\n    return issues\n\n# Run check\nissues = check_completeness(graph, metadata)\nif issues:\n    print(\"Graph issues found:\")\n    for issue in issues:\n        print(f\"  - {issue}\")\nelse:\n    print(\"\u2713 Graph is complete\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/graph-management/graph-analysis/#example-1-comprehensive-analysis","title":"Example 1: Comprehensive Analysis","text":"<pre><code>from docling_graph.core.converters import GraphConverter\nimport networkx as nx\n\n# Create graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\nprint(\"=== Graph Analysis ===\\n\")\n\n# Basic metrics\nprint(\"Basic Metrics:\")\nprint(f\"  Nodes: {metadata.node_count}\")\nprint(f\"  Edges: {metadata.edge_count}\")\nprint(f\"  Density: {metadata.density:.3f}\")\nprint(f\"  Avg degree: {metadata.avg_degree:.2f}\\n\")\n\n# Node types\nprint(\"Node Types:\")\nfor node_type, count in sorted(metadata.node_types.items(), key=lambda x: x[1], reverse=True):\n    percentage = (count / metadata.node_count) * 100\n    print(f\"  {node_type}: {count} ({percentage:.1f}%)\")\n\n# Edge types\nprint(\"\\nEdge Types:\")\nfor edge_type, count in sorted(metadata.edge_types.items(), key=lambda x: x[1], reverse=True):\n    percentage = (count / metadata.edge_count) * 100\n    print(f\"  {edge_type}: {count} ({percentage:.1f}%)\")\n\n# Connectivity\nprint(\"\\nConnectivity:\")\ncomponents = list(nx.weakly_connected_components(graph))\nprint(f\"  Connected components: {len(components)}\")\nprint(f\"  Largest component: {len(max(components, key=len))} nodes\")\n\n# Quality\nprint(\"\\nQuality:\")\nisolated = [n for n, d in graph.degree() if d == 0]\nprint(f\"  Isolated nodes: {len(isolated)}\")\nprint(f\"  Graph is connected: {nx.is_weakly_connected(graph)}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#example-2-batch-analysis","title":"Example 2: Batch Analysis","text":"<pre><code>from docling_graph import PipelineConfig\nfrom pathlib import Path\nimport json\nimport pandas as pd\n\n# Analyze multiple documents\nresults = []\n\nfor pdf_file in Path(\"documents\").glob(\"*.pdf\"):\n    # Process document\n    output_dir = f\"analysis/{pdf_file.stem}\"\n\n    config = PipelineConfig(\n        source=str(pdf_file),\n        template=\"my_templates.Invoice\",\n        output_dir=output_dir\n    )\n\n    config.run()\n\n    # Load statistics\n    with open(f\"{output_dir}/graph_stats.json\") as f:\n        stats = json.load(f)\n\n    results.append({\n        \"document\": pdf_file.name,\n        \"nodes\": stats[\"node_count\"],\n        \"edges\": stats[\"edge_count\"],\n        \"density\": stats[\"density\"],\n        \"avg_degree\": stats[\"avg_degree\"]\n    })\n\n# Create summary\ndf = pd.DataFrame(results)\nprint(\"\\n=== Batch Analysis Summary ===\")\nprint(df.describe())\n\n# Export\ndf.to_csv(\"batch_analysis.csv\", index=False)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#example-3-quality-report","title":"Example 3: Quality Report","text":"<pre><code>from docling_graph.core.converters import GraphConverter\nimport networkx as nx\n\ndef generate_quality_report(graph, metadata):\n    \"\"\"Generate comprehensive quality report.\"\"\"\n\n    report = {\n        \"basic_metrics\": {\n            \"nodes\": metadata.node_count,\n            \"edges\": metadata.edge_count,\n            \"density\": metadata.density,\n            \"avg_degree\": metadata.avg_degree\n        },\n        \"quality_checks\": {},\n        \"warnings\": []\n    }\n\n    # Check 1: Empty graph\n    if metadata.node_count == 0:\n        report[\"warnings\"].append(\"Graph is empty\")\n        return report\n\n    # Check 2: Isolated nodes\n    isolated = [n for n, d in graph.degree() if d == 0]\n    report[\"quality_checks\"][\"isolated_nodes\"] = len(isolated)\n    if isolated:\n        report[\"warnings\"].append(f\"{len(isolated)} isolated nodes found\")\n\n    # Check 3: Connectivity\n    is_connected = nx.is_weakly_connected(graph)\n    report[\"quality_checks\"][\"is_connected\"] = is_connected\n    if not is_connected:\n        components = list(nx.weakly_connected_components(graph))\n        report[\"warnings\"].append(f\"Graph has {len(components)} disconnected components\")\n\n    # Check 4: Node attributes\n    nodes_without_label = sum(1 for _, data in graph.nodes(data=True) if 'label' not in data)\n    report[\"quality_checks\"][\"nodes_without_label\"] = nodes_without_label\n    if nodes_without_label &gt; 0:\n        report[\"warnings\"].append(f\"{nodes_without_label} nodes missing labels\")\n\n    # Check 5: Self-loops\n    self_loops = list(nx.selfloop_edges(graph))\n    report[\"quality_checks\"][\"self_loops\"] = len(self_loops)\n    if self_loops:\n        report[\"warnings\"].append(f\"{len(self_loops)} self-loops found\")\n\n    return report\n\n# Generate report\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\nreport = generate_quality_report(graph, metadata)\n\n# Print report\nprint(\"=== Quality Report ===\\n\")\nprint(\"Basic Metrics:\")\nfor key, value in report[\"basic_metrics\"].items():\n    print(f\"  {key}: {value}\")\n\nprint(\"\\nQuality Checks:\")\nfor key, value in report[\"quality_checks\"].items():\n    print(f\"  {key}: {value}\")\n\nif report[\"warnings\"]:\n    print(\"\\nWarnings:\")\n    for warning in report[\"warnings\"]:\n        print(f\"  \u26a0 {warning}\")\nelse:\n    print(\"\\n\u2713 No quality issues found\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#advanced-analysis","title":"Advanced Analysis","text":""},{"location":"fundamentals/graph-management/graph-analysis/#centrality-measures","title":"Centrality Measures","text":"<pre><code>import networkx as nx\n\n# Degree centrality\ndegree_centrality = nx.degree_centrality(graph)\ntop_nodes = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n\nprint(\"Top 5 nodes by degree centrality:\")\nfor node, centrality in top_nodes:\n    print(f\"  {node}: {centrality:.3f}\")\n\n# Betweenness centrality (for undirected view)\nundirected = graph.to_undirected()\nbetweenness = nx.betweenness_centrality(undirected)\ntop_between = sorted(betweenness.items(), key=lambda x: x[1], reverse=True)[:5]\n\nprint(\"\\nTop 5 nodes by betweenness centrality:\")\nfor node, centrality in top_between:\n    print(f\"  {node}: {centrality:.3f}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#path-analysis","title":"Path Analysis","text":"<pre><code>import networkx as nx\n\n# Average shortest path length (for connected graphs)\nif nx.is_weakly_connected(graph):\n    avg_path_length = nx.average_shortest_path_length(graph.to_undirected())\n    print(f\"Average shortest path length: {avg_path_length:.2f}\")\n\n# Diameter (longest shortest path)\nif nx.is_weakly_connected(graph):\n    diameter = nx.diameter(graph.to_undirected())\n    print(f\"Graph diameter: {diameter}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#performance-optimization","title":"Performance Optimization","text":""},{"location":"fundamentals/graph-management/graph-analysis/#graph-size-optimization","title":"Graph Size Optimization","text":"<pre><code># Check graph size\nimport sys\n\ngraph_size = sys.getsizeof(graph)\nprint(f\"Graph size: {graph_size / 1024:.2f} KB\")\n\n# Optimize by removing unnecessary attributes\ndef optimize_graph(graph):\n    \"\"\"Remove unnecessary node attributes.\"\"\"\n    for node, data in graph.nodes(data=True):\n        # Keep only essential attributes\n        essential = ['id', 'label', 'type']\n        to_remove = [k for k in data.keys() if k not in essential and data[k] is None]\n        for key in to_remove:\n            del data[key]\n\n    return graph\n\noptimized = optimize_graph(graph.copy())\noptimized_size = sys.getsizeof(optimized)\nprint(f\"Optimized size: {optimized_size / 1024:.2f} KB\")\nprint(f\"Reduction: {(1 - optimized_size/graph_size) * 100:.1f}%\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/graph-analysis/#1-always-validate","title":"1. Always Validate","text":"<pre><code># \u2705 Good - Validate after creation\nfrom docling_graph.core.utils import validate_graph_structure\n\ntry:\n    validate_graph_structure(graph, raise_on_error=True)\nexcept ValueError as e:\n    print(f\"Validation failed: {e}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#2-check-statistics","title":"2. Check Statistics","text":"<pre><code># \u2705 Good - Review statistics\nif metadata.node_count == 0:\n    print(\"Warning: Empty graph\")\n\nif metadata.edge_count == 0:\n    print(\"Warning: No relationships\")\n\nif metadata.density &lt; 0.01:\n    print(\"Warning: Very sparse graph\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#3-monitor-quality","title":"3. Monitor Quality","text":"<pre><code># \u2705 Good - Regular quality checks\nisolated = [n for n, d in graph.degree() if d == 0]\nif len(isolated) &gt; metadata.node_count * 0.1:\n    print(f\"Warning: {len(isolated)} isolated nodes (&gt;10%)\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/graph-analysis/#issue-low-density","title":"Issue: Low Density","text":"<p>Solution: <pre><code># Check if entities are properly connected\n# Ensure relationships are defined in Pydantic models\n\nclass Invoice(BaseModel):\n    issued_by: Organization  # Creates edge\n    line_items: List[LineItem]  # Creates edges\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-analysis/#issue-many-isolated-nodes","title":"Issue: Many Isolated Nodes","text":"<p>Solution: <pre><code># Enable auto cleanup\nconverter = GraphConverter(auto_cleanup=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Or manually remove isolated nodes\nisolated = [n for n, d in graph.degree() if d == 0]\ngraph.remove_nodes_from(isolated)\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-analysis/#issue-disconnected-components","title":"Issue: Disconnected Components","text":"<p>Solution: <pre><code># Find largest component\nimport networkx as nx\n\ncomponents = list(nx.weakly_connected_components(graph))\nlargest = max(components, key=len)\n\n# Extract largest component\nsubgraph = graph.subgraph(largest).copy()\nprint(f\"Largest component: {len(subgraph.nodes())} nodes\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-analysis/#next-steps","title":"Next Steps","text":"<p>Now that you understand graph analysis:</p> <ol> <li>CLI Guide \u2192 - Use command-line tools</li> <li>API Reference \u2192 - Programmatic access</li> <li>Examples \u2192 - Real-world examples</li> </ol>"},{"location":"fundamentals/graph-management/graph-analysis/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/graph-management/graph-analysis/#basic-metrics_1","title":"Basic Metrics","text":"<pre><code>print(f\"Nodes: {metadata.node_count}\")\nprint(f\"Edges: {metadata.edge_count}\")\nprint(f\"Density: {metadata.density:.3f}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#connectivity","title":"Connectivity","text":"<pre><code>import networkx as nx\nis_connected = nx.is_weakly_connected(graph)\ncomponents = list(nx.weakly_connected_components(graph))\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#quality-check","title":"Quality Check","text":"<pre><code>isolated = [n for n, d in graph.degree() if d == 0]\nprint(f\"Isolated nodes: {len(isolated)}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#validation_1","title":"Validation","text":"<pre><code>from docling_graph.core.utils import validate_graph_structure\nvalidate_graph_structure(graph, raise_on_error=True)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/","title":"Graph Conversion","text":""},{"location":"fundamentals/graph-management/graph-conversion/#overview","title":"Overview","text":"<p>Graph conversion transforms Pydantic models into NetworkX directed graphs, creating nodes for entities and edges for relationships. This is the foundation of knowledge graph creation.</p> <p>In this guide: - Conversion process - Node and edge creation - Node ID registry - Graph validation - Automatic cleanup</p>"},{"location":"fundamentals/graph-management/graph-conversion/#conversion-process","title":"Conversion Process","text":""},{"location":"fundamentals/graph-management/graph-conversion/#high-level-flow","title":"High-Level Flow","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Pydantic Models\" }\n\n    B@{ shape: lin-proc, label: \"Pre-register Models\" }\n    C@{ shape: procs, label: \"Create Nodes\" }\n    D@{ shape: procs, label: \"Create Edges\" }\n\n    E@{ shape: tag-proc, label: \"Auto Cleanup\" }\n    F@{ shape: tag-proc, label: \"Validate Graph\" }\n    G@{ shape: tag-proc, label: \"Calculate Stats\" }\n\n    H@{ shape: doc, label: \"NetworkX Graph\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n    F --&gt; G\n    G --&gt; H\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D process\n    class E,F,G operator\n    class H output</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#graphconverter","title":"GraphConverter","text":""},{"location":"fundamentals/graph-management/graph-conversion/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph.core.converters import GraphConverter\n\n# Create converter\nconverter = GraphConverter()\n\n# Convert models to graph\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\nprint(f\"Created graph with {metadata.node_count} nodes and {metadata.edge_count} edges\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#with-configuration","title":"With Configuration","text":"<pre><code>from docling_graph.core.converters import GraphConverter\n\nconverter = GraphConverter(\n    add_reverse_edges=False,  # Don't create bidirectional edges\n    validate_graph=True,      # Validate structure\n    auto_cleanup=True         # Remove phantom nodes\n)\n\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#node-creation","title":"Node Creation","text":""},{"location":"fundamentals/graph-management/graph-conversion/#what-becomes-a-node","title":"What Becomes a Node?","text":"<p>Entities (models with <code>is_entity=True</code>) become nodes:</p> <pre><code>from pydantic import BaseModel\n\n# \u2705 Becomes a node\nclass Organization(BaseModel):\n    name: str\n    model_config = {\"is_entity\": True}  # Default\n\n# \u274c Does NOT become a node\nclass Address(BaseModel):\n    street: str\n    city: str\n    model_config = {\"is_entity\": False}  # Component\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#node-structure","title":"Node Structure","text":"<pre><code># Node in graph\n{\n    \"id\": \"organization_acme_corp\",\n    \"label\": \"Organization\",\n    \"type\": \"entity\",\n    \"__class__\": \"Organization\",\n    \"name\": \"Acme Corp\",\n    \"address\": None  # Reference to nested entity\n}\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#edge-creation","title":"Edge Creation","text":""},{"location":"fundamentals/graph-management/graph-conversion/#automatic-edge-generation","title":"Automatic Edge Generation","text":"<p>Edges are created automatically from model relationships:</p> <pre><code>class Invoice(BaseModel):\n    invoice_number: str\n    issued_by: Organization  # Creates edge: Invoice -&gt; Organization\n    line_items: List[LineItem]  # Creates edges: Invoice -&gt; LineItem (multiple)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#edge-structure","title":"Edge Structure","text":"<pre><code># Edge in graph\n{\n    \"source\": \"invoice_001\",\n    \"target\": \"organization_acme_corp\",\n    \"label\": \"issued_by\",\n    \"properties\": {}\n}\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#custom-edge-labels","title":"Custom Edge Labels","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass Invoice(BaseModel):\n    issued_by: Organization = Field(\n        json_schema_extra={\"edge_label\": \"ISSUED_BY\"}\n    )\n</code></pre> <p>Result: Edge label becomes <code>ISSUED_BY</code> instead of <code>issued_by</code></p>"},{"location":"fundamentals/graph-management/graph-conversion/#node-id-registry","title":"Node ID Registry","text":""},{"location":"fundamentals/graph-management/graph-conversion/#what-is-node-id-registry","title":"What is Node ID Registry?","text":"<p>The NodeIDRegistry ensures consistent, deterministic node IDs across multiple extractions.</p>"},{"location":"fundamentals/graph-management/graph-conversion/#how-it-works","title":"How It Works","text":"<pre><code># Same entity always gets same ID\norg1 = Organization(name=\"Acme Corp\")\norg2 = Organization(name=\"Acme Corp\")\n\n# Both get ID: \"organization_acme_corp\"\nid1 = registry.get_node_id(org1)\nid2 = registry.get_node_id(org2)\n\nassert id1 == id2  # True\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#id-generation","title":"ID Generation","text":"<pre><code>def generate_node_id(model: BaseModel) -&gt; str:\n    \"\"\"Generate deterministic node ID.\"\"\"\n    class_name = model.__class__.__name__.lower()\n\n    # Use stable fields for identity\n    stable_fields = {\n        k: v for k, v in model.model_dump().items()\n        if k not in {\"id\", \"__class__\"} and v is not None\n    }\n\n    # Create content hash\n    content = json.dumps(stable_fields, sort_keys=True)\n    hash_suffix = hashlib.blake2b(content.encode()).hexdigest()[:8]\n\n    return f\"{class_name}_{hash_suffix}\"\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#graph-validation","title":"Graph Validation","text":""},{"location":"fundamentals/graph-management/graph-conversion/#automatic-validation","title":"Automatic Validation","text":"<p>Validation checks graph structure:</p> <pre><code>converter = GraphConverter(validate_graph=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Validates:\n# - No isolated nodes\n# - Valid node IDs\n# - Valid edge connections\n# - No self-loops (optional)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#manual-validation","title":"Manual Validation","text":"<pre><code>from docling_graph.core.utils import validate_graph_structure\n\ntry:\n    validate_graph_structure(graph, raise_on_error=True)\n    print(\"\u2713 Graph structure valid\")\nexcept ValueError as e:\n    print(f\"\u2717 Validation failed: {e}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#automatic-cleanup","title":"Automatic Cleanup","text":""},{"location":"fundamentals/graph-management/graph-conversion/#what-gets-cleaned","title":"What Gets Cleaned?","text":"<p>Automatic cleanup removes:</p> <ol> <li>Phantom nodes - Nodes with no data</li> <li>Duplicate nodes - Same entity multiple times</li> <li>Orphaned edges - Edges to non-existent nodes</li> <li>Empty attributes - Null or empty values</li> </ol>"},{"location":"fundamentals/graph-management/graph-conversion/#configuration","title":"Configuration","text":"<pre><code>converter = GraphConverter(\n    auto_cleanup=True  # Enable cleanup (default)\n)\n\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#manual-cleanup","title":"Manual Cleanup","text":"<pre><code>from docling_graph.core.utils import GraphCleaner\n\ncleaner = GraphCleaner(verbose=True)\ncleaned_graph = cleaner.clean_graph(graph)\n\nprint(f\"Removed {graph.number_of_nodes() - cleaned_graph.number_of_nodes()} phantom nodes\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/graph-management/graph-conversion/#example-1-basic-conversion","title":"Example 1: Basic Conversion","text":"<pre><code>from docling_graph.core.converters import GraphConverter\nfrom my_templates import Invoice, Organization, LineItem\n\n# Create sample models\nmodels = [\n    Invoice(\n        invoice_number=\"INV-001\",\n        issued_by=Organization(name=\"Acme Corp\"),\n        line_items=[\n            LineItem(description=\"Product A\", total=100),\n            LineItem(description=\"Product B\", total=200)\n        ],\n        total=300\n    )\n]\n\n# Convert to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\nprint(f\"Nodes: {metadata.node_count}\")\nprint(f\"Edges: {metadata.edge_count}\")\nprint(f\"Node types: {metadata.node_types}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#example-2-with-reverse-edges","title":"Example 2: With Reverse Edges","text":"<pre><code>from docling_graph.core.converters import GraphConverter\n\n# Create bidirectional edges\nconverter = GraphConverter(add_reverse_edges=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Original edge: Invoice -&gt; Organization (ISSUED_BY)\n# Reverse edge: Organization -&gt; Invoice (reverse_ISSUED_BY)\n\nprint(f\"Total edges (with reverse): {metadata.edge_count}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#example-3-shared-registry-for-batches","title":"Example 3: Shared Registry for Batches","text":"<pre><code>from docling_graph.core.converters import GraphConverter, NodeIDRegistry\n\n# Create shared registry\nregistry = NodeIDRegistry()\n\n# Convert first batch\nconverter1 = GraphConverter(registry=registry)\ngraph1, _ = converter1.pydantic_list_to_graph(batch1_models)\n\n# Convert second batch (same registry)\nconverter2 = GraphConverter(registry=registry)\ngraph2, _ = converter2.pydantic_list_to_graph(batch2_models)\n\n# Same entities get same IDs across batches\nprint(f\"Registry has {registry.get_stats()['total_entities']} unique entities\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#example-4-custom-configuration","title":"Example 4: Custom Configuration","text":"<pre><code>from docling_graph.core.converters import GraphConverter, GraphConfig\n\n# Create custom config\nconfig = GraphConfig(\n    add_reverse_edges=True,\n    validate_graph=True,\n    node_id_prefix=\"doc_\"\n)\n\nconverter = GraphConverter(config=config)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#graph-metadata","title":"Graph Metadata","text":""},{"location":"fundamentals/graph-management/graph-conversion/#metadata-structure","title":"Metadata Structure","text":"<pre><code>@dataclass\nclass GraphMetadata:\n    node_count: int\n    edge_count: int\n    node_types: Dict[str, int]\n    edge_types: Dict[str, int]\n    avg_degree: float\n    density: float\n    source_model_count: int\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#using-metadata","title":"Using Metadata","text":"<pre><code>graph, metadata = converter.pydantic_list_to_graph(models)\n\nprint(f\"Graph Statistics:\")\nprint(f\"  Nodes: {metadata.node_count}\")\nprint(f\"  Edges: {metadata.edge_count}\")\nprint(f\"  Density: {metadata.density:.2f}\")\nprint(f\"  Avg degree: {metadata.avg_degree:.2f}\")\n\nprint(f\"\\nNode Types:\")\nfor node_type, count in metadata.node_types.items():\n    print(f\"  {node_type}: {count}\")\n\nprint(f\"\\nEdge Types:\")\nfor edge_type, count in metadata.edge_types.items():\n    print(f\"  {edge_type}: {count}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#advanced-features","title":"Advanced Features","text":""},{"location":"fundamentals/graph-management/graph-conversion/#reverse-edges","title":"Reverse Edges","text":"<p>Create bidirectional relationships:</p> <pre><code>converter = GraphConverter(add_reverse_edges=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# For each edge A -&gt; B, creates B -&gt; A\n# Useful for graph traversal in both directions\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#custom-node-ids","title":"Custom Node IDs","text":"<p>Provide custom node ID logic:</p> <pre><code>from docling_graph.core.converters import NodeIDRegistry\n\nclass CustomRegistry(NodeIDRegistry):\n    def generate_node_id(self, model: BaseModel) -&gt; str:\n        # Custom ID generation\n        return f\"custom_{model.__class__.__name__}_{hash(model)}\"\n\nregistry = CustomRegistry()\nconverter = GraphConverter(registry=registry)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#performance-optimization","title":"Performance Optimization","text":""},{"location":"fundamentals/graph-management/graph-conversion/#batch-processing","title":"Batch Processing","text":"<pre><code># Process large model lists efficiently\nconverter = GraphConverter(auto_cleanup=True)\n\n# Convert in single call (efficient)\ngraph, metadata = converter.pydantic_list_to_graph(all_models)\n\n# Don't convert one by one (inefficient)\n# for model in models:\n#     graph, _ = converter.pydantic_list_to_graph([model])\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#memory-management","title":"Memory Management","text":"<pre><code># For very large graphs\nconverter = GraphConverter(\n    auto_cleanup=True,  # Remove unnecessary nodes\n    validate_graph=False  # Skip validation for speed\n)\n\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Clear registry after conversion\nconverter.registry.clear()\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/graph-conversion/#issue-empty-graph","title":"Issue: Empty Graph","text":"<p>Solution: <pre><code># Check if models have entities\nfor model in models:\n    if hasattr(model, 'model_config'):\n        is_entity = model.model_config.get('is_entity', True)\n        print(f\"{model.__class__.__name__}: is_entity={is_entity}\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-conversion/#issue-missing-edges","title":"Issue: Missing Edges","text":"<p>Solution: <pre><code># Ensure relationships are defined\nclass Invoice(BaseModel):\n    issued_by: Organization  # Must be typed as entity\n    # Not: issued_by: dict  # Won't create edge\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-conversion/#issue-duplicate-nodes","title":"Issue: Duplicate Nodes","text":"<p>Solution: <pre><code># Enable auto cleanup\nconverter = GraphConverter(auto_cleanup=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-conversion/#issue-validation-fails","title":"Issue: Validation Fails","text":"<p>Solution: <pre><code># Check graph structure\nprint(f\"Nodes: {graph.number_of_nodes()}\")\nprint(f\"Edges: {graph.number_of_edges()}\")\n\n# Inspect nodes\nfor node_id, data in list(graph.nodes(data=True))[:5]:\n    print(f\"Node: {node_id}, Data: {data}\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-conversion/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/graph-conversion/#1-use-shared-registry-for-batches","title":"1. Use Shared Registry for Batches","text":"<pre><code># \u2705 Good - Consistent IDs across batches\nregistry = NodeIDRegistry()\n\nfor batch in batches:\n    converter = GraphConverter(registry=registry)\n    graph, _ = converter.pydantic_list_to_graph(batch)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#2-enable-auto-cleanup","title":"2. Enable Auto Cleanup","text":"<pre><code># \u2705 Good - Clean graphs\nconverter = GraphConverter(auto_cleanup=True)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#3-validate-in-development","title":"3. Validate in Development","text":"<pre><code># \u2705 Good - Catch issues early\nconverter = GraphConverter(validate_graph=True)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#4-disable-validation-in-production","title":"4. Disable Validation in Production","text":"<pre><code># \u2705 Good - Faster in production\nconverter = GraphConverter(validate_graph=False)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#next-steps","title":"Next Steps","text":"<p>Now that you understand graph conversion:</p> <ol> <li>Export Formats \u2192 - Export graphs to CSV, Cypher, JSON</li> <li>Visualization \u2192 - Visualize your graphs</li> <li>Neo4j Integration \u2192 - Import into Neo4j</li> </ol>"},{"location":"fundamentals/graph-management/graph-conversion/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/graph-management/graph-conversion/#basic-conversion","title":"Basic Conversion","text":"<pre><code>from docling_graph.core.converters import GraphConverter\n\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#with-options","title":"With Options","text":"<pre><code>converter = GraphConverter(\n    add_reverse_edges=True,\n    validate_graph=True,\n    auto_cleanup=True\n)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#shared-registry","title":"Shared Registry","text":"<pre><code>from docling_graph.core.converters import NodeIDRegistry\n\nregistry = NodeIDRegistry()\nconverter = GraphConverter(registry=registry)\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/","title":"Neo4j Integration","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#overview","title":"Overview","text":"<p>Neo4j integration enables you to import knowledge graphs into Neo4j graph database for powerful querying, analysis, and visualization using Cypher query language.</p> <p>In this guide: - Neo4j setup - Cypher import - Query examples - Best practices - Troubleshooting</p>"},{"location":"fundamentals/graph-management/neo4j-integration/#why-neo4j","title":"Why Neo4j?","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#benefits","title":"Benefits","text":"<p>\u2705 Graph-native database - Optimized for graph queries - Fast relationship traversal - ACID transactions</p> <p>\u2705 Cypher query language - Intuitive pattern matching - Powerful aggregations - Path finding algorithms</p> <p>\u2705 Visualization - Built-in graph browser - Interactive exploration - Custom styling</p> <p>\u2705 Scalability - Handles millions of nodes - Distributed architecture - High performance</p>"},{"location":"fundamentals/graph-management/neo4j-integration/#neo4j-setup","title":"Neo4j Setup","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#installation","title":"Installation","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#option-1-neo4j-desktop-recommended","title":"Option 1: Neo4j Desktop (Recommended)","text":"<pre><code># Download from https://neo4j.com/download/\n# Install and create a new database\n# Default credentials: neo4j/neo4j (change on first login)\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#option-2-docker","title":"Option 2: Docker","text":"<pre><code># Run Neo4j in Docker\ndocker run \\\n    --name neo4j \\\n    -p 7474:7474 -p 7687:7687 \\\n    -e NEO4J_AUTH=neo4j/password \\\n    neo4j:latest\n\n# Access at http://localhost:7474\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#option-3-cloud-neo4j-aura","title":"Option 3: Cloud (Neo4j Aura)","text":"<pre><code># Sign up at https://neo4j.com/cloud/aura/\n# Create free instance\n# Note connection URI and credentials\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#verify-installation","title":"Verify Installation","text":"<pre><code># Check Neo4j is running\ncurl http://localhost:7474\n\n# Test cypher-shell\ncypher-shell -u neo4j -p password \"RETURN 1\"\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#exporting-for-neo4j","title":"Exporting for Neo4j","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#generate-cypher-script","title":"Generate Cypher Script","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"cypher\",  # Generate Cypher script\n    output_dir=\"neo4j_import\"\n)\n\nconfig.run()\n\n# Generates: neo4j_import/graph.cypher\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#importing-to-neo4j","title":"Importing to Neo4j","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#method-1-cypher-shell-recommended","title":"Method 1: cypher-shell (Recommended)","text":"<pre><code># Import Cypher script\ncat neo4j_import/graph.cypher | cypher-shell -u neo4j -p password\n\n# Or with file\ncypher-shell -u neo4j -p password -f neo4j_import/graph.cypher\n\n# With error logging\ncat neo4j_import/graph.cypher | cypher-shell -u neo4j -p password 2&gt;&amp;1 | tee import.log\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#method-2-neo4j-browser","title":"Method 2: Neo4j Browser","text":"<ol> <li>Open Neo4j Browser (http://localhost:7474)</li> <li>Login with credentials</li> <li>Open <code>graph.cypher</code> file</li> <li>Copy contents</li> <li>Paste into query editor</li> <li>Click \"Run\" or press Ctrl+Enter</li> </ol>"},{"location":"fundamentals/graph-management/neo4j-integration/#method-3-python-driver","title":"Method 3: Python Driver","text":"<pre><code>from neo4j import GraphDatabase\n\n# Connect to Neo4j\ndriver = GraphDatabase.driver(\n    \"bolt://localhost:7687\",\n    auth=(\"neo4j\", \"password\")\n)\n\n# Read Cypher file\nwith open(\"neo4j_import/graph.cypher\") as f:\n    cypher_script = f.read()\n\n# Execute\nwith driver.session() as session:\n    session.run(cypher_script)\n\ndriver.close()\nprint(\"\u2713 Imported to Neo4j\")\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#method-4-automated-import","title":"Method 4: Automated Import","text":"<pre><code>from docling_graph import PipelineConfig\nimport subprocess\n\n# Extract and export\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"cypher\",\n    output_dir=\"neo4j_import\"\n)\n\nconfig.run()\n\n# Import to Neo4j\nresult = subprocess.run([\n    \"cypher-shell\",\n    \"-u\", \"neo4j\",\n    \"-p\", \"password\",\n    \"-f\", \"neo4j_import/graph.cypher\"\n], capture_output=True, text=True)\n\nif result.returncode == 0:\n    print(\"\u2713 Successfully imported to Neo4j\")\nelse:\n    print(f\"\u2717 Import failed: {result.stderr}\")\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#querying-neo4j","title":"Querying Neo4j","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#basic-queries","title":"Basic Queries","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#count-nodes","title":"Count Nodes","text":"<pre><code>// Count all nodes\nMATCH (n)\nRETURN count(n) as total_nodes\n\n// Count by type\nMATCH (n)\nRETURN labels(n) as type, count(n) as count\nORDER BY count DESC\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#count-relationships","title":"Count Relationships","text":"<pre><code>// Count all relationships\nMATCH ()-[r]-&gt;()\nRETURN count(r) as total_relationships\n\n// Count by type\nMATCH ()-[r]-&gt;()\nRETURN type(r) as relationship_type, count(r) as count\nORDER BY count DESC\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#finding-nodes","title":"Finding Nodes","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#find-specific-node","title":"Find Specific Node","text":"<pre><code>// Find invoice by number\nMATCH (i:Invoice {invoice_number: \"INV-001\"})\nRETURN i\n\n// Find organization by name\nMATCH (o:Organization {name: \"Acme Corp\"})\nRETURN o\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#find-all-of-type","title":"Find All of Type","text":"<pre><code>// Find all invoices\nMATCH (i:Invoice)\nRETURN i\nLIMIT 10\n\n// Find all organizations\nMATCH (o:Organization)\nRETURN o.name, o.address\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#relationship-queries","title":"Relationship Queries","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#direct-relationships","title":"Direct Relationships","text":"<pre><code>// Find who issued an invoice\nMATCH (i:Invoice {invoice_number: \"INV-001\"})-[:ISSUED_BY]-&gt;(o:Organization)\nRETURN i.invoice_number, o.name\n\n// Find all line items in an invoice\nMATCH (i:Invoice)-[:CONTAINS_ITEM]-&gt;(item:LineItem)\nWHERE i.invoice_number = \"INV-001\"\nRETURN item.description, item.total\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#multi-hop-relationships","title":"Multi-Hop Relationships","text":"<pre><code>// Find invoice -&gt; organization -&gt; address\nMATCH (i:Invoice)-[:ISSUED_BY]-&gt;(o:Organization)-[:LOCATED_AT]-&gt;(a:Address)\nRETURN i.invoice_number, o.name, a.city\n\n// Find all paths between two nodes\nMATCH path = (start:Invoice)-[*..3]-(end:Address)\nWHERE start.invoice_number = \"INV-001\"\nRETURN path\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#aggregation-queries","title":"Aggregation Queries","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#sum-and-average","title":"Sum and Average","text":"<pre><code>// Total invoice amount\nMATCH (i:Invoice)\nRETURN sum(i.total) as total_amount\n\n// Average invoice amount\nMATCH (i:Invoice)\nRETURN avg(i.total) as average_amount\n\n// Count invoices per organization\nMATCH (o:Organization)&lt;-[:ISSUED_BY]-(i:Invoice)\nRETURN o.name, count(i) as invoice_count\nORDER BY invoice_count DESC\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#pattern-matching","title":"Pattern Matching","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#complex-patterns","title":"Complex Patterns","text":"<pre><code>// Find invoices with specific pattern\nMATCH (i:Invoice)-[:ISSUED_BY]-&gt;(o:Organization),\n      (i)-[:SENT_TO]-&gt;(c:Organization),\n      (i)-[:CONTAINS_ITEM]-&gt;(item:LineItem)\nWHERE i.total &gt; 1000\nRETURN i, o, c, collect(item) as items\n\n// Find organizations that both issue and receive invoices\nMATCH (o:Organization)&lt;-[:ISSUED_BY]-(i1:Invoice),\n      (o)&lt;-[:SENT_TO]-(i2:Invoice)\nRETURN o.name, count(DISTINCT i1) as issued, count(DISTINCT i2) as received\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#example-1-import-and-query","title":"Example 1: Import and Query","text":"<pre><code>from docling_graph import PipelineConfig\nfrom neo4j import GraphDatabase\n\n# 1. Extract and export\nconfig = PipelineConfig(\n    source=\"invoices.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"cypher\",\n    output_dir=\"neo4j_data\"\n)\n\nconfig.run()\n\n# 2. Import to Neo4j\ndriver = GraphDatabase.driver(\n    \"bolt://localhost:7687\",\n    auth=(\"neo4j\", \"password\")\n)\n\nwith open(\"neo4j_data/graph.cypher\") as f:\n    cypher_script = f.read()\n\nwith driver.session() as session:\n    session.run(cypher_script)\n\n# 3. Query\nwith driver.session() as session:\n    result = session.run(\"\"\"\n        MATCH (i:Invoice)\n        RETURN i.invoice_number, i.total\n        ORDER BY i.total DESC\n        LIMIT 5\n    \"\"\")\n\n    for record in result:\n        print(f\"{record['i.invoice_number']}: ${record['i.total']}\")\n\ndriver.close()\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#example-2-batch-import","title":"Example 2: Batch Import","text":"<pre><code>from docling_graph import PipelineConfig\nfrom pathlib import Path\nimport subprocess\n\n# Process multiple documents\nfor pdf_file in Path(\"documents\").glob(\"*.pdf\"):\n    print(f\"Processing {pdf_file.name}\")\n\n    # Extract\n    config = PipelineConfig(\n        source=str(pdf_file),\n        template=\"my_templates.Invoice\",\n        export_format=\"cypher\",\n        output_dir=f\"neo4j_batch/{pdf_file.stem}\"\n    )\n\n    config.run()\n\n    # Import\n    cypher_file = f\"neo4j_batch/{pdf_file.stem}/graph.cypher\"\n    subprocess.run([\n        \"cypher-shell\",\n        \"-u\", \"neo4j\",\n        \"-p\", \"password\",\n        \"-f\", cypher_file\n    ])\n\nprint(\"\u2713 Batch import complete\")\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#example-3-query-and-export","title":"Example 3: Query and Export","text":"<pre><code>from neo4j import GraphDatabase\nimport pandas as pd\n\n# Connect\ndriver = GraphDatabase.driver(\n    \"bolt://localhost:7687\",\n    auth=(\"neo4j\", \"password\")\n)\n\n# Query\nwith driver.session() as session:\n    result = session.run(\"\"\"\n        MATCH (i:Invoice)-[:ISSUED_BY]-&gt;(o:Organization)\n        RETURN i.invoice_number as invoice,\n               o.name as organization,\n               i.total as amount\n        ORDER BY i.total DESC\n    \"\"\")\n\n    # Convert to DataFrame\n    df = pd.DataFrame([dict(record) for record in result])\n\n    # Export\n    df.to_csv(\"invoice_summary.csv\", index=False)\n    print(f\"Exported {len(df)} records\")\n\ndriver.close()\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#1-clear-database-before-import","title":"1. Clear Database Before Import","text":"<pre><code>// Delete all nodes and relationships\nMATCH (n)\nDETACH DELETE n\n\n// Verify empty\nMATCH (n)\nRETURN count(n)\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#2-create-indexes","title":"2. Create Indexes","text":"<pre><code>// Create index on invoice number\nCREATE INDEX invoice_number_idx FOR (i:Invoice) ON (i.invoice_number)\n\n// Create index on organization name\nCREATE INDEX org_name_idx FOR (o:Organization) ON (o.name)\n\n// List indexes\nSHOW INDEXES\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#3-use-constraints","title":"3. Use Constraints","text":"<pre><code>// Unique constraint on invoice number\nCREATE CONSTRAINT invoice_unique FOR (i:Invoice) REQUIRE i.invoice_number IS UNIQUE\n\n// Existence constraint\nCREATE CONSTRAINT invoice_number_exists FOR (i:Invoice) REQUIRE i.invoice_number IS NOT NULL\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#4-batch-imports","title":"4. Batch Imports","text":"<pre><code># \u2705 Good - Import in batches\nfrom neo4j import GraphDatabase\n\ndriver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n\n# Process in batches\nbatch_size = 1000\nfor i in range(0, len(statements), batch_size):\n    batch = statements[i:i+batch_size]\n\n    with driver.session() as session:\n        for statement in batch:\n            session.run(statement)\n\n    print(f\"Imported batch {i//batch_size + 1}\")\n\ndriver.close()\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#issue-connection-refused","title":"Issue: Connection Refused","text":"<p>Solution: <pre><code># Check Neo4j is running\ndocker ps | grep neo4j\n\n# Or check service\nsystemctl status neo4j\n\n# Restart if needed\ndocker restart neo4j\n</code></pre></p>"},{"location":"fundamentals/graph-management/neo4j-integration/#issue-authentication-failed","title":"Issue: Authentication Failed","text":"<p>Solution: <pre><code># Reset password\ncypher-shell -u neo4j -p neo4j\n# Then change password when prompted\n\n# Or set in Docker\ndocker run -e NEO4J_AUTH=neo4j/newpassword neo4j\n</code></pre></p>"},{"location":"fundamentals/graph-management/neo4j-integration/#issue-import-fails","title":"Issue: Import Fails","text":"<p>Solution: <pre><code># Check Cypher syntax\nhead -20 neo4j_import/graph.cypher\n\n# Test small portion\nhead -100 neo4j_import/graph.cypher | cypher-shell -u neo4j -p password\n\n# Check logs\ndocker logs neo4j\n</code></pre></p>"},{"location":"fundamentals/graph-management/neo4j-integration/#issue-slow-queries","title":"Issue: Slow Queries","text":"<p>Solution: <pre><code>// Create indexes\nCREATE INDEX FOR (i:Invoice) ON (i.invoice_number)\n\n// Use EXPLAIN to analyze\nEXPLAIN MATCH (i:Invoice) WHERE i.total &gt; 1000 RETURN i\n\n// Use PROFILE for detailed analysis\nPROFILE MATCH (i:Invoice) WHERE i.total &gt; 1000 RETURN i\n</code></pre></p>"},{"location":"fundamentals/graph-management/neo4j-integration/#advanced-topics","title":"Advanced Topics","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#graph-algorithms","title":"Graph Algorithms","text":"<pre><code>// Find shortest path\nMATCH path = shortestPath(\n    (start:Invoice {invoice_number: \"INV-001\"})-[*]-(end:Address)\n)\nRETURN path\n\n// PageRank (requires APOC or GDS)\nCALL gds.pageRank.stream('myGraph')\nYIELD nodeId, score\nRETURN gds.util.asNode(nodeId).name AS name, score\nORDER BY score DESC\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#full-text-search","title":"Full-Text Search","text":"<pre><code>// Create full-text index\nCREATE FULLTEXT INDEX organization_search FOR (o:Organization) ON EACH [o.name, o.description]\n\n// Search\nCALL db.index.fulltext.queryNodes('organization_search', 'Acme')\nYIELD node, score\nRETURN node.name, score\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#next-steps","title":"Next Steps","text":"<p>Now that you understand Neo4j integration:</p> <ol> <li>Graph Analysis \u2192 - Analyze graph structure</li> <li>CLI Guide \u2192 - Use command-line tools</li> <li>API Reference \u2192 - Programmatic access</li> </ol>"},{"location":"fundamentals/graph-management/neo4j-integration/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#export-for-neo4j","title":"Export for Neo4j","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"cypher\"\n)\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#import-to-neo4j","title":"Import to Neo4j","text":"<pre><code>cat graph.cypher | cypher-shell -u neo4j -p password\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#basic-query","title":"Basic Query","text":"<pre><code>MATCH (n) RETURN n LIMIT 10\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#clear-database","title":"Clear Database","text":"<pre><code>MATCH (n) DETACH DELETE n\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/","title":"Visualization","text":""},{"location":"fundamentals/graph-management/visualization/#overview","title":"Overview","text":"<p>Visualization transforms your knowledge graphs into interactive, explorable visualizations. Docling Graph automatically generates HTML visualizations and markdown reports for every pipeline run.</p> <p>In this guide: - Interactive HTML graphs - Markdown reports - Graph statistics - Customization options - Integration examples</p>"},{"location":"fundamentals/graph-management/visualization/#automatic-visualization","title":"Automatic Visualization","text":""},{"location":"fundamentals/graph-management/visualization/#what-gets-generated","title":"What Gets Generated?","text":"<p>Every pipeline run automatically creates:</p> <pre><code>outputs/\n\u251c\u2500\u2500 visualization.html  # Interactive graph\n\u251c\u2500\u2500 report.md          # Markdown report\n\u2514\u2500\u2500 graph_stats.json   # Statistics\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    output_dir=\"outputs\"\n)\n\nconfig.run()\n\n# Automatically generates:\n# - outputs/visualization.html\n# - outputs/report.md\n# - outputs/graph_stats.json\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#interactive-html-visualization","title":"Interactive HTML Visualization","text":""},{"location":"fundamentals/graph-management/visualization/#features","title":"Features","text":"<p>\u2705 Interactive exploration - Zoom and pan - Node selection - Search functionality - Layout algorithms</p> <p>\u2705 Visual styling - Color-coded node types - Edge labels - Hover tooltips - Responsive design</p> <p>\u2705 Export options - Save as image - Share via URL - Embed in websites</p>"},{"location":"fundamentals/graph-management/visualization/#opening-visualization","title":"Opening Visualization","text":"<pre><code># Open in browser\nopen outputs/visualization.html  # macOS\nxdg-open outputs/visualization.html  # Linux\nstart outputs/visualization.html  # Windows\n\n# Or double-click the file\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#manual-generation","title":"Manual Generation","text":"<pre><code>from docling_graph.core.visualizers import InteractiveVisualizer\nfrom docling_graph.core.converters import GraphConverter\n\n# Convert models to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Generate visualization\nvisualizer = InteractiveVisualizer()\nvisualizer.save_cytoscape_graph(\n    graph=graph,\n    output_path=\"my_graph.html\",\n    open_browser=True  # Automatically open\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#markdown-reports","title":"Markdown Reports","text":""},{"location":"fundamentals/graph-management/visualization/#whats-in-the-report","title":"What's in the Report?","text":"<p>Markdown reports contain:</p> <ol> <li>Overview - Node/edge counts, timestamps</li> <li>Node Distribution - Types and percentages</li> <li>Edge Distribution - Relationship types</li> <li>Sample Nodes - Example entities</li> <li>Sample Edges - Example relationships</li> </ol>"},{"location":"fundamentals/graph-management/visualization/#example-report","title":"Example Report","text":"<pre><code># Knowledge Graph Report\n\nAutomatically generated by docling-graph.\n\n## Overview\n\n- **Total Nodes**: 15\n- **Total Edges**: 18\n- **Source Models**: 1\n- **Generated**: 2024-01-15 14:30:00\n\n## Node Type Distribution\n\n| Node Type | Count | Percentage |\n|-----------|-------|------------|\n| LineItem | 9 | 60.0% |\n| Address | 3 | 20.0% |\n| Organization | 2 | 13.3% |\n| Invoice | 1 | 6.7% |\n\n## Edge Type Distribution\n\n| Edge Type | Count | Percentage |\n|-----------|-------|------------|\n| contains_item | 9 | 50.0% |\n| located_at | 5 | 27.8% |\n| has_total | 2 | 11.1% |\n| issued_by | 1 | 5.6% |\n| sent_to | 1 | 5.6% |\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#manual-report-generation","title":"Manual Report Generation","text":"<pre><code>from docling_graph.core.visualizers import ReportGenerator\nfrom docling_graph.core.converters import GraphConverter\n\n# Convert models to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Generate report\ngenerator = ReportGenerator()\ngenerator.visualize(\n    graph=graph,\n    output_path=\"my_report.md\",\n    source_model_count=len(models),\n    include_samples=True\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#graph-statistics","title":"Graph Statistics","text":""},{"location":"fundamentals/graph-management/visualization/#graph_statsjson-format","title":"graph_stats.json Format","text":"<pre><code>{\n  \"node_count\": 15,\n  \"edge_count\": 18,\n  \"node_types\": {\n    \"Invoice\": 1,\n    \"Organization\": 2,\n    \"Address\": 3,\n    \"LineItem\": 9\n  },\n  \"edge_types\": {\n    \"issued_by\": 1,\n    \"sent_to\": 1,\n    \"located_at\": 5,\n    \"contains_item\": 9,\n    \"has_total\": 2\n  },\n  \"avg_degree\": 2.4,\n  \"density\": 0.17,\n  \"source_models\": 1,\n  \"created_at\": \"2024-01-15T14:30:00\"\n}\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#using-statistics","title":"Using Statistics","text":"<pre><code>import json\n\n# Load statistics\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\n# Analyze\nprint(f\"Graph has {stats['node_count']} nodes\")\nprint(f\"Average degree: {stats['avg_degree']:.2f}\")\nprint(f\"Density: {stats['density']:.2f}\")\n\n# Most common node type\nmost_common = max(stats['node_types'], key=stats['node_types'].get)\nprint(f\"Most common node type: {most_common}\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/graph-management/visualization/#example-1-basic-visualization","title":"Example 1: Basic Visualization","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Run pipeline (automatic visualization)\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"my_templates.Invoice\",\n    output_dir=\"outputs\"\n)\n\nconfig.run()\n\n# Open visualization\nimport webbrowser\nwebbrowser.open(\"file://outputs/visualization.html\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#example-2-custom-visualization","title":"Example 2: Custom Visualization","text":"<pre><code>from docling_graph.core.visualizers import InteractiveVisualizer\nfrom docling_graph.core.converters import GraphConverter\n\n# Create graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Generate custom visualization\nvisualizer = InteractiveVisualizer()\nhtml_path = visualizer.save_cytoscape_graph(\n    graph=graph,\n    output_path=\"custom_graph.html\",\n    open_browser=False\n)\n\nprint(f\"Visualization saved to {html_path}\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#example-3-batch-visualization","title":"Example 3: Batch Visualization","text":"<pre><code>from docling_graph import PipelineConfig\nfrom pathlib import Path\n\n# Process multiple documents\nfor pdf_file in Path(\"documents\").glob(\"*.pdf\"):\n    output_dir = f\"visualizations/{pdf_file.stem}\"\n\n    config = PipelineConfig(\n        source=str(pdf_file),\n        template=\"my_templates.Invoice\",\n        output_dir=output_dir\n    )\n\n    config.run()\n\n    print(f\"Visualization: {output_dir}/visualization.html\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#example-4-report-analysis","title":"Example 4: Report Analysis","text":"<pre><code>import json\nfrom pathlib import Path\n\n# Analyze multiple reports\nreports = []\n\nfor stats_file in Path(\"outputs\").rglob(\"graph_stats.json\"):\n    with open(stats_file) as f:\n        stats = json.load(f)\n        reports.append({\n            \"file\": stats_file.parent.name,\n            \"nodes\": stats[\"node_count\"],\n            \"edges\": stats[\"edge_count\"],\n            \"density\": stats[\"density\"]\n        })\n\n# Summary\nimport pandas as pd\ndf = pd.DataFrame(reports)\nprint(df.describe())\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#visualization-from-csv","title":"Visualization from CSV","text":""},{"location":"fundamentals/graph-management/visualization/#load-and-visualize-csv","title":"Load and Visualize CSV","text":"<pre><code>from docling_graph.core.visualizers import InteractiveVisualizer\nfrom pathlib import Path\n\n# Load CSV and create visualization\nvisualizer = InteractiveVisualizer()\nhtml_path = visualizer.display_cytoscape_graph(\n    path=Path(\"outputs\"),  # Directory with nodes.csv and edges.csv\n    input_format=\"csv\",\n    output_path=\"from_csv.html\",\n    open_browser=True\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#visualization-from-json","title":"Visualization from JSON","text":""},{"location":"fundamentals/graph-management/visualization/#load-and-visualize-json","title":"Load and Visualize JSON","text":"<pre><code>from docling_graph.core.visualizers import InteractiveVisualizer\nfrom pathlib import Path\n\n# Load JSON and create visualization\nvisualizer = InteractiveVisualizer()\nhtml_path = visualizer.display_cytoscape_graph(\n    path=Path(\"outputs/graph_data.json\"),\n    input_format=\"json\",\n    output_path=\"from_json.html\",\n    open_browser=True\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#customization","title":"Customization","text":""},{"location":"fundamentals/graph-management/visualization/#custom-report","title":"Custom Report","text":"<pre><code>from docling_graph.core.visualizers import ReportGenerator\n\ngenerator = ReportGenerator()\ngenerator.visualize(\n    graph=graph,\n    output_path=\"custom_report.md\",\n    source_model_count=len(models),\n    include_samples=False  # Exclude sample nodes/edges\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#custom-statistics","title":"Custom Statistics","text":"<pre><code>from docling_graph.core.utils import calculate_graph_stats\n\n# Calculate custom statistics\nmetadata = calculate_graph_stats(graph, source_model_count=len(models))\n\nprint(f\"Nodes: {metadata.node_count}\")\nprint(f\"Edges: {metadata.edge_count}\")\nprint(f\"Density: {metadata.density:.3f}\")\nprint(f\"Avg degree: {metadata.avg_degree:.2f}\")\n\n# Node type distribution\nfor node_type, count in metadata.node_types.items():\n    percentage = (count / metadata.node_count) * 100\n    print(f\"{node_type}: {count} ({percentage:.1f}%)\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#integration-examples","title":"Integration Examples","text":""},{"location":"fundamentals/graph-management/visualization/#example-1-web-dashboard","title":"Example 1: Web Dashboard","text":"<pre><code>from flask import Flask, render_template\nfrom docling_graph import PipelineConfig\nimport json\n\napp = Flask(__name__)\n\n@app.route('/visualize/&lt;doc_id&gt;')\ndef visualize(doc_id):\n    # Load graph data\n    with open(f\"outputs/{doc_id}/graph_stats.json\") as f:\n        stats = json.load(f)\n\n    return render_template('dashboard.html', \n                         stats=stats,\n                         viz_url=f\"/static/{doc_id}/visualization.html\")\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#example-2-automated-reports","title":"Example 2: Automated Reports","text":"<pre><code>from docling_graph import PipelineConfig\nfrom pathlib import Path\nimport smtplib\nfrom email.mime.text import MIMEText\n\ndef process_and_email(pdf_path, recipient):\n    \"\"\"Process document and email report.\"\"\"\n\n    # Process document\n    config = PipelineConfig(\n        source=pdf_path,\n        template=\"my_templates.Invoice\",\n        output_dir=\"temp_output\"\n    )\n    config.run()\n\n    # Read report\n    with open(\"temp_output/report.md\") as f:\n        report = f.read()\n\n    # Email report\n    msg = MIMEText(report)\n    msg['Subject'] = f'Graph Report: {Path(pdf_path).name}'\n    msg['To'] = recipient\n\n    # Send email (configure SMTP)\n    # smtp.send_message(msg)\n\n    print(f\"Report sent to {recipient}\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/visualization/#1-always-generate-visualizations","title":"1. Always Generate Visualizations","text":"<pre><code># \u2705 Good - Keep visualizations enabled\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    # Visualizations generated automatically\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#2-check-statistics","title":"2. Check Statistics","text":"<pre><code># \u2705 Good - Verify graph quality\nimport json\n\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nif stats[\"node_count\"] == 0:\n    print(\"Warning: Empty graph\")\n\nif stats[\"edge_count\"] == 0:\n    print(\"Warning: No relationships\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#3-organize-visualizations","title":"3. Organize Visualizations","text":"<pre><code># \u2705 Good - Structured output\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\noutput_dir = f\"visualizations/{timestamp}\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    output_dir=output_dir\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/visualization/#issue-visualization-not-opening","title":"Issue: Visualization Not Opening","text":"<p>Solution: <pre><code># Check file exists\nimport os\n\nviz_path = \"outputs/visualization.html\"\nif os.path.exists(viz_path):\n    print(f\"\u2713 File exists: {viz_path}\")\n\n    # Open manually\n    import webbrowser\n    webbrowser.open(f\"file://{os.path.abspath(viz_path)}\")\nelse:\n    print(f\"\u2717 File not found: {viz_path}\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/visualization/#issue-empty-visualization","title":"Issue: Empty Visualization","text":"<p>Solution: <pre><code># Check graph has nodes\nimport json\n\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nif stats[\"node_count\"] == 0:\n    print(\"Graph is empty - check extraction\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/visualization/#issue-report-generation-fails","title":"Issue: Report Generation Fails","text":"<p>Solution: <pre><code># Check graph validity\nfrom docling_graph.core.visualizers import ReportGenerator\n\ngenerator = ReportGenerator()\n\nif generator.validate_graph(graph):\n    print(\"\u2713 Graph is valid\")\nelse:\n    print(\"\u2717 Graph is empty\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/visualization/#next-steps","title":"Next Steps","text":"<p>Now that you understand visualization:</p> <ol> <li>Neo4j Integration \u2192 - Import into Neo4j</li> <li>Graph Analysis \u2192 - Analyze graph structure</li> <li>CLI Guide \u2192 - Use command-line tools</li> </ol>"},{"location":"fundamentals/graph-management/visualization/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/graph-management/visualization/#automatic-visualization_1","title":"Automatic Visualization","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\"\n)\nconfig.run()\n# Generates: visualization.html, report.md, graph_stats.json\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#manual-visualization","title":"Manual Visualization","text":"<pre><code>from docling_graph.core.visualizers import InteractiveVisualizer\n\nvisualizer = InteractiveVisualizer()\nvisualizer.save_cytoscape_graph(graph, \"graph.html\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#manual-report","title":"Manual Report","text":"<pre><code>from docling_graph.core.visualizers import ReportGenerator\n\ngenerator = ReportGenerator()\ngenerator.visualize(graph, \"report.md\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#load-statistics","title":"Load Statistics","text":"<pre><code>import json\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n</code></pre>"},{"location":"fundamentals/installation/","title":"Installation","text":"<p>Pipeline Stage: 2 - Installation</p> <p>Prerequisites:  - Introduction</p> <p>This section guides you through setting up Docling Graph on your system.</p>"},{"location":"fundamentals/installation/#overview","title":"Overview","text":"<p>Docling Graph uses uv as the package manager for fast, reliable dependency management. All installation and execution commands use <code>uv</code> exclusively.</p>"},{"location":"fundamentals/installation/#what-youll-install","title":"What You'll Install","text":"<ol> <li>Core Package: Docling Graph with VLM support</li> <li>Optional Features: LLM providers (local and/or remote)</li> <li>GPU Support (optional): PyTorch with CUDA for local inference</li> <li>API Keys (optional): For remote LLM providers</li> </ol>"},{"location":"fundamentals/installation/#quick-start","title":"Quick Start","text":""},{"location":"fundamentals/installation/#minimal-installation","title":"Minimal Installation","text":"<p>For basic VLM functionality:</p> <pre><code># Clone repository\ngit clone https://github.com/IBM/docling-graph\ncd docling-graph\n\n# Install core dependencies\nuv sync\n</code></pre> <p>This installs: \u2705 Docling (document conversion) \u2705 VLM backend (NuExtract models) \u2705 Core graph functionality \u274c LLM providers (not included)</p>"},{"location":"fundamentals/installation/#full-installation","title":"Full Installation","text":"<p>For all features (VLM + all LLM providers):</p> <pre><code># Clone repository\ngit clone https://github.com/IBM/docling-graph\ncd docling-graph\n\n# Install all dependencies\nuv sync --extra all\n</code></pre> <p>This installs: \u2705 Everything from minimal \u2705 vLLM (local LLM inference) \u2705 Ollama client \u2705 Mistral AI client \u2705 OpenAI client \u2705 Google Gemini client \u2705 IBM WatsonX client</p>"},{"location":"fundamentals/installation/#installation-options","title":"Installation Options","text":""},{"location":"fundamentals/installation/#by-feature-set","title":"By Feature Set","text":"<p>Choose the installation that matches your needs:</p>"},{"location":"fundamentals/installation/#local-llm-support","title":"Local LLM Support","text":"<p>For local inference with vLLM and Ollama:</p> <pre><code>uv sync --extra local\n</code></pre> <p>Includes: - vLLM (requires GPU) - Ollama client</p> <p>Use when: - You have GPU available - Privacy is critical - No API costs desired</p>"},{"location":"fundamentals/installation/#remote-api-support","title":"Remote API Support","text":"<p>For cloud-based LLM providers:</p> <pre><code>uv sync --extra remote\n</code></pre> <p>Includes: - Mistral AI client - OpenAI client - Google Gemini client - IBM WatsonX client</p> <p>Use when: - No GPU available - Need high-quality models - Willing to pay API costs</p>"},{"location":"fundamentals/installation/#individual-providers","title":"Individual Providers","text":"<p>Install specific providers only:</p> <pre><code># OpenAI only\nuv sync --extra openai\n\n# Mistral only\nuv sync --extra mistral\n\n# Google Gemini only\nuv sync --extra gemini\n\n# IBM WatsonX only\nuv sync --extra watsonx\n\n# Ollama only (local)\nuv sync --extra ollama\n\n# vLLM only (local, requires GPU)\nuv sync --extra vllm\n</code></pre>"},{"location":"fundamentals/installation/#combining-features","title":"Combining Features","text":"<p>You can combine multiple extras:</p> <pre><code># Local + Remote\nuv sync --extra local --extra remote\n\n# Specific providers\nuv sync --extra ollama --extra openai --extra mistral\n</code></pre>"},{"location":"fundamentals/installation/#system-requirements","title":"System Requirements","text":""},{"location":"fundamentals/installation/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>Python: 3.10, 3.11, or 3.12</li> <li>RAM: 8 GB minimum</li> <li>Disk: 5 GB free space</li> <li>OS: Linux, macOS, or Windows (with WSL recommended)</li> </ul>"},{"location":"fundamentals/installation/#recommended-for-local-inference","title":"Recommended for Local Inference","text":"<ul> <li>GPU: NVIDIA GPU with 8+ GB VRAM</li> <li>CUDA: 11.8 or 12.1</li> <li>RAM: 16 GB or more</li> <li>Disk: 20 GB free space (for models)</li> </ul>"},{"location":"fundamentals/installation/#for-vlm-only","title":"For VLM Only","text":"<ul> <li>GPU: NVIDIA GPU with 4+ GB VRAM (for NuExtract-2B)</li> <li>GPU: NVIDIA GPU with 8+ GB VRAM (for NuExtract-8B)</li> </ul>"},{"location":"fundamentals/installation/#for-remote-api-only","title":"For Remote API Only","text":"<ul> <li>No GPU required</li> <li>Internet connection required</li> <li>API keys required</li> </ul>"},{"location":"fundamentals/installation/#verification","title":"Verification","text":""},{"location":"fundamentals/installation/#check-installation","title":"Check Installation","text":"<pre><code># Check version\nuv run docling-graph --version\n\n# Check Python version\nuv run python --version\n\n# Test CLI\nuv run docling-graph --help\n</code></pre> <p>Expected output: <pre><code>Docling Graph v0.3.0\nPython 3.10+ \nUsage: docling-graph [OPTIONS] COMMAND [ARGS]...\n</code></pre></p>"},{"location":"fundamentals/installation/#test-import","title":"Test Import","text":"<pre><code>uv run python -c \"import docling_graph; print(docling_graph.__version__)\"\n</code></pre> <p>Expected output: <pre><code>0.3.0\n</code></pre></p>"},{"location":"fundamentals/installation/#next-steps","title":"Next Steps","text":"<p>After installation, you need to:</p> <ol> <li>Set Up Requirements - Verify system requirements</li> <li>Configure GPU (optional) - Set up CUDA for local inference</li> <li>Set Up API Keys (optional) - Configure remote providers</li> <li>Define Schema - Create your first Pydantic template</li> </ol>"},{"location":"fundamentals/installation/#common-issues","title":"Common Issues","text":""},{"location":"fundamentals/installation/#issue-uv-not-found","title":"Issue: <code>uv</code> not found","text":"<p>Solution: Install uv first:</p> <pre><code># Linux/macOS\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows (PowerShell)\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# Or with pip\npip install uv\n</code></pre>"},{"location":"fundamentals/installation/#issue-python-version-mismatch","title":"Issue: Python version mismatch","text":"<p>Solution: Specify Python version:</p> <pre><code>uv python install 3.10\nuv sync\n</code></pre>"},{"location":"fundamentals/installation/#issue-import-errors-after-installation","title":"Issue: Import errors after installation","text":"<p>Solution: Ensure you're using <code>uv run</code>:</p> <pre><code># Wrong\npython script.py\n\n# Correct\nuv run python script.py\n</code></pre>"},{"location":"fundamentals/installation/#issue-gpu-not-detected","title":"Issue: GPU not detected","text":"<p>Solution: See GPU Setup Guide</p>"},{"location":"fundamentals/installation/#performance-notes","title":"Performance Notes","text":"<p>New in v0.3.0: Significant CLI performance improvements:</p> <ul> <li>Init command: 75-85% faster with intelligent dependency caching</li> <li>First run: ~1-1.5s (checks dependencies)</li> <li>Subsequent runs: ~0.5-1s (uses cache)</li> <li>Dependency validation: 90-95% faster (2-3s \u2192 0.1-0.2s)</li> <li>Lazy loading: Configuration constants loaded on-demand</li> </ul>"},{"location":"fundamentals/installation/#development-installation","title":"Development Installation","text":"<p>For contributing to the project:</p> <pre><code># Clone repository\ngit clone https://github.com/IBM/docling-graph\ncd docling-graph\n\n# Install with development dependencies\nuv sync --all-extras --dev\n\n# Install pre-commit hooks\nuv run pre-commit install\n\n# Run tests\nuv run pytest\n</code></pre>"},{"location":"fundamentals/installation/#updating","title":"Updating","text":"<p>To update to the latest version:</p> <pre><code># Update from git\ngit pull origin main\n\n# Sync dependencies\nuv sync --extra all\n</code></pre>"},{"location":"fundamentals/installation/#uninstalling","title":"Uninstalling","text":"<p>To remove Docling Graph:</p> <pre><code># Remove virtual environment\nrm -rf .venv\n\n# Remove cloned repository\ncd ..\nrm -rf docling-graph\n</code></pre>"},{"location":"fundamentals/installation/#related-documentation","title":"Related Documentation","text":"<ul> <li>Requirements: Detailed system requirements</li> <li>GPU Setup: Configure CUDA for local inference</li> <li>API Keys: Set up remote providers</li> <li>Quick Start: Your first extraction</li> </ul> <p>Installation complete? Move on to schema definition to create your first template!</p>"},{"location":"fundamentals/installation/api-keys/","title":"API Keys Setup","text":"<p>Pipeline Stage: 2 - Installation</p> <p>Prerequisites:  - Installation Overview - Basic Setup</p> <p>This page guides you through setting up API keys for remote LLM providers.</p>"},{"location":"fundamentals/installation/api-keys/#overview","title":"Overview","text":"<p>Remote LLM providers require API keys for authentication. This guide covers:</p> <ul> <li>OpenAI (GPT-4, GPT-3.5-turbo)</li> <li>Mistral AI (Mistral Small, Medium, Large)</li> <li>Google Gemini (Gemini Pro, Gemini Flash)</li> <li>IBM WatsonX (Granite, Llama, Mixtral)</li> </ul> <p>Note: API keys are not required for: - Local VLM (NuExtract) - Local LLM (vLLM, Ollama)</p>"},{"location":"fundamentals/installation/api-keys/#quick-setup","title":"Quick Setup","text":""},{"location":"fundamentals/installation/api-keys/#linuxmacos","title":"Linux/macOS","text":"<p>Add to your shell configuration file (<code>~/.bashrc</code>, <code>~/.zshrc</code>, or <code>~/.bash_profile</code>):</p> <pre><code># OpenAI\nexport OPENAI_API_KEY=\"sk-...\"\n\n# Mistral AI\nexport MISTRAL_API_KEY=\"...\"\n\n# Google Gemini\nexport GEMINI_API_KEY=\"...\"\n\n# IBM WatsonX\nexport WATSONX_API_KEY=\"...\"\nexport WATSONX_PROJECT_ID=\"...\"\nexport WATSONX_URL=\"https://us-south.ml.cloud.ibm.com\"  # Optional\n</code></pre> <p>Then reload: <pre><code>source ~/.bashrc  # or ~/.zshrc\n</code></pre></p>"},{"location":"fundamentals/installation/api-keys/#windows-powershell","title":"Windows (PowerShell)","text":"<pre><code># OpenAI\n$env:OPENAI_API_KEY=\"sk-...\"\n\n# Mistral AI\n$env:MISTRAL_API_KEY=\"...\"\n\n# Google Gemini\n$env:GEMINI_API_KEY=\"...\"\n\n# IBM WatsonX\n$env:WATSONX_API_KEY=\"...\"\n$env:WATSONX_PROJECT_ID=\"...\"\n$env:WATSONX_URL=\"https://us-south.ml.cloud.ibm.com\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#windows-command-prompt","title":"Windows (Command Prompt)","text":"<pre><code>set OPENAI_API_KEY=sk-...\nset MISTRAL_API_KEY=...\nset GEMINI_API_KEY=...\nset WATSONX_API_KEY=...\nset WATSONX_PROJECT_ID=...\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#using-env-file-recommended","title":"Using .env File (Recommended)","text":"<p>Create a <code>.env</code> file in your project root:</p> <pre><code># .env file\nOPENAI_API_KEY=sk-...\nMISTRAL_API_KEY=...\nGEMINI_API_KEY=...\nWATSONX_API_KEY=...\nWATSONX_PROJECT_ID=...\nWATSONX_URL=https://us-south.ml.cloud.ibm.com\n</code></pre> <p>Security: Add <code>.env</code> to <code>.gitignore</code>: <pre><code>echo \".env\" &gt;&gt; .gitignore\n</code></pre></p>"},{"location":"fundamentals/installation/api-keys/#provider-specific-setup","title":"Provider-Specific Setup","text":""},{"location":"fundamentals/installation/api-keys/#openai","title":"OpenAI","text":""},{"location":"fundamentals/installation/api-keys/#1-get-api-key","title":"1. Get API Key","text":"<ol> <li>Visit OpenAI Platform</li> <li>Sign up or log in</li> <li>Navigate to API Keys</li> <li>Click \"Create new secret key\"</li> <li>Copy the key (starts with <code>sk-</code>)</li> </ol>"},{"location":"fundamentals/installation/api-keys/#2-set-environment-variable","title":"2. Set Environment Variable","text":"<pre><code>export OPENAI_API_KEY=\"sk-...\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#3-verify","title":"3. Verify","text":"<pre><code>uv run python -c \"import os; print('OpenAI key set:', bool(os.getenv('OPENAI_API_KEY')))\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#4-test","title":"4. Test","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider openai \\\n    --model gpt-4-turbo\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#available-models","title":"Available Models","text":"Model Context Cost (per 1M tokens) Best For gpt-4-turbo 128K $10 / $30 Complex extraction gpt-4 8K $30 / $60 High quality gpt-3.5-turbo 16K $0.50 / $1.50 Fast, cost-effective"},{"location":"fundamentals/installation/api-keys/#mistral-ai","title":"Mistral AI","text":""},{"location":"fundamentals/installation/api-keys/#1-get-api-key_1","title":"1. Get API Key","text":"<ol> <li>Visit Mistral AI Console</li> <li>Sign up or log in</li> <li>Navigate to API Keys</li> <li>Create new API key</li> <li>Copy the key</li> </ol>"},{"location":"fundamentals/installation/api-keys/#2-set-environment-variable_1","title":"2. Set Environment Variable","text":"<pre><code>export MISTRAL_API_KEY=\"...\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#3-verify_1","title":"3. Verify","text":"<pre><code>uv run python -c \"import os; print('Mistral key set:', bool(os.getenv('MISTRAL_API_KEY')))\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#4-test_1","title":"4. Test","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider mistral \\\n    --model mistral-medium-latest\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#available-models_1","title":"Available Models","text":"Model Context Cost (per 1M tokens) Best For mistral-large-latest 32K $4 / $12 Complex tasks mistral-medium-latest 32K $2.7 / $8.1 Balanced mistral-small-latest 32K $1 / $3 Fast, affordable"},{"location":"fundamentals/installation/api-keys/#google-gemini","title":"Google Gemini","text":""},{"location":"fundamentals/installation/api-keys/#1-get-api-key_2","title":"1. Get API Key","text":"<ol> <li>Visit Google AI Studio</li> <li>Sign in with Google account</li> <li>Click \"Create API Key\"</li> <li>Copy the key</li> </ol>"},{"location":"fundamentals/installation/api-keys/#2-set-environment-variable_2","title":"2. Set Environment Variable","text":"<pre><code>export GEMINI_API_KEY=\"...\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#3-verify_2","title":"3. Verify","text":"<pre><code>uv run python -c \"import os; print('Gemini key set:', bool(os.getenv('GEMINI_API_KEY')))\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#4-test_2","title":"4. Test","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider gemini \\\n    --model gemini-2.5-flash\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#available-models_2","title":"Available Models","text":"Model Context Cost (per 1M tokens) Best For gemini-2.5-flash 1M $0.075 / $0.30 Very fast, cheap gemini-pro 32K $0.50 / $1.50 Balanced"},{"location":"fundamentals/installation/api-keys/#ibm-watsonx","title":"IBM WatsonX","text":""},{"location":"fundamentals/installation/api-keys/#1-get-credentials","title":"1. Get Credentials","text":"<ol> <li>Visit IBM Cloud</li> <li>Create or log into account</li> <li>Navigate to WatsonX</li> <li>Create a project</li> <li>Get API key and project ID from project settings</li> </ol>"},{"location":"fundamentals/installation/api-keys/#2-set-environment-variables","title":"2. Set Environment Variables","text":"<pre><code>export WATSONX_API_KEY=\"...\"\nexport WATSONX_PROJECT_ID=\"...\"\nexport WATSONX_URL=\"https://us-south.ml.cloud.ibm.com\"  # Optional, defaults to US South\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#3-verify_3","title":"3. Verify","text":"<pre><code>uv run python -c \"import os; print('WatsonX key set:', bool(os.getenv('WATSONX_API_KEY'))); print('WatsonX project set:', bool(os.getenv('WATSONX_PROJECT_ID')))\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#4-test_3","title":"4. Test","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider watsonx \\\n    --model ibm/granite-13b-chat-v2\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#available-models_3","title":"Available Models","text":"Model Context Best For ibm/granite-13b-chat-v2 8K General purpose meta-llama/llama-3-70b-instruct 8K High quality mistralai/mixtral-8x7b-instruct-v01 32K Complex tasks <p>Note: For detailed WatsonX configuration, refer to the Model Configuration guide.</p>"},{"location":"fundamentals/installation/api-keys/#verification","title":"Verification","text":""},{"location":"fundamentals/installation/api-keys/#check-all-keys","title":"Check All Keys","text":"<pre><code>uv run python &lt;&lt; EOF\nimport os\n\nproviders = {\n    'OpenAI': 'OPENAI_API_KEY',\n    'Mistral': 'MISTRAL_API_KEY',\n    'Gemini': 'GEMINI_API_KEY',\n    'WatsonX API': 'WATSONX_API_KEY',\n    'WatsonX Project': 'WATSONX_PROJECT_ID'\n}\n\nfor name, var in providers.items():\n    value = os.getenv(var)\n    status = '\u2713 Set' if value else '\u2717 Not set'\n    print(f'{name:20} {status}')\nEOF\n</code></pre> <p>Expected output: <pre><code>OpenAI               \u2713 Set\nMistral              \u2713 Set\nGemini               \u2713 Set\nWatsonX API          \u2713 Set\nWatsonX Project      \u2713 Set\n</code></pre></p>"},{"location":"fundamentals/installation/api-keys/#test-connection","title":"Test Connection","text":"<pre><code># Test with a simple extraction\nuv run docling-graph convert docs/examples/data/sample.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider openai \\\n    --model gpt-3.5-turbo \\\n    --output-dir test_output\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#security-best-practices","title":"Security Best Practices","text":""},{"location":"fundamentals/installation/api-keys/#1-never-commit-api-keys","title":"1. Never Commit API Keys","text":"<pre><code># Add to .gitignore\necho \".env\" &gt;&gt; .gitignore\necho \"*.key\" &gt;&gt; .gitignore\necho \"secrets/\" &gt;&gt; .gitignore\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#2-use-environment-variables","title":"2. Use Environment Variables","text":"<p>Don't: <pre><code># \u274c Hardcoded in code\napi_key = \"sk-...\"\n</code></pre></p> <p>Do: <pre><code># \u2705 From environment\nimport os\napi_key = os.getenv('OPENAI_API_KEY')\n</code></pre></p>"},{"location":"fundamentals/installation/api-keys/#3-rotate-keys-regularly","title":"3. Rotate Keys Regularly","text":"<ul> <li>Rotate API keys every 90 days</li> <li>Immediately rotate if compromised</li> <li>Use separate keys for dev/prod</li> </ul>"},{"location":"fundamentals/installation/api-keys/#4-limit-key-permissions","title":"4. Limit Key Permissions","text":"<ul> <li>Use read-only keys when possible</li> <li>Set usage limits</li> <li>Monitor usage regularly</li> </ul>"},{"location":"fundamentals/installation/api-keys/#5-use-secret-management","title":"5. Use Secret Management","text":"<p>For production: - AWS Secrets Manager - Azure Key Vault - Google Secret Manager - HashiCorp Vault</p>"},{"location":"fundamentals/installation/api-keys/#cost-management","title":"Cost Management","text":""},{"location":"fundamentals/installation/api-keys/#monitor-usage","title":"Monitor Usage","text":"<p>OpenAI: - Dashboard: https://platform.openai.com/usage</p> <p>Mistral: - Console: https://console.mistral.ai/usage</p> <p>Gemini: - Console: https://makersuite.google.com/</p> <p>WatsonX: - IBM Cloud Dashboard</p>"},{"location":"fundamentals/installation/api-keys/#set-usage-limits","title":"Set Usage Limits","text":"<p>OpenAI: 1. Go to Usage Limits 2. Set monthly budget 3. Enable email alerts</p> <p>Mistral: 1. Go to Console 2. Set budget alerts 3. Monitor usage</p>"},{"location":"fundamentals/installation/api-keys/#cost-optimization-tips","title":"Cost Optimization Tips","text":"<ol> <li>Use appropriate models:</li> <li>GPT-3.5-turbo for simple tasks</li> <li> <p>GPT-4 only when needed</p> </li> <li> <p>Enable chunking:</p> </li> <li>Reduces token usage</li> <li> <p>Processes only relevant parts</p> </li> <li> <p>Cache results:</p> </li> <li> <p>Avoid re-processing same documents</p> </li> <li> <p>Batch processing:</p> </li> <li> <p>Process multiple documents together</p> </li> <li> <p>Monitor costs:</p> </li> <li>Check usage daily</li> <li>Set alerts</li> </ol>"},{"location":"fundamentals/installation/api-keys/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/installation/api-keys/#issue-api-key-not-recognized","title":"Issue: API key not recognized","text":"<p>Check: <pre><code>echo $OPENAI_API_KEY  # Should show your key\n</code></pre></p> <p>If empty: <pre><code># Re-export\nexport OPENAI_API_KEY=\"sk-...\"\n\n# Or reload shell config\nsource ~/.bashrc\n</code></pre></p>"},{"location":"fundamentals/installation/api-keys/#issue-authentication-failed","title":"Issue: Authentication failed","text":"<p>Symptoms: <pre><code>Error: Invalid API key\n</code></pre></p> <p>Solutions:</p> <ol> <li>Verify key is correct:</li> <li>Check for typos</li> <li>Ensure no extra spaces</li> <li> <p>Verify key hasn't expired</p> </li> <li> <p>Check key format:</p> </li> <li>OpenAI: starts with <code>sk-</code></li> <li>Mistral: alphanumeric string</li> <li> <p>Gemini: alphanumeric string</p> </li> <li> <p>Regenerate key:</p> </li> <li>Go to provider dashboard</li> <li>Create new key</li> <li>Update environment variable</li> </ol>"},{"location":"fundamentals/installation/api-keys/#issue-rate-limit-exceeded","title":"Issue: Rate limit exceeded","text":"<p>Symptoms: <pre><code>Error: Rate limit exceeded\n</code></pre></p> <p>Solutions:</p> <ol> <li>Wait and retry:</li> <li> <p>Most limits reset after 1 minute</p> </li> <li> <p>Upgrade plan:</p> </li> <li> <p>Increase rate limits</p> </li> <li> <p>Use different provider:</p> </li> <li>Switch to provider with higher limits</li> </ol>"},{"location":"fundamentals/installation/api-keys/#issue-insufficient-credits","title":"Issue: Insufficient credits","text":"<p>Symptoms: <pre><code>Error: Insufficient credits\n</code></pre></p> <p>Solutions:</p> <ol> <li>Add credits:</li> <li>Go to billing dashboard</li> <li> <p>Add payment method</p> </li> <li> <p>Use different provider:</p> </li> <li> <p>Switch to provider with credits</p> </li> <li> <p>Use local inference:</p> </li> <li>No API costs</li> </ol>"},{"location":"fundamentals/installation/api-keys/#provider-comparison","title":"Provider Comparison","text":"Provider Pros Cons Best For OpenAI High quality, reliable Expensive Complex extraction Mistral Good balance, affordable Smaller context General purpose Gemini Very cheap, fast Newer, less tested High volume WatsonX Enterprise features Setup complexity Enterprise use"},{"location":"fundamentals/installation/api-keys/#next-steps","title":"Next Steps","text":"<p>API keys configured! Now:</p> <ol> <li>Schema Definition - Create your first template</li> <li>Pipeline Configuration - Configure extraction</li> <li>Quick Start - Run your first extraction</li> </ol>"},{"location":"fundamentals/installation/api-keys/#related-documentation","title":"Related Documentation","text":"<ul> <li>Installation Overview: Installation options</li> <li>Basic Setup: Installation steps</li> <li>Model Configuration: Model selection and WatsonX setup</li> <li>Requirements: System requirements</li> </ul> <p>API keys ready? Continue to schema definition to create your first template!</p>"},{"location":"fundamentals/installation/basic-setup/","title":"Basic Setup","text":"<p>Pipeline Stage: 2 - Installation</p> <p>Prerequisites:  - Installation Overview - System Requirements</p> <p>This page provides step-by-step instructions for installing Docling Graph.</p>"},{"location":"fundamentals/installation/basic-setup/#installation-methods","title":"Installation Methods","text":""},{"location":"fundamentals/installation/basic-setup/#method-1-from-source-recommended","title":"Method 1: From Source (Recommended)","text":"<p>This is the recommended method for most users.</p>"},{"location":"fundamentals/installation/basic-setup/#step-1-install-uv","title":"Step 1: Install uv","text":"<p>First, install the <code>uv</code> package manager:</p> <p>Linux/macOS: <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre></p> <p>Windows (PowerShell): <pre><code>powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre></p> <p>Alternative (using pip): <pre><code>pip install uv\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#step-2-clone-repository","title":"Step 2: Clone Repository","text":"<pre><code>git clone https://github.com/IBM/docling-graph\ncd docling-graph\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#step-3-choose-installation-type","title":"Step 3: Choose Installation Type","text":"<p>Minimal (VLM only): <pre><code>uv sync\n</code></pre></p> <p>Full (all features): <pre><code>uv sync --extra all\n</code></pre></p> <p>Local LLM only: <pre><code>uv sync --extra local\n</code></pre></p> <p>Remote API only: <pre><code>uv sync --extra remote\n</code></pre></p> <p>Specific providers: <pre><code># OpenAI\nuv sync --extra openai\n\n# Mistral\nuv sync --extra mistral\n\n# Gemini\nuv sync --extra gemini\n\n# WatsonX\nuv sync --extra watsonx\n\n# Ollama (local)\nuv sync --extra ollama\n\n# vLLM (local, requires GPU)\nuv sync --extra vllm\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#step-4-verify-installation","title":"Step 4: Verify Installation","text":"<pre><code># Check version\nuv run docling-graph --version\n\n# Test CLI\nuv run docling-graph --help\n\n# Test Python import\nuv run python -c \"import docling_graph; print(docling_graph.__version__)\"\n</code></pre> <p>Expected output: <pre><code>Docling Graph v0.3.0\nUsage: docling-graph [OPTIONS] COMMAND [ARGS]...\n0.3.0\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#method-2-from-pypi-coming-soon","title":"Method 2: From PyPI (Coming Soon)","text":"<p>Note: PyPI installation will be available in a future release.</p> <pre><code># Future release\npip install docling-graph[all]\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#installation-scenarios","title":"Installation Scenarios","text":""},{"location":"fundamentals/installation/basic-setup/#scenario-1-quick-start-remote-llm","title":"Scenario 1: Quick Start (Remote LLM)","text":"<p>For users who want to get started quickly without GPU:</p> <pre><code># Install\ngit clone https://github.com/IBM/docling-graph\ncd docling-graph\nuv sync --extra remote\n\n# Set API key\nexport OPENAI_API_KEY=\"your-key-here\"\n\n# Test\nuv run docling-graph --version\n</code></pre> <p>Time: ~2-3 minutes Requirements: Internet connection, API key GPU: Not required</p>"},{"location":"fundamentals/installation/basic-setup/#scenario-2-local-vlm-gpu-required","title":"Scenario 2: Local VLM (GPU Required)","text":"<p>For users with GPU who want local inference:</p> <pre><code># Install\ngit clone https://github.com/IBM/docling-graph\ncd docling-graph\nuv sync\n\n# Verify GPU\nnvidia-smi\n\n# Test\nuv run docling-graph --version\n</code></pre> <p>Time: ~5-10 minutes Requirements: NVIDIA GPU with 4+ GB VRAM GPU: Required</p>"},{"location":"fundamentals/installation/basic-setup/#scenario-3-full-local-setup-gpu-required","title":"Scenario 3: Full Local Setup (GPU Required)","text":"<p>For users who want all local capabilities:</p> <pre><code># Install\ngit clone https://github.com/IBM/docling-graph\ncd docling-graph\nuv sync --extra local\n\n# Verify GPU\nnvidia-smi\n\n# Test\nuv run docling-graph --version\n</code></pre> <p>Time: ~10-15 minutes Requirements: NVIDIA GPU with 8+ GB VRAM GPU: Required</p>"},{"location":"fundamentals/installation/basic-setup/#scenario-4-hybrid-local-remote","title":"Scenario 4: Hybrid (Local + Remote)","text":"<p>For maximum flexibility:</p> <pre><code># Install\ngit clone https://github.com/IBM/docling-graph\ncd docling-graph\nuv sync --extra all\n\n# Set API keys (optional)\nexport OPENAI_API_KEY=\"your-key-here\"\nexport MISTRAL_API_KEY=\"your-key-here\"\n\n# Test\nuv run docling-graph --version\n</code></pre> <p>Time: ~10-15 minutes Requirements: GPU recommended, API keys optional GPU: Optional</p>"},{"location":"fundamentals/installation/basic-setup/#post-installation-configuration","title":"Post-Installation Configuration","text":""},{"location":"fundamentals/installation/basic-setup/#initialize-configuration","title":"Initialize Configuration","text":"<p>Run the interactive configuration wizard:</p> <pre><code>uv run docling-graph init\n</code></pre> <p>This creates a <code>config.yaml</code> file with your preferences.</p> <p>New in v0.3.0: Init command is 75-85% faster with intelligent caching!</p>"},{"location":"fundamentals/installation/basic-setup/#verify-installation","title":"Verify Installation","text":"<p>Run a simple test:</p> <pre><code># Check all commands work\nuv run docling-graph --help\nuv run docling-graph init --help\nuv run docling-graph convert --help\nuv run docling-graph inspect --help\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#test-with-example","title":"Test with Example","text":"<pre><code># Run a simple example (requires API key or GPU)\nuv run python docs/examples/scripts/03_llm_remote_api.py\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#directory-structure","title":"Directory Structure","text":"<p>After installation, your directory should look like:</p> <pre><code>docling-graph/\n\u251c\u2500\u2500 .venv/                  # Virtual environment (created by uv)\n\u251c\u2500\u2500 docs/                   # Documentation\n\u251c\u2500\u2500 docling_graph/          # Source code\n\u251c\u2500\u2500 examples/               # Example scripts and templates\n\u251c\u2500\u2500 tests/                  # Test suite\n\u251c\u2500\u2500 pyproject.toml          # Project configuration\n\u251c\u2500\u2500 uv.lock                 # Dependency lock file\n\u2514\u2500\u2500 README.md               # Project readme\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#environment-variables","title":"Environment Variables","text":""},{"location":"fundamentals/installation/basic-setup/#optional-configuration","title":"Optional Configuration","text":"<p>Set these environment variables for customization:</p> <pre><code># Logging level\nexport LOG_LEVEL=\"INFO\"  # DEBUG, INFO, WARNING, ERROR\n\n# Temporary directory\nexport TEMP_DIR=\"/tmp/docling\"\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#api-keys-if-using-remote-providers","title":"API Keys (if using remote providers)","text":"<p>See API Keys Setup for detailed instructions.</p>"},{"location":"fundamentals/installation/basic-setup/#updating","title":"Updating","text":""},{"location":"fundamentals/installation/basic-setup/#update-to-latest-version","title":"Update to Latest Version","text":"<pre><code># Navigate to repository\ncd docling-graph\n\n# Pull latest changes\ngit pull origin main\n\n# Update dependencies\nuv sync --extra all\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#update-specific-components","title":"Update Specific Components","text":"<pre><code># Update only remote providers\nuv sync --extra remote\n\n# Update only local providers\nuv sync --extra local\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/installation/basic-setup/#issue-uv-command-not-found","title":"Issue: <code>uv</code> command not found","text":"<p>Cause: uv not in PATH</p> <p>Solution: <pre><code># Add to PATH (Linux/macOS)\nexport PATH=\"$HOME/.cargo/bin:$PATH\"\n\n# Or reinstall\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#issue-permission-denied","title":"Issue: Permission denied","text":"<p>Cause: Insufficient permissions</p> <p>Solution: <pre><code># Don't use sudo with uv\n# If you used sudo, remove and reinstall:\nrm -rf .venv\nuv sync --extra all\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#issue-import-errors","title":"Issue: Import errors","text":"<p>Cause: Not using <code>uv run</code></p> <p>Solution: <pre><code># Wrong\npython script.py\n\n# Correct\nuv run python script.py\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#issue-slow-installation","title":"Issue: Slow installation","text":"<p>Cause: Network or disk speed</p> <p>Solution: <pre><code># Use verbose mode to see progress\nuv sync --extra all --verbose\n\n# Or install in stages\nuv sync                    # Core first\nuv sync --extra remote     # Then remote\nuv sync --extra local      # Then local\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#issue-cuda-not-found-for-gpu-users","title":"Issue: CUDA not found (for GPU users)","text":"<p>Cause: CUDA not installed or not in PATH</p> <p>Solution: See GPU Setup Guide</p>"},{"location":"fundamentals/installation/basic-setup/#issue-out-of-disk-space","title":"Issue: Out of disk space","text":"<p>Cause: Insufficient disk space</p> <p>Solution: <pre><code># Check disk space\ndf -h\n\n# Clean up if needed\nuv cache clean\n\n# Or install minimal version\nuv sync  # No extras\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#verification-checklist","title":"Verification Checklist","text":"<p>After installation, verify:</p> <ul> <li> <code>uv run docling-graph --version</code> works</li> <li> <code>uv run docling-graph --help</code> shows commands</li> <li> <code>uv run python -c \"import docling_graph\"</code> succeeds</li> <li> GPU detected (if using local inference): <code>nvidia-smi</code></li> <li> API keys set (if using remote): <code>echo $OPENAI_API_KEY</code></li> <li> Config initialized: <code>uv run docling-graph init</code></li> </ul>"},{"location":"fundamentals/installation/basic-setup/#performance-notes","title":"Performance Notes","text":""},{"location":"fundamentals/installation/basic-setup/#installation-speed","title":"Installation Speed","text":"<p>New in v0.3.0: - First install: ~2-5 minutes (depending on extras) - Subsequent updates: ~30-60 seconds - Dependency caching: 90-95% faster validation</p>"},{"location":"fundamentals/installation/basic-setup/#disk-usage","title":"Disk Usage","text":"<pre><code>Minimal install:     ~2.5 GB\nFull install:        ~5 GB\nWith models:         ~20 GB (varies by model)\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#memory-usage","title":"Memory Usage","text":"<pre><code>Installation:        ~1 GB RAM\nRuntime (minimal):   ~2 GB RAM\nRuntime (with GPU):  ~8-16 GB RAM\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#development-setup","title":"Development Setup","text":"<p>For contributors:</p> <pre><code># Clone repository\ngit clone https://github.com/IBM/docling-graph\ncd docling-graph\n\n# Install with dev dependencies\nuv sync --all-extras --dev\n\n# Install pre-commit hooks\nuv run pre-commit install\n\n# Run tests\nuv run pytest\n\n# Run linting\nuv run ruff check .\n\n# Run type checking\nuv run mypy docling_graph\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#uninstalling","title":"Uninstalling","text":"<p>To completely remove Docling Graph:</p> <pre><code># Remove virtual environment\ncd docling-graph\nrm -rf .venv\n\n# Remove repository (optional)\ncd ..\nrm -rf docling-graph\n\n# Remove cache (optional)\nrm -rf ~/.cache/docling-graph\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#next-steps","title":"Next Steps","text":"<p>Installation complete! Now:</p> <ol> <li>GPU Setup (if using local inference) - Configure CUDA</li> <li>API Keys (if using remote) - Set up API keys</li> <li>Schema Definition - Create your first template</li> <li>Quick Start - Run your first extraction</li> </ol>"},{"location":"fundamentals/installation/basic-setup/#related-documentation","title":"Related Documentation","text":"<ul> <li>Requirements: System requirements</li> <li>GPU Setup: CUDA configuration</li> <li>API Keys: Remote provider setup</li> <li>Installation Overview: Installation options</li> </ul> <p>Installation successful? Continue to GPU setup or API keys depending on your use case!</p>"},{"location":"fundamentals/installation/gpu-setup/","title":"GPU Setup","text":"<p>Pipeline Stage: 2 - Installation</p> <p>Prerequisites:  - Installation Overview - System Requirements - Basic Setup</p> <p>This page guides you through setting up GPU support for local inference with Docling Graph.</p>"},{"location":"fundamentals/installation/gpu-setup/#overview","title":"Overview","text":"<p>GPU acceleration significantly improves performance for: - VLM Backend: NuExtract models (4-8 GB VRAM) - Local LLM: vLLM inference (8-24 GB VRAM)</p> <p>Note: Remote LLM providers (OpenAI, Mistral, Gemini, WatsonX) do not require GPU.</p>"},{"location":"fundamentals/installation/gpu-setup/#important-package-conflict-notice","title":"Important: Package Conflict Notice","text":"<p>\u26a0\ufe0f Current Limitation: There is a package conflict preventing the use of PyTorch with GPU support via <code>uv</code> together with <code>docling[vlm]</code>. Installing GPU-enabled torch through <code>uv sync</code> alongside <code>docling[vlm]</code> causes dependency resolution failures.</p> <p>Workaround: Manual installation using <code>pip</code> (see below).</p>"},{"location":"fundamentals/installation/gpu-setup/#prerequisites","title":"Prerequisites","text":""},{"location":"fundamentals/installation/gpu-setup/#1-nvidia-gpu","title":"1. NVIDIA GPU","text":"<p>Verify you have a compatible NVIDIA GPU:</p> <pre><code>nvidia-smi\n</code></pre> <p>Expected output: <pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03   Driver Version: 535.129.03   CUDA Version: 12.2   |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n| 30%   45C    P8    15W / 250W |    500MiB /  8192MiB |      2%      Default |\n+-------------------------------+----------------------+----------------------+\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#2-cuda-toolkit","title":"2. CUDA Toolkit","text":"<p>Check your CUDA version from <code>nvidia-smi</code> output above.</p> <p>Supported CUDA Versions: - CUDA 11.8 (recommended) - CUDA 12.1 (recommended) - CUDA 12.2+</p>"},{"location":"fundamentals/installation/gpu-setup/#3-cuda-toolkit-installation","title":"3. CUDA Toolkit Installation","text":"<p>If CUDA is not installed:</p> <p>Linux (Ubuntu/Debian): <pre><code># CUDA 12.1\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb\nsudo dpkg -i cuda-keyring_1.0-1_all.deb\nsudo apt-get update\nsudo apt-get -y install cuda-12-1\n\n# Add to PATH\necho 'export PATH=/usr/local/cuda-12.1/bin:$PATH' &gt;&gt; ~/.bashrc\necho 'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre></p> <p>Windows: 1. Download CUDA Toolkit from NVIDIA website 2. Run installer 3. Verify installation: <code>nvcc --version</code></p>"},{"location":"fundamentals/installation/gpu-setup/#manual-gpu-setup-workaround","title":"Manual GPU Setup (Workaround)","text":"<p>Due to the package conflict, follow these steps for GPU support:</p>"},{"location":"fundamentals/installation/gpu-setup/#step-1-create-virtual-environment","title":"Step 1: Create Virtual Environment","text":"<pre><code># Navigate to docling-graph directory\ncd docling-graph\n\n# Create virtual environment\npython -m venv .venv\n\n# Activate virtual environment\n# Linux/macOS:\nsource .venv/bin/activate\n\n# Windows PowerShell:\n.\\.venv\\Scripts\\Activate\n\n# Windows CMD:\n.venv\\Scripts\\activate.bat\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#step-2-install-docling-graph","title":"Step 2: Install Docling Graph","text":"<p>Choose the installation that matches your needs:</p> <p>Minimal (VLM only): <pre><code>pip install -e .\n</code></pre></p> <p>Full (all features): <pre><code>pip install -e .[all]\n</code></pre></p> <p>Local LLM only: <pre><code>pip install -e .[local]\n</code></pre></p> <p>Remote API only: <pre><code>pip install -e .[remote]\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#step-3-uninstall-cpu-only-pytorch","title":"Step 3: Uninstall CPU-only PyTorch","text":"<pre><code>pip uninstall torch torchvision torchaudio -y\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#step-4-install-gpu-enabled-pytorch","title":"Step 4: Install GPU-enabled PyTorch","text":"<p>Visit PyTorch installation page for the exact command matching your CUDA version.</p> <p>CUDA 11.8: <pre><code>pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n</code></pre></p> <p>CUDA 12.1: <pre><code>pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n</code></pre></p> <p>CUDA 12.2+: <pre><code>pip3 install torch torchvision torchaudio\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#step-5-verify-gpu-installation","title":"Step 5: Verify GPU Installation","text":"<pre><code>python -c \"import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}'); print(f'GPU count: {torch.cuda.device_count()}'); print(f'GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \\\"N/A\\\"}')\"\n</code></pre> <p>Expected output: <pre><code>PyTorch version: 2.2.0+cu121\nCUDA available: True\nCUDA version: 12.1\nGPU count: 1\nGPU name: NVIDIA GeForce RTX 3060\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#cli-usage-with-gpu-setup","title":"CLI Usage with GPU Setup","text":"<p>\u26a0\ufe0f Important: When using the manual GPU setup (pip-based virtual environment), do not use <code>uv run</code>. Instead, call commands directly:</p>"},{"location":"fundamentals/installation/gpu-setup/#correct-usage-with-gpu-setup","title":"Correct Usage (with GPU setup)","text":"<pre><code># Activate virtual environment first\nsource .venv/bin/activate  # Linux/macOS\n# or\n.\\venv\\Scripts\\Activate  # Windows\n\n# Then use direct commands\ndocling-graph --version\ndocling-graph init\ndocling-graph convert document.pdf --template \"templates.Invoice\"\ndocling-graph inspect outputs\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#incorrect-usage-will-not-work","title":"Incorrect Usage (will not work)","text":"<pre><code># Don't use uv run with manual GPU setup\nuv run docling-graph convert document.pdf  # \u274c Wrong\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#testing-gpu-performance","title":"Testing GPU Performance","text":""},{"location":"fundamentals/installation/gpu-setup/#test-vlm-with-gpu","title":"Test VLM with GPU","text":"<pre><code># Activate virtual environment\nsource .venv/bin/activate\n\n# Run VLM example\npython docs/examples/scripts/01_vlm_from_image.py\n</code></pre> <p>Monitor GPU usage: <pre><code># In another terminal\nwatch -n 1 nvidia-smi\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#test-local-llm-with-gpu","title":"Test Local LLM with GPU","text":"<pre><code># Activate virtual environment\nsource .venv/bin/activate\n\n# Start vLLM server (if using vLLM)\npython -m vllm.entrypoints.openai.api_server \\\n    --model ibm-granite/granite-4.0-1b \\\n    --port 8000\n\n# In another terminal, run extraction\ndocling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm \\\n    --inference local \\\n    --provider vllm\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#performance-expectations","title":"Performance Expectations","text":""},{"location":"fundamentals/installation/gpu-setup/#vlm-performance","title":"VLM Performance","text":"Model GPU Processing Speed (per page) NuExtract-2B RTX 3060 (8GB) 2-3 seconds NuExtract-2B RTX 4090 (24GB) 1-2 seconds NuExtract-8B RTX 3060 (8GB) 5-7 seconds NuExtract-8B RTX 4090 (24GB) 2-3 seconds"},{"location":"fundamentals/installation/gpu-setup/#local-llm-performance","title":"Local LLM Performance","text":"Model Size GPU Processing Speed (per chunk) 1B-4B RTX 3060 (8GB) 5-10 seconds 1B-4B RTX 4090 (24GB) 2-5 seconds 7B-8B RTX 3080 (16GB) 10-20 seconds 7B-8B RTX 4090 (24GB) 5-10 seconds"},{"location":"fundamentals/installation/gpu-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/installation/gpu-setup/#issue-cuda-not-available","title":"Issue: CUDA not available","text":"<p>Check: <pre><code>python -c \"import torch; print(torch.cuda.is_available())\"\n</code></pre></p> <p>If False:</p> <ol> <li> <p>Verify NVIDIA driver:    <pre><code>nvidia-smi\n</code></pre></p> </li> <li> <p>Check CUDA installation:    <pre><code>nvcc --version\n</code></pre></p> </li> <li> <p>Reinstall PyTorch with correct CUDA version:    <pre><code>pip uninstall torch torchvision torchaudio -y\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n</code></pre></p> </li> </ol>"},{"location":"fundamentals/installation/gpu-setup/#issue-out-of-memory","title":"Issue: Out of memory","text":"<p>Symptoms: <pre><code>RuntimeError: CUDA out of memory\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Use smaller model:    <pre><code># Use NuExtract-2B instead of 8B\n# Or use smaller LLM\n</code></pre></p> </li> <li> <p>Enable chunking:    <pre><code>docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --use-chunking\n</code></pre></p> </li> <li> <p>Reduce batch size:    <pre><code>config = PipelineConfig(\n    max_batch_size=1,  # Process one chunk at a time\n    use_chunking=True\n)\n</code></pre></p> </li> <li> <p>Clear GPU memory:    <pre><code># Kill other GPU processes\nnvidia-smi\n# Note PIDs and kill if needed\nkill -9 &lt;PID&gt;\n</code></pre></p> </li> </ol>"},{"location":"fundamentals/installation/gpu-setup/#issue-slow-performance","title":"Issue: Slow performance","text":"<p>Check GPU utilization: <pre><code>nvidia-smi\n</code></pre></p> <p>If GPU utilization is low:</p> <ol> <li> <p>Verify GPU is being used:    <pre><code>import torch\nprint(torch.cuda.is_available())\nprint(torch.cuda.current_device())\n</code></pre></p> </li> <li> <p>Check for CPU fallback:</p> </li> <li>Look for warnings in output</li> <li> <p>Verify PyTorch CUDA version matches system CUDA</p> </li> <li> <p>Optimize batch size:</p> </li> <li>Increase batch size if memory allows</li> <li>Monitor with <code>nvidia-smi</code></li> </ol>"},{"location":"fundamentals/installation/gpu-setup/#issue-driver-version-mismatch","title":"Issue: Driver version mismatch","text":"<p>Symptoms: <pre><code>CUDA driver version is insufficient for CUDA runtime version\n</code></pre></p> <p>Solution: <pre><code># Update NVIDIA driver\n# Ubuntu/Debian:\nsudo apt update\nsudo apt install nvidia-driver-535\n\n# Or download from NVIDIA website\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#gpu-memory-management","title":"GPU Memory Management","text":""},{"location":"fundamentals/installation/gpu-setup/#monitor-memory-usage","title":"Monitor Memory Usage","text":"<pre><code># Real-time monitoring\nwatch -n 1 nvidia-smi\n\n# Or use Python\npython -c \"import torch; print(f'Allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB'); print(f'Reserved: {torch.cuda.memory_reserved()/1024**3:.2f} GB')\"\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#clear-gpu-cache","title":"Clear GPU Cache","text":"<pre><code>import torch\ntorch.cuda.empty_cache()\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#best-practices","title":"Best Practices","text":"<ol> <li>Process documents sequentially for large batches</li> <li>Use chunking for large documents</li> <li>Monitor memory with <code>nvidia-smi</code></li> <li>Close unused processes to free VRAM</li> <li>Use appropriate model size for your GPU</li> </ol>"},{"location":"fundamentals/installation/gpu-setup/#alternative-cloud-gpu","title":"Alternative: Cloud GPU","text":"<p>If you don't have a local GPU, consider cloud options:</p>"},{"location":"fundamentals/installation/gpu-setup/#google-colab","title":"Google Colab","text":"<pre><code># In Colab notebook\n!git clone https://github.com/IBM/docling-graph\n%cd docling-graph\n!pip install -e .[all]\n\n# GPU is automatically available\nimport torch\nprint(torch.cuda.is_available())  # Should be True\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#awsazuregcp","title":"AWS/Azure/GCP","text":"<ul> <li>Launch GPU instance (e.g., g4dn.xlarge on AWS)</li> <li>Follow Linux installation instructions</li> <li>GPU drivers usually pre-installed</li> </ul>"},{"location":"fundamentals/installation/gpu-setup/#next-steps","title":"Next Steps","text":"<p>GPU setup complete! Now:</p> <ol> <li>API Keys (optional) - Set up remote providers</li> <li>Schema Definition - Create your first template</li> <li>Quick Start - Run your first extraction</li> </ol>"},{"location":"fundamentals/installation/gpu-setup/#related-documentation","title":"Related Documentation","text":"<ul> <li>Requirements: GPU requirements</li> <li>Basic Setup: Installation without GPU</li> <li>API Keys: Remote provider setup (no GPU needed)</li> <li>Troubleshooting: Common issues</li> </ul>"},{"location":"fundamentals/installation/requirements/","title":"System Requirements","text":"<p>Pipeline Stage: 2 - Installation</p> <p>Prerequisites:  - Installation Overview</p> <p>This page details the system requirements for running Docling Graph.</p>"},{"location":"fundamentals/installation/requirements/#python-requirements","title":"Python Requirements","text":""},{"location":"fundamentals/installation/requirements/#supported-versions","title":"Supported Versions","text":"<ul> <li>Python 3.10 \u2705</li> <li>Python 3.11 \u2705</li> <li>Python 3.12 \u2705</li> </ul>"},{"location":"fundamentals/installation/requirements/#check-your-python-version","title":"Check Your Python Version","text":"<pre><code>python --version\n# or\npython3 --version\n</code></pre>"},{"location":"fundamentals/installation/requirements/#installing-python","title":"Installing Python","text":"<p>If you need to install or upgrade Python:</p> <p>Linux (Ubuntu/Debian): <pre><code>sudo apt update\nsudo apt install python3.10 python3.10-venv python3.10-dev\n</code></pre></p> <p>macOS: <pre><code>brew install python@3.10\n</code></pre></p> <p>Windows: Download from python.org</p>"},{"location":"fundamentals/installation/requirements/#hardware-requirements","title":"Hardware Requirements","text":""},{"location":"fundamentals/installation/requirements/#minimum-configuration","title":"Minimum Configuration","text":"<p>For basic usage (VLM with small documents or remote LLM):</p> Component Requirement CPU 4 cores, 2.0 GHz+ RAM 8 GB Disk 5 GB free space GPU Not required (for remote LLM only) Network Required for remote LLM"},{"location":"fundamentals/installation/requirements/#recommended-configuration","title":"Recommended Configuration","text":"<p>For optimal performance with local inference:</p> Component Requirement CPU 8+ cores, 3.0 GHz+ RAM 16 GB or more Disk 20 GB free space (for models) GPU NVIDIA GPU with 8+ GB VRAM CUDA 11.8 or 12.1 Network Optional (for remote LLM)"},{"location":"fundamentals/installation/requirements/#gpu-requirements-by-use-case","title":"GPU Requirements by Use Case","text":""},{"location":"fundamentals/installation/requirements/#vlm-only-nuextract","title":"VLM Only (NuExtract)","text":"Model VRAM Required Recommended GPU NuExtract-2B 4 GB GTX 1650, RTX 3050 NuExtract-8B 8 GB RTX 3060, RTX 4060"},{"location":"fundamentals/installation/requirements/#local-llm-vllm","title":"Local LLM (vLLM)","text":"Model Size VRAM Required Recommended GPU 1B-4B params 8 GB RTX 3060, RTX 4060 7B-8B params 16 GB RTX 3080, RTX 4070 Ti 13B+ params 24 GB+ RTX 3090, RTX 4090, A100"},{"location":"fundamentals/installation/requirements/#remote-llm-only","title":"Remote LLM Only","text":"Requirement Value GPU Not required Network Stable internet connection API Keys Required for chosen provider"},{"location":"fundamentals/installation/requirements/#operating-system-requirements","title":"Operating System Requirements","text":""},{"location":"fundamentals/installation/requirements/#linux","title":"Linux","text":"<p>Supported Distributions: - Ubuntu 20.04, 22.04, 24.04 - Debian 11, 12 - CentOS 8+ - Fedora 35+ - Arch Linux (latest)</p> <p>Required Packages: <pre><code># Ubuntu/Debian\nsudo apt install build-essential python3-dev git\n\n# CentOS/Fedora\nsudo dnf install gcc gcc-c++ python3-devel git\n\n# Arch\nsudo pacman -S base-devel python git\n</code></pre></p>"},{"location":"fundamentals/installation/requirements/#macos","title":"macOS","text":"<p>Supported Versions: - macOS 11 (Big Sur) or later - macOS 12 (Monterey) - macOS 13 (Ventura) - macOS 14 (Sonoma)</p> <p>Required Tools: <pre><code># Install Xcode Command Line Tools\nxcode-select --install\n\n# Install Homebrew (if not installed)\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre></p> <p>Note: GPU acceleration not available on macOS (Apple Silicon or Intel). Use remote LLM for best performance.</p>"},{"location":"fundamentals/installation/requirements/#windows","title":"Windows","text":"<p>Supported Versions: - Windows 10 (version 1903 or later) - Windows 11</p> <p>Recommended Setup: - WSL2 (Windows Subsystem for Linux) for best compatibility - Native Windows supported but WSL2 recommended</p> <p>WSL2 Setup: <pre><code># Enable WSL2\nwsl --install\n\n# Install Ubuntu\nwsl --install -d Ubuntu-22.04\n\n# Inside WSL2, follow Linux instructions\n</code></pre></p> <p>Native Windows Requirements: - Visual Studio Build Tools or Visual Studio 2019+ - Git for Windows - CUDA Toolkit (for GPU support)</p>"},{"location":"fundamentals/installation/requirements/#gpu-and-cuda-requirements","title":"GPU and CUDA Requirements","text":""},{"location":"fundamentals/installation/requirements/#nvidia-gpu","title":"NVIDIA GPU","text":"<p>Supported GPUs: - GeForce RTX 20/30/40 series - GeForce GTX 16 series (limited) - Quadro RTX series - Tesla/A100/H100 series</p> <p>Check GPU: <pre><code># Linux\nnvidia-smi\n\n# Windows\nnvidia-smi.exe\n</code></pre></p>"},{"location":"fundamentals/installation/requirements/#cuda-toolkit","title":"CUDA Toolkit","text":"<p>Supported Versions: - CUDA 11.8 (recommended) - CUDA 12.1 (recommended) - CUDA 12.2+</p> <p>Check CUDA Version: <pre><code>nvcc --version\n# or\nnvidia-smi\n</code></pre></p> <p>Installation: See GPU Setup Guide</p>"},{"location":"fundamentals/installation/requirements/#amd-gpu","title":"AMD GPU","text":"<p>Status: Not currently supported - AMD ROCm support planned for future release - Use remote LLM as alternative</p>"},{"location":"fundamentals/installation/requirements/#apple-silicon-m1m2m3","title":"Apple Silicon (M1/M2/M3)","text":"<p>Status: Limited support - VLM works via CPU (slower) - Local LLM not optimized - Recommended: Use remote LLM providers</p>"},{"location":"fundamentals/installation/requirements/#network-requirements","title":"Network Requirements","text":""},{"location":"fundamentals/installation/requirements/#for-remote-llm","title":"For Remote LLM","text":"Requirement Specification Bandwidth 1 Mbps minimum, 10+ Mbps recommended Latency &lt; 200ms to provider Stability Consistent connection required Firewall Allow HTTPS (port 443)"},{"location":"fundamentals/installation/requirements/#for-local-inference","title":"For Local Inference","text":"Requirement Specification Network Optional (for downloading models) Bandwidth Only needed for initial model download"},{"location":"fundamentals/installation/requirements/#disk-space-requirements","title":"Disk Space Requirements","text":""},{"location":"fundamentals/installation/requirements/#base-installation","title":"Base Installation","text":"<pre><code>Core Package:           ~500 MB\nPython Dependencies:    ~2 GB\nTotal:                  ~2.5 GB\n</code></pre>"},{"location":"fundamentals/installation/requirements/#with-models","title":"With Models","text":"<pre><code>VLM Models:\n  - NuExtract-2B:       ~4 GB\n  - NuExtract-8B:       ~16 GB\n\nLLM Models (examples):\n  - Granite-1B:         ~2 GB\n  - Llama-7B:           ~14 GB\n  - Llama-13B:          ~26 GB\n\nRecommended Free Space: 20 GB\n</code></pre>"},{"location":"fundamentals/installation/requirements/#for-processing","title":"For Processing","text":"<pre><code>Temporary Files:        ~1 GB per document\nOutput Files:           ~100 MB per document\nCache:                  ~500 MB\n\nRecommended Free Space: 5 GB for active processing\n</code></pre>"},{"location":"fundamentals/installation/requirements/#memory-ram-requirements","title":"Memory (RAM) Requirements","text":""},{"location":"fundamentals/installation/requirements/#by-use-case","title":"By Use Case","text":"Use Case Minimum RAM Recommended RAM Remote LLM only 4 GB 8 GB VLM (NuExtract-2B) 8 GB 16 GB VLM (NuExtract-8B) 12 GB 24 GB Local LLM (1B-4B) 16 GB 32 GB Local LLM (7B-8B) 24 GB 48 GB Local LLM (13B+) 32 GB 64 GB+"},{"location":"fundamentals/installation/requirements/#memory-usage-patterns","title":"Memory Usage Patterns","text":"<pre><code>Base Process:           ~500 MB\nDocument Processing:    ~1-2 GB per document\nModel Loading:          Varies by model size\nGraph Construction:     ~100 MB per 1000 nodes\n</code></pre>"},{"location":"fundamentals/installation/requirements/#software-dependencies","title":"Software Dependencies","text":""},{"location":"fundamentals/installation/requirements/#required","title":"Required","text":"<ul> <li>Python: 3.10, 3.11, or 3.12</li> <li>uv: Package manager (installed automatically)</li> <li>Git: For cloning repository</li> </ul>"},{"location":"fundamentals/installation/requirements/#optional-installed-by-uv","title":"Optional (Installed by uv)","text":"<ul> <li>PyTorch: For GPU acceleration</li> <li>CUDA Toolkit: For NVIDIA GPU support</li> <li>Docling: Document conversion</li> <li>NetworkX: Graph operations</li> <li>Pydantic: Data validation</li> </ul>"},{"location":"fundamentals/installation/requirements/#compatibility-matrix","title":"Compatibility Matrix","text":""},{"location":"fundamentals/installation/requirements/#backend-compatibility","title":"Backend Compatibility","text":"Backend Linux macOS Windows GPU Required VLM (NuExtract) \u2705 \u2705 \u2705 Recommended LLM (vLLM) \u2705 \u274c \u26a0\ufe0f Yes LLM (Ollama) \u2705 \u2705 \u2705 Optional LLM (Remote APIs) \u2705 \u2705 \u2705 No <p>Legend: \u2705 Fully supported \u26a0\ufe0f Supported with limitations \u274c Not supported</p>"},{"location":"fundamentals/installation/requirements/#provider-compatibility","title":"Provider Compatibility","text":"Provider Local Remote GPU Required API Key Required NuExtract (VLM) \u2705 \u274c Recommended No vLLM \u2705 \u274c Yes No Ollama \u2705 \u274c Optional No OpenAI \u274c \u2705 No Yes Mistral \u274c \u2705 No Yes Gemini \u274c \u2705 No Yes WatsonX \u274c \u2705 No Yes"},{"location":"fundamentals/installation/requirements/#verification-checklist","title":"Verification Checklist","text":"<p>Before proceeding with installation, verify:</p> <ul> <li> Python 3.10+ installed</li> <li> Sufficient disk space (5 GB minimum, 20 GB recommended)</li> <li> Sufficient RAM (8 GB minimum, 16 GB recommended)</li> <li> GPU available (if using local inference)</li> <li> CUDA installed (if using NVIDIA GPU)</li> <li> Network connection (if using remote LLM)</li> <li> API keys ready (if using remote LLM)</li> </ul>"},{"location":"fundamentals/installation/requirements/#performance-expectations","title":"Performance Expectations","text":""},{"location":"fundamentals/installation/requirements/#document-processing-speed","title":"Document Processing Speed","text":"Configuration Small Doc (1-2 pages) Large Doc (10+ pages) VLM (GPU) 5-10 seconds 30-60 seconds VLM (CPU) 30-60 seconds 3-5 minutes LLM Local (GPU) 10-30 seconds 1-3 minutes LLM Remote 5-15 seconds 30-90 seconds"},{"location":"fundamentals/installation/requirements/#memory-usage","title":"Memory Usage","text":"Configuration Peak Memory Sustained Memory Remote LLM 2-4 GB 1-2 GB VLM (2B) 6-8 GB 4-6 GB VLM (8B) 12-16 GB 10-12 GB Local LLM (7B) 20-24 GB 16-20 GB"},{"location":"fundamentals/installation/requirements/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/installation/requirements/#check-system-resources","title":"Check System Resources","text":"<pre><code># Check RAM\nfree -h  # Linux\nvm_stat  # macOS\n\n# Check disk space\ndf -h\n\n# Check GPU\nnvidia-smi  # NVIDIA\n</code></pre>"},{"location":"fundamentals/installation/requirements/#insufficient-resources","title":"Insufficient Resources","text":"<p>Problem: Not enough RAM/VRAM</p> <p>Solutions: 1. Use remote LLM instead of local 2. Use smaller models (NuExtract-2B instead of 8B) 3. Enable chunking to reduce memory usage 4. Close other applications</p> <p>Problem: No GPU available</p> <p>Solutions: 1. Use remote LLM providers (no GPU needed) 2. Use Ollama with CPU (slower but works) 3. Consider cloud GPU instances</p>"},{"location":"fundamentals/installation/requirements/#next-steps","title":"Next Steps","text":"<p>Requirements verified? Continue with:</p> <ol> <li>Basic Setup - Install Docling Graph</li> <li>GPU Setup - Configure CUDA (if using GPU)</li> <li>API Keys - Set up remote providers (if using APIs)</li> </ol>"},{"location":"fundamentals/installation/requirements/#related-documentation","title":"Related Documentation","text":"<ul> <li>Installation Overview: Installation options</li> <li>GPU Setup: Detailed GPU configuration</li> <li>Troubleshooting: Common installation issues</li> </ul> <p>Questions about requirements? Check the installation overview or proceed to basic setup!</p>"},{"location":"fundamentals/pipeline-configuration/","title":"Pipeline Configuration","text":""},{"location":"fundamentals/pipeline-configuration/#overview","title":"Overview","text":"<p>Pipeline configuration controls how Docling Graph processes documents and extracts knowledge graphs. The <code>PipelineConfig</code> class provides a type-safe, programmatic way to configure all aspects of the extraction pipeline.</p> <p>In this section: - Understanding PipelineConfig - Backend selection (LLM vs VLM) - Model configuration - Processing modes - Export settings - Advanced configuration</p>"},{"location":"fundamentals/pipeline-configuration/#what-is-pipeline-configuration","title":"What is Pipeline Configuration?","text":"<p>Pipeline configuration defines:</p> <ol> <li>What to extract - Source document and template</li> <li>How to extract - Backend, model, and processing mode</li> <li>How to process - Chunking, consolidation, and validation</li> <li>What to export - Output formats and locations</li> </ol>"},{"location":"fundamentals/pipeline-configuration/#configuration-methods","title":"Configuration Methods","text":"<p>You can configure the pipeline in three ways:</p>"},{"location":"fundamentals/pipeline-configuration/#1-python-api-recommended","title":"1. Python API (Recommended)","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    output_dir=\"outputs\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#2-cli-with-flags","title":"2. CLI with Flags","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"my_templates.Invoice\" \\\n    --backend llm \\\n    --inference remote \\\n    --output-dir outputs\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#3-yaml-configuration-file","title":"3. YAML Configuration File","text":"<pre><code># config.yaml\ndefaults:\n  backend: llm\n  inference: remote\n  processing_mode: many-to-one\n  export_format: csv\n\nmodels:\n  llm:\n    remote:\n      default_model: \"mistral-small-latest\"\n      provider: \"mistral\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#section-contents","title":"Section Contents","text":"Document Description Time Configuration Basics PipelineConfig fundamentals and required settings 15 min Input Formats Supported input formats (PDF, images, text, URLs, etc.) 20 min Backend Selection Choosing between LLM and VLM backends 15 min Model Configuration Configuring models for local and remote inference 20 min Processing Modes One-to-one vs many-to-one extraction 15 min Docling Settings Document conversion configuration 10 min Export Configuration Output formats and export options 15 min Configuration Examples Complete configuration scenarios 15 min <p>Total Time: ~2.5 hours</p>"},{"location":"fundamentals/pipeline-configuration/#quick-start","title":"Quick Start","text":""},{"location":"fundamentals/pipeline-configuration/#minimal-configuration","title":"Minimal Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Minimal config - uses all defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.MyTemplate\"\n)\n\nconfig.run()\n</code></pre> <p>Defaults: - Backend: <code>llm</code> - Inference: <code>local</code> - Processing mode: <code>many-to-one</code> - Export format: <code>csv</code> - Output directory: <code>outputs</code></p>"},{"location":"fundamentals/pipeline-configuration/#common-configurations","title":"Common Configurations","text":""},{"location":"fundamentals/pipeline-configuration/#remote-api-extraction","title":"Remote API Extraction","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#local-gpu-extraction","title":"Local GPU Extraction","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\",\n    provider_override=\"vllm\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#vlm-vision-extraction","title":"VLM (Vision) Extraction","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",\n    inference=\"local\",  # VLM only supports local\n    docling_config=\"vision\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#configuration-architecture","title":"Configuration Architecture","text":""},{"location":"fundamentals/pipeline-configuration/#configuration-flow","title":"Configuration Flow","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% Subgraph Styling (Transparent with dashed border for visibility)\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5,color:#969696\n\n    %% 2. Define Nodes &amp; Subgraphs\n    A@{ shape: procs, label: \"PipelineConfig\" }\n\n    subgraph Backends [\"Backend Configuration\"]\n        B@{ shape: lin-proc, label: \"Backend Selection\" }\n        F@{ shape: tag-proc, label: \"LLM Backend\" }\n        G@{ shape: tag-proc, label: \"VLM Backend\" }\n    end\n\n    subgraph Models [\"Inference Settings\"]\n        C@{ shape: lin-proc, label: \"Model Selection\" }\n        H@{ shape: tag-proc, label: \"Local Inference\" }\n        I@{ shape: tag-proc, label: \"Remote Inference\" }\n    end\n\n    subgraph Strategy [\"Processing Mode\"]\n        D@{ shape: lin-proc, label: \"Processing Mode\" }\n        J@{ shape: tag-proc, label: \"One-to-One\" }\n        K@{ shape: tag-proc, label: \"Many-to-One\" }\n    end\n\n    subgraph Exports [\"Output Settings\"]\n        E@{ shape: lin-proc, label: \"Export Settings\" }\n        L@{ shape: tag-proc, label: \"CSV Export\" }\n        M@{ shape: tag-proc, label: \"Cypher Export\" }\n    end\n\n    %% 3. Define Connections\n    A --&gt; B &amp; C &amp; D &amp; E\n\n    B --&gt; F &amp; G\n    C --&gt; H &amp; I\n    D --&gt; J &amp; K\n    E --&gt; L &amp; M\n\n    %% 4. Apply Classes\n    class A config\n    class B,C,D,E process\n    class F,G,H,I,J,K operator\n    class L,M output\n    class Backends,Models,Strategy,Exports subgraph_style</code></pre>"},{"location":"fundamentals/pipeline-configuration/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<pre><code>PipelineConfig\n\u251c\u2500\u2500 Source &amp; Template (required)\n\u2502   \u251c\u2500\u2500 source: Path to document\n\u2502   \u2514\u2500\u2500 template: Pydantic template\n\u2502\n\u251c\u2500\u2500 Backend Configuration\n\u2502   \u251c\u2500\u2500 backend: llm | vlm\n\u2502   \u251c\u2500\u2500 inference: local | remote\n\u2502   \u2514\u2500\u2500 models: Model configurations\n\u2502\n\u251c\u2500\u2500 Processing Configuration\n\u2502   \u251c\u2500\u2500 processing_mode: one-to-one | many-to-one\n\u2502   \u251c\u2500\u2500 docling_config: ocr | vision\n\u2502   \u251c\u2500\u2500 use_chunking: bool\n\u2502   \u2514\u2500\u2500 llm_consolidation: bool\n\u2502\n\u251c\u2500\u2500 Export Configuration\n\u2502   \u251c\u2500\u2500 export_format: csv | cypher\n\u2502   \u251c\u2500\u2500 export_docling: bool\n\u2502   \u2514\u2500\u2500 output_dir: Path\n\u2502\n\u2514\u2500\u2500 Advanced Settings\n    \u251c\u2500\u2500 max_batch_size: int\n    \u251c\u2500\u2500 reverse_edges: bool\n    \u2514\u2500\u2500 chunker_config: dict\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#key-configuration-decisions","title":"Key Configuration Decisions","text":""},{"location":"fundamentals/pipeline-configuration/#1-backend-llm-vs-vlm","title":"1. Backend: LLM vs VLM","text":"<p>Choose LLM when: - Processing text-heavy documents - Need remote API support - Want flexible model selection - Cost is a concern (remote APIs)</p> <p>Choose VLM when: - Processing image-heavy documents - Need vision understanding - Have local GPU available - Want highest accuracy for complex layouts</p> <p>See: Backend Selection</p>"},{"location":"fundamentals/pipeline-configuration/#2-inference-local-vs-remote","title":"2. Inference: Local vs Remote","text":"<p>Choose Local when: - Have GPU available - Processing sensitive data - Need offline capability - Want to avoid API costs</p> <p>Choose Remote when: - No GPU available - Need quick setup - Want latest models - Processing non-sensitive data</p> <p>See: Model Configuration</p>"},{"location":"fundamentals/pipeline-configuration/#3-processing-mode-one-to-one-vs-many-to-one","title":"3. Processing Mode: One-to-One vs Many-to-One","text":"<p>Choose One-to-One when: - Documents have distinct pages - Need page-level granularity - Pages are independent</p> <p>Choose Many-to-One when: - Document is a single entity - Need document-level view - Want consolidated output</p> <p>See: Processing Modes</p>"},{"location":"fundamentals/pipeline-configuration/#configuration-validation","title":"Configuration Validation","text":"<p>PipelineConfig validates your configuration:</p> <pre><code>from docling_graph import PipelineConfig\n\n# This will raise ValidationError\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"my_templates.Invoice\",\n        backend=\"vlm\",\n        inference=\"remote\"  # \u274c VLM doesn't support remote\n    )\nexcept ValueError as e:\n    print(f\"Configuration error: {e}\")\n    # Output: VLM backend currently only supports local inference\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#common-validation-errors","title":"Common Validation Errors","text":"Error Cause Solution VLM remote inference VLM + remote Use <code>inference=\"local\"</code> or <code>backend=\"llm\"</code> Missing source No source specified Provide <code>source=\"path/to/doc\"</code> Missing template No template specified Provide <code>template=\"module.Class\"</code> Invalid backend Wrong backend value Use <code>\"llm\"</code> or <code>\"vlm\"</code> Invalid inference Wrong inference value Use <code>\"local\"</code> or <code>\"remote\"</code>"},{"location":"fundamentals/pipeline-configuration/#default-values","title":"Default Values","text":"<p>PipelineConfig provides sensible defaults:</p> <pre><code># All defaults\nPipelineConfig(\n    source=\"\",  # Required at runtime\n    template=\"\",  # Required at runtime\n    backend=\"llm\",\n    inference=\"local\",\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n    llm_consolidation=False,\n    export_format=\"csv\",\n    export_docling=True,\n    export_docling_json=True,\n    export_markdown=True,\n    export_per_page_markdown=False,\n    reverse_edges=False,\n    output_dir=\"outputs\",\n    max_batch_size=1\n)\n</code></pre> <p>See: Configuration Basics for details on each setting.</p>"},{"location":"fundamentals/pipeline-configuration/#environment-variables","title":"Environment Variables","text":"<p>Some settings can be configured via environment variables:</p> <pre><code># API Keys\nexport OPENAI_API_KEY=\"your-key\"\nexport MISTRAL_API_KEY=\"your-key\"\nexport GOOGLE_API_KEY=\"your-key\"\nexport WATSONX_API_KEY=\"your-key\"\n\n# Model Configuration\nexport VLLM_BASE_URL=\"http://localhost:8000/v1\"\nexport OLLAMA_BASE_URL=\"http://localhost:11434\"\n</code></pre> <p>See: Installation: API Keys</p>"},{"location":"fundamentals/pipeline-configuration/#configuration-best-practices","title":"Configuration Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/#1-start-simple","title":"1. Start Simple","text":"<pre><code># \u2705 Good - Start with defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\"\n)\n\n# \u274c Bad - Over-configure initially\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    llm_consolidation=False,\n    # ... many more settings\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#2-override-only-whats-needed","title":"2. Override Only What's Needed","text":"<pre><code># \u2705 Good - Override specific settings\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",  # Only change this\n    model_override=\"gpt-4-turbo\"  # And this\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#3-use-type-hints","title":"3. Use Type Hints","text":"<pre><code>from docling_graph import PipelineConfig\n\n# \u2705 Good - Type hints help catch errors\nconfig: PipelineConfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#4-validate-early","title":"4. Validate Early","text":"<pre><code># \u2705 Good - Validate config before running\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",\n    inference=\"local\"\n)\n\n# Check config is valid\nprint(f\"Backend: {config.backend}\")\nprint(f\"Inference: {config.inference}\")\n\n# Then run\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#next-steps","title":"Next Steps","text":"<p>Ready to configure your pipeline?</p> <ol> <li>Configuration Basics \u2192 - Learn PipelineConfig fundamentals</li> <li>Backend Selection - Choose the right backend</li> <li>Configuration Examples - See complete scenarios</li> </ol>"},{"location":"fundamentals/pipeline-configuration/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/pipeline-configuration/#minimal-configuration_1","title":"Minimal Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.MyTemplate\"\n)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#cli-equivalent","title":"CLI Equivalent","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"my_templates.MyTemplate\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#key-settings","title":"Key Settings","text":"<ul> <li>backend: <code>\"llm\"</code> (text) or <code>\"vlm\"</code> (vision)</li> <li>inference: <code>\"local\"</code> (GPU) or <code>\"remote\"</code> (API)</li> <li>processing_mode: <code>\"one-to-one\"</code> or <code>\"many-to-one\"</code></li> <li>export_format: <code>\"csv\"</code> or <code>\"cypher\"</code></li> </ul>"},{"location":"fundamentals/pipeline-configuration/backend-selection/","title":"Backend Selection: LLM vs VLM","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#overview","title":"Overview","text":"<p>Docling Graph supports two extraction backends: LLM (Language Model) for text-based extraction and VLM (Vision-Language Model) for vision-based extraction. Choosing the right backend is crucial for extraction quality and performance.</p> <p>In this guide: - LLM vs VLM comparison - When to use each backend - Performance characteristics - Cost considerations - Switching between backends</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#backend-comparison","title":"Backend Comparison","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#quick-comparison-table","title":"Quick Comparison Table","text":"Aspect LLM Backend VLM Backend Input Markdown text Document images Best For Text-heavy documents Complex layouts, images Inference Local or Remote Local only Speed Fast Slower Accuracy High for text Highest for complex layouts GPU Required Optional (remote) Yes (local only) Cost Low (local) to Medium (remote) Medium (GPU required) Setup Easy Moderate"},{"location":"fundamentals/pipeline-configuration/backend-selection/#llm-backend","title":"LLM Backend","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#what-is-llm-backend","title":"What is LLM Backend?","text":"<p>The LLM backend uses language models to extract structured data from markdown text. Documents are first converted to markdown using Docling, then processed by the LLM.</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#architecture","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: procs, label: \"Docling Conversion\" }\n    C@{ shape: doc, label: \"Markdown Text\" }\n    D@{ shape: tag-proc, label: \"Chunking Optional\" }\n    E@{ shape: procs, label: \"LLM Extraction\" }\n\n    F@{ shape: doc, label: \"Structured Data\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,E process\n    class C data\n    class D operator\n    class F output</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",  # LLM backend\n    inference=\"local\"  # or \"remote\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#when-to-use-llm","title":"When to Use LLM","text":"<p>\u2705 Use LLM when: - Documents are primarily text-based - Layout is standard (invoices, contracts, reports) - You need remote API support - Cost efficiency is important - You want fast processing - You don't have GPU available (use remote)</p> <p>\u274c Don't use LLM when: - Documents have complex visual layouts - Images contain critical information - Tables have complex structures - Handwriting needs to be processed</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#llm-advantages","title":"LLM Advantages","text":"<ol> <li>Flexible Inference</li> <li>Local: Use your own GPU/CPU</li> <li> <p>Remote: Use cloud APIs (OpenAI, Mistral, Gemini)</p> </li> <li> <p>Fast Processing</p> </li> <li>Quick markdown conversion</li> <li>Efficient text processing</li> <li> <p>Parallel chunking support</p> </li> <li> <p>Cost Effective</p> </li> <li>Local inference: Free (after GPU cost)</li> <li>Remote inference: Pay per token</li> <li> <p>Generally cheaper than VLM</p> </li> <li> <p>Easy Setup</p> </li> <li>No GPU required for remote</li> <li>Simple API key configuration</li> <li>Wide model selection</li> </ol>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#llm-limitations","title":"LLM Limitations","text":"<ol> <li>Text-Only Processing</li> <li>Loses visual information</li> <li>May miss layout cues</li> <li> <p>Can't process images directly</p> </li> <li> <p>OCR Dependency</p> </li> <li>Relies on Docling OCR quality</li> <li>May struggle with poor scans</li> <li> <p>Handwriting not well supported</p> </li> <li> <p>Context Limits</p> </li> <li>Large documents need chunking</li> <li>May lose cross-page context</li> <li>Requires consolidation for coherence</li> </ol>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#vlm-backend","title":"VLM Backend","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#what-is-vlm-backend","title":"What is VLM Backend?","text":"<p>The VLM backend uses vision-language models to extract structured data directly from document images. It processes visual information alongside text, understanding layout and structure.</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#architecture_1","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    InputPDF@{ shape: terminal, label: \"PDF Document\" }\n    InputImg@{ shape: terminal, label: \"Images\" }\n\n    Convert@{ shape: procs, label: \"PDF to Image&lt;br&gt;Conversion\" }\n    PageImgs@{ shape: doc, label: \"Page Images\" }\n\n    VLM@{ shape: procs, label: \"VLM Processing\" }\n    Understand@{ shape: lin-proc, label: \"Visual Understanding\" }\n    Extract@{ shape: tag-proc, label: \"Direct Extraction\" }\n\n    Output@{ shape: doc, label: \"Pydantic Models\" }\n\n    %% 3. Define Connections\n    %% Path A: PDF requires conversion\n    InputPDF --&gt; Convert\n    Convert --&gt; PageImgs\n    PageImgs --&gt; VLM\n\n    %% Path B: Direct Image Input (Merges here)\n    InputImg --&gt; VLM\n\n    %% Shared Processing Chain\n    VLM --&gt; Understand\n    Understand --&gt; Extract\n    Extract --&gt; Output\n\n    %% 4. Apply Classes\n    class InputPDF,InputImg input\n    class Convert,VLM,Understand process\n    class PageImgs data\n    class Extract operator\n    class Output output</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",  # VLM backend\n    inference=\"local\",  # VLM only supports local\n    docling_config=\"vision\"  # Optional: use vision pipeline\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#when-to-use-vlm","title":"When to Use VLM","text":"<p>\u2705 Use VLM when: - Documents have complex visual layouts - Images contain critical information - Tables have intricate structures - Forms have specific visual patterns - Highest accuracy is required - You have GPU available</p> <p>\u274c Don't use VLM when: - Documents are simple text - You need remote API support - GPU is not available - Processing speed is critical - Cost is a major concern</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#vlm-advantages","title":"VLM Advantages","text":"<ol> <li>Visual Understanding</li> <li>Processes layout and structure</li> <li>Understands visual relationships</li> <li>Handles complex tables</li> <li> <p>Processes embedded images</p> </li> <li> <p>Higher Accuracy</p> </li> <li>Best for complex documents</li> <li>Understands visual context</li> <li>Fewer extraction errors</li> <li> <p>Better table handling</p> </li> <li> <p>No OCR Dependency</p> </li> <li>Direct image processing</li> <li>Better with poor scans</li> <li>Handles handwriting better</li> <li>Preserves visual information</li> </ol>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#vlm-limitations","title":"VLM Limitations","text":"<ol> <li>Local Only</li> <li>Requires local GPU</li> <li>No remote API support</li> <li>Higher setup complexity</li> <li> <p>GPU memory requirements</p> </li> <li> <p>Slower Processing</p> </li> <li>Image processing overhead</li> <li>Larger model size</li> <li>More GPU memory needed</li> <li> <p>Longer inference time</p> </li> <li> <p>Higher Cost</p> </li> <li>GPU required</li> <li>More expensive hardware</li> <li>Higher power consumption</li> <li>Larger storage needs</li> </ol>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#decision-matrix","title":"Decision Matrix","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#by-document-type","title":"By Document Type","text":"Document Type Recommended Backend Reason Invoices LLM Standard layout, text-heavy Contracts LLM Text-heavy, standard format Research Papers LLM Text-heavy, standard layout Forms VLM Visual structure important ID Cards VLM Visual layout critical Complex Tables VLM Visual structure needed Handwritten VLM Visual processing required Mixed Content VLM Images and text combined"},{"location":"fundamentals/pipeline-configuration/backend-selection/#by-infrastructure","title":"By Infrastructure","text":"Infrastructure Recommended Backend Configuration No GPU LLM Remote <code>backend=\"llm\", inference=\"remote\"</code> CPU Only LLM Remote <code>backend=\"llm\", inference=\"remote\"</code> GPU Available LLM or VLM Local <code>backend=\"llm/vlm\", inference=\"local\"</code> Cloud/API LLM Remote <code>backend=\"llm\", inference=\"remote\"</code>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#by-priority","title":"By Priority","text":"Priority Recommended Backend Reason Speed LLM Faster processing Accuracy VLM Better visual understanding Cost LLM Local No API costs Simplicity LLM Remote Easy setup Offline LLM or VLM Local No internet needed"},{"location":"fundamentals/pipeline-configuration/backend-selection/#performance-comparison","title":"Performance Comparison","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#processing-speed","title":"Processing Speed","text":"<pre><code>Document: 10-page invoice PDF\n\nLLM Local (GPU):     ~30 seconds\nLLM Remote (API):    ~45 seconds\nVLM Local (GPU):     ~90 seconds\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#accuracy-comparison","title":"Accuracy Comparison","text":"<pre><code>Document Type: Complex invoice with tables\n\nLLM Accuracy:  92% field extraction\nVLM Accuracy:  97% field extraction\n\nDocument Type: Simple text contract\n\nLLM Accuracy:  98% field extraction\nVLM Accuracy:  96% field extraction\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#cost-comparison","title":"Cost Comparison","text":"<pre><code>Processing 1000 documents:\n\nLLM Local:     $0 (GPU amortized)\nLLM Remote:    $50-200 (API costs)\nVLM Local:     $0 (GPU amortized)\nVLM Remote:    Not available\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#switching-between-backends","title":"Switching Between Backends","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#from-llm-to-vlm","title":"From LLM to VLM","text":"<pre><code># Original LLM config\nconfig_llm = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\n\n# Switch to VLM\nconfig_vlm = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",  # Change backend\n    inference=\"local\",  # Must be local for VLM\n    docling_config=\"vision\"  # Optional: use vision pipeline\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#from-vlm-to-llm","title":"From VLM to LLM","text":"<pre><code># Original VLM config\nconfig_vlm = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",\n    inference=\"local\"\n)\n\n# Switch to LLM\nconfig_llm = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",  # Change backend\n    inference=\"remote\",  # Can now use remote\n    model_override=\"gpt-4-turbo\"  # Specify model\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#hybrid-approach","title":"Hybrid Approach","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#strategy-1-document-type-based","title":"Strategy 1: Document Type Based","text":"<pre><code>def get_config(document_path: str, document_type: str):\n    \"\"\"Choose backend based on document type.\"\"\"\n    if document_type in [\"invoice\", \"contract\", \"report\"]:\n        # Use LLM for text-heavy documents\n        return PipelineConfig(\n            source=document_path,\n            template=\"my_templates.Invoice\",\n            backend=\"llm\",\n            inference=\"remote\"\n        )\n    else:\n        # Use VLM for complex layouts\n        return PipelineConfig(\n            source=document_path,\n            template=\"my_templates.Form\",\n            backend=\"vlm\",\n            inference=\"local\"\n        )\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#strategy-2-fallback-pattern","title":"Strategy 2: Fallback Pattern","text":"<pre><code>def extract_with_fallback(document_path: str):\n    \"\"\"Try LLM first, fallback to VLM if needed.\"\"\"\n    try:\n        # Try LLM first (faster)\n        config = PipelineConfig(\n            source=document_path,\n            template=\"my_templates.Invoice\",\n            backend=\"llm\",\n            inference=\"remote\"\n        )\n        config.run()\n    except ExtractionError:\n        # Fallback to VLM for better accuracy\n        config = PipelineConfig(\n            source=document_path,\n            template=\"my_templates.Invoice\",\n            backend=\"vlm\",\n            inference=\"local\"\n        )\n        config.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#backend-specific-settings","title":"Backend-Specific Settings","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#llm-specific-settings","title":"LLM-Specific Settings","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n\n    # LLM-specific\n    use_chunking=True,  # Split large documents\n    llm_consolidation=True,  # Merge results with LLM\n    max_batch_size=5  # Process multiple chunks\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#vlm-specific-settings","title":"VLM-Specific Settings","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",\n\n    # VLM-specific\n    docling_config=\"vision\",  # Use vision pipeline\n    processing_mode=\"one-to-one\"  # Process pages individually\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#common-questions","title":"Common Questions","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#q-can-i-use-vlm-with-remote-inference","title":"Q: Can I use VLM with remote inference?","text":"<p>A: No, VLM currently only supports local inference. Use LLM backend for remote API support.</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#q-which-backend-is-more-accurate","title":"Q: Which backend is more accurate?","text":"<p>A: VLM is generally more accurate for complex layouts and visual documents. LLM is more accurate for simple text documents.</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#q-which-backend-is-faster","title":"Q: Which backend is faster?","text":"<p>A: LLM is faster, especially with remote APIs. VLM requires more processing time due to image analysis.</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#q-can-i-switch-backends-mid-project","title":"Q: Can I switch backends mid-project?","text":"<p>A: Yes, backends are interchangeable. Just change the <code>backend</code> parameter in your config.</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#q-do-i-need-different-templates-for-different-backends","title":"Q: Do I need different templates for different backends?","text":"<p>A: No, the same Pydantic template works with both backends.</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#next-steps","title":"Next Steps","text":"<p>Now that you understand backend selection:</p> <ol> <li>Model Configuration \u2192 - Configure models for your chosen backend</li> <li>Processing Modes - Choose processing strategy</li> <li>Configuration Examples - See complete scenarios</li> </ol>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#llm-backend_1","title":"LLM Backend","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\"  # or \"remote\"\n)\n</code></pre> <p>Best for: Text-heavy documents, standard layouts, remote processing</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#vlm-backend_1","title":"VLM Backend","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",\n    inference=\"local\"  # Only local supported\n)\n</code></pre> <p>Best for: Complex layouts, visual documents, highest accuracy</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/","title":"Configuration Basics","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#overview","title":"Overview","text":"<p>The <code>PipelineConfig</code> class is the foundation of Docling Graph configuration. It provides type-safe, validated configuration for all pipeline operations. This guide covers the fundamentals of creating and using pipeline configurations.</p> <p>In this guide: - PipelineConfig structure - Required vs optional settings - Creating configurations - Configuration validation - Common patterns</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pipelineconfig-structure","title":"PipelineConfig Structure","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#core-components","title":"Core Components","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    # Required (at runtime)\n    source=\"document.pdf\",\n    template=\"my_templates.MyTemplate\",\n\n    # Backend settings\n    backend=\"llm\",              # \"llm\" or \"vlm\"\n    inference=\"local\",          # \"local\" or \"remote\"\n\n    # Processing settings\n    processing_mode=\"many-to-one\",  # \"one-to-one\" or \"many-to-one\"\n    docling_config=\"ocr\",           # \"ocr\" or \"vision\"\n    use_chunking=True,\n    llm_consolidation=False,\n\n    # Export settings\n    export_format=\"csv\",        # \"csv\" or \"cypher\"\n    output_dir=\"outputs\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#configuration-categories","title":"Configuration Categories","text":"Category Settings Purpose Source <code>source</code>, <code>template</code> What to extract Backend <code>backend</code>, <code>inference</code>, <code>models</code> How to extract Processing <code>processing_mode</code>, <code>docling_config</code>, <code>use_chunking</code> How to process Export <code>export_format</code>, <code>output_dir</code>, <code>export_*</code> What to output Advanced <code>max_batch_size</code>, <code>reverse_edges</code>, <code>chunker_config</code> Optimization"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#required-settings","title":"Required Settings","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#1-source-document","title":"1. Source Document","text":"<pre><code># File path (string or Path)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\"\n)\n\n# Also accepts Path objects\nfrom pathlib import Path\nconfig = PipelineConfig(\n    source=Path(\"documents/invoice.pdf\"),\n    template=\"my_templates.Invoice\"\n)\n</code></pre> <p>Supported formats: - PDF documents - Images (PNG, JPG, JPEG) - DOCX files</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#2-pydantic-template","title":"2. Pydantic Template","text":"<pre><code># Dotted path string (recommended)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\"\n)\n\n# Direct class reference (alternative)\nfrom my_templates import Invoice\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=Invoice\n)\n</code></pre> <p>Template must: - Be a valid Pydantic BaseModel - Have proper <code>model_config</code> (graph_id_fields or is_entity) - Include the <code>edge()</code> helper function - Follow template best practices</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#backend-settings","title":"Backend Settings","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#backend-type","title":"Backend Type","text":"<pre><code># LLM backend (default) - for text extraction\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\"\n)\n\n# VLM backend - for vision-based extraction\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\"\n)\n</code></pre> <p>See: Backend Selection for detailed comparison.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#inference-location","title":"Inference Location","text":"<pre><code># Local inference (default) - uses local GPU/CPU\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\"\n)\n\n# Remote inference - uses API providers\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\"\n)\n</code></pre> <p>See: Model Configuration for setup details.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#model-overrides","title":"Model Overrides","text":"<pre><code># Override default model\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#processing-settings","title":"Processing Settings","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#processing-mode","title":"Processing Mode","text":"<pre><code># Many-to-one (default) - whole document as single entity\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"many-to-one\"\n)\n\n# One-to-one - process each page separately\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"one-to-one\"\n)\n</code></pre> <p>See: Processing Modes for when to use each.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#docling-configuration","title":"Docling Configuration","text":"<pre><code># OCR pipeline (default) - traditional OCR\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"ocr\"\n)\n\n# Vision pipeline - VLM-based conversion\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"vision\"\n)\n</code></pre> <p>See: Docling Settings for details.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#chunking","title":"Chunking","text":"<pre><code># With chunking (default) - splits large documents\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    use_chunking=True\n)\n\n# Without chunking - processes entire document\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    use_chunking=False\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#llm-consolidation","title":"LLM Consolidation","text":"<pre><code># Without consolidation (default)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    llm_consolidation=False\n)\n\n# With consolidation - merges results using LLM\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    llm_consolidation=True\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#export-settings","title":"Export Settings","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#export-format","title":"Export Format","text":"<pre><code># CSV format (default)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\"\n)\n\n# Cypher format - for Neo4j import\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"cypher\"\n)\n</code></pre> <p>See: Export Configuration for format details.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#output-directory","title":"Output Directory","text":"<pre><code># Default output directory\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    output_dir=\"outputs\"\n)\n\n# Custom output directory\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    output_dir=\"my_results/invoice_001\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#docling-exports","title":"Docling Exports","text":"<pre><code># Control Docling document exports\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_docling=True,           # Export Docling document\n    export_docling_json=True,      # Export as JSON\n    export_markdown=True,          # Export as markdown\n    export_per_page_markdown=False # Export per-page markdown\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#creating-configurations","title":"Creating Configurations","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#method-1-direct-instantiation","title":"Method 1: Direct Instantiation","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\n\n# Run the pipeline\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#method-2-programmatic-building","title":"Method 2: Programmatic Building","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Start with defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\"\n)\n\n# Modify as needed\nif use_gpu:\n    config.inference = \"local\"\n    config.model_override = \"ibm-granite/granite-4.0-1b\"\nelse:\n    config.inference = \"remote\"\n    config.model_override = \"gpt-4-turbo\"\n\n# Run\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#method-3-from-dictionary","title":"Method 3: From Dictionary","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig_dict = {\n    \"source\": \"document.pdf\",\n    \"template\": \"my_templates.Invoice\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\"\n}\n\nconfig = PipelineConfig(**config_dict)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#method-4-using-run_pipeline","title":"Method 4: Using run_pipeline","text":"<pre><code>from docling_graph import run_pipeline\n\n# Pass config dict directly\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"my_templates.Invoice\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\"\n})\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#configuration-validation","title":"Configuration Validation","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#automatic-validation","title":"Automatic Validation","text":"<p>PipelineConfig validates settings automatically:</p> <pre><code>from docling_graph import PipelineConfig\n\n# This raises ValueError\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"my_templates.Invoice\",\n        backend=\"vlm\",\n        inference=\"remote\"  # \u274c VLM doesn't support remote\n    )\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n    # Output: VLM backend currently only supports local inference\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#common-validation-errors","title":"Common Validation Errors","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#error-1-vlm-remote-inference","title":"Error 1: VLM Remote Inference","text":"<pre><code># \u274c Wrong\nconfig = PipelineConfig(\n    backend=\"vlm\",\n    inference=\"remote\"\n)\n\n# \u2705 Correct\nconfig = PipelineConfig(\n    backend=\"vlm\",\n    inference=\"local\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#error-2-invalid-backend","title":"Error 2: Invalid Backend","text":"<pre><code># \u274c Wrong\nconfig = PipelineConfig(\n    backend=\"gpt\"  # Not a valid backend\n)\n\n# \u2705 Correct\nconfig = PipelineConfig(\n    backend=\"llm\"  # or \"vlm\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#error-3-invalid-processing-mode","title":"Error 3: Invalid Processing Mode","text":"<pre><code># \u274c Wrong\nconfig = PipelineConfig(\n    processing_mode=\"batch\"  # Not valid\n)\n\n# \u2705 Correct\nconfig = PipelineConfig(\n    processing_mode=\"many-to-one\"  # or \"one-to-one\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#default-values-reference","title":"Default Values Reference","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#all-defaults","title":"All Defaults","text":"<pre><code>PipelineConfig(\n    # Required (no defaults)\n    source=\"\",\n    template=\"\",\n\n    # Backend defaults\n    backend=\"llm\",\n    inference=\"local\",\n    model_override=None,\n    provider_override=None,\n\n    # Processing defaults\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n    llm_consolidation=False,\n    max_batch_size=1,\n\n    # Export defaults\n    export_format=\"csv\",\n    export_docling=True,\n    export_docling_json=True,\n    export_markdown=True,\n    export_per_page_markdown=False,\n\n    # Graph defaults\n    reverse_edges=False,\n\n    # Output defaults\n    output_dir=\"outputs\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#model-defaults","title":"Model Defaults","text":"<pre><code># LLM Local\ndefault_model=\"ibm-granite/granite-4.0-1b\"\nprovider=\"vllm\"\n\n# LLM Remote\ndefault_model=\"mistral-small-latest\"\nprovider=\"mistral\"\n\n# VLM Local\ndefault_model=\"numind/NuExtract-2.0-8B\"\nprovider=\"docling\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#common-configuration-patterns","title":"Common Configuration Patterns","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pattern-1-quick-local-test","title":"Pattern 1: Quick Local Test","text":"<pre><code># Minimal config for quick testing\nconfig = PipelineConfig(\n    source=\"test.pdf\",\n    template=\"my_templates.Invoice\"\n)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pattern-2-production-remote","title":"Pattern 2: Production Remote","text":"<pre><code># Production config with remote API\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\",\n    output_dir=\"production_outputs\"\n)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pattern-3-gpu-accelerated-local","title":"Pattern 3: GPU-Accelerated Local","text":"<pre><code># Local GPU extraction\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\",\n    provider_override=\"vllm\"\n)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pattern-4-vision-based-extraction","title":"Pattern 4: Vision-Based Extraction","text":"<pre><code># VLM extraction for complex layouts\nconfig = PipelineConfig(\n    source=\"complex_layout.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",\n    inference=\"local\",\n    docling_config=\"vision\"\n)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pattern-5-page-by-page-processing","title":"Pattern 5: Page-by-Page Processing","text":"<pre><code># Process each page separately\nconfig = PipelineConfig(\n    source=\"multi_page.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"one-to-one\",\n    export_per_page_markdown=True\n)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#configuration-inspection","title":"Configuration Inspection","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#view-configuration","title":"View Configuration","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\"\n)\n\n# Print configuration\nprint(f\"Backend: {config.backend}\")\nprint(f\"Inference: {config.inference}\")\nprint(f\"Processing mode: {config.processing_mode}\")\nprint(f\"Output dir: {config.output_dir}\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#convert-to-dictionary","title":"Convert to Dictionary","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\"\n)\n\n# Get as dictionary\nconfig_dict = config.to_dict()\nprint(config_dict)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#serialize-to-json","title":"Serialize to JSON","text":"<pre><code>import json\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\"\n)\n\n# Serialize\njson_str = config.model_dump_json(indent=2)\nprint(json_str)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#1-use-type-hints","title":"1. Use Type Hints","text":"<pre><code>from docling_graph import PipelineConfig\n\n# \u2705 Good - Type hints help catch errors\nconfig: PipelineConfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#2-validate-early","title":"2. Validate Early","text":"<pre><code># \u2705 Good - Create and validate before processing\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",\n    inference=\"local\"\n)\n\n# Verify settings\nassert config.backend == \"vlm\"\nassert config.inference == \"local\"\n\n# Then run\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#3-use-defaults","title":"3. Use Defaults","text":"<pre><code># \u2705 Good - Rely on sensible defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\"\n)\n\n# \u274c Bad - Over-specify defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",  # Already default\n    inference=\"local\",  # Already default\n    processing_mode=\"many-to-one\",  # Already default\n    use_chunking=True,  # Already default\n    # ... etc\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#4-document-custom-configs","title":"4. Document Custom Configs","text":"<pre><code># \u2705 Good - Document why you override defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    # Use remote API for better accuracy on complex documents\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    # Disable chunking for short documents\n    use_chunking=False\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#next-steps","title":"Next Steps","text":"<p>Now that you understand configuration basics:</p> <ol> <li>Backend Selection \u2192 - Choose between LLM and VLM</li> <li>Model Configuration - Configure models</li> <li>Configuration Examples - See complete scenarios</li> </ol>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#minimal-configuration","title":"Minimal Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.MyTemplate\"\n)\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#common-overrides","title":"Common Overrides","text":"<pre><code># Remote API\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.MyTemplate\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\"\n)\n\n# VLM extraction\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.MyTemplate\",\n    backend=\"vlm\"\n)\n\n# Page-by-page\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.MyTemplate\",\n    processing_mode=\"one-to-one\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/","title":"Complete Configuration Examples","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#overview","title":"Overview","text":"<p>This guide provides complete, real-world configuration examples for common use cases. Each example includes full configuration, expected outputs, and integration patterns.</p> <p>In this guide: - Production-ready configurations - Common use case patterns - Integration examples - Troubleshooting scenarios - Best practices</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#quick-navigation","title":"Quick Navigation","text":"Use Case Backend Inference Processing Local Development LLM Local Many-to-one Production API LLM Remote Many-to-one High Accuracy VLM Local One-to-one Batch Processing LLM Remote Many-to-one Research Papers LLM Remote Many-to-one Invoices LLM Local Many-to-one Forms VLM Local One-to-one Multi-language LLM Remote Many-to-one"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-1-local-development","title":"Example 1: Local Development","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case","title":"Use Case","text":"<p>Fast iteration during template development using local models.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    # Source and template\n    source=\"test_document.pdf\",\n    template=\"my_templates.Invoice\",\n\n    # Local LLM for fast iteration\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n\n    # Fast processing\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n\n    # CSV for easy inspection\n    export_format=\"csv\",\n    export_markdown=True,\n\n    # Development output\n    output_dir=\"dev_outputs\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#prerequisites","title":"Prerequisites","text":"<pre><code># Install Ollama\ncurl -fsSL https://ollama.com/install.sh | sh\n\n# Pull model\nollama pull llama3.1:8b\n\n# Verify\nollama list\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#expected-output","title":"Expected Output","text":"<pre><code>dev_outputs/\n\u251c\u2500\u2500 nodes.csv              # Easy to inspect in Excel\n\u251c\u2500\u2500 edges.csv\n\u251c\u2500\u2500 document.md            # Check markdown conversion\n\u251c\u2500\u2500 graph_stats.json       # Quick metrics\n\u2514\u2500\u2500 visualization.html     # Visual inspection\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use","title":"When to Use","text":"<p>\u2705 Use for: - Template development - Quick testing - Debugging extraction - Offline development</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-2-production-api","title":"Example 2: Production API","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_1","title":"Use Case","text":"<p>Production deployment using remote API for reliability and scale.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\nimport os\n\nconfig = PipelineConfig(\n    # Source and template\n    source=\"production_document.pdf\",\n    template=\"my_templates.Invoice\",\n\n    # Remote API for reliability\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n\n    # Robust processing\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n    llm_consolidation=True,  # Extra accuracy\n\n    # Cypher for Neo4j\n    export_format=\"cypher\",\n    export_docling=False,  # Minimal exports\n    export_markdown=False,\n\n    # Production output\n    output_dir=f\"production/{os.getenv('DOCUMENT_ID')}\"\n)\n\n# Set API key\nos.environ[\"MISTRAL_API_KEY\"] = \"your_api_key\"\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#environment-setup","title":"Environment Setup","text":"<pre><code># .env file\nMISTRAL_API_KEY=your_api_key_here\nDOCUMENT_ID=doc_12345\n\n# Load environment\nuv run python -c \"from dotenv import load_dotenv; load_dotenv()\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#expected-output_1","title":"Expected Output","text":"<pre><code>production/doc_12345/\n\u251c\u2500\u2500 graph.cypher           # Ready for Neo4j import\n\u251c\u2500\u2500 graph_data.json        # Backup\n\u251c\u2500\u2500 graph_stats.json       # Metrics\n\u2514\u2500\u2500 visualization.html     # QA check\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#integration","title":"Integration","text":"<pre><code># Import to Neo4j\nimport subprocess\n\ncypher_file = f\"production/{os.getenv('DOCUMENT_ID')}/graph.cypher\"\nsubprocess.run([\n    \"cypher-shell\",\n    \"-u\", \"neo4j\",\n    \"-p\", os.getenv(\"NEO4J_PASSWORD\"),\n    \"-f\", cypher_file\n])\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_1","title":"When to Use","text":"<p>\u2705 Use for: - Production deployments - High reliability needs - Scalable processing - API-based workflows</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-3-high-accuracy-extraction","title":"Example 3: High Accuracy Extraction","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_2","title":"Use Case","text":"<p>Maximum accuracy for complex documents using VLM.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_2","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    # Source and template\n    source=\"complex_document.pdf\",\n    template=\"my_templates.ResearchPaper\",\n\n    # VLM for visual understanding\n    backend=\"vlm\",\n    inference=\"local\",\n    model_override=\"numind/NuExtract-2.0-8B\",\n\n    # Page-by-page for accuracy\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\",  # Vision pipeline\n\n    # No chunking for VLM\n    use_chunking=False,\n\n    # CSV for analysis\n    export_format=\"csv\",\n    export_per_page_markdown=True,  # Debug per page\n\n    output_dir=\"high_accuracy_outputs\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#prerequisites_1","title":"Prerequisites","text":"<pre><code># GPU required\nnvidia-smi\n\n# Install with GPU support\nuv pip install \"docling-graph[gpu]\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#expected-output_2","title":"Expected Output","text":"<pre><code>high_accuracy_outputs/\n\u251c\u2500\u2500 nodes.csv\n\u251c\u2500\u2500 edges.csv\n\u251c\u2500\u2500 pages/\n\u2502   \u251c\u2500\u2500 page_001.md       # Per-page markdown\n\u2502   \u251c\u2500\u2500 page_002.md\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 visualization.html\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_2","title":"When to Use","text":"<p>\u2705 Use for: - Complex layouts - Visual elements - High accuracy needs - Research papers</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-4-batch-processing","title":"Example 4: Batch Processing","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_3","title":"Use Case","text":"<p>Process multiple documents efficiently.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_3","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\nfrom pathlib import Path\nimport logging\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef process_batch(input_dir: str, template: str):\n    \"\"\"Process all PDFs in a directory.\"\"\"\n\n    input_path = Path(input_dir)\n    results = []\n\n    for pdf_file in input_path.glob(\"*.pdf\"):\n        logger.info(f\"Processing {pdf_file.name}\")\n\n        try:\n            config = PipelineConfig(\n                source=str(pdf_file),\n                template=template,\n\n                # Remote for reliability\n                backend=\"llm\",\n                inference=\"remote\",\n                provider_override=\"mistral\",\n\n                # Efficient processing\n                processing_mode=\"many-to-one\",\n                use_chunking=True,\n\n                # Organized outputs\n                output_dir=f\"batch_outputs/{pdf_file.stem}\",\n                export_format=\"csv\"\n            )\n\n            config.run()\n            results.append({\"file\": pdf_file.name, \"status\": \"success\"})\n\n        except Exception as e:\n            logger.error(f\"Failed to process {pdf_file.name}: {e}\")\n            results.append({\"file\": pdf_file.name, \"status\": \"failed\", \"error\": str(e)})\n\n    return results\n\n# Process batch\nresults = process_batch(\"documents/invoices\", \"my_templates.Invoice\")\n\n# Summary\nsuccess_count = sum(1 for r in results if r[\"status\"] == \"success\")\nprint(f\"Processed {success_count}/{len(results)} documents successfully\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#expected-output_3","title":"Expected Output","text":"<pre><code>batch_outputs/\n\u251c\u2500\u2500 invoice_001/\n\u2502   \u251c\u2500\u2500 nodes.csv\n\u2502   \u2514\u2500\u2500 edges.csv\n\u251c\u2500\u2500 invoice_002/\n\u2502   \u251c\u2500\u2500 nodes.csv\n\u2502   \u2514\u2500\u2500 edges.csv\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_3","title":"When to Use","text":"<p>\u2705 Use for: - Multiple documents - Automated workflows - Scheduled processing - Data pipelines</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-5-research-papers","title":"Example 5: Research Papers","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_4","title":"Use Case","text":"<p>Extract structured data from academic papers.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_4","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    # Research paper\n    source=\"research_paper.pdf\",\n    template=\"my_templates.ResearchPaper\",\n\n    # Remote LLM for understanding\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",\n\n    # Full document context\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n    llm_consolidation=True,  # Merge findings\n\n    # CSV for analysis\n    export_format=\"csv\",\n    export_markdown=True,\n\n    output_dir=\"research_outputs\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#template-example","title":"Template Example","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import List\n\nclass Author(BaseModel):\n    \"\"\"Research paper author.\"\"\"\n    name: str\n    affiliation: str | None = None\n    email: str | None = None\n\nclass Citation(BaseModel):\n    \"\"\"Paper citation.\"\"\"\n    title: str\n    authors: str\n    year: int | None = None\n\nclass ResearchPaper(BaseModel):\n    \"\"\"Research paper extraction template.\"\"\"\n\n    title: str = Field(description=\"Paper title\")\n    authors: List[Author] = Field(description=\"Paper authors\")\n    abstract: str = Field(description=\"Paper abstract\")\n\n    keywords: List[str] = Field(description=\"Paper keywords\")\n    methodology: str = Field(description=\"Research methodology\")\n    findings: List[str] = Field(description=\"Key findings\")\n\n    citations: List[Citation] = Field(description=\"Referenced papers\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_4","title":"When to Use","text":"<p>\u2705 Use for: - Academic papers - Literature reviews - Citation extraction - Research analysis</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-6-invoice-processing","title":"Example 6: Invoice Processing","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_5","title":"Use Case","text":"<p>Extract invoice data for accounting systems.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_5","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    # Invoice document\n    source=\"invoice.pdf\",\n    template=\"my_templates.Invoice\",\n\n    # Local for cost efficiency\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n\n    # Fast processing\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n\n    # CSV for accounting software\n    export_format=\"csv\",\n\n    output_dir=\"invoices/processed\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#template-example_1","title":"Template Example","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import List\nfrom datetime import date\n\nclass LineItem(BaseModel):\n    \"\"\"Invoice line item.\"\"\"\n    description: str\n    quantity: float\n    unit_price: float\n    total: float\n\nclass Address(BaseModel):\n    \"\"\"Address information.\"\"\"\n    street: str\n    city: str\n    postal_code: str\n    country: str\n\nclass Organization(BaseModel):\n    \"\"\"Organization details.\"\"\"\n    name: str\n    address: Address\n    tax_id: str | None = None\n\nclass Invoice(BaseModel):\n    \"\"\"Invoice extraction template.\"\"\"\n\n    invoice_number: str = Field(description=\"Invoice number\")\n    invoice_date: date = Field(description=\"Invoice date\")\n    due_date: date | None = Field(description=\"Payment due date\")\n\n    issued_by: Organization = Field(description=\"Issuing organization\")\n    sent_to: Organization = Field(description=\"Recipient organization\")\n\n    line_items: List[LineItem] = Field(description=\"Invoice line items\")\n\n    subtotal: float = Field(description=\"Subtotal amount\")\n    tax: float = Field(description=\"Tax amount\")\n    total: float = Field(description=\"Total amount\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#integration-with-accounting","title":"Integration with Accounting","text":"<pre><code>import pandas as pd\n\n# Load extracted data\nnodes = pd.read_csv(\"invoices/processed/nodes.csv\")\n\n# Filter invoices\ninvoices = nodes[nodes['node_type'] == 'Invoice']\n\n# Export to accounting system\ninvoices.to_csv(\"accounting_import.csv\", index=False)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_5","title":"When to Use","text":"<p>\u2705 Use for: - Invoice processing - Accounting automation - Financial data extraction - ERP integration</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-7-form-extraction","title":"Example 7: Form Extraction","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_6","title":"Use Case","text":"<p>Extract data from structured forms using VLM.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_6","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    # Form document\n    source=\"application_form.pdf\",\n    template=\"my_templates.ApplicationForm\",\n\n    # VLM for form structure\n    backend=\"vlm\",\n    inference=\"local\",\n\n    # Page-by-page for forms\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\",\n    use_chunking=False,\n\n    # CSV for database import\n    export_format=\"csv\",\n\n    output_dir=\"forms/processed\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#template-example_2","title":"Template Example","text":"<pre><code>from pydantic import BaseModel, Field, EmailStr\nfrom datetime import date\n\nclass Applicant(BaseModel):\n    \"\"\"Applicant information.\"\"\"\n    first_name: str\n    last_name: str\n    email: EmailStr\n    phone: str\n    date_of_birth: date\n\nclass Address(BaseModel):\n    \"\"\"Address information.\"\"\"\n    street: str\n    city: str\n    state: str\n    zip_code: str\n\nclass ApplicationForm(BaseModel):\n    \"\"\"Application form template.\"\"\"\n\n    application_id: str = Field(description=\"Application ID\")\n    submission_date: date = Field(description=\"Submission date\")\n\n    applicant: Applicant = Field(description=\"Applicant details\")\n    address: Address = Field(description=\"Applicant address\")\n\n    employment_status: str = Field(description=\"Employment status\")\n    annual_income: float | None = Field(description=\"Annual income\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_6","title":"When to Use","text":"<p>\u2705 Use for: - Application forms - Registration forms - Survey responses - Structured documents</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-8-multi-language-documents","title":"Example 8: Multi-language Documents","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_7","title":"Use Case","text":"<p>Process documents in multiple languages.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_7","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    # Multi-language document\n    source=\"multilingual_document.pdf\",\n    template=\"my_templates.Contract\",\n\n    # Remote LLM with multi-language support\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",  # Good multi-language support\n\n    # Full document context\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n\n    # CSV export\n    export_format=\"csv\",\n\n    output_dir=\"multilingual_outputs\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_7","title":"When to Use","text":"<p>\u2705 Use for: - International documents - Multi-language contracts - Global operations - Translation workflows</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#pattern-1-error-handling","title":"Pattern 1: Error Handling","text":"<pre><code>from docling_graph import PipelineConfig\nfrom docling_graph.exceptions import PipelineError, ExtractionError\nimport logging\n\nlogger = logging.getLogger(__name__)\n\ndef safe_process(source: str, template: str) -&gt; bool:\n    \"\"\"Process document with error handling.\"\"\"\n\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=template,\n            backend=\"llm\",\n            inference=\"remote\"\n        )\n\n        config.run()\n        logger.info(f\"Successfully processed {source}\")\n        return True\n\n    except ExtractionError as e:\n        logger.error(f\"Extraction failed for {source}: {e}\")\n        return False\n\n    except PipelineError as e:\n        logger.error(f\"Pipeline error for {source}: {e}\")\n        return False\n\n    except Exception as e:\n        logger.error(f\"Unexpected error for {source}: {e}\")\n        return False\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#pattern-2-configuration-validation","title":"Pattern 2: Configuration Validation","text":"<pre><code>from docling_graph import PipelineConfig\nfrom pydantic import ValidationError\n\ndef validate_config(config_dict: dict) -&gt; bool:\n    \"\"\"Validate configuration before running.\"\"\"\n\n    try:\n        config = PipelineConfig(**config_dict)\n        print(\"\u2713 Configuration valid\")\n        return True\n\n    except ValidationError as e:\n        print(f\"\u2717 Configuration invalid:\")\n        for error in e.errors():\n            print(f\"  - {error['loc']}: {error['msg']}\")\n        return False\n\n# Test configuration\nconfig_dict = {\n    \"source\": \"document.pdf\",\n    \"template\": \"my_templates.Invoice\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\"\n}\n\nif validate_config(config_dict):\n    config = PipelineConfig(**config_dict)\n    config.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#pattern-3-dynamic-configuration","title":"Pattern 3: Dynamic Configuration","text":"<pre><code>from docling_graph import PipelineConfig\nimport os\n\ndef get_config_for_document(doc_path: str) -&gt; PipelineConfig:\n    \"\"\"Generate configuration based on document type.\"\"\"\n\n    # Determine document type\n    if \"invoice\" in doc_path.lower():\n        template = \"my_templates.Invoice\"\n        processing_mode = \"many-to-one\"\n\n    elif \"form\" in doc_path.lower():\n        template = \"my_templates.Form\"\n        processing_mode = \"one-to-one\"\n\n    else:\n        template = \"my_templates.Generic\"\n        processing_mode = \"many-to-one\"\n\n    # Choose backend based on environment\n    if os.getenv(\"USE_GPU\") == \"true\":\n        backend = \"vlm\"\n        inference = \"local\"\n    else:\n        backend = \"llm\"\n        inference = \"remote\"\n\n    return PipelineConfig(\n        source=doc_path,\n        template=template,\n        backend=backend,\n        inference=inference,\n        processing_mode=processing_mode\n    )\n\n# Use dynamic configuration\nconfig = get_config_for_document(\"documents/invoice_001.pdf\")\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#best-practices-summary","title":"Best Practices Summary","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#1-choose-the-right-backend","title":"1. Choose the Right Backend","text":"<pre><code># \u2705 Good - Match backend to use case\nif document_has_complex_layout:\n    backend = \"vlm\"\nelif need_fast_iteration:\n    backend = \"llm\"\n    inference = \"local\"\nelse:\n    backend = \"llm\"\n    inference = \"remote\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#2-organize-outputs","title":"2. Organize Outputs","text":"<pre><code># \u2705 Good - Structured output directories\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\noutput_dir = f\"outputs/{document_type}/{timestamp}\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#3-handle-errors-gracefully","title":"3. Handle Errors Gracefully","text":"<pre><code># \u2705 Good - Comprehensive error handling\ntry:\n    config.run()\nexcept ExtractionError:\n    # Handle extraction failures\n    pass\nexcept PipelineError:\n    # Handle pipeline failures\n    pass\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#4-validate-before-running","title":"4. Validate Before Running","text":"<pre><code># \u2705 Good - Validate configuration\ntry:\n    config = PipelineConfig(**config_dict)\nexcept ValidationError as e:\n    print(f\"Invalid configuration: {e}\")\n    exit(1)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#issue-configuration-validation-fails","title":"Issue: Configuration Validation Fails","text":"<p>Solution: <pre><code>from pydantic import ValidationError\n\ntry:\n    config = PipelineConfig(**config_dict)\nexcept ValidationError as e:\n    print(\"Configuration errors:\")\n    for error in e.errors():\n        print(f\"  {error['loc']}: {error['msg']}\")\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#issue-extraction-produces-no-results","title":"Issue: Extraction Produces No Results","text":"<p>Solution: <pre><code># Check extraction output\nimport json\n\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nif stats[\"node_count\"] == 0:\n    print(\"No nodes extracted - check template and document\")\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#issue-out-of-memory","title":"Issue: Out of Memory","text":"<p>Solution: <pre><code># Use chunking and smaller batch sizes\nconfig = PipelineConfig(\n    source=\"large_document.pdf\",\n    template=\"my_templates.Invoice\",\n    use_chunking=True,  # Enable chunking\n    max_batch_size=1,   # Smaller batches\n    backend=\"llm\",\n    inference=\"remote\"  # Use remote to save memory\n)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#next-steps","title":"Next Steps","text":"<p>Now that you understand complete configurations:</p> <ol> <li>Extraction Process \u2192 - Learn how extraction works</li> <li>Graph Management - Work with extracted graphs</li> <li>CLI Guide - Use command-line interface</li> </ol>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#local-development","title":"Local Development","text":"<pre><code>PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#production-api","title":"Production API","text":"<pre><code>PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    llm_consolidation=True\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#high-accuracy","title":"High Accuracy","text":"<pre><code>PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",\n    inference=\"local\",\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/","title":"Docling Settings","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#overview","title":"Overview","text":"<p>Docling settings control how documents are converted before extraction. Docling Graph uses the Docling library to convert PDFs and images into structured formats (markdown or JSON) that can be processed by LLMs or VLMs.</p> <p>In this guide: - OCR vs Vision pipeline - Export options - Pipeline selection - Performance considerations - Troubleshooting</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#docling-pipeline-types","title":"Docling Pipeline Types","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#quick-comparison","title":"Quick Comparison","text":"Aspect OCR Pipeline Vision Pipeline Method Traditional OCR Vision-Language Model Speed Fast Slower Accuracy Good for standard docs Best for complex layouts GPU Required No Yes Best For Text-heavy documents Complex visual layouts Default Yes No"},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-pipeline","title":"OCR Pipeline","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#what-is-ocr-pipeline","title":"What is OCR Pipeline?","text":"<p>The OCR pipeline uses traditional Optical Character Recognition to extract text from documents. It's fast, accurate for standard documents, and doesn't require a GPU.</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"ocr\"  # OCR pipeline (default)\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#how-it-works","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Image / PDF Document\" }\n\n    B@{ shape: procs, label: \"OCR Engine\" }\n    C@{ shape: lin-proc, label: \"Text Extraction\" }\n    D@{ shape: lin-proc, label: \"Layout Analysis\" }\n\n    E@{ shape: doc, label: \"Markdown\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D process\n    class E output</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#when-to-use-ocr","title":"When to Use OCR","text":"<p>\u2705 Use OCR when: - Documents are text-heavy - Layout is standard (invoices, contracts, reports) - Speed is important - GPU is not available - Documents are high-quality scans - Cost efficiency is a priority</p> <p>\u274c Don't use OCR when: - Documents have complex visual layouts - Tables have intricate structures - Handwriting needs processing - Images contain critical information - Document quality is poor</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-advantages","title":"OCR Advantages","text":"<ol> <li>Fast Processing</li> <li>Quick text extraction</li> <li>No GPU required</li> <li> <p>Efficient for batch processing</p> </li> <li> <p>Good Accuracy</p> </li> <li>Excellent for standard documents</li> <li>Reliable text extraction</li> <li> <p>Handles most layouts well</p> </li> <li> <p>Low Resource Usage</p> </li> <li>CPU-only processing</li> <li>Lower memory requirements</li> <li>No special hardware needed</li> </ol>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-limitations","title":"OCR Limitations","text":"<ol> <li>Layout Challenges</li> <li>May struggle with complex tables</li> <li>Can miss visual relationships</li> <li> <p>Limited understanding of structure</p> </li> <li> <p>Quality Dependent</p> </li> <li>Poor scans reduce accuracy</li> <li>Handwriting not well supported</li> <li>Image quality matters</li> </ol>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#vision-pipeline","title":"Vision Pipeline","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#what-is-vision-pipeline","title":"What is Vision Pipeline?","text":"<p>The Vision pipeline uses Vision-Language Models (VLMs) to understand documents visually. It processes layout, structure, and visual relationships alongside text.</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"vision\"  # Vision pipeline\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#how-it-works_1","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Images / PDF Document\" }\n\n    B@{ shape: doc, label: \"Page Images\" }\n    C@{ shape: procs, label: \"VLM Processing\" }\n    D@{ shape: lin-proc, label: \"Visual Understanding\" }\n\n    E@{ shape: doc, label: \"Structured Output\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B data\n    class C,D process\n    class E output</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#when-to-use-vision","title":"When to Use Vision","text":"<p>\u2705 Use Vision when: - Documents have complex layouts - Tables have intricate structures - Visual relationships are important - Forms have specific patterns - Highest accuracy is required - GPU is available</p> <p>\u274c Don't use Vision when: - Documents are simple text - Speed is critical - GPU is not available - Cost is a major concern - Processing large batches</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#vision-advantages","title":"Vision Advantages","text":"<ol> <li>Visual Understanding</li> <li>Processes layout and structure</li> <li>Understands visual relationships</li> <li>Handles complex tables</li> <li> <p>Better with forms</p> </li> <li> <p>Higher Accuracy</p> </li> <li>Best for complex documents</li> <li>Understands context visually</li> <li>Fewer extraction errors</li> <li> <p>Better table handling</p> </li> <li> <p>Robust to Quality</p> </li> <li>Handles poor scans better</li> <li>Works with handwriting</li> <li>Processes images directly</li> </ol>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#vision-limitations","title":"Vision Limitations","text":"<ol> <li>Resource Intensive</li> <li>Requires GPU</li> <li>Higher memory usage</li> <li>Slower processing</li> <li> <p>More expensive hardware</p> </li> <li> <p>Setup Complexity</p> </li> <li>GPU drivers required</li> <li>Model downloads needed</li> <li>More configuration</li> </ol>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#export-options","title":"Export Options","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#docling-document-export","title":"Docling Document Export","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n\n    # Docling export settings\n    export_docling=True,  # Export Docling document (default)\n    export_docling_json=True,  # Export as JSON (default)\n    export_markdown=True,  # Export as markdown (default)\n    export_per_page_markdown=False  # Export per-page markdown\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#export-options-explained","title":"Export Options Explained","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#1-export_docling","title":"1. export_docling","text":"<p>Controls whether to export the Docling document object.</p> <pre><code>export_docling=True  # Default\n</code></pre> <p>Output: <code>outputs/docling_document.pkl</code> (Python pickle)</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#2-export_docling_json","title":"2. export_docling_json","text":"<p>Exports the full Docling document structure as JSON.</p> <pre><code>export_docling_json=True  # Default\n</code></pre> <p>Output: <code>outputs/docling_document.json</code></p> <p>Contains: - Document metadata - Layout information - Tables and figures - Text content - Page structure</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#3-export_markdown","title":"3. export_markdown","text":"<p>Exports the document as markdown (full document).</p> <pre><code>export_markdown=True  # Default\n</code></pre> <p>Output: <code>outputs/document.md</code></p> <p>Best for: - Human-readable output - Documentation - Text analysis - Debugging</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#4-export_per_page_markdown","title":"4. export_per_page_markdown","text":"<p>Exports markdown for each page separately.</p> <pre><code>export_per_page_markdown=False  # Default\n</code></pre> <p>Output: <code>outputs/pages/page_001.md</code>, <code>page_002.md</code>, etc.</p> <p>Best for: - Page-by-page analysis - One-to-one processing - Page-level debugging</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#complete-configuration-examples","title":"Complete Configuration Examples","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#example-1-ocr-with-full-exports","title":"Example 1: OCR with Full Exports","text":"<pre><code>config = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"my_templates.Invoice\",\n\n    # OCR pipeline\n    docling_config=\"ocr\",\n\n    # Export everything\n    export_docling=True,\n    export_docling_json=True,\n    export_markdown=True,\n    export_per_page_markdown=True\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#example-2-vision-with-minimal-exports","title":"Example 2: Vision with Minimal Exports","text":"<pre><code>config = PipelineConfig(\n    source=\"complex_form.pdf\",\n    template=\"my_templates.Form\",\n\n    # Vision pipeline\n    docling_config=\"vision\",\n\n    # Minimal exports (save space)\n    export_docling=False,\n    export_docling_json=False,\n    export_markdown=False,\n    export_per_page_markdown=False\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#example-3-ocr-with-page-level-exports","title":"Example 3: OCR with Page-Level Exports","text":"<pre><code>config = PipelineConfig(\n    source=\"batch_invoices.pdf\",\n    template=\"my_templates.Invoice\",\n\n    # OCR pipeline\n    docling_config=\"ocr\",\n\n    # Page-level exports for one-to-one processing\n    processing_mode=\"one-to-one\",\n    export_per_page_markdown=True,\n    export_markdown=False  # Don't need full document\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#pipeline-selection-strategy","title":"Pipeline Selection Strategy","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#by-document-type","title":"By Document Type","text":"Document Type Recommended Pipeline Reason Invoices OCR Standard layout, text-heavy Contracts OCR Text-heavy, standard format Research Papers OCR Text-heavy, standard layout Forms Vision Visual structure important ID Cards Vision Visual layout critical Complex Tables Vision Visual structure needed Handwritten Vision Visual processing required Mixed Content Vision Images and text combined"},{"location":"fundamentals/pipeline-configuration/docling-settings/#by-quality","title":"By Quality","text":"<pre><code>def get_docling_config(scan_quality: str):\n    \"\"\"Choose pipeline based on scan quality.\"\"\"\n    if scan_quality == \"high\":\n        return \"ocr\"  # OCR works well\n    elif scan_quality == \"medium\":\n        return \"ocr\"  # OCR still acceptable\n    else:\n        return \"vision\"  # Vision better for poor quality\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#by-infrastructure","title":"By Infrastructure","text":"<pre><code>def get_docling_config(has_gpu: bool):\n    \"\"\"Choose pipeline based on available hardware.\"\"\"\n    if has_gpu:\n        return \"vision\"  # Can use vision\n    else:\n        return \"ocr\"  # Must use OCR\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#performance-comparison","title":"Performance Comparison","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#processing-speed","title":"Processing Speed","text":"<pre><code>Document: 10-page invoice PDF\n\nOCR Pipeline:         ~10 seconds\nVision Pipeline:      ~60 seconds\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#accuracy-comparison","title":"Accuracy Comparison","text":"<pre><code>Document Type: Complex invoice with tables\n\nOCR Accuracy:   92% field extraction\nVision Accuracy: 97% field extraction\n\nDocument Type: Simple text contract\n\nOCR Accuracy:   98% field extraction\nVision Accuracy: 96% field extraction\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#resource-usage","title":"Resource Usage","text":"<pre><code>OCR Pipeline:\n- CPU: 50-70%\n- Memory: 2-4GB\n- GPU: Not required\n\nVision Pipeline:\n- CPU: 30-40%\n- Memory: 6-8GB\n- GPU: Required (4-8GB VRAM)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#combining-with-backend-settings","title":"Combining with Backend Settings","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-llm-backend","title":"OCR + LLM Backend","text":"<pre><code># Most common combination\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n\n    # OCR for conversion\n    docling_config=\"ocr\",\n\n    # LLM for extraction\n    backend=\"llm\",\n    inference=\"remote\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#vision-vlm-backend","title":"Vision + VLM Backend","text":"<pre><code># Highest accuracy combination\nconfig = PipelineConfig(\n    source=\"complex_document.pdf\",\n    template=\"my_templates.Form\",\n\n    # Vision for conversion\n    docling_config=\"vision\",\n\n    # VLM for extraction\n    backend=\"vlm\",\n    inference=\"local\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-vlm-backend","title":"OCR + VLM Backend","text":"<pre><code># Mixed approach (less common)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n\n    # OCR for conversion (faster)\n    docling_config=\"ocr\",\n\n    # VLM for extraction (higher accuracy)\n    backend=\"vlm\",\n    inference=\"local\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#issue-poor-ocr-quality","title":"Issue: Poor OCR Quality","text":"<p>Symptoms: Missing text, garbled characters</p> <p>Solutions: <pre><code># 1. Try vision pipeline\nconfig = PipelineConfig(\n    source=\"poor_scan.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"vision\"  # Better for poor quality\n)\n\n# 2. Pre-process document (external tool)\n# - Increase resolution\n# - Enhance contrast\n# - Deskew pages\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#issue-vision-pipeline-too-slow","title":"Issue: Vision Pipeline Too Slow","text":"<p>Symptoms: Long processing times</p> <p>Solutions: <pre><code># 1. Use OCR if acceptable\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"ocr\"  # Faster\n)\n\n# 2. Process fewer pages\n# 3. Use more powerful GPU\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#issue-missing-tables","title":"Issue: Missing Tables","text":"<p>Symptoms: Table data not extracted</p> <p>Solutions: <pre><code># Use vision pipeline for better table handling\nconfig = PipelineConfig(\n    source=\"document_with_tables.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"vision\"  # Better table extraction\n)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#1-start-with-ocr","title":"1. Start with OCR","text":"<pre><code># \u2705 Good - Start with faster option\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"ocr\"  # Try OCR first\n)\n\n# If accuracy insufficient, switch to vision\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#2-match-pipeline-to-document","title":"2. Match Pipeline to Document","text":"<pre><code># \u2705 Good - Choose based on document type\nif document_has_complex_layout:\n    docling_config = \"vision\"\nelse:\n    docling_config = \"ocr\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=docling_config\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#3-enable-appropriate-exports","title":"3. Enable Appropriate Exports","text":"<pre><code># \u2705 Good - Export what you need\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"ocr\",\n\n    # Enable useful exports\n    export_markdown=True,  # For debugging\n    export_docling_json=False,  # Don't need full structure\n    export_per_page_markdown=False  # Not doing page-level\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#next-steps","title":"Next Steps","text":"<p>Now that you understand Docling settings:</p> <ol> <li>Export Configuration \u2192 - Configure output formats</li> <li>Configuration Examples - Complete scenarios</li> <li>Model Configuration - Model settings</li> </ol>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-pipeline-default","title":"OCR Pipeline (Default)","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"ocr\"\n)\n</code></pre> <p>Best for: Standard documents, speed, no GPU</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#vision-pipeline_1","title":"Vision Pipeline","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    docling_config=\"vision\"\n)\n</code></pre> <p>Best for: Complex layouts, highest accuracy, GPU available</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#export-settings","title":"Export Settings","text":"<pre><code>export_docling=True           # Export Docling document\nexport_docling_json=True      # Export as JSON\nexport_markdown=True          # Export as markdown\nexport_per_page_markdown=False # Export per-page markdown\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/","title":"Export Configuration","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#overview","title":"Overview","text":"<p>Export configuration controls how Docling Graph outputs extracted data and knowledge graphs. Multiple export formats are supported, allowing you to integrate with various downstream tools and databases.</p> <p>In this guide: - Export formats (CSV, Cypher, JSON) - Output directory structure - Format-specific options - Export best practices - Integration scenarios</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#export-formats","title":"Export Formats","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#quick-comparison","title":"Quick Comparison","text":"Format Best For File Type Use Case CSV Analysis, spreadsheets <code>.csv</code> Data analysis, Excel Cypher Neo4j import <code>.cypher</code> Graph database import JSON APIs, processing <code>.json</code> Programmatic access"},{"location":"fundamentals/pipeline-configuration/export-configuration/#csv-export","title":"CSV Export","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#what-is-csv-export","title":"What is CSV Export?","text":"<p>CSV export creates separate CSV files for nodes and edges, making it easy to analyze data in spreadsheets or import into databases.</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\"  # CSV export (default)\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#output-structure","title":"Output Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 nodes.csv          # All nodes\n\u251c\u2500\u2500 edges.csv          # All edges\n\u251c\u2500\u2500 graph_stats.json   # Graph statistics\n\u2514\u2500\u2500 visualization.html # Interactive visualization\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#csv-files-format","title":"CSV Files Format","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#nodescsv","title":"nodes.csv","text":"<pre><code>node_id,node_type,properties\ninvoice_001,Invoice,\"{\"\"invoice_number\"\": \"\"INV-001\"\", \"\"total\"\": 1000}\"\norg_acme,Organization,\"{\"\"name\"\": \"\"Acme Corp\"\"}\"\naddr_123,Address,\"{\"\"street\"\": \"\"123 Main St\"\", \"\"city\"\": \"\"Paris\"\"}\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#edgescsv","title":"edges.csv","text":"<pre><code>source_id,edge_type,target_id\ninvoice_001,ISSUED_BY,org_acme\norg_acme,LOCATED_AT,addr_123\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#when-to-use-csv","title":"When to Use CSV","text":"<p>\u2705 Use CSV when: - Analyzing data in Excel/spreadsheets - Importing into SQL databases - Need human-readable format - Performing data analysis - Creating reports</p> <p>\u274c Don't use CSV when: - Need direct Neo4j import - Want programmatic access - Require nested structures - Need type preservation</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#cypher-export","title":"Cypher Export","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#what-is-cypher-export","title":"What is Cypher Export?","text":"<p>Cypher export creates Cypher statements for direct import into Neo4j graph databases.</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"cypher\"  # Cypher export\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#output-structure_1","title":"Output Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 graph.cypher       # Cypher statements\n\u251c\u2500\u2500 graph_stats.json   # Graph statistics\n\u2514\u2500\u2500 visualization.html # Interactive visualization\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#cypher-file-format","title":"Cypher File Format","text":"<pre><code>// Create nodes\nCREATE (:Invoice {invoice_number: \"INV-001\", total: 1000, node_id: \"invoice_001\"})\nCREATE (:Organization {name: \"Acme Corp\", node_id: \"org_acme\"})\nCREATE (:Address {street: \"123 Main St\", city: \"Paris\", node_id: \"addr_123\"})\n\n// Create relationships\nMATCH (a {node_id: \"invoice_001\"}), (b {node_id: \"org_acme\"})\nCREATE (a)-[:ISSUED_BY]-&gt;(b)\n\nMATCH (a {node_id: \"org_acme\"}), (b {node_id: \"addr_123\"})\nCREATE (a)-[:LOCATED_AT]-&gt;(b)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#when-to-use-cypher","title":"When to Use Cypher","text":"<p>\u2705 Use Cypher when: - Importing into Neo4j - Building graph databases - Need graph queries - Want graph visualization - Performing graph analytics</p> <p>\u274c Don't use Cypher when: - Not using Neo4j - Need tabular format - Want simple data analysis - Require Excel compatibility</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#neo4j-import","title":"Neo4j Import","text":"<pre><code># Import into Neo4j\ncat outputs/graph.cypher | cypher-shell -u neo4j -p password\n\n# Or use Neo4j Browser\n# 1. Open Neo4j Browser\n# 2. Copy contents of graph.cypher\n# 3. Paste and execute\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#json-export","title":"JSON Export","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#what-is-json-export","title":"What is JSON Export?","text":"<p>JSON export is always generated alongside CSV or Cypher, providing structured data for programmatic access.</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#output-structure_2","title":"Output Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 extracted_data.json  # Extracted Pydantic models\n\u251c\u2500\u2500 graph_data.json      # Graph structure\n\u251c\u2500\u2500 graph_stats.json     # Graph statistics\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#json-files-format","title":"JSON Files Format","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#extracted_datajson","title":"extracted_data.json","text":"<pre><code>{\n  \"models\": [\n    {\n      \"invoice_number\": \"INV-001\",\n      \"total\": 1000,\n      \"issued_by\": {\n        \"name\": \"Acme Corp\",\n        \"located_at\": {\n          \"street\": \"123 Main St\",\n          \"city\": \"Paris\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#graph_datajson","title":"graph_data.json","text":"<pre><code>{\n  \"nodes\": [\n    {\n      \"id\": \"invoice_001\",\n      \"type\": \"Invoice\",\n      \"properties\": {\n        \"invoice_number\": \"INV-001\",\n        \"total\": 1000\n      }\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"invoice_001\",\n      \"type\": \"ISSUED_BY\",\n      \"target\": \"org_acme\"\n    }\n  ]\n}\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#when-to-use-json","title":"When to Use JSON","text":"<p>\u2705 Use JSON when: - Building APIs - Programmatic processing - Need nested structures - Want type preservation - Integrating with applications</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#output-directory-structure","title":"Output Directory Structure","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#default-structure","title":"Default Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 extracted_data.json      # Pydantic models\n\u251c\u2500\u2500 graph_data.json          # Graph structure\n\u251c\u2500\u2500 graph_stats.json         # Statistics\n\u251c\u2500\u2500 nodes.csv                # Nodes (CSV format)\n\u251c\u2500\u2500 edges.csv                # Edges (CSV format)\n\u251c\u2500\u2500 graph.cypher             # Cypher (Cypher format)\n\u251c\u2500\u2500 visualization.html       # Interactive viz\n\u251c\u2500\u2500 report.md                # Markdown report\n\u251c\u2500\u2500 docling_document.json    # Docling output\n\u251c\u2500\u2500 document.md              # Markdown export\n\u2514\u2500\u2500 pages/                   # Per-page exports\n    \u251c\u2500\u2500 page_001.md\n    \u251c\u2500\u2500 page_002.md\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#custom-output-directory","title":"Custom Output Directory","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    output_dir=\"my_results/invoice_001\"  # Custom directory\n)\n</code></pre> <p>Output: <code>my_results/invoice_001/nodes.csv</code>, etc.</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#complete-configuration-examples","title":"Complete Configuration Examples","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#example-1-csv-export-with-full-outputs","title":"Example 1: CSV Export with Full Outputs","text":"<pre><code>config = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"my_templates.Invoice\",\n\n    # CSV export\n    export_format=\"csv\",\n\n    # Enable all exports\n    export_docling=True,\n    export_docling_json=True,\n    export_markdown=True,\n\n    # Custom output directory\n    output_dir=\"results/invoice_001\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#example-2-cypher-export-for-neo4j","title":"Example 2: Cypher Export for Neo4j","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n\n    # Cypher export for Neo4j\n    export_format=\"cypher\",\n\n    # Minimal other exports\n    export_docling=False,\n    export_markdown=False,\n\n    output_dir=\"neo4j_import\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#example-3-batch-processing-with-organized-outputs","title":"Example 3: Batch Processing with Organized Outputs","text":"<pre><code>import os\nfrom pathlib import Path\n\nfor doc_path in Path(\"documents\").glob(\"*.pdf\"):\n    # Create output directory per document\n    output_dir = f\"results/{doc_path.stem}\"\n\n    config = PipelineConfig(\n        source=str(doc_path),\n        template=\"my_templates.Invoice\",\n        export_format=\"csv\",\n        output_dir=output_dir\n    )\n\n    config.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#graph-statistics","title":"Graph Statistics","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#graph_statsjson","title":"graph_stats.json","text":"<p>Always generated, contains graph metrics:</p> <pre><code>{\n  \"node_count\": 15,\n  \"edge_count\": 18,\n  \"node_types\": {\n    \"Invoice\": 1,\n    \"Organization\": 2,\n    \"Address\": 3,\n    \"LineItem\": 9\n  },\n  \"edge_types\": {\n    \"ISSUED_BY\": 1,\n    \"SENT_TO\": 1,\n    \"LOCATED_AT\": 5,\n    \"CONTAINS_ITEM\": 9,\n    \"HAS_TOTAL\": 2\n  },\n  \"avg_degree\": 2.4,\n  \"density\": 0.17\n}\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#using-statistics","title":"Using Statistics","text":"<pre><code>import json\n\n# Load statistics\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nprint(f\"Nodes: {stats['node_count']}\")\nprint(f\"Edges: {stats['edge_count']}\")\nprint(f\"Node types: {stats['node_types']}\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#visualization","title":"Visualization","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#interactive-html-visualization","title":"Interactive HTML Visualization","text":"<p>Always generated: <code>outputs/visualization.html</code></p> <p>Features: - Interactive graph visualization - Node and edge inspection - Zoom and pan - Search functionality - Export to image</p> <p>Open in browser: <pre><code># Open visualization\nopen outputs/visualization.html  # macOS\nxdg-open outputs/visualization.html  # Linux\nstart outputs/visualization.html  # Windows\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#markdown-report","title":"Markdown Report","text":"<p>Always generated: <code>outputs/report.md</code></p> <p>Contains: - Extraction summary - Graph statistics - Node and edge counts - Processing time - Configuration used</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#export-format-selection","title":"Export Format Selection","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#by-use-case","title":"By Use Case","text":"Use Case Recommended Format Reason Data Analysis CSV Excel/spreadsheet compatible Graph Database Cypher Direct Neo4j import API Integration JSON Programmatic access Reporting CSV + Markdown Human-readable Machine Learning JSON Structured data Visualization Any HTML viz always generated"},{"location":"fundamentals/pipeline-configuration/export-configuration/#by-tool","title":"By Tool","text":"Tool Format Import Method Excel CSV Open directly Neo4j Cypher cypher-shell or Browser Python JSON json.load() Pandas CSV pd.read_csv() SQL Database CSV COPY or LOAD DATA Power BI CSV Import data"},{"location":"fundamentals/pipeline-configuration/export-configuration/#advanced-export-options","title":"Advanced Export Options","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#reverse-edges","title":"Reverse Edges","text":"<p>Create bidirectional relationships:</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"cypher\",\n    reverse_edges=True  # Create reverse relationships\n)\n</code></pre> <p>Effect: <pre><code>// Original\nCREATE (a)-[:ISSUED_BY]-&gt;(b)\n\n// With reverse_edges=True\nCREATE (a)-[:ISSUED_BY]-&gt;(b)\nCREATE (b)-[:ISSUES]-&gt;(a)  # Reverse edge added\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#integration-scenarios","title":"Integration Scenarios","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#scenario-1-excel-analysis","title":"Scenario 1: Excel Analysis","text":"<pre><code># Export for Excel analysis\nconfig = PipelineConfig(\n    source=\"invoices.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\",\n    output_dir=\"excel_analysis\"\n)\n\nconfig.run()\n\n# Open in Excel\n# File -&gt; Open -&gt; excel_analysis/nodes.csv\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#scenario-2-neo4j-graph-database","title":"Scenario 2: Neo4j Graph Database","text":"<pre><code># Export for Neo4j\nconfig = PipelineConfig(\n    source=\"documents.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"cypher\",\n    output_dir=\"neo4j_import\"\n)\n\nconfig.run()\n\n# Import to Neo4j\n# cat neo4j_import/graph.cypher | cypher-shell\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#scenario-3-python-data-processing","title":"Scenario 3: Python Data Processing","text":"<pre><code># Export and process in Python\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\",\n    output_dir=\"python_processing\"\n)\n\nconfig.run()\n\n# Load and process\nimport pandas as pd\n\nnodes = pd.read_csv(\"python_processing/nodes.csv\")\nedges = pd.read_csv(\"python_processing/edges.csv\")\n\nprint(f\"Total nodes: {len(nodes)}\")\nprint(f\"Total edges: {len(edges)}\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#scenario-4-api-integration","title":"Scenario 4: API Integration","text":"<pre><code># Export for API\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\",  # Format doesn't matter, JSON always generated\n    output_dir=\"api_data\"\n)\n\nconfig.run()\n\n# Load JSON for API\nimport json\n\nwith open(\"api_data/extracted_data.json\") as f:\n    data = json.load(f)\n\n# Send to API\n# requests.post(\"https://api.example.com/invoices\", json=data)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#1-choose-format-by-use-case","title":"1. Choose Format by Use Case","text":"<pre><code># \u2705 Good - Match format to use case\nif use_case == \"neo4j\":\n    export_format = \"cypher\"\nelif use_case == \"excel\":\n    export_format = \"csv\"\nelse:\n    export_format = \"csv\"  # Default\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=export_format\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#2-organize-output-directories","title":"2. Organize Output Directories","text":"<pre><code># \u2705 Good - Organized structure\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\noutput_dir = f\"results/{document_type}/{timestamp}\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    output_dir=output_dir\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#3-enable-useful-exports","title":"3. Enable Useful Exports","text":"<pre><code># \u2705 Good - Enable what you need\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\",\n\n    # Enable for debugging\n    export_markdown=True,\n\n    # Disable if not needed\n    export_docling=False,\n    export_docling_json=False\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#4-check-output-files","title":"4. Check Output Files","text":"<pre><code># \u2705 Good - Verify outputs\nconfig.run()\n\nimport os\noutput_dir = config.output_dir\n\n# Check files exist\nassert os.path.exists(f\"{output_dir}/nodes.csv\")\nassert os.path.exists(f\"{output_dir}/edges.csv\")\nassert os.path.exists(f\"{output_dir}/graph_stats.json\")\n\nprint(\"\u2713 All outputs generated successfully\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#issue-output-directory-not-created","title":"Issue: Output Directory Not Created","text":"<p>Solution: <pre><code># Ensure parent directory exists\nimport os\nos.makedirs(\"results/invoices\", exist_ok=True)\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    output_dir=\"results/invoices/invoice_001\"\n)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#issue-csv-files-empty","title":"Issue: CSV Files Empty","text":"<p>Solution: <pre><code># Check extraction succeeded\nconfig.run()\n\n# Verify graph has nodes\nimport json\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nif stats[\"node_count\"] == 0:\n    print(\"Warning: No nodes extracted\")\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#issue-cypher-import-fails","title":"Issue: Cypher Import Fails","text":"<p>Solution: <pre><code># Check Cypher syntax\ncat outputs/graph.cypher | head -20\n\n# Import with error handling\ncat outputs/graph.cypher | cypher-shell -u neo4j -p password 2&gt;&amp;1 | tee import.log\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#next-steps","title":"Next Steps","text":"<p>Now that you understand export configuration:</p> <ol> <li>Configuration Examples \u2192 - Complete scenarios</li> <li>Model Configuration - Model settings</li> <li>Graph Management - Working with graphs</li> </ol>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#csv-export-default","title":"CSV Export (Default)","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"csv\"\n)\n</code></pre> <p>Output: <code>nodes.csv</code>, <code>edges.csv</code>, JSON files</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#cypher-export_1","title":"Cypher Export","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    export_format=\"cypher\"\n)\n</code></pre> <p>Output: <code>graph.cypher</code>, JSON files</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#custom-output-directory_1","title":"Custom Output Directory","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    output_dir=\"my_results/doc_001\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/","title":"Input Formats","text":"<p>Docling Graph supports multiple input formats, allowing you to process various types of documents and data sources through the same pipeline.</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#input-normalization-process","title":"Input Normalization Process","text":"<p>The pipeline automatically detects and validates input types, routing them through the appropriate processing stages:</p> <pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    Start@{ shape: terminal, label: \"Input Source\" }\n    Detect@{ shape: procs, label: \"Input Type Detection\" }\n\n    %% Validators\n    ValPDF@{ shape: lin-proc, label: \"Validate PDF\" }\n    ValImg@{ shape: lin-proc, label: \"Validate Image\" }\n    ValText@{ shape: lin-proc, label: \"Validate Text\" }\n    ValMD@{ shape: lin-proc, label: \"Validate MD\" }\n    ValDoc@{ shape: lin-proc, label: \"Validate Docling\" }\n\n    %% URL Specifics\n    ValURL@{ shape: lin-proc, label: \"Validate &amp; Download URL\" }\n    CheckDL{\"Type?\"}\n\n    %% Handlers\n    HandVisual@{ shape: tag-proc, label: \"Visual Handler\" }\n    HandText@{ shape: tag-proc, label: \"Text Handler\" }\n    HandDoc@{ shape: tag-proc, label: \"Object Handler\" }\n\n    %% Outcomes\n    SetFlags@{ shape: procs, label: \"Set Processing Flags\" }\n    Output@{ shape: doc, label: \"Normalized Context\" }\n\n    %% 3. Define Connections\n    Start --&gt; Detect\n\n    %% Input Detection Routing\n    Detect -- PDF --&gt; ValPDF\n    Detect -- Image --&gt; ValImg\n    Detect -- Text --&gt; ValText\n    Detect -- MD --&gt; ValMD\n    Detect -- Docling --&gt; ValDoc\n    Detect -- URL --&gt; ValURL\n\n    %% URL Routing (Feeds back into validators)\n    ValURL --&gt; CheckDL\n    CheckDL -- PDF --&gt; ValPDF\n    CheckDL -- Image --&gt; ValImg\n    CheckDL -- Text --&gt; ValText\n    CheckDL -- MD --&gt; ValMD\n\n    %% Validation to Handlers (The \"Happy Path\")\n    ValPDF &amp; ValImg --&gt; HandVisual\n    ValText &amp; ValMD --&gt; HandText\n    ValDoc --&gt; HandDoc\n\n    %% Converge Handlers to Output\n    HandVisual &amp; HandText &amp; HandDoc --&gt; SetFlags --&gt; Output\n\n    %% 4. Apply Classes\n    class Start input\n    class Detect,SetFlags process\n    class ValPDF,ValImg,ValText,ValMD,ValURL,ValDoc process\n    class HandVisual,HandText,HandDoc operator\n    class CheckDL decision\n    class Output output</code></pre> <p>Key Features: - Automatic Type Detection: Identifies input format from file extension, URL, or content - Validation: Ensures input meets requirements (non-empty, correct format, etc.) - Smart Routing: Skips unnecessary stages based on input type   - Text/Markdown inputs skip OCR   - DoclingDocument inputs skip extraction and go directly to graph conversion   - URLs are downloaded and processed based on their content type</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#supported-input-formats","title":"Supported Input Formats","text":""},{"location":"fundamentals/pipeline-configuration/input-formats/#1-pdf-documents","title":"1. PDF Documents","text":"<p>Description: Standard PDF files with text, images, and complex layouts.</p> <p>File Extensions: <code>.pdf</code></p> <p>Processing: Full pipeline with OCR/VLM, segmentation, and extraction.</p> <p>CLI Example: <pre><code>docling-graph convert document.pdf -t templates.invoice.Invoice\n</code></pre></p> <p>Python API Example: <pre><code>from docling_graph import PipelineConfig, run_pipeline\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.invoice.Invoice\",\n    backend=\"llm\",\n    inference=\"local\",\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    output_dir=\"outputs\",\n    export_format=\"csv\"\n)\n\nrun_pipeline(config)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#2-image-files","title":"2. Image Files","text":"<p>Description: Image files containing document content (scanned documents, photos of documents, etc.).</p> <p>File Extensions: <code>.png</code>, <code>.jpg</code>, <code>.jpeg</code></p> <p>Processing: Full pipeline with OCR/VLM, segmentation, and extraction.</p> <p>CLI Example: <pre><code>docling-graph convert scanned_invoice.png -t templates.invoice.Invoice\n</code></pre></p> <p>Python API Example: <pre><code>config = PipelineConfig(\n    source=\"scanned_invoice.jpg\",\n    template=\"templates.invoice.Invoice\",\n    backend=\"vlm\",  # VLM works well with images\n    inference=\"local\",\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\",\n    output_dir=\"outputs\",\n    export_format=\"json\"\n)\n\nrun_pipeline(config)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#3-plain-text-files","title":"3. Plain Text Files","text":"<p>Description: Simple text files containing unstructured content.</p> <p>File Extensions: <code>.txt</code></p> <p>Processing: Skips OCR and visual processing. Goes directly to LLM extraction.</p> <p>Requirements: - Must use LLM backend (VLM requires visual content) - File must not be empty or contain only whitespace</p> <p>CLI Example: <pre><code>docling-graph convert notes.txt -t templates.report.Report --backend llm\n</code></pre></p> <p>Python API Example: <pre><code>config = PipelineConfig(\n    source=\"meeting_notes.txt\",\n    template=\"templates.report.Report\",\n    backend=\"llm\",  # Required for text inputs\n    inference=\"remote\",\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",  # Ignored for text inputs\n    output_dir=\"outputs\",\n    export_format=\"csv\"\n)\n\nrun_pipeline(config)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#4-markdown-files","title":"4. Markdown Files","text":"<p>Description: Markdown-formatted text files with structure and formatting.</p> <p>File Extensions: <code>.md</code></p> <p>Processing: Skips OCR and visual processing. Markdown structure is preserved during extraction.</p> <p>Requirements: - Must use LLM backend - File must not be empty</p> <p>CLI Example: <pre><code>docling-graph convert README.md -t templates.documentation.Documentation --backend llm\n</code></pre></p> <p>Python API Example: <pre><code>config = PipelineConfig(\n    source=\"documentation.md\",\n    template=\"templates.documentation.Documentation\",\n    backend=\"llm\",\n    inference=\"local\",\n    processing_mode=\"many-to-one\",\n    output_dir=\"outputs\",\n    export_format=\"json\"\n)\n\nrun_pipeline(config)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#5-urls","title":"5. URLs","text":"<p>Description: Download and process documents from URLs.</p> <p>Format: <code>http://</code> or <code>https://</code> URLs</p> <p>Processing:  1. Downloads content to temporary location 2. Detects content type (PDF, image, text, markdown) 3. Routes to appropriate processing pipeline</p> <p>Supported URL Content Types: - PDF documents - Image files (PNG, JPG, JPEG) - Plain text files - Markdown files</p> <p>Requirements: - Valid HTTP/HTTPS URL - Accessible without authentication (for now) - File size under limit (default: 100MB)</p> <p>CLI Example: <pre><code># PDF from URL\ndocling-graph convert https://example.com/invoice.pdf -t templates.invoice.Invoice\n\n# Image from URL\ndocling-graph convert https://example.com/scan.jpg -t templates.form.Form\n\n# Text from URL\ndocling-graph convert https://example.com/notes.txt -t templates.report.Report --backend llm\n</code></pre></p> <p>Python API Example: <pre><code>config = PipelineConfig(\n    source=\"https://example.com/document.pdf\",\n    template=\"templates.invoice.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\",\n    output_dir=\"outputs\",\n    export_format=\"csv\"\n)\n\nrun_pipeline(config)\n</code></pre></p> <p>URL Configuration: <pre><code>from docling_graph.core.input.handlers import URLInputHandler\n\n# Custom timeout and size limit\nhandler = URLInputHandler(\n    timeout=30,      # seconds\n    max_size_mb=50   # megabytes\n)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#6-plain-text-strings-python-api-only","title":"6. Plain Text Strings (Python API Only)","text":"<p>Description: Raw text strings passed directly to the pipeline.</p> <p>Format: Python string</p> <p>Processing: Skips OCR and visual processing. Direct LLM extraction.</p> <p>Requirements: - Only available via Python API (not CLI) - Must use LLM backend - String must not be empty or whitespace-only</p> <p>Python API Example: <pre><code># Direct text input\ntext_content = \"\"\"\nInvoice #12345\nDate: 2024-01-15\nAmount: $1,234.56\nCustomer: Acme Corp\n\"\"\"\n\nconfig = PipelineConfig(\n    source=text_content,  # Pass string directly\n    template=\"templates.invoice.Invoice\",\n    backend=\"llm\",\n    inference=\"local\",\n    processing_mode=\"many-to-one\",\n    output_dir=\"outputs\",\n    export_format=\"json\"\n)\n\nrun_pipeline(config, mode=\"api\")  # mode=\"api\" required\n</code></pre></p> <p>Note: CLI does not accept plain text strings to avoid ambiguity with file paths.</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#7-doclingdocument-json-advanced","title":"7. DoclingDocument JSON (Advanced)","text":"<p>Description: Pre-processed DoclingDocument JSON files.</p> <p>File Extensions: <code>.json</code> (with DoclingDocument schema)</p> <p>Processing: Skips document conversion. Uses pre-existing structure.</p> <p>Use Cases: - Reprocessing previously converted documents - Custom document preprocessing pipelines - Integration with external Docling workflows</p> <p>Requirements: - Valid DoclingDocument JSON schema - Must include <code>schema_name: \"DoclingDocument\"</code> - Must include <code>version</code> field</p> <p>CLI Example: <pre><code>docling-graph convert processed_document.json -t templates.custom.Custom\n</code></pre></p> <p>Python API Example: <pre><code>config = PipelineConfig(\n    source=\"preprocessed.json\",\n    template=\"templates.custom.Custom\",\n    backend=\"llm\",\n    inference=\"local\",\n    processing_mode=\"many-to-one\",\n    output_dir=\"outputs\",\n    export_format=\"csv\"\n)\n\nrun_pipeline(config)\n</code></pre></p> <p>DoclingDocument JSON Structure: <pre><code>{\n  \"schema_name\": \"DoclingDocument\",\n  \"version\": \"1.0.0\",\n  \"name\": \"document_name\",\n  \"pages\": {\n    \"0\": {\n      \"page_no\": 0,\n      \"size\": {\"width\": 612, \"height\": 792}\n    }\n  },\n  \"body\": {\n    \"self_ref\": \"#/body\",\n    \"children\": []\n  },\n  \"furniture\": {}\n}\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#input-format-detection","title":"Input Format Detection","text":"<p>The pipeline automatically detects input format based on:</p> <ol> <li>File Extension: <code>.pdf</code>, <code>.png</code>, <code>.jpg</code>, <code>.txt</code>, <code>.md</code>, <code>.json</code></li> <li>URL Scheme: <code>http://</code> or <code>https://</code></li> <li>Content Analysis: For JSON files, checks for DoclingDocument schema</li> <li>Fallback: Plain text for unrecognized formats (API mode only)</li> </ol> <p>Detection Examples:</p> <pre><code>from docling_graph.core.input.types import InputTypeDetector\n\n# Detect from file path\ninput_type = InputTypeDetector.detect(\"document.pdf\", mode=\"cli\")\n# Returns: InputType.PDF\n\n# Detect from URL\ninput_type = InputTypeDetector.detect(\"https://example.com/file.txt\", mode=\"cli\")\n# Returns: InputType.URL\n\n# Detect from text (API mode only)\ninput_type = InputTypeDetector.detect(\"Plain text content\", mode=\"api\")\n# Returns: InputType.TEXT\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#processing-pipeline-by-input-type","title":"Processing Pipeline by Input Type","text":""},{"location":"fundamentals/pipeline-configuration/input-formats/#visual-documents-pdf-images","title":"Visual Documents (PDF, Images)","text":"<pre><code>Input \u2192 Document Conversion (OCR/VLM) \u2192 Segmentation \u2192 \nExtraction \u2192 Graph Construction \u2192 Export\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#text-documents-txt-md-plain-text","title":"Text Documents (.txt, .md, plain text)","text":"<pre><code>Input \u2192 Text Normalization \u2192 Extraction (LLM only) \u2192 \nGraph Construction \u2192 Export\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#urls","title":"URLs","text":"<pre><code>URL \u2192 Download \u2192 Type Detection \u2192 Route to appropriate pipeline\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#doclingdocument-json","title":"DoclingDocument JSON","text":"<pre><code>Input \u2192 Validation \u2192 Graph Construction \u2192 Export\n(Skips conversion and extraction)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#backend-compatibility","title":"Backend Compatibility","text":"Input Format LLM Backend VLM Backend PDF \u2705 Yes \u2705 Yes Images \u2705 Yes \u2705 Yes Text Files \u2705 Yes \u274c No Markdown \u2705 Yes \u274c No URLs (PDF/Image) \u2705 Yes \u2705 Yes URLs (Text/MD) \u2705 Yes \u274c No Plain Text \u2705 Yes \u274c No DoclingDocument \u2705 Yes \u2705 Yes <p>Note: VLM (Vision Language Model) backend requires visual content. Use LLM backend for text-only inputs.</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#error-handling","title":"Error Handling","text":""},{"location":"fundamentals/pipeline-configuration/input-formats/#empty-files","title":"Empty Files","text":"<pre><code>$ docling-graph convert empty.txt -t templates.Report\nError: Text input is empty\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#unsupported-backend","title":"Unsupported Backend","text":"<pre><code>$ docling-graph convert notes.txt -t templates.Report --backend vlm\nError: VLM backend does not support text-only inputs. Use LLM backend instead.\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#invalid-url","title":"Invalid URL","text":"<pre><code>$ docling-graph convert ftp://example.com/file.pdf -t templates.Invoice\nError: URL must use http or https scheme\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#file-not-found","title":"File Not Found","text":"<pre><code>$ docling-graph convert missing.pdf -t templates.Invoice\nError: File not found: missing.pdf\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/input-formats/#1-choose-the-right-backend","title":"1. Choose the Right Backend","text":"<ul> <li>PDFs and Images: Use VLM for complex layouts, LLM for text-heavy documents</li> <li>Text Files: Always use LLM backend</li> <li>Mixed Workflows: Use LLM backend for maximum compatibility</li> </ul>"},{"location":"fundamentals/pipeline-configuration/input-formats/#2-validate-input-files","title":"2. Validate Input Files","text":"<pre><code>from pathlib import Path\n\nsource_path = Path(\"document.txt\")\nif not source_path.exists():\n    raise FileNotFoundError(f\"Input file not found: {source_path}\")\n\nif source_path.stat().st_size == 0:\n    raise ValueError(\"Input file is empty\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#3-handle-urls-safely","title":"3. Handle URLs Safely","text":"<pre><code>from docling_graph.core.input.validators import URLValidator\n\nvalidator = URLValidator()\ntry:\n    validator.validate(url)\nexcept ValidationError as e:\n    print(f\"Invalid URL: {e.message}\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#4-use-appropriate-processing-modes","title":"4. Use Appropriate Processing Modes","text":"<ul> <li>one-to-one: Best for multi-page PDFs where each page is independent</li> <li>many-to-one: Best for text files and single-entity documents</li> </ul>"},{"location":"fundamentals/pipeline-configuration/input-formats/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/pipeline-configuration/input-formats/#issue-plain-text-input-is-only-supported-via-python-api","title":"Issue: \"Plain text input is only supported via Python API\"","text":"<p>Cause: Trying to pass plain text string via CLI</p> <p>Solution: Use Python API or save text to a <code>.txt</code> file first</p> <pre><code># Option 1: Use Python API\nrun_pipeline(config, mode=\"api\")\n\n# Option 2: Save to file\nPath(\"temp.txt\").write_text(text_content)\nconfig.source = \"temp.txt\"\nrun_pipeline(config, mode=\"cli\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#issue-vlm-backend-does-not-support-text-only-inputs","title":"Issue: \"VLM backend does not support text-only inputs\"","text":"<p>Cause: Using VLM backend with text files</p> <p>Solution: Switch to LLM backend</p> <pre><code>docling-graph convert notes.txt -t templates.Report --backend llm\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#issue-url-download-timeout","title":"Issue: URL download timeout","text":"<p>Cause: Slow network or large file</p> <p>Solution: Increase timeout or download manually</p> <pre><code>from docling_graph.core.input.handlers import URLInputHandler\n\nhandler = URLInputHandler(timeout=60)  # 60 seconds\ntemp_path = handler.load(url)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#next-steps","title":"Next Steps","text":"<ul> <li>Backend Selection - Choose the right backend for your input</li> <li>Processing Modes - Understand one-to-one vs many-to-one</li> <li>Configuration Examples - See complete configuration examples</li> </ul>"},{"location":"fundamentals/pipeline-configuration/model-configuration/","title":"Model Configuration","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#overview","title":"Overview","text":"<p>Model configuration determines which AI model processes your documents. Docling Graph supports multiple providers for both local and remote inference, giving you flexibility in choosing the right model for your needs.</p> <p>In this guide: - Local vs remote inference - Supported providers and models - Model capability tiers - Model selection strategies - Provider-specific configuration - Performance and cost considerations</p> <p>New: Automatic Model Capability Detection</p> <p>Docling Graph now automatically detects model capabilities based on parameter count and adapts prompts and consolidation strategies accordingly. See Model Capabilities for details.</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#local-vs-remote-inference","title":"Local vs Remote Inference","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#quick-comparison","title":"Quick Comparison","text":"Aspect Local Inference Remote Inference Location Your GPU/CPU Cloud API Setup Complex (GPU drivers, models) Simple (API key) Cost Hardware + electricity Pay per token Speed Fast (with GPU) Variable (network dependent) Privacy Complete Data sent to provider Offline Yes No Models Limited by hardware Latest models available"},{"location":"fundamentals/pipeline-configuration/model-configuration/#local-inference","title":"Local Inference","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#overview_1","title":"Overview","text":"<p>Local inference runs models on your own hardware (GPU or CPU). Best for privacy, offline use, and high-volume processing.</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\",  # Local inference\n    model_override=\"ibm-granite/granite-4.0-1b\",\n    provider_override=\"vllm\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#supported-local-providers","title":"Supported Local Providers","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#1-vllm-recommended-for-llm","title":"1. vLLM (Recommended for LLM)","text":"<p>Best for: Fast local LLM inference with GPU</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\",\n    provider_override=\"vllm\"\n)\n</code></pre> <p>Setup: <pre><code># Install vLLM\nuv add vllm\n\n# Start vLLM server\nuv run python -m vllm.entrypoints.openai.api_server \\\n    --model ibm-granite/granite-4.0-1b \\\n    --port 8000\n</code></pre></p> <p>Supported Models: - <code>ibm-granite/granite-4.0-1b</code> (default, fast) - <code>ibm-granite/granite-4.0-3b</code> (balanced) - <code>meta-llama/Llama-3.1-8B</code> (high quality) - Any HuggingFace model compatible with vLLM</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#2-ollama","title":"2. Ollama","text":"<p>Best for: Easy local setup, multiple models</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\",\n    model_override=\"llama-3.1-8b\",\n    provider_override=\"ollama\"\n)\n</code></pre> <p>Setup: <pre><code># Install Ollama (see ollama.ai)\n# Pull model\nollama pull llama3.1:8b\n\n# Ollama runs automatically on localhost:11434\n</code></pre></p> <p>Supported Models: - <code>llama3.1:8b</code> (recommended) - <code>mistral:7b</code> - <code>mixtral:8x7b</code> - Any model in Ollama library</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#3-docling-vlm-for-vlm-backend","title":"3. Docling VLM (For VLM Backend)","text":"<p>Best for: Vision-based extraction</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"vlm\",\n    inference=\"local\",\n    model_override=\"numind/NuExtract-2.0-8B\",\n    provider_override=\"docling\"\n)\n</code></pre> <p>Supported Models: - <code>numind/NuExtract-2.0-8B</code> (default, recommended) - <code>numind/NuExtract-2.0-2B</code> (faster, less accurate)</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#local-inference-requirements","title":"Local Inference Requirements","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#hardware-requirements","title":"Hardware Requirements","text":"<p>Minimum (CPU only): - 16GB RAM - 50GB disk space - Slow processing</p> <p>Recommended (GPU): - NVIDIA GPU with 8GB+ VRAM - 32GB RAM - 100GB disk space - CUDA 12.1+</p> <p>Optimal (GPU): - NVIDIA GPU with 24GB+ VRAM (RTX 4090, A100) - 64GB RAM - 200GB SSD - CUDA 12.1+</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#software-requirements","title":"Software Requirements","text":"<pre><code># CUDA drivers (for GPU)\nnvidia-smi  # Verify CUDA installation\n\n# Python packages\nuv add vllm  # For vLLM\n# or\n# Install Ollama from ollama.ai\n</code></pre> <p>See: Installation: GPU Setup</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#remote-inference","title":"Remote Inference","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#overview_2","title":"Overview","text":"<p>Remote inference uses cloud API providers. Best for quick setup, latest models, and no hardware requirements.</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",  # Remote inference\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#supported-remote-providers","title":"Supported Remote Providers","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#1-openai","title":"1. OpenAI","text":"<p>Best for: Highest quality, latest models</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\"\n)\n</code></pre> <p>Setup: <pre><code># Set API key\nexport OPENAI_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Supported Models: - <code>gpt-4-turbo</code> (recommended, best quality) - <code>gpt-4</code> (high quality) - <code>gpt-3.5-turbo</code> (fast, economical)</p> <p>Pricing (approximate): - GPT-4 Turbo: $0.01/1K input tokens, $0.03/1K output tokens - GPT-3.5 Turbo: $0.0005/1K input tokens, $0.0015/1K output tokens</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#2-mistral-ai","title":"2. Mistral AI","text":"<p>Best for: European provider, good balance</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",\n    model_override=\"mistral-small-latest\",\n    provider_override=\"mistral\"\n)\n</code></pre> <p>Setup: <pre><code># Set API key\nexport MISTRAL_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Supported Models: - <code>mistral-small-latest</code> (default, economical) - <code>mistral-medium-latest</code> (balanced) - <code>mistral-large-latest</code> (highest quality)</p> <p>Pricing (approximate): - Small: $0.001/1K tokens - Medium: $0.0027/1K tokens - Large: $0.008/1K tokens</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#3-google-gemini","title":"3. Google Gemini","text":"<p>Best for: Multimodal capabilities, competitive pricing</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",\n    model_override=\"gemini-2.5-flash\",\n    provider_override=\"gemini\"\n)\n</code></pre> <p>Setup: <pre><code># Set API key\nexport GOOGLE_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Supported Models: - <code>gemini-2.5-flash</code> (default, fast) - <code>gemini-2.0-pro</code> (high quality)</p> <p>Pricing (approximate): - Flash: $0.00025/1K input tokens, $0.00075/1K output tokens - Pro: $0.00125/1K input tokens, $0.005/1K output tokens</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#4-ibm-watsonx","title":"4. IBM WatsonX","text":"<p>Best for: Enterprise deployments, IBM ecosystem</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",\n    model_override=\"ibm/granite-13b-chat-v2\",\n    provider_override=\"watsonx\"\n)\n</code></pre> <p>Setup: <pre><code># Set API key and project ID\nexport WATSONX_API_KEY=\"your-api-key\"\nexport WATSONX_PROJECT_ID=\"your-project-id\"\n</code></pre></p> <p>See: API Keys Setup for WatsonX configuration details.</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#model-capability-tiers","title":"Model Capability Tiers","text":"<p>Docling Graph automatically categorizes models into capability tiers based on parameter count:</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#tier-overview","title":"Tier Overview","text":"Tier Model Size Prompt Style Consolidation Best For SIMPLE 1B-7B Minimal instructions Basic merge Simple forms, high volume STANDARD 7B-13B Balanced instructions Standard merge General documents ADVANCED 13B+ Detailed instructions Chain of Density Complex documents, critical data"},{"location":"fundamentals/pipeline-configuration/model-configuration/#automatic-detection","title":"Automatic Detection","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Small model - Automatically uses SIMPLE tier\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\",\n    provider_override=\"vllm\",\n    model_override=\"ibm-granite/granite-4.0-1b\"  # 1B params \u2192 SIMPLE\n)\n\n# Medium model - Automatically uses STANDARD tier\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\"  # 8B params \u2192 STANDARD\n)\n\n# Large model - Automatically uses ADVANCED tier\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\"  # 175B+ params \u2192 ADVANCED\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#performance-impact","title":"Performance Impact","text":"<p>Token Usage per Extraction:</p> Tier Prompt Tokens Consolidation Total Overhead SIMPLE ~200-300 Single-turn Low STANDARD ~400-500 Single-turn Medium ADVANCED ~600-800 Multi-turn (3x) High <p>Quality vs Speed:</p> Tier Extraction Quality Speed Cost SIMPLE 85-90% \u26a1 Fast $ Low STANDARD 90-95% \u26a1 Fast $$ Medium ADVANCED 95-98% \ud83d\udc22 Slower $$$ High <p>See Model Capabilities for complete details.</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#model-selection-strategies","title":"Model Selection Strategies","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#by-document-complexity","title":"By Document Complexity","text":"<pre><code>def get_model_config(document_complexity: str):\n    \"\"\"Choose model based on document complexity.\"\"\"\n    if document_complexity == \"simple\":\n        # Simple documents: SIMPLE tier (fast, economical)\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"ibm-granite/granite-4.0-1b\",  # SIMPLE tier\n            \"provider_override\": \"vllm\"\n        }\n    elif document_complexity == \"medium\":\n        # Medium complexity: STANDARD tier (balanced)\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"llama3.1:8b\",  # STANDARD tier\n            \"provider_override\": \"ollama\"\n        }\n    else:\n        # Complex documents: ADVANCED tier (highest quality)\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"gpt-4-turbo\",  # ADVANCED tier\n            \"provider_override\": \"openai\"\n        }\n</code></pre> <p>Capability Tier Matching</p> <p>Match model capability tier to document complexity:</p> <ul> <li>Simple forms/invoices \u2192 SIMPLE tier (1B-7B models)</li> <li>General documents \u2192 STANDARD tier (7B-13B models)</li> <li>Complex contracts/research \u2192 ADVANCED tier (13B+ models)</li> </ul>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#by-volume","title":"By Volume","text":"<pre><code>def get_model_config(document_count: int):\n    \"\"\"Choose model based on processing volume.\"\"\"\n    if document_count &lt; 100:\n        # Low volume: use best quality\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"gpt-4-turbo\",\n            \"provider_override\": \"openai\"\n        }\n    elif document_count &lt; 1000:\n        # Medium volume: balanced\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"mistral-small-latest\",\n            \"provider_override\": \"mistral\"\n        }\n    else:\n        # High volume: use local to avoid costs\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"ibm-granite/granite-4.0-1b\",\n            \"provider_override\": \"vllm\"\n        }\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#by-budget","title":"By Budget","text":"<pre><code>def get_model_config(budget: str):\n    \"\"\"Choose model based on budget.\"\"\"\n    if budget == \"minimal\":\n        # Minimal cost: local inference\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"ibm-granite/granite-4.0-1b\",\n            \"provider_override\": \"vllm\"\n        }\n    elif budget == \"moderate\":\n        # Moderate cost: economical API\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"mistral-small-latest\",\n            \"provider_override\": \"mistral\"\n        }\n    else:\n        # No budget constraint: best quality\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"gpt-4-turbo\",\n            \"provider_override\": \"openai\"\n        }\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#by-capability-tier","title":"By Capability Tier","text":"<pre><code>def get_model_by_tier(tier: str):\n    \"\"\"Choose model based on desired capability tier.\"\"\"\n    if tier == \"SIMPLE\":\n        # SIMPLE tier: 1B-7B models\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"ibm-granite/granite-4.0-1b\",\n            \"provider_override\": \"vllm\"\n        }\n    elif tier == \"STANDARD\":\n        # STANDARD tier: 7B-13B models\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"llama3.1:8b\",\n            \"provider_override\": \"ollama\"\n        }\n    else:  # ADVANCED\n        # ADVANCED tier: 13B+ models\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"gpt-4-turbo\",\n            \"provider_override\": \"openai\"\n        }\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#by-quality-requirements","title":"By Quality Requirements","text":"<pre><code>def get_model_by_quality(quality_requirement: str):\n    \"\"\"Choose model based on quality requirements.\"\"\"\n    if quality_requirement == \"acceptable\":\n        # 85-90% accuracy: SIMPLE tier\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"ibm-granite/granite-4.0-1b\",\n            \"provider_override\": \"vllm\"\n        }\n    elif quality_requirement == \"high\":\n        # 90-95% accuracy: STANDARD tier\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"llama3.1:8b\",\n            \"provider_override\": \"ollama\"\n        }\n    else:  # critical\n        # 95-98% accuracy: ADVANCED tier with Chain of Density\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"gpt-4-turbo\",\n            \"provider_override\": \"openai\",\n            \"llm_consolidation\": True  # Enables Chain of Density\n        }\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#provider-specific-configuration","title":"Provider-Specific Configuration","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#vllm-configuration","title":"vLLM Configuration","text":"<pre><code># Custom vLLM base URL\nimport os\nos.environ[\"VLLM_BASE_URL\"] = \"http://localhost:8000/v1\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\",\n    provider_override=\"vllm\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#ollama-configuration","title":"Ollama Configuration","text":"<pre><code># Custom Ollama base URL\nimport os\nos.environ[\"OLLAMA_BASE_URL\"] = \"http://localhost:11434\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\",\n    provider_override=\"ollama\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#api-key-configuration","title":"API Key Configuration","text":"<pre><code># Set via environment variables (recommended)\nexport OPENAI_API_KEY=\"your-key\"\nexport MISTRAL_API_KEY=\"your-key\"\nexport GOOGLE_API_KEY=\"your-key\"\nexport WATSONX_API_KEY=\"your-key\"\nexport WATSONX_PROJECT_ID=\"your-project-id\"\n</code></pre> <p>Or via <code>.env</code> file: <pre><code># .env file\nOPENAI_API_KEY=your-key\nMISTRAL_API_KEY=your-key\nGOOGLE_API_KEY=your-key\n</code></pre></p> <p>See: Installation: API Keys</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#performance-comparison","title":"Performance Comparison","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#speed-comparison","title":"Speed Comparison","text":"<pre><code>Document: 10-page invoice PDF\n\nLocal (vLLM, GPU):        ~30 seconds\nLocal (Ollama, GPU):      ~45 seconds\nRemote (GPT-3.5):         ~40 seconds\nRemote (GPT-4):           ~60 seconds\nRemote (Mistral Small):   ~35 seconds\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#quality-comparison","title":"Quality Comparison","text":"<pre><code>Extraction Accuracy (Complex Documents):\n\nGPT-4 Turbo:              97%\nGPT-3.5 Turbo:            92%\nMistral Large:            95%\nMistral Small:            90%\nGranite 4.0-1B (local):   88%\nLlama 3.1-8B (local):     93%\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#cost-comparison","title":"Cost Comparison","text":"<pre><code>Processing 1000 documents (10 pages each):\n\nLocal (vLLM):             $0 (GPU amortized)\nLocal (Ollama):           $0 (GPU amortized)\nRemote (GPT-4):           $150-300\nRemote (GPT-3.5):         $10-20\nRemote (Mistral Small):   $5-15\nRemote (Gemini Flash):    $3-10\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#local-inference-issues","title":"Local Inference Issues","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#issue-cuda-out-of-memory","title":"Issue: CUDA Out of Memory","text":"<pre><code># Solution: Use smaller model\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\",  # Smaller model\n    provider_override=\"vllm\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#issue-vllm-server-not-running","title":"Issue: vLLM Server Not Running","text":"<pre><code># Check if server is running\ncurl http://localhost:8000/v1/models\n\n# Start server if needed\nuv run python -m vllm.entrypoints.openai.api_server \\\n    --model ibm-granite/granite-4.0-1b \\\n    --port 8000\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#remote-inference-issues","title":"Remote Inference Issues","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#issue-api-key-not-found","title":"Issue: API Key Not Found","text":"<pre><code># Verify API key is set\necho $OPENAI_API_KEY\n\n# Set if missing\nexport OPENAI_API_KEY=\"your-key\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#issue-rate-limit-exceeded","title":"Issue: Rate Limit Exceeded","text":"<pre><code># Solution: Add retry logic or switch provider\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",\n    model_override=\"mistral-small-latest\",  # Different provider\n    provider_override=\"mistral\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#1-start-with-remote-for-testing","title":"1. Start with Remote for Testing","text":"<pre><code># \u2705 Good - Quick setup for testing\nconfig = PipelineConfig(\n    source=\"test.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",\n    model_override=\"gpt-3.5-turbo\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#2-use-local-for-production-volume","title":"2. Use Local for Production Volume","text":"<pre><code># \u2705 Good - Cost-effective for high volume\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#3-match-model-to-document-complexity","title":"3. Match Model to Document Complexity","text":"<pre><code># \u2705 Good - Use appropriate model\nif document_is_complex:\n    model = \"gpt-4-turbo\"\nelse:\n    model = \"gpt-3.5-turbo\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",\n    model_override=model\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#4-monitor-costs","title":"4. Monitor Costs","text":"<pre><code># \u2705 Good - Track API usage\nimport logging\n\nlogging.info(f\"Processing {document_count} documents\")\nlogging.info(f\"Estimated cost: ${estimated_cost}\")\n\nconfig.run()\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#model-recommendations-by-use-case","title":"Model Recommendations by Use Case","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#high-volume-processing","title":"High-Volume Processing","text":"<pre><code># Use SIMPLE tier for speed and cost efficiency\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\",  # SIMPLE tier\n    provider_override=\"vllm\",\n    use_chunking=True,\n    llm_consolidation=False  # Fast programmatic merge\n)\n</code></pre> <p>Benefits: - \u26a1 Fast processing (30-60s per document) - \ud83d\udcb0 Zero API costs - \ud83d\udcca 85-90% accuracy (sufficient for most cases)</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#critical-documents","title":"Critical Documents","text":"<pre><code># Use ADVANCED tier for maximum accuracy\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"my_templates.Contract\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",  # ADVANCED tier\n    provider_override=\"openai\",\n    use_chunking=True,\n    llm_consolidation=True  # Chain of Density consolidation\n)\n</code></pre> <p>Benefits: - \ud83d\udc8e 95-98% accuracy - \ud83d\udd04 Multi-turn consolidation - \u2705 Best for legal/financial documents</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#balanced-approach","title":"Balanced Approach","text":"<pre><code># Use STANDARD tier for general documents\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Report\",\n    inference=\"local\",\n    model_override=\"llama3.1:8b\",  # STANDARD tier\n    provider_override=\"ollama\",\n    use_chunking=True,\n    llm_consolidation=False  # Standard merge\n)\n</code></pre> <p>Benefits: - \u2696\ufe0f Good balance of speed and quality - \ud83d\udcb0 Zero API costs - \ud83d\udcca 90-95% accuracy</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#next-steps","title":"Next Steps","text":"<p>Now that you understand model configuration:</p> <ol> <li>Model Capabilities \u2192 - Learn about capability tiers</li> <li>Processing Modes \u2192 - Choose processing strategy</li> <li>Configuration Examples - See complete scenarios</li> <li>Extraction Process - Understand extraction</li> <li>Performance Tuning \u2192 - Optimize performance</li> </ol>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#local-inference-vllm","title":"Local Inference (vLLM)","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\",\n    provider_override=\"vllm\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#remote-inference-openai","title":"Remote Inference (OpenAI)","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#model-defaults","title":"Model Defaults","text":"<ul> <li>LLM Local: <code>ibm-granite/granite-4.0-1b</code> (vllm)</li> <li>LLM Remote: <code>mistral-small-latest</code> (mistral)</li> <li>VLM Local: <code>numind/NuExtract-2.0-8B</code> (docling)</li> </ul>"},{"location":"fundamentals/pipeline-configuration/processing-modes/","title":"Processing Modes","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#overview","title":"Overview","text":"<p>Processing modes determine how Docling Graph handles multi-page documents. The choice between one-to-one and many-to-one modes significantly affects extraction results and graph structure.</p> <p>In this guide: - One-to-one vs many-to-one comparison - When to use each mode - Graph structure differences - Performance implications - Mode-specific configuration</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#processing-mode-comparison","title":"Processing Mode Comparison","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#quick-comparison","title":"Quick Comparison","text":"Aspect One-to-One Many-to-One Processing Each page separately Whole document together Output N models (one per page) 1 merged model Best For Independent pages Single document entity Graph Nodes More nodes Fewer nodes Context Page-level Document-level Speed Slower (N extractions) Faster (1 extraction) Accuracy Page-specific Document-wide"},{"location":"fundamentals/pipeline-configuration/processing-modes/#one-to-one-mode","title":"One-to-One Mode","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#what-is-one-to-one","title":"What is One-to-One?","text":"<p>One-to-one mode processes each page independently, creating separate extraction results for each page. Best for documents where pages are independent entities.</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"one-to-one\"  # Process each page separately\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#how-it-works","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: doc, label: \"Page 1\" }\n    C@{ shape: doc, label: \"Page 2\" }\n    D@{ shape: doc, label: \"Page 3\" }\n\n    E@{ shape: tag-proc, label: \"Extract 1\" }\n    F@{ shape: tag-proc, label: \"Extract 2\" }\n    G@{ shape: tag-proc, label: \"Extract 3\" }\n\n    H@{ shape: procs, label: \"Model 1\" }\n    I@{ shape: procs, label: \"Model 2\" }\n    J@{ shape: procs, label: \"Model 3\" }\n\n    %% 3. Define Connections\n    A --&gt; B &amp; C &amp; D\n\n    B --&gt; E\n    C --&gt; F\n    D --&gt; G\n\n    E --&gt; H\n    F --&gt; I\n    G --&gt; J\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D data\n    class E,F,G operator\n    class H,I,J output</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#when-to-use-one-to-one","title":"When to Use One-to-One","text":"<p>\u2705 Use one-to-one when: - Each page is an independent document (e.g., batch of invoices) - Pages have different structures - You need page-level granularity - Pages represent separate entities - You want to track which page data came from</p> <p>\u274c Don't use one-to-one when: - Document is a single entity spanning multiple pages - Pages are continuation of same content - You need document-wide context - You want a single consolidated result</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#example-use-cases","title":"Example Use Cases","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-1-batch-invoice-processing","title":"Use Case 1: Batch Invoice Processing","text":"<pre><code># Multiple invoices in one PDF\nconfig = PipelineConfig(\n    source=\"invoices_batch.pdf\",  # 10 invoices, 1 page each\n    template=\"my_templates.Invoice\",\n    processing_mode=\"one-to-one\"  # Each page is separate invoice\n)\n</code></pre> <p>Result: 10 Invoice models, one per page</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-2-form-collection","title":"Use Case 2: Form Collection","text":"<pre><code># Multiple forms in one PDF\nconfig = PipelineConfig(\n    source=\"forms_collection.pdf\",  # 20 forms\n    template=\"my_templates.ApplicationForm\",\n    processing_mode=\"one-to-one\"  # Each page is separate form\n)\n</code></pre> <p>Result: 20 ApplicationForm models</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-3-id-card-batch","title":"Use Case 3: ID Card Batch","text":"<pre><code># Multiple ID cards scanned together\nconfig = PipelineConfig(\n    source=\"id_cards_batch.pdf\",  # 50 ID cards\n    template=\"my_templates.IDCard\",\n    processing_mode=\"one-to-one\"  # Each page is separate ID\n)\n</code></pre> <p>Result: 50 IDCard models</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#graph-structure","title":"Graph Structure","text":"<p>One-to-one creates multiple root nodes:</p> <pre><code>Invoice-Page1 (node)\n  \u251c\u2500 ISSUED_BY \u2192 Organization-A\n  \u2514\u2500 SENT_TO \u2192 Client-A\n\nInvoice-Page2 (node)\n  \u251c\u2500 ISSUED_BY \u2192 Organization-B\n  \u2514\u2500 SENT_TO \u2192 Client-B\n\nInvoice-Page3 (node)\n  \u251c\u2500 ISSUED_BY \u2192 Organization-C\n  \u2514\u2500 SENT_TO \u2192 Client-C\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#performance-characteristics","title":"Performance Characteristics","text":"<pre><code>Document: 10-page PDF\n\nOne-to-One Processing:\n- Extractions: 10 (one per page)\n- Time: ~5 minutes (10 \u00d7 30 seconds)\n- Memory: Moderate (sequential processing)\n- Output: 10 separate models\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#many-to-one-mode","title":"Many-to-One Mode","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#what-is-many-to-one","title":"What is Many-to-One?","text":"<p>Many-to-one mode processes the entire document as a single entity, merging all pages into one extraction result. Best for documents that represent a single entity.</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"many-to-one\"  # Process whole document (default)\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#how-it-works_1","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: doc, label: \"All Pages\" }\n    C@{ shape: tag-proc, label: \"Chunking\" }\n    D@{ shape: procs, label: \"Extract Chunks\" }\n    E@{ shape: lin-proc, label: \"Merge Results\" }\n\n    F@{ shape: procs, label: \"Single Model\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B data\n    class C operator\n    class D,E process\n    class F output</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#when-to-use-many-to-one","title":"When to Use Many-to-One","text":"<p>\u2705 Use many-to-one when: - Document is a single entity (e.g., one invoice spanning multiple pages) - Pages are continuation of same content - You need document-wide context - You want a single consolidated result - Document has cross-page relationships</p> <p>\u274c Don't use many-to-one when: - Each page is independent - Pages have different structures - You need page-level tracking - Pages represent separate entities</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#example-use-cases_1","title":"Example Use Cases","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-1-multi-page-invoice","title":"Use Case 1: Multi-Page Invoice","text":"<pre><code># Single invoice spanning 3 pages\nconfig = PipelineConfig(\n    source=\"invoice_multipage.pdf\",  # 1 invoice, 3 pages\n    template=\"my_templates.Invoice\",\n    processing_mode=\"many-to-one\"  # Merge all pages\n)\n</code></pre> <p>Result: 1 Invoice model with data from all pages</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-2-research-paper","title":"Use Case 2: Research Paper","text":"<pre><code># Research paper with 15 pages\nconfig = PipelineConfig(\n    source=\"research_paper.pdf\",  # 1 paper, 15 pages\n    template=\"my_templates.Research\",\n    processing_mode=\"many-to-one\"  # Single paper entity\n)\n</code></pre> <p>Result: 1 Research model</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-3-contract-document","title":"Use Case 3: Contract Document","text":"<pre><code># Contract with 20 pages\nconfig = PipelineConfig(\n    source=\"contract.pdf\",  # 1 contract, 20 pages\n    template=\"my_templates.Contract\",\n    processing_mode=\"many-to-one\"  # Single contract\n)\n</code></pre> <p>Result: 1 Contract model</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#graph-structure_1","title":"Graph Structure","text":"<p>Many-to-one creates single root node:</p> <pre><code>Invoice-001 (node)\n  \u251c\u2500 ISSUED_BY \u2192 Organization-A\n  \u251c\u2500 SENT_TO \u2192 Client-A\n  \u251c\u2500 CONTAINS_ITEM \u2192 LineItem-1\n  \u251c\u2500 CONTAINS_ITEM \u2192 LineItem-2\n  \u2514\u2500 CONTAINS_ITEM \u2192 LineItem-3\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#performance-characteristics_1","title":"Performance Characteristics","text":"<pre><code>Document: 10-page PDF\n\nMany-to-One Processing:\n- Extractions: 1 (whole document)\n- Time: ~30 seconds (single extraction)\n- Memory: Higher (all pages in context)\n- Output: 1 merged model\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#detailed-comparison","title":"Detailed Comparison","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#processing-flow","title":"Processing Flow","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#one-to-one-flow","title":"One-to-One Flow","text":"<pre><code>1. Convert PDF to pages\n2. For each page:\n   a. Convert to markdown\n   b. Extract with LLM\n   c. Create model instance\n3. Return list of models\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#many-to-one-flow","title":"Many-to-One Flow","text":"<pre><code>1. Convert PDF to markdown (all pages)\n2. Chunk markdown if needed\n3. Extract from chunks\n4. Merge chunk results\n5. Return single model\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#context-handling","title":"Context Handling","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#one-to-one-context","title":"One-to-One Context","text":"<pre><code># Each page has isolated context\nPage 1: \"Invoice #001, Total: $100\"\nPage 2: \"Invoice #002, Total: $200\"\nPage 3: \"Invoice #003, Total: $300\"\n\n# Result: 3 separate invoices\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#many-to-one-context","title":"Many-to-One Context","text":"<pre><code># All pages share context\nPage 1: \"Invoice #001\"\nPage 2: \"Line items continued...\"\nPage 3: \"Total: $1000\"\n\n# Result: 1 invoice with all information\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#memory-usage","title":"Memory Usage","text":"<pre><code>Document: 100-page PDF\n\nOne-to-One:\n- Peak memory: ~2GB (one page at a time)\n- Sustained: Low (sequential)\n\nMany-to-One:\n- Peak memory: ~8GB (all pages loaded)\n- Sustained: High (full document)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#choosing-the-right-mode","title":"Choosing the Right Mode","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#decision-tree","title":"Decision Tree","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A(\"Start\")\n\n    B{\"Are pages&lt;br/&gt;independent?\"}\n    D{\"Single entity&lt;br/&gt;across pages?\"}\n    F{\"Need page-level&lt;br/&gt;tracking?\"}\n\n    C@{ shape: tag-proc, label: \"One-to-One\" }\n    E@{ shape: tag-proc, label: \"Many-to-One\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n\n    B -- Yes --&gt; C\n    B -- No --&gt; D\n\n    D -- Yes --&gt; E\n    D -- No --&gt; F\n\n    F -- Yes --&gt; C\n    F -- No --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B,D,F decision\n    class C,E output</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#by-document-type","title":"By Document Type","text":"Document Type Recommended Mode Reason Single Invoice (multi-page) Many-to-One Single entity Batch Invoices (1 per page) One-to-One Independent pages Research Paper Many-to-One Single document Form Collection One-to-One Independent forms Contract Many-to-One Single contract ID Card Batch One-to-One Independent IDs Report Many-to-One Single report Receipt Stack One-to-One Independent receipts"},{"location":"fundamentals/pipeline-configuration/processing-modes/#mode-specific-configuration","title":"Mode-Specific Configuration","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#one-to-one-configuration","title":"One-to-One Configuration","text":"<pre><code>config = PipelineConfig(\n    source=\"batch.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"one-to-one\",\n\n    # One-to-one specific settings\n    export_per_page_markdown=True,  # Export markdown per page\n    use_chunking=False  # No chunking needed (pages are small)\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#many-to-one-configuration","title":"Many-to-One Configuration","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"many-to-one\",\n\n    # Many-to-one specific settings\n    use_chunking=True,  # Enable chunking for large docs\n    llm_consolidation=True,  # Merge results with LLM\n    max_batch_size=5  # Process chunks in batches\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#switching-between-modes","title":"Switching Between Modes","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#from-many-to-one-to-one-to-one","title":"From Many-to-One to One-to-One","text":"<pre><code># Original: many-to-one\nconfig_many = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"many-to-one\"\n)\n\n# Switch to one-to-one\nconfig_one = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"one-to-one\",  # Change mode\n    export_per_page_markdown=True  # Add page-specific export\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#from-one-to-one-to-many-to-one","title":"From One-to-One to Many-to-One","text":"<pre><code># Original: one-to-one\nconfig_one = PipelineConfig(\n    source=\"batch.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"one-to-one\"\n)\n\n# Switch to many-to-one\nconfig_many = PipelineConfig(\n    source=\"batch.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"many-to-one\",  # Change mode\n    use_chunking=True,  # Enable chunking\n    llm_consolidation=True  # Enable consolidation\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#common-patterns","title":"Common Patterns","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#pattern-1-batch-processing-with-one-to-one","title":"Pattern 1: Batch Processing with One-to-One","text":"<pre><code># Process batch of documents\nconfig = PipelineConfig(\n    source=\"invoices_batch.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"one-to-one\",\n    export_per_page_markdown=True\n)\n\n# Result: One invoice per page\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#pattern-2-single-document-with-many-to-one","title":"Pattern 2: Single Document with Many-to-One","text":"<pre><code># Process single multi-page document\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"my_templates.Contract\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    llm_consolidation=True\n)\n\n# Result: One contract with all pages\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#pattern-3-conditional-mode-selection","title":"Pattern 3: Conditional Mode Selection","text":"<pre><code>def get_processing_mode(page_count: int, is_batch: bool):\n    \"\"\"Choose mode based on document characteristics.\"\"\"\n    if is_batch:\n        return \"one-to-one\"\n    elif page_count &gt; 10:\n        return \"many-to-one\"  # Use chunking for large docs\n    else:\n        return \"many-to-one\"  # Small doc, process as one\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=get_processing_mode(page_count=15, is_batch=False)\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#1-match-mode-to-document-structure","title":"1. Match Mode to Document Structure","text":"<pre><code># \u2705 Good - Mode matches document structure\nif document_is_batch:\n    mode = \"one-to-one\"\nelse:\n    mode = \"many-to-one\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=mode\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#2-enable-appropriate-settings","title":"2. Enable Appropriate Settings","text":"<pre><code># \u2705 Good - Settings match mode\nif mode == \"one-to-one\":\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"my_templates.Invoice\",\n        processing_mode=\"one-to-one\",\n        export_per_page_markdown=True  # Page-specific\n    )\nelse:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"my_templates.Invoice\",\n        processing_mode=\"many-to-one\",\n        use_chunking=True,  # Document-wide\n        llm_consolidation=True\n    )\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#3-consider-performance","title":"3. Consider Performance","text":"<pre><code># \u2705 Good - Consider document size\nif page_count &gt; 50:\n    # Large batch: one-to-one might be slow\n    print(\"Warning: Processing 50+ pages individually\")\n\nconfig = PipelineConfig(\n    source=\"large_batch.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"one-to-one\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#next-steps","title":"Next Steps","text":"<p>Now that you understand processing modes:</p> <ol> <li>Docling Settings \u2192 - Configure document conversion</li> <li>Export Configuration - Set output formats</li> <li>Configuration Examples - See complete scenarios</li> </ol>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#one-to-one-mode_1","title":"One-to-One Mode","text":"<pre><code>config = PipelineConfig(\n    source=\"batch.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"one-to-one\"\n)\n</code></pre> <p>Use for: Independent pages, batch processing, page-level tracking</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#many-to-one-mode_1","title":"Many-to-One Mode","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    processing_mode=\"many-to-one\"  # Default\n)\n</code></pre> <p>Use for: Single entity, multi-page documents, document-wide context</p>"},{"location":"fundamentals/schema-definition/","title":"Schema Definition: Pydantic Templates","text":""},{"location":"fundamentals/schema-definition/#overview","title":"Overview","text":"<p>Pydantic templates are the foundation of knowledge graph extraction in Docling Graph. They serve three critical purposes:</p> <ol> <li>LLM Guidance - Field descriptions and examples guide the language model to extract accurate, structured data</li> <li>Data Validation - Field validators ensure data quality and consistency</li> <li>Graph Structure - Models define nodes, edges, and relationships for the knowledge graph</li> </ol>"},{"location":"fundamentals/schema-definition/#what-youll-learn","title":"What You'll Learn","text":"<p>This section provides a complete guide to creating Pydantic templates optimized for LLM-based document extraction and automatic conversion to knowledge graphs.</p>"},{"location":"fundamentals/schema-definition/#section-contents","title":"Section Contents","text":"Document Description Time Template Basics File structure, imports, and the <code>edge()</code> helper 10 min Entities vs Components Critical distinction for graph construction 15 min Field Definitions Field types, descriptions, and examples 20 min Relationships Edge definitions and graph relationships 15 min Validation Validators and data normalization 20 min Advanced Patterns Complex patterns and reusable components 25 min Best Practices Template creation checklist and testing 10 min <p>Total Time: ~2 hours</p>"},{"location":"fundamentals/schema-definition/#quick-example","title":"Quick Example","text":"<p>Here's a minimal template showing the key concepts:</p> <pre><code>\"\"\"Invoice extraction template.\"\"\"\n\nfrom typing import Any, List\nfrom pydantic import BaseModel, ConfigDict, Field\n\n# Required: Edge helper function\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    \"\"\"Helper to create graph edges.\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# Component: Deduplicated by content\nclass Address(BaseModel):\n    \"\"\"Physical address (value object).\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street: str = Field(\n        description=\"Street name and number\",\n        examples=[\"123 Main St\", \"45 Avenue des Champs-\u00c9lys\u00e9es\"]\n    )\n    city: str = Field(\n        description=\"City name\",\n        examples=[\"Paris\", \"London\"]\n    )\n\n# Entity: Unique by name\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(\n        description=\"Legal organization name\",\n        examples=[\"Acme Corp\", \"Tech Solutions Ltd\"]\n    )\n\n    # Edge to Address component\n    located_at: Address = edge(\n        label=\"LOCATED_AT\",\n        description=\"Organization's physical address\"\n    )\n\n# Root document\nclass Invoice(BaseModel):\n    \"\"\"Invoice document.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n\n    invoice_number: str = Field(\n        description=\"Unique invoice identifier\",\n        examples=[\"INV-2024-001\", \"12345\"]\n    )\n\n    # Edge to Organization entity\n    issued_by: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Organization that issued this invoice\"\n    )\n</code></pre> <p>Key Concepts Shown: \u2705 <code>edge()</code> helper function for relationships \u2705 Component with <code>is_entity=False</code> (Address) \u2705 Entity with <code>graph_id_fields</code> (Organization, Invoice) \u2705 Clear field descriptions and examples \u2705 Graph relationships via <code>edge()</code> calls</p>"},{"location":"fundamentals/schema-definition/#why-pydantic-for-knowledge-graphs","title":"Why Pydantic for Knowledge Graphs?","text":""},{"location":"fundamentals/schema-definition/#1-type-safety-and-validation","title":"1. Type Safety and Validation","text":"<p>Pydantic provides automatic type checking and validation:</p> <pre><code>class MonetaryAmount(BaseModel):\n    value: float = Field(...)\n    currency: str = Field(...)\n\n    @field_validator(\"value\")\n    @classmethod\n    def validate_positive(cls, v: Any) -&gt; Any:\n        if v &lt; 0:\n            raise ValueError(\"Amount must be non-negative\")\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/#2-llm-friendly-schema","title":"2. LLM-Friendly Schema","text":"<p>Field descriptions and examples guide the LLM:</p> <pre><code>date_of_birth: date = Field(\n    description=(\n        \"Person's date of birth. \"\n        \"Look for 'Date of birth', 'Date de naiss.', or 'Born on'. \"\n        \"Parse formats like 'DD MM YYYY' and normalize to YYYY-MM-DD.\"\n    ),\n    examples=[\"1990-05-15\", \"1985-12-20\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/#3-automatic-graph-conversion","title":"3. Automatic Graph Conversion","text":"<p>The pipeline automatically converts Pydantic models to knowledge graphs:</p> <pre><code>Invoice (node)\n  \u251c\u2500 ISSUED_BY \u2192 Organization (node)\n  \u2502               \u2514\u2500 LOCATED_AT \u2192 Address (node)\n  \u2514\u2500 SENT_TO \u2192 Client (node)\n                \u2514\u2500 LIVES_AT \u2192 Address (node)\n</code></pre>"},{"location":"fundamentals/schema-definition/#core-terminology","title":"Core Terminology","text":"Term Definition Example Entity Unique, identifiable object tracked individually Person, Organization, Document Component Value object deduplicated by content Address, MonetaryAmount, Measurement Node Any Pydantic model that becomes a graph node All BaseModel subclasses Edge Relationship between nodes <code>ISSUED_BY</code>, <code>LOCATED_AT</code>, <code>CONTAINS_ITEM</code> graph_id_fields Fields used to create stable, unique node IDs <code>[\"name\"]</code>, <code>[\"first_name\", \"last_name\"]</code>"},{"location":"fundamentals/schema-definition/#template-examples-by-domain","title":"Template Examples by Domain","text":"<p>Docling Graph includes production-ready templates for various domains:</p>"},{"location":"fundamentals/schema-definition/#invoice-template","title":"\ud83d\udcc4 Invoice Template","text":"<ul> <li>Entities: Invoice, Organization, Client</li> <li>Components: Address, LineItem</li> <li>Use Case: Financial document processing</li> </ul>"},{"location":"fundamentals/schema-definition/#id-card-template","title":"\ud83c\udd94 ID Card Template","text":"<ul> <li>Entities: IDCard, Person</li> <li>Components: Address</li> <li>Use Case: Identity document extraction</li> </ul>"},{"location":"fundamentals/schema-definition/#research-paper-template","title":"\ud83d\udd2c Research Paper Template","text":"<ul> <li>Entities: Research, Experiment, Material</li> <li>Components: Measurement, VibrationParameter</li> <li>Use Case: Scientific literature mining</li> </ul>"},{"location":"fundamentals/schema-definition/#insurance-template","title":"\ud83c\udfe5 Insurance Template","text":"<ul> <li>Entities: InsuranceTerms, InsurancePlan, Guarantee</li> <li>Components: MonetaryAmount, Address</li> <li>Use Case: Insurance document analysis</li> </ul> <p>Location: <code>docs/examples/templates/</code></p>"},{"location":"fundamentals/schema-definition/#prerequisites","title":"Prerequisites","text":"<p>Before creating templates, ensure you have:</p> <p>\u2705 Python 3.10+ installed \u2705 Docling Graph installed (<code>uv sync --extra all</code>) \u2705 Basic Pydantic knowledge (recommended but not required) \u2705 Understanding of your domain (document types, entities, relationships)</p>"},{"location":"fundamentals/schema-definition/#learning-path","title":"Learning Path","text":""},{"location":"fundamentals/schema-definition/#beginner-path-start-here","title":"Beginner Path (Start Here)","text":"<ol> <li>Template Basics - Learn file structure and imports</li> <li>Entities vs Components - Understand the critical distinction</li> <li>Field Definitions - Master field descriptions and examples</li> <li>Best Practices - Follow the checklist</li> </ol>"},{"location":"fundamentals/schema-definition/#advanced-path","title":"Advanced Path","text":"<ol> <li>Relationships - Complex edge patterns</li> <li>Validation - Custom validators and normalization</li> <li>Advanced Patterns - Reusable components and complex structures</li> </ol>"},{"location":"fundamentals/schema-definition/#common-questions","title":"Common Questions","text":""},{"location":"fundamentals/schema-definition/#q-do-i-need-to-know-pydantic","title":"Q: Do I need to know Pydantic?","text":"<p>A: Basic knowledge helps, but this guide covers everything you need. Pydantic is intuitive and well-documented.</p>"},{"location":"fundamentals/schema-definition/#q-can-i-use-existing-pydantic-models","title":"Q: Can I use existing Pydantic models?","text":"<p>A: Yes! Add <code>graph_id_fields</code> or <code>is_entity=False</code> to <code>model_config</code>, and use the <code>edge()</code> helper for relationships.</p>"},{"location":"fundamentals/schema-definition/#q-how-do-i-choose-between-entity-and-component","title":"Q: How do I choose between Entity and Component?","text":"<p>A: Ask: \"Should this be tracked individually?\" If yes \u2192 Entity. If it's a shared value \u2192 Component. See Entities vs Components.</p>"},{"location":"fundamentals/schema-definition/#q-what-if-my-domain-is-complex","title":"Q: What if my domain is complex?","text":"<p>A: Start simple with core entities, then add complexity. See Advanced Patterns for nested structures.</p>"},{"location":"fundamentals/schema-definition/#next-steps","title":"Next Steps","text":"<p>Ready to create your first template?</p> <ol> <li>Template Basics \u2192 - Learn the required structure</li> <li>Examples - See complete working examples</li> <li>Pipeline Configuration - Configure extraction after creating templates</li> </ol>"},{"location":"fundamentals/schema-definition/#additional-resources","title":"Additional Resources","text":"<ul> <li>Pydantic Documentation - Official Pydantic docs</li> <li>Example Templates - Production-ready templates</li> <li>API Reference - PipelineConfig and model details</li> </ul>"},{"location":"fundamentals/schema-definition/advanced-patterns/","title":"Advanced Patterns","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#overview","title":"Overview","text":"<p>This guide covers advanced Pydantic patterns for complex document structures, reusable components, and sophisticated validation scenarios. These patterns are drawn from production templates across multiple domains.</p> <p>In this guide: - Flexible measurement models - Nested list patterns with edges - Multiple address support - Optional edges and conditional fields - Reusable component library</p>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-1-flexible-measurement-with-range-support","title":"Pattern 1: Flexible Measurement with Range Support","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge","title":"The Challenge","text":"<p>Scientific and technical documents often contain measurements in various formats: - Single values: \"25\u00b0C\", \"1.6 mPa.s\" - Ranges: \"80-90\u00b0C\", \"1.5-2.0 mm\" - Text values: \"High\", \"Low\", \"Stable\"</p>"},{"location":"fundamentals/schema-definition/advanced-patterns/#the-solution","title":"The Solution","text":"<pre><code>from typing import Union, Optional, Self\nfrom pydantic import BaseModel, ConfigDict, Field, model_validator\n\nclass Measurement(BaseModel):\n    \"\"\"\n    Flexible measurement supporting single values, ranges, or text.\n    Can represent '25\u00b0C', '1.6 mPa.s', '80-90\u00b0C', or 'High'.\n    \"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    name: str = Field(\n        description=\"Name of the measured property\",\n        examples=[\"Temperature\", \"Viscosity\", \"pH\", \"Concentration\"]\n    )\n\n    text_value: Optional[str] = Field(\n        default=None,\n        description=\"Textual value if not numerical\",\n        examples=[\"High\", \"Low\", \"Stable\", \"Increasing\"]\n    )\n\n    numeric_value: Optional[Union[float, int]] = Field(\n        default=None,\n        description=\"Single numerical value\",\n        examples=[25.0, 1.6, 8.2]\n    )\n\n    numeric_value_min: Optional[Union[float, int]] = Field(\n        default=None,\n        description=\"Minimum value for range measurements\",\n        examples=[80.0, 1.5]\n    )\n\n    numeric_value_max: Optional[Union[float, int]] = Field(\n        default=None,\n        description=\"Maximum value for range measurements\",\n        examples=[90.0, 2.0]\n    )\n\n    unit: Optional[str] = Field(\n        default=None,\n        description=\"Unit of measurement\",\n        examples=[\"\u00b0C\", \"mPa.s\", \"wt%\", \"kg\"]\n    )\n\n    condition: Optional[str] = Field(\n        default=None,\n        description=\"Measurement conditions or context\",\n        examples=[\"at 25\u00b0C\", \"after 24h\", \"under normal pressure\"]\n    )\n\n    @model_validator(mode=\"after\")\n    def validate_value_consistency(self) -&gt; Self:\n        \"\"\"Ensure value fields don't conflict.\"\"\"\n        has_single = self.numeric_value is not None\n        has_min = self.numeric_value_min is not None\n        has_max = self.numeric_value_max is not None\n\n        # Reject ambiguous cases\n        if has_single and has_min and has_max:\n            raise ValueError(\n                \"Cannot specify all three: numeric_value, \"\n                \"numeric_value_min, and numeric_value_max\"\n            )\n\n        # Allow implicit range: if numeric_value + min/max, treat as range\n        if has_single and (has_min or has_max):\n            if has_max and not has_min:\n                # Treat numeric_value as min\n                self.numeric_value_min = self.numeric_value\n                self.numeric_value = None\n            elif has_min and not has_max:\n                # Treat numeric_value as max\n                self.numeric_value_max = self.numeric_value\n                self.numeric_value = None\n\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#usage-examples","title":"Usage Examples","text":"<pre><code># Single value\ntemp = Measurement(\n    name=\"Temperature\",\n    numeric_value=25.0,\n    unit=\"\u00b0C\"\n)\n\n# Range\ntemp_range = Measurement(\n    name=\"Temperature\",\n    numeric_value_min=80.0,\n    numeric_value_max=90.0,\n    unit=\"\u00b0C\"\n)\n\n# Text value\nquality = Measurement(\n    name=\"Quality\",\n    text_value=\"High\"\n)\n\n# With condition\nviscosity = Measurement(\n    name=\"Viscosity\",\n    numeric_value=1.6,\n    unit=\"mPa.s\",\n    condition=\"at 25\u00b0C\"\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-2-nested-list-with-edges","title":"Pattern 2: Nested List with Edges","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_1","title":"The Challenge","text":"<p>Complex documents have nested structures where list items themselves have relationships:</p> <pre><code>Assembly\n  \u2514\u2500 Components (list)\n      \u251c\u2500 Material (edge)\n      \u251c\u2500 Role\n      \u2514\u2500 Amount (edge)\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#the-solution_1","title":"The Solution","text":"<pre><code>from typing import Any, List\nfrom pydantic import BaseModel, ConfigDict, Field\nfrom enum import Enum\n\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\nclass RoleEnum(str, Enum):\n    PRIMARY = \"Primary\"\n    SECONDARY = \"Secondary\"\n    ADDITIVE = \"Additive\"\n\nclass Material(BaseModel):\n    \"\"\"Material entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(\n        description=\"Material name\",\n        examples=[\"Steel\", \"Aluminum\", \"Polymer\"]\n    )\n\n    grade: Optional[str] = Field(\n        None,\n        description=\"Material grade or specification\",\n        examples=[\"304\", \"6061\", \"ABS\"]\n    )\n\nclass Component(BaseModel):\n    \"\"\"Component with material, role, and amount.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"material\", \"role\"])\n\n    # Edge to Material entity\n    material: Material = edge(\n        label=\"USES_MATERIAL\",\n        description=\"The material used in this component\"\n    )\n\n    role: RoleEnum = Field(\n        description=\"Function of this component\",\n        examples=[\"Primary\", \"Secondary\", \"Additive\"]\n    )\n\n    # Edge to Measurement component\n    amount: Optional[Measurement] = edge(\n        label=\"HAS_AMOUNT\",\n        description=\"Amount specification\"\n    )\n\nclass Assembly(BaseModel):\n    \"\"\"Root assembly containing components.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"assembly_id\"])\n\n    assembly_id: str = Field(...)\n\n    # List edge to Component entities\n    components: List[Component] = edge(\n        label=\"HAS_COMPONENT\",\n        default_factory=list,\n        description=\"List of components in this assembly\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#graph-structure","title":"Graph Structure","text":"<pre><code>Assembly-001\n  \u251c\u2500 HAS_COMPONENT \u2192 Component-1\n  \u2502                   \u251c\u2500 USES_MATERIAL \u2192 Material(Steel)\n  \u2502                   \u2514\u2500 HAS_AMOUNT \u2192 Measurement(12.0 kg)\n  \u2514\u2500 HAS_COMPONENT \u2192 Component-2\n                      \u251c\u2500 USES_MATERIAL \u2192 Material(Aluminum)\n                      \u2514\u2500 HAS_AMOUNT \u2192 Measurement(5.0 kg)\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-3-multiple-address-support","title":"Pattern 3: Multiple Address Support","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_2","title":"The Challenge","text":"<p>Entities often have multiple addresses (home, work, billing, shipping):</p> <pre><code>class Entity(BaseModel):\n    \"\"\"Entity that may have multiple addresses.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n\n    # Support multiple addresses\n    addresses: List[Address] = edge(\n        label=\"LOCATED_AT\",\n        default_factory=list,\n        description=\"Physical addresses (headquarters, branches, etc.)\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#enhanced-with-address-types","title":"Enhanced with Address Types","text":"<pre><code>from enum import Enum\n\nclass AddressType(str, Enum):\n    HOME = \"Home\"\n    WORK = \"Work\"\n    BILLING = \"Billing\"\n    SHIPPING = \"Shipping\"\n    HEADQUARTERS = \"Headquarters\"\n    BRANCH = \"Branch\"\n\nclass TypedAddress(BaseModel):\n    \"\"\"Address with type classification.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    address_type: AddressType = Field(\n        description=\"Type of address\",\n        examples=[\"Home\", \"Work\", \"Billing\"]\n    )\n\n    street_address: Optional[str] = Field(None)\n    city: Optional[str] = Field(None)\n    postal_code: Optional[str] = Field(None)\n    country: Optional[str] = Field(None)\n\nclass Organization(BaseModel):\n    \"\"\"Organization with typed addresses.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n\n    addresses: List[TypedAddress] = edge(\n        label=\"LOCATED_AT\",\n        default_factory=list,\n        description=\"Physical addresses with types\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-4-optional-edges","title":"Pattern 4: Optional Edges","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_3","title":"The Challenge","text":"<p>Some relationships are conditional - they may or may not exist:</p> <pre><code>class Document(BaseModel):\n    \"\"\"Document that may or may not have a verifier.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_id\"])\n\n    document_id: str = Field(...)\n\n    # Required edge\n    issued_by: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Organization that issued this document\"\n    )\n\n    # Optional edge - document may not be verified\n    verified_by: Optional[Person] = edge(\n        label=\"VERIFIED_BY\",\n        description=\"Person who verified this document, if verified\"\n    )\n\n    # Optional edge - document may not be approved\n    approved_by: Optional[Person] = edge(\n        label=\"APPROVED_BY\",\n        description=\"Person who approved this document, if approved\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#graph-behavior","title":"Graph Behavior","text":"<pre><code># Verified document\nDocument-001 --ISSUED_BY--&gt; Org-A\nDocument-001 --VERIFIED_BY--&gt; Person-A\n\n# Unverified document\nDocument-002 --ISSUED_BY--&gt; Org-B\n# No VERIFIED_BY edge\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-5-conditional-fields-with-validators","title":"Pattern 5: Conditional Fields with Validators","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_4","title":"The Challenge","text":"<p>Some fields are only relevant for certain document types:</p> <pre><code>class Document(BaseModel):\n    \"\"\"Document with type-specific fields.\"\"\"\n\n    document_type: str = Field(\n        description=\"Type of document\",\n        examples=[\"Invoice\", \"Receipt\", \"Credit Note\"]\n    )\n\n    # Field only relevant for invoices\n    payment_terms: Optional[str] = Field(\n        None,\n        description=\"Payment terms (primarily for invoices)\",\n        examples=[\"Net 30\", \"Due on receipt\", \"Net 60\"]\n    )\n\n    # Field only relevant for credit notes\n    original_document_ref: Optional[str] = Field(\n        None,\n        description=\"Reference to original document (for credit notes)\",\n        examples=[\"INV-2024-001\", \"DOC-123456\"]\n    )\n\n    @model_validator(mode=\"after\")\n    def validate_type_specific_fields(self) -&gt; Self:\n        \"\"\"Validate fields based on document type.\"\"\"\n        if self.document_type == \"Invoice\":\n            if not self.payment_terms:\n                # Could warn or set default\n                self.payment_terms = \"Net 30\"\n\n        if self.document_type == \"Credit Note\":\n            if not self.original_document_ref:\n                raise ValueError(\n                    \"original_document_ref required for Credit Note\"\n                )\n\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-6-polymorphic-fields","title":"Pattern 6: Polymorphic Fields","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_5","title":"The Challenge","text":"<p>A field might accept multiple types:</p> <pre><code>class FlexibleValue(BaseModel):\n    \"\"\"Value that can be numeric or textual.\"\"\"\n\n    value: Union[str, int, float] = Field(\n        ...,\n        description=(\n            \"Value can be numeric (int/float) or textual. \"\n            \"Extract as-is: '100', '25.5', or 'High'.\"\n        ),\n        examples=[100, 25.5, \"High\", \"Medium\"]\n    )\n\n    @field_validator(\"value\", mode=\"before\")\n    @classmethod\n    def coerce_value(cls, v: Any) -&gt; Any:\n        \"\"\"Try to convert to number if possible.\"\"\"\n        if isinstance(v, str):\n            # Try numeric conversion\n            try:\n                if \".\" in v:\n                    return float(v)\n                return int(v)\n            except ValueError:\n                # Keep as string\n                return v\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-7-hierarchical-structures","title":"Pattern 7: Hierarchical Structures","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_6","title":"The Challenge","text":"<p>Documents with nested sections or chapters:</p> <pre><code>class Section(BaseModel):\n    \"\"\"Document section.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"section_number\"])\n\n    section_number: str = Field(...)\n    title: str = Field(...)\n    content: str = Field(...)\n\n    # Recursive: sections can contain subsections\n    subsections: List[\"Section\"] = edge(\n        label=\"HAS_SUBSECTION\",\n        default_factory=list,\n        description=\"Nested subsections\"\n    )\n\nclass Document(BaseModel):\n    \"\"\"Document with hierarchical structure.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_id\"])\n\n    document_id: str = Field(...)\n\n    sections: List[Section] = edge(\n        label=\"HAS_SECTION\",\n        default_factory=list,\n        description=\"Top-level sections\"\n    )\n</code></pre> <p>Note: Pydantic requires forward references for recursive models. Use string quotes for the type hint.</p>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-8-reusable-component-library","title":"Pattern 8: Reusable Component Library","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#common-components","title":"Common Components","text":"<p>Build a library of reusable components:</p> <pre><code># --- Address Component ---\nclass Address(BaseModel):\n    \"\"\"Physical address component (deduplicated by content).\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street_address: Optional[str] = Field(None)\n    city: Optional[str] = Field(None)\n    state_or_province: Optional[str] = Field(None)\n    postal_code: Optional[str] = Field(None)\n    country: Optional[str] = Field(None)\n\n    def __str__(self) -&gt; str:\n        parts = [\n            self.street_address,\n            self.city,\n            self.state_or_province,\n            self.postal_code,\n            self.country\n        ]\n        return \", \".join(p for p in parts if p)\n\n# --- Monetary Amount Component ---\nclass MonetaryAmount(BaseModel):\n    \"\"\"Monetary value with currency (deduplicated by content).\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    value: float = Field(...)\n    currency: Optional[str] = Field(None)\n\n    @field_validator(\"value\")\n    @classmethod\n    def validate_positive(cls, v: Any) -&gt; Any:\n        if v &lt; 0:\n            raise ValueError(\"Amount must be non-negative\")\n        return v\n\n    @field_validator(\"currency\")\n    @classmethod\n    def validate_currency_format(cls, v: Any) -&gt; Any:\n        if v and not (len(v) == 3 and v.isupper()):\n            raise ValueError(\"Currency must be 3 uppercase letters (ISO 4217)\")\n        return v\n\n    def __str__(self) -&gt; str:\n        return f\"{self.value} {self.currency or ''}\".strip()\n\n# --- Contact Information Component ---\nclass ContactInfo(BaseModel):\n    \"\"\"Contact information component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    email: Optional[str] = Field(None)\n    phone: Optional[str] = Field(None)\n    website: Optional[str] = Field(None)\n\n    @field_validator(\"email\", mode=\"before\")\n    @classmethod\n    def normalize_email(cls, v: Any) -&gt; Any:\n        if v:\n            return v.lower().strip()\n        return v\n\n# --- Date Range Component ---\nclass DateRange(BaseModel):\n    \"\"\"Date range component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    start_date: Optional[date] = Field(None)\n    end_date: Optional[date] = Field(None)\n\n    @model_validator(mode=\"after\")\n    def validate_date_order(self) -&gt; Self:\n        if self.start_date and self.end_date:\n            if self.end_date &lt; self.start_date:\n                raise ValueError(\"end_date must be after start_date\")\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#common-entities","title":"Common Entities","text":"<pre><code># --- Person Entity ---\nclass Person(BaseModel):\n    \"\"\"Person entity (unique by name and date of birth).\"\"\"\n    model_config = ConfigDict(\n        graph_id_fields=[\"first_name\", \"last_name\", \"date_of_birth\"]\n    )\n\n    first_name: Optional[str] = Field(None)\n    last_name: Optional[str] = Field(None)\n    date_of_birth: Optional[date] = Field(None)\n\n    contact: Optional[ContactInfo] = Field(None)\n\n    addresses: List[Address] = edge(\n        label=\"LIVES_AT\",\n        default_factory=list,\n        description=\"Residential addresses\"\n    )\n\n    def __str__(self) -&gt; str:\n        parts = [self.first_name, self.last_name]\n        return \" \".join(p for p in parts if p) or \"Unknown\"\n\n# --- Organization Entity ---\nclass Organization(BaseModel):\n    \"\"\"Organization entity (unique by name).\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n    tax_id: Optional[str] = Field(None)\n\n    contact: Optional[ContactInfo] = Field(None)\n\n    addresses: List[Address] = edge(\n        label=\"LOCATED_AT\",\n        default_factory=list,\n        description=\"Business addresses\"\n    )\n\n    def __str__(self) -&gt; str:\n        return self.name\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-9-string-representations","title":"Pattern 9: String Representations","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#purpose","title":"Purpose","text":"<p>Add <code>__str__</code> methods for debugging, logging, and visualization:</p> <pre><code># Simple concatenation\nclass Person(BaseModel):\n    first_name: Optional[str] = Field(...)\n    last_name: Optional[str] = Field(...)\n\n    def __str__(self) -&gt; str:\n        parts = [self.first_name, self.last_name]\n        return \" \".join(p for p in parts if p) or \"Unknown\"\n\n# With list handling\nclass Person(BaseModel):\n    given_names: Optional[List[str]] = Field(...)\n    last_name: Optional[str] = Field(...)\n\n    def __str__(self) -&gt; str:\n        first_names = \" \".join(self.given_names) if self.given_names else \"\"\n        parts = [first_names, self.last_name]\n        return \" \".join(p for p in parts if p) or \"Unknown\"\n\n# Address formatting\nclass Address(BaseModel):\n    street_address: Optional[str] = Field(...)\n    city: Optional[str] = Field(...)\n    postal_code: Optional[str] = Field(...)\n    country: Optional[str] = Field(...)\n\n    def __str__(self) -&gt; str:\n        parts = [self.street_address, self.city, self.postal_code, self.country]\n        return \", \".join(p for p in parts if p)\n\n# Value with unit\nclass MonetaryAmount(BaseModel):\n    value: float = Field(...)\n    currency: Optional[str] = Field(None)\n\n    def __str__(self) -&gt; str:\n        return f\"{self.value} {self.currency or ''}\".strip()\n\n# With identifier\nclass Document(BaseModel):\n    document_type: str = Field(...)\n    document_number: str = Field(...)\n\n    def __str__(self) -&gt; str:\n        return f\"{self.document_type} {self.document_number}\"\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-10-template-composition","title":"Pattern 10: Template Composition","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_7","title":"The Challenge","text":"<p>Large templates can become unwieldy. Break them into modules:</p> <pre><code># common_components.py\n\"\"\"Reusable components for all templates.\"\"\"\n\nclass Address(BaseModel):\n    \"\"\"Physical address component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    # ... fields\n\nclass MonetaryAmount(BaseModel):\n    \"\"\"Monetary value component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    # ... fields\n\n# common_entities.py\n\"\"\"Reusable entities for all templates.\"\"\"\n\nfrom .common_components import Address\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\"])\n    # ... fields\n    addresses: List[Address] = edge(label=\"LIVES_AT\", default_factory=list)\n\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n    # ... fields\n    addresses: List[Address] = edge(label=\"LOCATED_AT\", default_factory=list)\n\n# invoice_template.py\n\"\"\"Invoice-specific template.\"\"\"\n\nfrom .common_components import Address, MonetaryAmount\nfrom .common_entities import Person, Organization\n\nclass LineItem(BaseModel):\n    \"\"\"Invoice line item.\"\"\"\n    # ... fields\n\nclass Invoice(BaseModel):\n    \"\"\"Invoice document.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n    # ... fields\n    issued_by: Organization = edge(label=\"ISSUED_BY\")\n    sent_to: Person = edge(label=\"SENT_TO\")\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#next-steps","title":"Next Steps","text":"<p>Now that you understand advanced patterns:</p> <ol> <li>Best Practices \u2192 - Complete template checklist</li> <li>Examples - See patterns in production templates</li> <li>Pipeline Configuration - Configure extraction</li> </ol>"},{"location":"fundamentals/schema-definition/advanced-patterns/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-checklist","title":"Pattern Checklist","text":"<ul> <li> Flexible measurements for scientific data</li> <li> Nested lists with edges for complex structures</li> <li> Multiple addresses with optional types</li> <li> Optional edges for conditional relationships</li> <li> Conditional fields with validators</li> <li> Polymorphic fields for flexible values</li> <li> Hierarchical structures for nested content</li> <li> Reusable component library</li> <li> String representations for all entities</li> <li> Template composition for large projects</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/","title":"Best Practices and Checklist","text":""},{"location":"fundamentals/schema-definition/best-practices/#overview","title":"Overview","text":"<p>This guide provides a comprehensive checklist and best practices for creating high-quality Pydantic templates. Use this as a final review before deploying your template.</p> <p>In this guide: - Complete template checklist - Testing your template - Common pitfalls to avoid - Performance considerations - Maintenance tips</p>"},{"location":"fundamentals/schema-definition/best-practices/#complete-template-checklist","title":"Complete Template Checklist","text":""},{"location":"fundamentals/schema-definition/best-practices/#structure-and-organization","title":"\u2705 Structure and Organization","text":"<ul> <li> Module docstring - Clear description of template purpose</li> <li> Standard imports - All necessary imports included</li> <li> Edge helper function - Defined correctly with exact signature</li> <li> Logical organization - Components \u2192 Entities \u2192 Domain Models \u2192 Root</li> <li> Model docstrings - All models have clear docstrings</li> <li> Consistent naming - Follow Python naming conventions</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#entity-configuration","title":"\u2705 Entity Configuration","text":"<ul> <li> graph_id_fields defined - All entities have appropriate ID fields</li> <li> ID fields are stable - Won't change frequently</li> <li> ID fields are likely present - Will be extracted from documents</li> <li> Composite IDs make sense - Multiple fields form natural unique identifier</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#component-configuration","title":"\u2705 Component Configuration","text":"<ul> <li> is_entity=False set - All components marked correctly</li> <li> Appropriate for sharing - Components represent value objects</li> <li> Content-based deduplication - All fields used for uniqueness</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#field-definitions","title":"\u2705 Field Definitions","text":"<ul> <li> Clear descriptions - LLM-friendly with extraction hints</li> <li> Realistic examples - 2-5 diverse examples per field</li> <li> Proper type hints - Optional, List, Union used correctly</li> <li> Appropriate defaults - Required (...), None, or meaningful defaults</li> <li> List fields use default_factory - Never use [] as default</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#edge-definitions","title":"\u2705 Edge Definitions","text":"<ul> <li> Descriptive labels - ALL_CAPS_WITH_UNDERSCORES format</li> <li> Consistent naming - Same pattern across template</li> <li> List edges have default_factory - Required for list relationships</li> <li> Clear descriptions - Explain the relationship</li> <li> Appropriate cardinality - Single vs list chosen correctly</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#validation","title":"\u2705 Validation","text":"<ul> <li> Field validators - Data quality checks where needed</li> <li> Model validators - Cross-field validation implemented</li> <li> Clear error messages - Specific, actionable errors</li> <li> Handle None values - Validators allow None for optional fields</li> <li> Pre-validators for normalization - mode='before' used appropriately</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#string-representations","title":"\u2705 String Representations","text":"<ul> <li> str methods - Defined for entities and key components</li> <li> Handle None values - String methods don't crash on None</li> <li> Meaningful output - Useful for debugging and logging</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#type-hints-and-consistency","title":"\u2705 Type Hints and Consistency","text":"<ul> <li> Proper type hints - All fields have correct types</li> <li> Consistent patterns - Similar fields use similar patterns</li> <li> No duplicate code - Reusable components extracted</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#testing-your-template","title":"Testing Your Template","text":""},{"location":"fundamentals/schema-definition/best-practices/#test-1-basic-instantiation","title":"Test 1: Basic Instantiation","text":"<pre><code># test_template_basic.py\nfrom my_template import Document, Organization, Address\n\ndef test_basic_instantiation():\n    \"\"\"Test that models can be instantiated.\"\"\"\n    doc = Document(\n        document_id=\"TEST-001\",\n        issued_by=Organization(\n            name=\"Test Corp\",\n            located_at=Address(\n                street=\"123 Test St\",\n                city=\"Paris\"\n            )\n        )\n    )\n    assert doc.document_id == \"TEST-001\"\n    assert doc.issued_by.name == \"Test Corp\"\n    print(\"\u2713 Basic instantiation works\")\n\nif __name__ == \"__main__\":\n    test_basic_instantiation()\n</code></pre> <p>Run with: <pre><code>uv run python test_template_basic.py\n</code></pre></p>"},{"location":"fundamentals/schema-definition/best-practices/#test-2-validation","title":"Test 2: Validation","text":"<pre><code># test_template_validation.py\nfrom my_template import MonetaryAmount\nimport pytest\n\ndef test_positive_amount():\n    \"\"\"Test that negative amounts are rejected.\"\"\"\n    with pytest.raises(ValueError, match=\"non-negative\"):\n        MonetaryAmount(value=-100, currency=\"EUR\")\n    print(\"\u2713 Validation works\")\n\ndef test_valid_amount():\n    \"\"\"Test that positive amounts are accepted.\"\"\"\n    amount = MonetaryAmount(value=100, currency=\"EUR\")\n    assert amount.value == 100\n    print(\"\u2713 Valid data accepted\")\n\nif __name__ == \"__main__\":\n    test_positive_amount()\n    test_valid_amount()\n</code></pre> <p>Run with: <pre><code>uv run pytest test_template_validation.py -v\n</code></pre></p>"},{"location":"fundamentals/schema-definition/best-practices/#test-3-serialization","title":"Test 3: Serialization","text":"<pre><code># test_template_serialization.py\nfrom my_template import Document, Organization, Address\nimport json\n\ndef test_json_serialization():\n    \"\"\"Test that models can be serialized to JSON.\"\"\"\n    doc = Document(\n        document_id=\"TEST-001\",\n        issued_by=Organization(\n            name=\"Test Corp\",\n            located_at=Address(\n                street=\"123 Test St\",\n                city=\"Paris\"\n            )\n        )\n    )\n\n    # Serialize to JSON\n    json_str = doc.model_dump_json(indent=2)\n    print(\"\u2713 JSON serialization works\")\n    print(json_str)\n\n    # Deserialize from JSON\n    json_data = json.loads(json_str)\n    doc2 = Document(**json_data)\n    assert doc2.document_id == doc.document_id\n    print(\"\u2713 JSON deserialization works\")\n\nif __name__ == \"__main__\":\n    test_json_serialization()\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#test-4-edge-metadata","title":"Test 4: Edge Metadata","text":"<pre><code># test_template_edges.py\nfrom my_template import Document\n\ndef test_edge_metadata():\n    \"\"\"Test that edge metadata is present.\"\"\"\n    # Get field info\n    fields = Document.model_fields\n\n    # Check issued_by has edge metadata\n    issued_by_field = fields[\"issued_by\"]\n    metadata = issued_by_field.json_schema_extra\n\n    assert metadata is not None\n    assert \"edge_label\" in metadata\n    assert metadata[\"edge_label\"] == \"ISSUED_BY\"\n    print(\"\u2713 Edge metadata present\")\n\nif __name__ == \"__main__\":\n    test_edge_metadata()\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#test-5-end-to-end-extraction","title":"Test 5: End-to-End Extraction","text":"<pre><code># test_template_extraction.py\n\"\"\"Test template with actual extraction.\"\"\"\n\ndef test_extraction():\n    \"\"\"Test extraction with a sample document.\"\"\"\n    import subprocess\n\n    result = subprocess.run([\n        \"uv\", \"run\", \"docling-graph\", \"convert\",\n        \"test_document.pdf\",\n        \"--template\", \"my_template.Document\",\n        \"--output-dir\", \"test_output\",\n        \"--backend\", \"llm\",\n        \"--inference\", \"local\"\n    ], capture_output=True, text=True)\n\n    assert result.returncode == 0, f\"Extraction failed: {result.stderr}\"\n    print(\"\u2713 End-to-end extraction works\")\n\nif __name__ == \"__main__\":\n    test_extraction()\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#common-pitfalls-to-avoid","title":"Common Pitfalls to Avoid","text":""},{"location":"fundamentals/schema-definition/best-practices/#pitfall-1-wrong-edge-definition","title":"\u274c Pitfall 1: Wrong edge() Definition","text":"<pre><code># WRONG - Missing **kwargs\ndef edge(label: str) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label})\n\n# CORRECT\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#pitfall-2-missing-default_factory-for-lists","title":"\u274c Pitfall 2: Missing default_factory for Lists","text":"<pre><code># WRONG\nitems: List[Item] = edge(label=\"CONTAINS_ITEM\")\n\n# CORRECT\nitems: List[Item] = edge(\n    label=\"CONTAINS_ITEM\",\n    default_factory=list\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#pitfall-3-mutable-default-values","title":"\u274c Pitfall 3: Mutable Default Values","text":"<pre><code># WRONG - Shared mutable object\nitems: List[str] = Field([])\n\n# CORRECT\nitems: List[str] = Field(default_factory=list)\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#pitfall-4-vague-descriptions","title":"\u274c Pitfall 4: Vague Descriptions","text":"<pre><code># WRONG\nname: str = Field(..., description=\"Name\")\n\n# CORRECT\nname: str = Field(\n    ...,\n    description=(\n        \"Full legal name of the organization. \"\n        \"Look for 'Company Name' or header text. \"\n        \"Include legal suffixes like 'Ltd', 'Inc'.\"\n    ),\n    examples=[\"Acme Corp Ltd\", \"Tech Solutions Inc\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#pitfall-5-inconsistent-edge-labels","title":"\u274c Pitfall 5: Inconsistent Edge Labels","text":"<pre><code># WRONG - Mixed formats\nissued_by: Org = edge(label=\"issuedBy\")\nsent_to: Client = edge(label=\"SENT_TO\")\nhas_items: List[Item] = edge(label=\"contains-item\")\n\n# CORRECT - Consistent ALL_CAPS_WITH_UNDERSCORES\nissued_by: Org = edge(label=\"ISSUED_BY\")\nsent_to: Client = edge(label=\"SENT_TO\")\nhas_items: List[Item] = edge(label=\"CONTAINS_ITEM\")\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#pitfall-6-wrong-entitycomponent-classification","title":"\u274c Pitfall 6: Wrong Entity/Component Classification","text":"<pre><code># WRONG - Address as entity (creates duplicate nodes)\nclass Address(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"street\", \"city\"])\n\n# CORRECT - Address as component (shared nodes)\nclass Address(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#pitfall-7-unstable-id-fields","title":"\u274c Pitfall 7: Unstable ID Fields","text":"<pre><code># WRONG - Email can change\nclass Person(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"email\"])\n\n# CORRECT - Stable fields\nclass Person(BaseModel):\n    model_config = ConfigDict(\n        graph_id_fields=[\"first_name\", \"last_name\", \"date_of_birth\"]\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#pitfall-8-missing-validators","title":"\u274c Pitfall 8: Missing Validators","text":"<pre><code># WRONG - No validation\ncurrency: str = Field(...)\n\n# CORRECT - Validated\ncurrency: str = Field(...)\n\n@field_validator(\"currency\")\n@classmethod\ndef validate_currency(cls, v: Any) -&gt; Any:\n    if v and not (len(v) == 3 and v.isupper()):\n        raise ValueError(\"Currency must be 3 uppercase letters\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#performance-considerations","title":"Performance Considerations","text":""},{"location":"fundamentals/schema-definition/best-practices/#1-keep-templates-focused","title":"1. Keep Templates Focused","text":"<pre><code># \u2705 Good - Focused template\nclass Invoice(BaseModel):\n    \"\"\"Invoice document.\"\"\"\n    # Only invoice-related fields\n\n# \u274c Bad - Kitchen sink template\nclass Document(BaseModel):\n    \"\"\"Generic document.\"\"\"\n    # Hundreds of fields for every document type\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#2-use-appropriate-validators","title":"2. Use Appropriate Validators","text":"<pre><code># \u2705 Good - Simple validation\n@field_validator(\"value\")\n@classmethod\ndef validate_positive(cls, v: Any) -&gt; Any:\n    if v &lt; 0:\n        raise ValueError(\"Must be non-negative\")\n    return v\n\n# \u274c Bad - Complex validation in validator\n@field_validator(\"value\")\n@classmethod\ndef validate_complex(cls, v: Any) -&gt; Any:\n    # Expensive database lookup\n    # Complex calculations\n    # Multiple API calls\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#3-minimize-nested-depth","title":"3. Minimize Nested Depth","text":"<pre><code># \u2705 Good - Reasonable nesting (2-3 levels)\nInvoice \u2192 LineItem \u2192 MonetaryAmount\n\n# \u274c Bad - Excessive nesting (5+ levels)\nDocument \u2192 Section \u2192 Subsection \u2192 Paragraph \u2192 Sentence \u2192 Word\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#maintenance-tips","title":"Maintenance Tips","text":""},{"location":"fundamentals/schema-definition/best-practices/#1-version-your-templates","title":"1. Version Your Templates","text":"<pre><code>\"\"\"\nInvoice extraction template.\n\nVersion: 2.0.0\nLast Updated: 2024-01-15\nChanges:\n  - Added payment_terms field\n  - Updated Organization to include tax_id\n  - Fixed email validation\n\"\"\"\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#2-document-breaking-changes","title":"2. Document Breaking Changes","text":"<pre><code>\"\"\"\nBREAKING CHANGES in v2.0.0:\n- Renamed 'bill_no' to 'invoice_number'\n- Changed 'date' from str to date type\n- Removed deprecated 'legacy_field'\n\"\"\"\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#3-keep-examples-updated","title":"3. Keep Examples Updated","text":"<pre><code># \u2705 Good - Current examples\ninvoice_number: str = Field(\n    ...,\n    description=\"Unique invoice identifier\",\n    examples=[\"INV-2024-001\", \"2024-INV-12345\"]  # Current format\n)\n\n# \u274c Bad - Outdated examples\ninvoice_number: str = Field(\n    ...,\n    description=\"Unique invoice identifier\",\n    examples=[\"INV-2020-001\", \"2020-INV-12345\"]  # Old format\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#4-add-migration-guides","title":"4. Add Migration Guides","text":"<pre><code>\"\"\"\nMigration from v1.x to v2.0:\n\n1. Rename fields:\n   - bill_no \u2192 invoice_number\n   - client \u2192 sent_to\n\n2. Update types:\n   - date: str \u2192 date\n\n3. Add required fields:\n   - payment_terms (default: \"Net 30\")\n\"\"\"\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#template-quality-checklist","title":"Template Quality Checklist","text":""},{"location":"fundamentals/schema-definition/best-practices/#before-deployment","title":"Before Deployment","text":"<ul> <li> All tests pass</li> <li> Template validated with sample documents</li> <li> Edge metadata verified</li> <li> Documentation complete</li> <li> Examples realistic and current</li> <li> No TODO or FIXME comments</li> <li> Code reviewed by team</li> <li> Performance tested with large documents</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#after-deployment","title":"After Deployment","text":"<ul> <li> Monitor extraction quality</li> <li> Collect feedback from users</li> <li> Track common extraction errors</li> <li> Update examples based on real data</li> <li> Refine descriptions based on LLM performance</li> <li> Version and document changes</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#quick-start-template","title":"Quick Start Template","text":"<p>Use this as a starting point for new templates:</p> <pre><code>\"\"\"\n[Template Name] extraction template.\n\nExtracts [key information] from [document type] documents.\n\nVersion: 1.0.0\nLast Updated: [Date]\n\"\"\"\n\nfrom typing import Any, List, Optional\nfrom pydantic import BaseModel, ConfigDict, Field, field_validator\n\n# --- Edge Helper Function (REQUIRED) ---\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    \"\"\"Helper to create graph edges.\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- Components ---\nclass Address(BaseModel):\n    \"\"\"Physical address component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street: str = Field(\n        description=\"Street name and number\",\n        examples=[\"123 Main St\", \"45 Rue de la Paix\"]\n    )\n    city: str = Field(\n        description=\"City name\",\n        examples=[\"Paris\", \"London\"]\n    )\n\n# --- Entities ---\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(\n        description=\"Legal organization name\",\n        examples=[\"Acme Corp\", \"Tech Solutions Ltd\"]\n    )\n\n    located_at: Address = edge(\n        label=\"LOCATED_AT\",\n        description=\"Organization's physical address\"\n    )\n\n# --- Root Document ---\nclass [DocumentName](BaseModel):\n    \"\"\"[Document type] document.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_id\"])\n\n    document_id: str = Field(\n        description=\"Unique document identifier\",\n        examples=[\"DOC-2024-001\", \"12345\"]\n    )\n\n    issued_by: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Organization that issued this document\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/best-practices/#next-steps","title":"Next Steps","text":"<p>Congratulations! You've completed the Schema Definition guide. Now:</p> <ol> <li>Pipeline Configuration \u2192 - Configure extraction settings</li> <li>Examples - See complete working templates</li> <li>Extraction Process - Understand the extraction pipeline</li> </ol>"},{"location":"fundamentals/schema-definition/best-practices/#additional-resources","title":"Additional Resources","text":""},{"location":"fundamentals/schema-definition/best-practices/#documentation","title":"Documentation","text":"<ul> <li>Pydantic Documentation - Official Pydantic docs</li> <li>Template Examples - Production-ready templates</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#example-templates","title":"Example Templates","text":"<ul> <li>Invoice Template - <code>docs/examples/templates/invoice.py</code></li> <li>ID Card Template - <code>docs/examples/templates/id_card.py</code></li> <li>Research Paper Template - <code>docs/examples/templates/rheology_research.py</code></li> <li>Insurance Template - <code>docs/examples/templates/insurance.py</code></li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#community","title":"Community","text":"<ul> <li>GitHub Issues - Report bugs or request features</li> <li>Discussions - Ask questions and share templates</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#final-checklist","title":"Final Checklist","text":"<p>Before moving to Pipeline Configuration, ensure:</p> <p>\u2705 Template structure follows best practices \u2705 All entities have appropriate <code>graph_id_fields</code> \u2705 All components have <code>is_entity=False</code> \u2705 Edge labels are consistent and descriptive \u2705 Field descriptions are LLM-friendly \u2705 Examples are realistic and diverse \u2705 Validators ensure data quality \u2705 Tests pass successfully \u2705 Template tested with sample documents</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/","title":"Entities vs Components","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#overview","title":"Overview","text":"<p>The most critical decision when designing a Pydantic template is classifying each model as either an Entity or a Component. This distinction fundamentally affects how your knowledge graph is constructed and how nodes are deduplicated.</p> <p>In this guide: - Understanding the Entity vs Component distinction - When to use each classification - How to configure <code>graph_id_fields</code> and <code>is_entity</code> - Real-world examples and decision trees</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#the-critical-distinction","title":"The Critical Distinction","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#quick-comparison","title":"Quick Comparison","text":"Aspect Entity Component Purpose Unique, identifiable objects Value objects, content-based deduplication Configuration <code>graph_id_fields=[...]</code> <code>is_entity=False</code> Deduplication By specified ID fields By all field values When to Use Track individually (people, documents, organizations) Shared values (addresses, amounts, measurements) Graph Behavior One node per unique ID combination One node per unique content combination"},{"location":"fundamentals/schema-definition/entities-vs-components/#visual-example","title":"Visual Example","text":"<pre><code># Entity: Person (unique by name + DOB)\nPerson(first_name=\"John\", last_name=\"Doe\", dob=\"1990-01-01\")\nPerson(first_name=\"John\", last_name=\"Doe\", dob=\"1990-01-01\")\n\u2192 Creates 1 node (same ID fields)\n\nPerson(first_name=\"John\", last_name=\"Doe\", dob=\"1991-01-01\")\n\u2192 Creates 2nd node (different DOB)\n\n# Component: Address (unique by content)\nAddress(street=\"123 Main St\", city=\"Paris\")\nAddress(street=\"123 Main St\", city=\"Paris\")\n\u2192 Creates 1 node (identical content)\n\nAddress(street=\"123 Main St\", city=\"London\")\n\u2192 Creates 2nd node (different city)\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#entities-unique-identifiable-objects","title":"Entities: Unique, Identifiable Objects","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#what-is-an-entity","title":"What is an Entity?","text":"<p>An Entity is a model that represents a unique, identifiable object that should be tracked individually in your knowledge graph. Entities are deduplicated based on specific identifying fields.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#configuration","title":"Configuration","text":"<pre><code>class Person(BaseModel):\n    \"\"\"\n    A person entity.\n    Uniquely identified by first name, last name, and date of birth.\n    \"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\", \"date_of_birth\"])\n\n    first_name: Optional[str] = Field(...)\n    last_name: Optional[str] = Field(...)\n    date_of_birth: Optional[date] = Field(...)\n    email: Optional[str] = Field(None)  # Not part of ID\n    phone: Optional[str] = Field(None)  # Not part of ID\n</code></pre> <p>Key Points: - Use <code>graph_id_fields</code> to specify which fields form the unique identifier - Only fields in <code>graph_id_fields</code> are used for deduplication - Other fields can vary without creating new nodes</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#when-to-use-entities","title":"When to Use Entities","text":"<p>Use entities for models that represent:</p> <p>\u2705 People - Individuals with unique identities <pre><code>model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\", \"date_of_birth\"])\n</code></pre></p> <p>\u2705 Organizations - Companies, institutions <pre><code>model_config = ConfigDict(graph_id_fields=[\"name\"])\n</code></pre></p> <p>\u2705 Documents - Invoices, contracts, reports <pre><code>model_config = ConfigDict(graph_id_fields=[\"document_number\"])\n</code></pre></p> <p>\u2705 Products - Items with SKUs or unique identifiers <pre><code>model_config = ConfigDict(graph_id_fields=[\"sku\"])\n</code></pre></p> <p>\u2705 Experiments - Research experiments with IDs <pre><code>model_config = ConfigDict(graph_id_fields=[\"experiment_id\"])\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#choosing-graph_id_fields","title":"Choosing graph_id_fields","text":"<p>Select fields that: 1. Together form a natural unique identifier 2. Are stable (don't change frequently) 3. Are likely to be present in extracted data</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#examples","title":"Examples","text":"<pre><code># Single field ID\nclass Organization(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n    name: str = Field(...)\n\n# Multi-field ID\nclass Person(BaseModel):\n    model_config = ConfigDict(\n        graph_id_fields=[\"first_name\", \"last_name\", \"date_of_birth\"]\n    )\n    first_name: Optional[str] = Field(...)\n    last_name: Optional[str] = Field(...)\n    date_of_birth: Optional[date] = Field(...)\n\n# Complex ID\nclass Measurement(BaseModel):\n    model_config = ConfigDict(\n        graph_id_fields=[\"name\", \"text_value\", \"numeric_value\", \"unit\"]\n    )\n    name: str = Field(...)\n    text_value: Optional[str] = Field(None)\n    numeric_value: Optional[float] = Field(None)\n    unit: Optional[str] = Field(None)\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#entity-examples","title":"Entity Examples","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#example-1-person-entity","title":"Example 1: Person Entity","text":"<pre><code>class Person(BaseModel):\n    \"\"\"\n    Person entity.\n    Uniquely identified by name and date of birth.\n    \"\"\"\n    model_config = ConfigDict(\n        graph_id_fields=[\"first_name\", \"last_name\", \"date_of_birth\"]\n    )\n\n    first_name: Optional[str] = Field(\n        None,\n        description=\"Person's given name\",\n        examples=[\"Jean\", \"Maria\", \"John\"]\n    )\n\n    last_name: Optional[str] = Field(\n        None,\n        description=\"Person's family name\",\n        examples=[\"Dupont\", \"Garcia\", \"Smith\"]\n    )\n\n    date_of_birth: Optional[date] = Field(\n        None,\n        description=\"Date of birth in YYYY-MM-DD format\",\n        examples=[\"1985-03-12\", \"1990-06-20\"]\n    )\n\n    # These fields don't affect identity\n    email: Optional[str] = Field(None)\n    phone: Optional[str] = Field(None)\n\n    def __str__(self) -&gt; str:\n        parts = [self.first_name, self.last_name]\n        return \" \".join(p for p in parts if p) or \"Unknown\"\n</code></pre> <p>Graph Behavior: <pre><code>Person(first_name=\"John\", last_name=\"Doe\", dob=\"1990-01-01\", email=\"john@email.com\")\nPerson(first_name=\"John\", last_name=\"Doe\", dob=\"1990-01-01\", email=\"john@work.com\")\n\u2192 Same node (same ID fields, email difference ignored)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#example-2-document-entity","title":"Example 2: Document Entity","text":"<pre><code>class Invoice(BaseModel):\n    \"\"\"\n    Invoice document entity.\n    Uniquely identified by invoice number.\n    \"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n\n    invoice_number: str = Field(\n        ...,\n        description=\"Unique invoice identifier\",\n        examples=[\"INV-2024-001\", \"12345\"]\n    )\n\n    date: Optional[str] = Field(None)\n    total: Optional[float] = Field(None)\n\n    def __str__(self) -&gt; str:\n        return f\"Invoice {self.invoice_number}\"\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#components-value-objects","title":"Components: Value Objects","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#what-is-a-component","title":"What is a Component?","text":"<p>A Component is a model that represents a value object - it's deduplicated by its entire content. If two components have identical field values, they share the same graph node.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#configuration_1","title":"Configuration","text":"<pre><code>class Address(BaseModel):\n    \"\"\"\n    Physical address component.\n    Deduplicated by content - identical addresses share the same node.\n    \"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street_address: Optional[str] = Field(...)\n    city: Optional[str] = Field(...)\n    postal_code: Optional[str] = Field(...)\n    country: Optional[str] = Field(...)\n</code></pre> <p>Key Points: - Use <code>is_entity=False</code> to mark as component - All fields are used for deduplication - Identical content = same node</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#when-to-use-components","title":"When to Use Components","text":"<p>Use components for models that represent:</p> <p>\u2705 Addresses - Physical locations <pre><code>model_config = ConfigDict(is_entity=False)\n</code></pre></p> <p>\u2705 Monetary Amounts - Values with currency <pre><code>model_config = ConfigDict(is_entity=False)\n</code></pre></p> <p>\u2705 Measurements - Quantities with units <pre><code>model_config = ConfigDict(is_entity=False)\n</code></pre></p> <p>\u2705 Dates/Times - Temporal values <pre><code>model_config = ConfigDict(is_entity=False)\n</code></pre></p> <p>\u2705 Coordinates - Geographic points <pre><code>model_config = ConfigDict(is_entity=False)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#component-examples","title":"Component Examples","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#example-1-address-component","title":"Example 1: Address Component","text":"<pre><code>class Address(BaseModel):\n    \"\"\"\n    Physical address component.\n    Deduplicated by content - identical addresses share the same node.\n    \"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street_address: Optional[str] = Field(\n        None,\n        description=\"Street name and number\",\n        examples=[\"123 Main Street\", \"45 Avenue des Champs-\u00c9lys\u00e9es\"]\n    )\n\n    city: Optional[str] = Field(\n        None,\n        description=\"City name\",\n        examples=[\"Paris\", \"London\", \"New York\"]\n    )\n\n    postal_code: Optional[str] = Field(\n        None,\n        description=\"Postal or ZIP code\",\n        examples=[\"75001\", \"SW1A 1AA\", \"10001\"]\n    )\n\n    country: Optional[str] = Field(\n        None,\n        description=\"Country name or code\",\n        examples=[\"France\", \"FR\", \"United Kingdom\"]\n    )\n\n    def __str__(self) -&gt; str:\n        parts = [self.street_address, self.city, self.postal_code, self.country]\n        return \", \".join(p for p in parts if p)\n</code></pre> <p>Graph Behavior: <pre><code>Address(street=\"123 Main St\", city=\"Paris\", postal_code=\"75001\")\nAddress(street=\"123 Main St\", city=\"Paris\", postal_code=\"75001\")\n\u2192 Same node (identical content)\n\nAddress(street=\"123 Main St\", city=\"Paris\", postal_code=\"75002\")\n\u2192 Different node (postal code differs)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#example-2-monetary-amount-component","title":"Example 2: Monetary Amount Component","text":"<pre><code>class MonetaryAmount(BaseModel):\n    \"\"\"\n    Monetary value with currency.\n    Deduplicated by content - same value and currency share a node.\n    \"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    value: float = Field(\n        ...,\n        description=\"Numeric amount\",\n        examples=[500.00, 1250.50, 89.99]\n    )\n\n    currency: Optional[str] = Field(\n        None,\n        description=\"ISO 4217 currency code\",\n        examples=[\"EUR\", \"USD\", \"GBP\"]\n    )\n\n    @field_validator(\"value\")\n    @classmethod\n    def validate_positive(cls, v: Any) -&gt; Any:\n        if v &lt; 0:\n            raise ValueError(\"Amount must be non-negative\")\n        return v\n\n    def __str__(self) -&gt; str:\n        return f\"{self.value} {self.currency or ''}\".strip()\n</code></pre> <p>Graph Behavior: <pre><code>MonetaryAmount(value=100.00, currency=\"EUR\")\nMonetaryAmount(value=100.00, currency=\"EUR\")\n\u2192 Same node (identical value and currency)\n\nMonetaryAmount(value=100.00, currency=\"USD\")\n\u2192 Different node (different currency)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#decision-tree","title":"Decision Tree","text":"<p>Use this decision tree to classify your models:</p> <pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"New Model\" }\n\n    B{\"Should this be&lt;br/&gt;tracked individually?\"}\n    C{\"Does it have a&lt;br/&gt;natural unique ID?\"}\n    F{\"Can you create&lt;br/&gt;a composite ID?\"}\n    G{\"Is it a value&lt;br/&gt;that's shared?\"}\n\n    %% Outcomes\n    D@{ shape: tag-proc, label: \"Component&lt;br/&gt;is_entity=False\" }\n    E@{ shape: procs, label: \"Entity&lt;br/&gt;graph_id_fields\" }\n    H@{ shape: lin-proc, label: \"Consider redesigning&lt;br/&gt;or use content-based ID\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B -- Yes --&gt; C\n    B -- No --&gt; D\n\n    C -- Yes --&gt; E\n    C -- No --&gt; F\n\n    F -- Yes --&gt; E\n    F -- No --&gt; G\n\n    G -- Yes --&gt; D\n    G -- No --&gt; H\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,F,G decision\n    class E output\n    class D data\n    class H config</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#questions-to-ask","title":"Questions to Ask","text":"<ol> <li>\"Should this be tracked individually?\"</li> <li>Yes \u2192 Likely an Entity</li> <li> <p>No \u2192 Likely a Component</p> </li> <li> <p>\"If I see this twice with identical values, should it be one thing or two?\"</p> </li> <li>One thing \u2192 Component</li> <li> <p>Two things \u2192 Entity</p> </li> <li> <p>\"Does this represent a unique object or a shared value?\"</p> </li> <li>Unique object \u2192 Entity</li> <li> <p>Shared value \u2192 Component</p> </li> <li> <p>\"Would I want to query for all instances of this specific thing?\"</p> </li> <li>Yes \u2192 Entity</li> <li>No \u2192 Component</li> </ol>"},{"location":"fundamentals/schema-definition/entities-vs-components/#real-world-examples","title":"Real-World Examples","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#example-1-invoice-processing","title":"Example 1: Invoice Processing","text":"<pre><code># ENTITY: Invoice (unique document)\nclass Invoice(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n    invoice_number: str = Field(...)\n    # Each invoice is unique\n\n# ENTITY: Organization (unique company)\nclass Organization(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n    name: str = Field(...)\n    # Each organization is unique\n\n# COMPONENT: Address (shared value)\nclass Address(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    street: str = Field(...)\n    city: str = Field(...)\n    # Multiple organizations can share the same address\n\n# COMPONENT: MonetaryAmount (shared value)\nclass MonetaryAmount(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    value: float = Field(...)\n    currency: str = Field(...)\n    # Multiple invoices can have the same amount\n</code></pre> <p>Graph Structure: <pre><code>Invoice-001 --ISSUED_BY--&gt; Acme Corp --LOCATED_AT--&gt; Address(123 Main St, Paris)\nInvoice-002 --ISSUED_BY--&gt; Tech Ltd --LOCATED_AT--&gt; Address(123 Main St, Paris)\n                                                      \u2191 Same address node shared\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#example-2-research-paper","title":"Example 2: Research Paper","text":"<pre><code># ENTITY: Research (unique paper)\nclass Research(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"title\"])\n    title: str = Field(...)\n\n# ENTITY: Experiment (unique experiment)\nclass Experiment(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"experiment_id\"])\n    experiment_id: str = Field(...)\n\n# ENTITY: Material (unique material type)\nclass Material(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"material_type\"])\n    material_type: str = Field(...)\n\n# COMPONENT: Measurement (shared value)\nclass Measurement(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    name: str = Field(...)\n    value: float = Field(...)\n    unit: str = Field(...)\n    # Multiple experiments can have the same measurement\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#example-3-id-card","title":"Example 3: ID Card","text":"<pre><code># ENTITY: IDCard (unique document)\nclass IDCard(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"document_number\"])\n    document_number: str = Field(...)\n\n# ENTITY: Person (unique individual)\nclass Person(BaseModel):\n    model_config = ConfigDict(\n        graph_id_fields=[\"given_names\", \"last_name\", \"date_of_birth\"]\n    )\n    given_names: List[str] = Field(...)\n    last_name: str = Field(...)\n    date_of_birth: date = Field(...)\n\n# COMPONENT: Address (shared value)\nclass Address(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    street_address: str = Field(...)\n    city: str = Field(...)\n    # Multiple people can live at the same address\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#common-patterns","title":"Common Patterns","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#pattern-1-shared-addresses","title":"Pattern 1: Shared Addresses","text":"<p>Scenario: Multiple people or organizations at the same address.</p> <p>Solution: Make Address a component.</p> <pre><code>class Address(BaseModel):\n    \"\"\"Component - shared by multiple entities.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    # ...\n\nclass Person(BaseModel):\n    \"\"\"Entity - unique individual.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\"])\n    # ...\n    addresses: List[Address] = edge(label=\"LIVES_AT\", default_factory=list)\n\nclass Organization(BaseModel):\n    \"\"\"Entity - unique company.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n    # ...\n    addresses: List[Address] = edge(label=\"LOCATED_AT\", default_factory=list)\n</code></pre> <p>Result: Same address node is shared across multiple people/organizations.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#pattern-2-measurements-in-research","title":"Pattern 2: Measurements in Research","text":"<p>Scenario: Multiple experiments report the same measurement value.</p> <p>Solution: Make Measurement a component.</p> <pre><code>class Measurement(BaseModel):\n    \"\"\"Component - shared measurement value.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    name: str = Field(...)\n    value: float = Field(...)\n    unit: str = Field(...)\n\nclass Experiment(BaseModel):\n    \"\"\"Entity - unique experiment.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"experiment_id\"])\n    # ...\n    measurements: List[Measurement] = Field(default_factory=list)\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#pattern-3-line-items","title":"Pattern 3: Line Items","text":"<p>Scenario: Invoice line items - should each be unique or shared?</p> <p>Decision: Usually neither - line items are typically embedded data, not separate nodes.</p> <pre><code>class LineItem(BaseModel):\n    \"\"\"Line item - embedded in invoice, not a separate node.\"\"\"\n    # No model_config needed - this won't become a node\n    description: str = Field(...)\n    quantity: float = Field(...)\n    unit_price: float = Field(...)\n\nclass Invoice(BaseModel):\n    \"\"\"Entity - unique invoice.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n    # ...\n    # Use regular Field, not edge() - these are embedded\n    items: List[LineItem] = Field(default_factory=list)\n</code></pre> <p>Note: If you want line items as nodes, use <code>edge()</code> and decide if they're entities or components.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#common-mistakes","title":"Common Mistakes","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#mistake-1-making-everything-an-entity","title":"\u274c Mistake 1: Making Everything an Entity","text":"<pre><code># WRONG - Address as entity\nclass Address(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"street\", \"city\"])\n    # This creates separate nodes for identical addresses\n</code></pre> <p>Problem: Identical addresses create separate nodes, losing the benefit of shared locations.</p> <p>Fix: Make Address a component.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#mistake-2-making-everything-a-component","title":"\u274c Mistake 2: Making Everything a Component","text":"<pre><code># WRONG - Person as component\nclass Person(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    # This merges people with identical names\n</code></pre> <p>Problem: Two people with the same name become one node.</p> <p>Fix: Make Person an entity with appropriate <code>graph_id_fields</code>.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#mistake-3-wrong-id-fields","title":"\u274c Mistake 3: Wrong ID Fields","text":"<pre><code># WRONG - Using non-stable fields\nclass Person(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"email\"])\n    # Email can change, creating duplicate nodes\n</code></pre> <p>Problem: When email changes, a new node is created for the same person.</p> <p>Fix: Use stable fields like name + date of birth.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#testing-your-classification","title":"Testing Your Classification","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#test-1-deduplication-behavior","title":"Test 1: Deduplication Behavior","text":"<pre><code># Test entity deduplication\nperson1 = Person(first_name=\"John\", last_name=\"Doe\", email=\"john@email.com\")\nperson2 = Person(first_name=\"John\", last_name=\"Doe\", email=\"john@work.com\")\n# Should create 1 node (same ID fields)\n\n# Test component deduplication\naddr1 = Address(street=\"123 Main St\", city=\"Paris\")\naddr2 = Address(street=\"123 Main St\", city=\"Paris\")\n# Should create 1 node (identical content)\n\naddr3 = Address(street=\"123 Main St\", city=\"London\")\n# Should create 2nd node (different city)\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#test-2-graph-structure","title":"Test 2: Graph Structure","text":"<p>Run extraction and check the graph:</p> <pre><code>uv run docling-graph convert document.pdf \\\n    --template \"my_template.MyTemplate\" \\\n    --export-format csv \\\n    --output-dir test_output\n</code></pre> <p>Check <code>test_output/nodes.csv</code>: - Entities should have one row per unique ID combination - Components should have one row per unique content combination</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#next-steps","title":"Next Steps","text":"<p>Now that you understand entities vs components:</p> <ol> <li>Field Definitions \u2192 - Learn to write effective field descriptions</li> <li>Relationships - Connect entities and components with edges</li> <li>Advanced Patterns - Complex entity/component patterns</li> </ol>"},{"location":"fundamentals/schema-definition/entities-vs-components/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#entity-configuration","title":"Entity Configuration","text":"<pre><code>class MyEntity(BaseModel):\n    \"\"\"Entity description.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"field1\", \"field2\"])\n\n    field1: str = Field(...)\n    field2: str = Field(...)\n    other_field: Optional[str] = Field(None)  # Not part of ID\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#component-configuration","title":"Component Configuration","text":"<pre><code>class MyComponent(BaseModel):\n    \"\"\"Component description.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    field1: str = Field(...)\n    field2: str = Field(...)\n    # All fields used for deduplication\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/","title":"Field Definitions","text":""},{"location":"fundamentals/schema-definition/field-definitions/#overview","title":"Overview","text":"<p>Field definitions are where you guide the LLM to extract accurate data. Well-written field descriptions and examples are crucial for extraction quality. This guide covers best practices for defining fields that maximize LLM accuracy.</p> <p>In this guide: - Field anatomy and structure - Required vs optional fields - Writing effective descriptions - Providing helpful examples - Type hints and defaults</p>"},{"location":"fundamentals/schema-definition/field-definitions/#field-anatomy","title":"Field Anatomy","text":""},{"location":"fundamentals/schema-definition/field-definitions/#basic-structure","title":"Basic Structure","text":"<pre><code>field_name: FieldType = Field(\n    default_value,  # ... for required, None for optional, or a default\n    description=\"Detailed, LLM-friendly description with extraction hints\",\n    examples=[\"Example 1\", \"Example 2\", \"Example 3\"]  # 2-5 realistic examples\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#components-explained","title":"Components Explained","text":"Component Purpose Required <code>field_name</code> Python variable name Yes <code>FieldType</code> Type hint (str, int, date, etc.) Yes <code>Field(...)</code> Pydantic field definition Yes <code>default_value</code> Default or required marker (<code>...</code>) Yes <code>description</code> LLM guidance text Highly recommended <code>examples</code> Sample values Highly recommended"},{"location":"fundamentals/schema-definition/field-definitions/#required-vs-optional-fields","title":"Required vs Optional Fields","text":""},{"location":"fundamentals/schema-definition/field-definitions/#required-fields","title":"Required Fields","text":"<p>Use <code>...</code> (ellipsis) to mark a field as required:</p> <pre><code>document_id: str = Field(\n    ...,  # Ellipsis = required\n    description=\"Unique document identifier\",\n    examples=[\"DOC-2024-001\", \"INV-123456\"]\n)\n</code></pre> <p>When to use: - Fields that must always be present - Core identifying fields - Fields critical for graph structure</p>"},{"location":"fundamentals/schema-definition/field-definitions/#optional-fields-with-none-default","title":"Optional Fields with None Default","text":"<p>Use <code>Optional[Type]</code> with <code>None</code> default:</p> <pre><code>phone: Optional[str] = Field(\n    None,  # None = optional\n    description=\"Contact phone number\",\n    examples=[\"+33 1 23 45 67 89\", \"06 12 34 56 78\"]\n)\n</code></pre> <p>When to use: - Fields that may not be present in all documents - Supplementary information - Fields that vary by document type</p>"},{"location":"fundamentals/schema-definition/field-definitions/#optional-fields-with-custom-default","title":"Optional Fields with Custom Default","text":"<p>Provide a meaningful default value:</p> <pre><code>status: str = Field(\n    \"pending\",  # Custom default\n    description=\"Current processing status\",\n    examples=[\"pending\", \"approved\", \"rejected\"]\n)\n\npriority: int = Field(\n    0,  # Numeric default\n    description=\"Priority level (0-10)\",\n    examples=[0, 5, 10]\n)\n</code></pre> <p>When to use: - Fields with sensible fallback values - Status or state fields - Counters or flags</p>"},{"location":"fundamentals/schema-definition/field-definitions/#optional-lists","title":"Optional Lists","text":"<p>Always use <code>default_factory=list</code> for optional lists:</p> <pre><code>items: List[Item] = Field(\n    default_factory=list,  # Required for lists!\n    description=\"List of items\",\n    examples=[[{\"name\": \"Item1\"}, {\"name\": \"Item2\"}]]\n)\n</code></pre> <p>Why: Using <code>[]</code> as default creates a shared mutable object (Python gotcha).</p>"},{"location":"fundamentals/schema-definition/field-definitions/#writing-effective-descriptions","title":"Writing Effective Descriptions","text":""},{"location":"fundamentals/schema-definition/field-definitions/#the-golden-rules","title":"The Golden Rules","text":"<ol> <li>Be specific - Tell the LLM exactly what to look for</li> <li>Include extraction hints - Mention field names, patterns, synonyms</li> <li>Provide parsing instructions - Explain how to normalize data</li> <li>Guide ambiguous cases - Tell the LLM how to handle edge cases</li> </ol>"},{"location":"fundamentals/schema-definition/field-definitions/#excellent-description-pattern","title":"Excellent Description Pattern","text":"<pre><code>date_of_birth: Optional[date] = Field(\n    None,\n    description=(\n        \"The person's date of birth. \"\n        \"Look for text like 'Date of birth', 'Date de naiss.', or 'Born on'. \"\n        \"Parse formats like 'DD MM YYYY' or 'DDMMYYYY' and normalize to YYYY-MM-DD.\"\n    ),\n    examples=[\"1990-05-15\", \"1985-12-20\", \"1978-03-30\"]\n)\n</code></pre> <p>What makes this excellent: \u2705 Clear purpose (\"person's date of birth\") \u2705 Extraction hints (field name variations) \u2705 Parsing instructions (format normalization) \u2705 Multiple realistic examples</p>"},{"location":"fundamentals/schema-definition/field-definitions/#poor-description-examples","title":"Poor Description Examples","text":"<p>\u274c Too vague: <pre><code>date_of_birth: Optional[date] = Field(None, description=\"Birth date\")\n</code></pre></p> <p>\u274c No extraction hints: <pre><code>email: Optional[str] = Field(None, description=\"Email address\")\n</code></pre></p> <p>\u274c Missing parsing guidance: <pre><code>amount: float = Field(..., description=\"The amount\")\n</code></pre></p>"},{"location":"fundamentals/schema-definition/field-definitions/#description-templates-by-field-type","title":"Description Templates by Field Type","text":""},{"location":"fundamentals/schema-definition/field-definitions/#text-fields","title":"Text Fields","text":"<pre><code>name: str = Field(\n    ...,\n    description=(\n        \"Full legal name of the organization. \"\n        \"Look for 'Company Name', 'Organization', or header text. \"\n        \"Include legal suffixes like 'Ltd', 'Inc', 'SA'.\"\n    ),\n    examples=[\"Acme Corporation Ltd\", \"Tech Solutions Inc\", \"Global Industries SA\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#numeric-fields","title":"Numeric Fields","text":"<pre><code>amount: float = Field(\n    ...,\n    description=(\n        \"Total monetary amount. \"\n        \"Extract numeric value only, removing currency symbols and commas. \"\n        \"Convert formats like '1,234.56' to 1234.56.\"\n    ),\n    examples=[1234.56, 500.00, 89.99]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#date-fields","title":"Date Fields","text":"<pre><code>issue_date: Optional[date] = Field(\n    None,\n    description=(\n        \"Date the document was issued. \"\n        \"Look for 'Issue Date', 'Date d'\u00e9mission', 'Issued on'. \"\n        \"Parse various formats (DD/MM/YYYY, MM-DD-YYYY, YYYY-MM-DD) \"\n        \"and normalize to YYYY-MM-DD.\"\n    ),\n    examples=[\"2024-01-15\", \"2023-12-20\", \"2024-03-01\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#email-fields","title":"Email Fields","text":"<pre><code>email: Optional[str] = Field(\n    None,\n    description=(\n        \"Contact email address. \"\n        \"Look for text containing '@' symbol. \"\n        \"Common labels: 'Email', 'E-mail', 'Contact', 'Courriel'. \"\n        \"Normalize to lowercase.\"\n    ),\n    examples=[\"contact@company.com\", \"info@organization.fr\", \"support@business.co.uk\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#phone-fields","title":"Phone Fields","text":"<pre><code>phone: Optional[str] = Field(\n    None,\n    description=(\n        \"Contact phone number. \"\n        \"Look for 'Phone', 'Tel', 'Telephone', 'Mobile'. \"\n        \"Preserve formatting (spaces, dashes, parentheses). \"\n        \"Include country code if present.\"\n    ),\n    examples=[\"+33 1 23 45 67 89\", \"06 12 34 56 78\", \"+1 (555) 123-4567\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#list-fields","title":"List Fields","text":"<pre><code>guarantees: List[str] = Field(\n    default_factory=list,\n    description=(\n        \"List of coverage items or guarantees. \"\n        \"Look for bullet points, numbered lists, or comma-separated items. \"\n        \"Extract each item as a separate string. \"\n        \"Common section headers: 'Coverage', 'Guarantees', 'Benefits'.\"\n    ),\n    examples=[\n        [\"Fire protection\", \"Water damage\", \"Theft\"],\n        [\"Basic coverage\", \"Extended warranty\"],\n        [\"Liability\", \"Property damage\", \"Personal injury\"]\n    ]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#providing-helpful-examples","title":"Providing Helpful Examples","text":""},{"location":"fundamentals/schema-definition/field-definitions/#the-2-5-rule","title":"The 2-5 Rule","text":"<p>Provide 2-5 diverse, realistic examples per field:</p> <pre><code># Good: 3 diverse examples\ncurrency: str = Field(\n    ...,\n    description=\"ISO 4217 currency code\",\n    examples=[\"EUR\", \"USD\", \"GBP\"]\n)\n\n# Too few: Only 1 example\ncurrency: str = Field(\n    ...,\n    description=\"ISO 4217 currency code\",\n    examples=[\"EUR\"]  # Not enough variety\n)\n\n# Too many: Overwhelming\ncurrency: str = Field(\n    ...,\n    description=\"ISO 4217 currency code\",\n    examples=[\"EUR\", \"USD\", \"GBP\", \"CHF\", \"JPY\", \"CNY\", \"AUD\", \"CAD\"]  # Too many\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#example-diversity","title":"Example Diversity","text":"<p>Show different formats and edge cases:</p> <pre><code># Good: Shows format variations\ndate: str = Field(\n    ...,\n    description=\"Document date\",\n    examples=[\n        \"2024-01-15\",      # ISO format\n        \"01/15/2024\",      # US format\n        \"15.01.2024\"       # European format\n    ]\n)\n\n# Good: Shows value ranges\nquantity: float = Field(\n    ...,\n    description=\"Item quantity\",\n    examples=[1.0, 28.5, 115.0]  # Small, medium, large\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#examples-for-complex-types","title":"Examples for Complex Types","text":""},{"location":"fundamentals/schema-definition/field-definitions/#list-examples","title":"List Examples","text":"<p>Show the list structure, not just individual items:</p> <pre><code># Correct: Show list structure\nitems: List[str] = Field(\n    default_factory=list,\n    description=\"List of item names\",\n    examples=[\n        [\"Item A\", \"Item B\", \"Item C\"],\n        [\"Product 1\", \"Product 2\"],\n        [\"Service X\"]\n    ]\n)\n\n# Wrong: Show individual items\nitems: List[str] = Field(\n    default_factory=list,\n    description=\"List of item names\",\n    examples=[\"Item A\", \"Item B\", \"Item C\"]  # Not a list of lists!\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#nested-object-examples","title":"Nested Object Examples","text":"<p>Show the complete structure:</p> <pre><code>components: List[Component] = Field(\n    default_factory=list,\n    description=\"List of components with roles and amounts\",\n    examples=[\n        [\n            {\n                \"material\": {\"name\": \"Steel\", \"grade\": \"304\"},\n                \"role\": \"Primary\",\n                \"amount\": {\"value\": 12.0, \"unit\": \"kg\"}\n            },\n            {\n                \"material\": {\"name\": \"Aluminum\", \"grade\": \"6061\"},\n                \"role\": \"Secondary\",\n                \"amount\": {\"value\": 5.0, \"unit\": \"kg\"}\n            }\n        ]\n    ]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#type-hints-and-defaults","title":"Type Hints and Defaults","text":""},{"location":"fundamentals/schema-definition/field-definitions/#common-type-patterns","title":"Common Type Patterns","text":"<pre><code># Simple types\nname: str = Field(...)\nage: int = Field(...)\nprice: float = Field(...)\nactive: bool = Field(...)\n\n# Optional types\nemail: Optional[str] = Field(None)\nphone: Optional[int] = Field(None)\n\n# Union types (multiple possible types)\nvalue: Union[str, int, float] = Field(...)\n\n# List types\ntags: List[str] = Field(default_factory=list)\nitems: List[Item] = Field(default_factory=list)\n\n# Date/time types\nbirth_date: date = Field(...)\ncreated_at: datetime = Field(...)\n\n# Enum types\nstatus: StatusEnum = Field(...)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#optional-vs-uniontype-none","title":"Optional vs Union[Type, None]","text":"<p>These are equivalent:</p> <pre><code># Preferred (cleaner)\nemail: Optional[str] = Field(None)\n\n# Equivalent (more explicit)\nemail: Union[str, None] = Field(None)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#default-values-by-type","title":"Default Values by Type","text":"<pre><code># Strings\nname: str = Field(\"Unknown\")\nstatus: str = Field(\"pending\")\n\n# Numbers\ncount: int = Field(0)\nprice: float = Field(0.0)\n\n# Booleans\nactive: bool = Field(True)\nverified: bool = Field(False)\n\n# Lists (always use default_factory)\nitems: List[str] = Field(default_factory=list)\n\n# Dicts (always use default_factory)\nmetadata: Dict[str, Any] = Field(default_factory=dict)\n\n# Dates (use callable)\ncreated_at: datetime = Field(default_factory=datetime.now)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#field-organization","title":"Field Organization","text":""},{"location":"fundamentals/schema-definition/field-definitions/#grouping-related-fields","title":"Grouping Related Fields","text":"<p>Organize fields logically within models:</p> <pre><code>class Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\"])\n\n    # --- Identity Fields ---\n    first_name: str = Field(...)\n    last_name: str = Field(...)\n    date_of_birth: Optional[date] = Field(None)\n\n    # --- Contact Information ---\n    email: Optional[str] = Field(None)\n    phone: Optional[str] = Field(None)\n\n    # --- Address ---\n    addresses: List[Address] = edge(\n        label=\"LIVES_AT\",\n        default_factory=list,\n        description=\"Residential addresses\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#field-ordering-best-practices","title":"Field Ordering Best Practices","text":"<ol> <li>Required fields first</li> <li>ID fields at the top (for entities)</li> <li>Group related fields together</li> <li>Edges at the end</li> </ol> <pre><code>class Invoice(BaseModel):\n    \"\"\"Invoice document.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n\n    # 1. Required ID field\n    invoice_number: str = Field(...)\n\n    # 2. Required core fields\n    date: str = Field(...)\n    total: float = Field(...)\n\n    # 3. Optional fields\n    notes: Optional[str] = Field(None)\n    payment_terms: Optional[str] = Field(None)\n\n    # 4. Edges\n    issued_by: Organization = edge(label=\"ISSUED_BY\")\n    sent_to: Client = edge(label=\"SENT_TO\")\n    contains_items: List[LineItem] = edge(\n        label=\"CONTAINS_ITEM\",\n        default_factory=list\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#advanced-field-patterns","title":"Advanced Field Patterns","text":""},{"location":"fundamentals/schema-definition/field-definitions/#multi-line-descriptions","title":"Multi-line Descriptions","text":"<p>For complex fields, use multi-line strings:</p> <pre><code># Using parentheses (preferred)\nfield: str = Field(\n    ...,\n    description=(\n        \"First line of description. \"\n        \"Second line with more details. \"\n        \"Third line with extraction hints.\"\n    ),\n    examples=[\"Example 1\", \"Example 2\"]\n)\n\n# Using triple quotes (alternative)\nfield: str = Field(\n    ...,\n    description=\"\"\"\n        First line of description.\n        Second line with more details.\n        Third line with extraction hints.\n    \"\"\".strip(),\n    examples=[\"Example 1\", \"Example 2\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#conditional-fields","title":"Conditional Fields","text":"<p>Document when fields are relevant:</p> <pre><code>document_type: str = Field(\n    description=\"Type of document\",\n    examples=[\"Invoice\", \"Receipt\", \"Credit Note\"]\n)\n\n# Field only relevant for invoices\npayment_terms: Optional[str] = Field(\n    None,\n    description=\"Payment terms (primarily for invoices)\",\n    examples=[\"Net 30\", \"Due on receipt\", \"Net 60\"]\n)\n\n# Field only relevant for credit notes\noriginal_document_ref: Optional[str] = Field(\n    None,\n    description=\"Reference to original document (for credit notes)\",\n    examples=[\"INV-2024-001\", \"DOC-123456\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#flexible-value-fields","title":"Flexible Value Fields","text":"<p>Support multiple value types:</p> <pre><code>value: Union[str, int, float] = Field(\n    ...,\n    description=(\n        \"Value can be numeric (int/float) or textual. \"\n        \"Extract as-is: '100', '25.5', or 'High'.\"\n    ),\n    examples=[100, 25.5, \"High\", \"Medium\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#testing-field-definitions","title":"Testing Field Definitions","text":""},{"location":"fundamentals/schema-definition/field-definitions/#test-1-llm-understanding","title":"Test 1: LLM Understanding","text":"<p>Ask yourself: - \"If I were an LLM, could I extract this field from the description alone?\" - \"Are there ambiguous cases I haven't addressed?\" - \"Do the examples cover the expected variety?\"</p>"},{"location":"fundamentals/schema-definition/field-definitions/#test-2-extraction-quality","title":"Test 2: Extraction Quality","text":"<p>Run extraction and check results:</p> <pre><code>uv run docling-graph convert document.pdf \\\n    --template \"my_template.MyTemplate\" \\\n    --output-dir test_output\n</code></pre> <p>Check <code>test_output/extracted_data.json</code>: - Are fields extracted correctly? - Are values normalized as expected? - Are edge cases handled properly?</p>"},{"location":"fundamentals/schema-definition/field-definitions/#test-3-example-coverage","title":"Test 3: Example Coverage","text":"<p>Verify examples match real data:</p> <pre><code># Compare examples to actual extracted values\nimport json\n\nwith open(\"test_output/extracted_data.json\") as f:\n    data = json.load(f)\n\n# Check if extracted values match example patterns\nfor item in data:\n    print(f\"Extracted: {item['field_name']}\")\n    # Does this match the examples you provided?\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#common-mistakes","title":"Common Mistakes","text":""},{"location":"fundamentals/schema-definition/field-definitions/#mistake-1-vague-descriptions","title":"\u274c Mistake 1: Vague Descriptions","text":"<pre><code># Bad\nname: str = Field(..., description=\"Name\")\n\n# Good\nname: str = Field(\n    ...,\n    description=(\n        \"Full legal name of the organization. \"\n        \"Look for 'Company Name' or header text. \"\n        \"Include legal suffixes like 'Ltd', 'Inc'.\"\n    ),\n    examples=[\"Acme Corp Ltd\", \"Tech Solutions Inc\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#mistake-2-missing-examples","title":"\u274c Mistake 2: Missing Examples","text":"<pre><code># Bad\nemail: str = Field(..., description=\"Email address\")\n\n# Good\nemail: str = Field(\n    ...,\n    description=\"Contact email address\",\n    examples=[\"contact@company.com\", \"info@org.fr\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#mistake-3-wrong-list-defaults","title":"\u274c Mistake 3: Wrong List Defaults","text":"<pre><code># Bad - Creates shared mutable object\nitems: List[str] = Field([], description=\"Items\")\n\n# Good - Uses factory\nitems: List[str] = Field(\n    default_factory=list,\n    description=\"Items\"\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#mistake-4-inconsistent-examples","title":"\u274c Mistake 4: Inconsistent Examples","text":"<pre><code># Bad - Examples don't match description\ncurrency: str = Field(\n    ...,\n    description=\"ISO 4217 currency code (3 uppercase letters)\",\n    examples=[\"Euro\", \"Dollar\", \"Pound\"]  # Wrong format!\n)\n\n# Good - Examples match description\ncurrency: str = Field(\n    ...,\n    description=\"ISO 4217 currency code (3 uppercase letters)\",\n    examples=[\"EUR\", \"USD\", \"GBP\"]  # Correct format\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#next-steps","title":"Next Steps","text":"<p>Now that you understand field definitions:</p> <ol> <li>Relationships \u2192 - Connect models with edges</li> <li>Validation - Add validators for data quality</li> <li>Best Practices - Follow the complete checklist</li> </ol>"},{"location":"fundamentals/schema-definition/field-definitions/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/schema-definition/field-definitions/#field-definition-template","title":"Field Definition Template","text":"<pre><code>field_name: FieldType = Field(\n    default_or_required,  # ... or None or value\n    description=(\n        \"Clear purpose. \"\n        \"Extraction hints (field names, patterns). \"\n        \"Parsing instructions (normalization).\"\n    ),\n    examples=[\"Example 1\", \"Example 2\", \"Example 3\"]\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#common-patterns","title":"Common Patterns","text":"<pre><code># Required field\nfield: str = Field(..., description=\"...\", examples=[...])\n\n# Optional field\nfield: Optional[str] = Field(None, description=\"...\", examples=[...])\n\n# List field\nfield: List[str] = Field(default_factory=list, description=\"...\", examples=[[...]])\n\n# Field with default\nfield: str = Field(\"default\", description=\"...\", examples=[...])\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/","title":"Relationships: Edge Definitions","text":""},{"location":"fundamentals/schema-definition/relationships/#overview","title":"Overview","text":"<p>Relationships (edges) connect nodes in your knowledge graph. The <code>edge()</code> helper function marks fields as graph relationships and defines their labels. Well-designed edges create meaningful, queryable graph structures.</p> <p>In this guide: - Using the <code>edge()</code> function - Edge label conventions - Single vs list relationships - Common edge patterns - Relationship best practices</p>"},{"location":"fundamentals/schema-definition/relationships/#using-the-edge-function","title":"Using the edge() Function","text":""},{"location":"fundamentals/schema-definition/relationships/#basic-syntax","title":"Basic Syntax","text":"<pre><code>field_name: TargetType = edge(\n    label=\"EDGE_LABEL\",\n    description=\"Description of the relationship\",\n    # Additional Field parameters...\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#required-vs-optional-edges","title":"Required vs Optional Edges","text":"<pre><code># Required single relationship\nissued_by: Organization = edge(\n    label=\"ISSUED_BY\",\n    description=\"The organization that issued this document\"\n)\n\n# Optional single relationship\nverified_by: Optional[Person] = edge(\n    label=\"VERIFIED_BY\",\n    description=\"Person who verified this document, if applicable\"\n)\n\n# Required list relationship (one-to-many)\ncontains_items: List[LineItem] = edge(\n    label=\"CONTAINS_ITEM\",\n    default_factory=list,  # REQUIRED for lists\n    description=\"Line items contained in this document\"\n)\n\n# Optional list relationship\naddresses: List[Address] = edge(\n    label=\"LOCATED_AT\",\n    default_factory=list,\n    description=\"Physical addresses for this entity\"\n)\n</code></pre> <p>Critical Rule: For list edges, you must provide <code>default_factory=list</code>.</p>"},{"location":"fundamentals/schema-definition/relationships/#edge-label-conventions","title":"Edge Label Conventions","text":""},{"location":"fundamentals/schema-definition/relationships/#naming-standards","title":"Naming Standards","text":"<p>\u2705 DO: - Use ALL_CAPS with underscores - Use verb phrases that describe the relationship - Choose descriptive, domain-appropriate verbs - Be consistent across your template</p> <p>\u274c DON'T: - Use camelCase, lowercase, or mixed case - Use vague labels like \"LINK\" or \"RELATED\" - Mix naming styles</p>"},{"location":"fundamentals/schema-definition/relationships/#good-vs-bad-labels","title":"Good vs Bad Labels","text":"<pre><code># \u2705 Good - Clear, descriptive, consistent\nissued_by: Organization = edge(label=\"ISSUED_BY\")\nsent_to: Client = edge(label=\"SENT_TO\")\ncontains_items: List[Item] = edge(label=\"CONTAINS_ITEM\")\nlocated_at: Address = edge(label=\"LOCATED_AT\")\n\n# \u274c Bad - Inconsistent, vague\nissued_by: Organization = edge(label=\"issuedBy\")  # Wrong case\nsent_to: Client = edge(label=\"sent-to\")  # Wrong separator\ncontains_items: List[Item] = edge(label=\"has\")  # Too vague\nlocated_at: Address = edge(label=\"LINK\")  # Not descriptive\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#common-edge-labels-by-category","title":"Common Edge Labels by Category","text":""},{"location":"fundamentals/schema-definition/relationships/#authorship-ownership","title":"Authorship &amp; Ownership","text":"<pre><code># Document creation\nissued_by: Organization = edge(label=\"ISSUED_BY\")\ncreated_by: Person = edge(label=\"CREATED_BY\")\nauthored_by: Person = edge(label=\"AUTHORED_BY\")\nowned_by: Organization = edge(label=\"OWNED_BY\")\npublished_by: Organization = edge(label=\"PUBLISHED_BY\")\n\n# Verification &amp; approval\nverified_by: Person = edge(label=\"VERIFIED_BY\")\napproved_by: Person = edge(label=\"APPROVED_BY\")\nsigned_by: Person = edge(label=\"SIGNED_BY\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#recipients-targets","title":"Recipients &amp; Targets","text":"<pre><code># Document recipients\nsent_to: Client = edge(label=\"SENT_TO\")\naddressed_to: Person = edge(label=\"ADDRESSED_TO\")\ndelivered_to: Organization = edge(label=\"DELIVERED_TO\")\nbilled_to: Client = edge(label=\"BILLED_TO\")\n\n# Beneficiaries\ninsured_by: Person = edge(label=\"INSURED_BY\")\ncovered_by: InsurancePlan = edge(label=\"COVERED_BY\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#location-physical-presence","title":"Location &amp; Physical Presence","text":"<pre><code># Physical locations\nlocated_at: Address = edge(label=\"LOCATED_AT\")\nlives_at: Address = edge(label=\"LIVES_AT\")\nbased_at: Address = edge(label=\"BASED_AT\")\nmanufactured_at: Address = edge(label=\"MANUFACTURED_AT\")\n\n# Geographic relationships\noperates_in: Region = edge(label=\"OPERATES_IN\")\nships_to: Country = edge(label=\"SHIPS_TO\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#composition-containment","title":"Composition &amp; Containment","text":"<pre><code># Document structure\ncontains_item: List[LineItem] = edge(label=\"CONTAINS_ITEM\")\nhas_component: List[Component] = edge(label=\"HAS_COMPONENT\")\nincludes_part: List[Part] = edge(label=\"INCLUDES_PART\")\ncomposed_of: List[Material] = edge(label=\"COMPOSED_OF\")\n\n# Hierarchical relationships\nhas_section: List[Section] = edge(label=\"HAS_SECTION\")\nhas_chapter: List[Chapter] = edge(label=\"HAS_CHAPTER\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#membership-association","title":"Membership &amp; Association","text":"<pre><code># Organizational relationships\nbelongs_to: Organization = edge(label=\"BELONGS_TO\")\npart_of: Group = edge(label=\"PART_OF\")\nmember_of: Organization = edge(label=\"MEMBER_OF\")\nemployed_by: Organization = edge(label=\"EMPLOYED_BY\")\n\n# Associations\naffiliated_with: Organization = edge(label=\"AFFILIATED_WITH\")\npartnered_with: Organization = edge(label=\"PARTNERED_WITH\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#services-offerings","title":"Services &amp; Offerings","text":"<pre><code># Insurance &amp; coverage\nhas_guarantee: List[Guarantee] = edge(label=\"HAS_GUARANTEE\")\noffers_plan: List[Plan] = edge(label=\"OFFERS_PLAN\")\nprovides_coverage: List[Coverage] = edge(label=\"PROVIDES_COVERAGE\")\n\n# Products &amp; services\noffers_product: List[Product] = edge(label=\"OFFERS_PRODUCT\")\nprovides_service: List[Service] = edge(label=\"PROVIDES_SERVICE\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#research-scientific","title":"Research &amp; Scientific","text":"<pre><code># Experiments &amp; studies\nhas_experiment: List[Experiment] = edge(label=\"HAS_EXPERIMENT\")\nuses_material: Material = edge(label=\"USES_MATERIAL\")\nhas_measurement: List[Measurement] = edge(label=\"HAS_MEASUREMENT\")\nhas_result: List[Result] = edge(label=\"HAS_RESULT\")\n\n# Processes &amp; methods\nhas_process_step: List[Step] = edge(label=\"HAS_PROCESS_STEP\")\nuses_method: Method = edge(label=\"USES_METHOD\")\nhas_evaluation: Evaluation = edge(label=\"HAS_EVALUATION\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#single-vs-list-relationships","title":"Single vs List Relationships","text":""},{"location":"fundamentals/schema-definition/relationships/#single-relationships-one-to-one","title":"Single Relationships (One-to-One)","text":"<p>Use when an entity has exactly one or at most one related entity:</p> <pre><code>class Invoice(BaseModel):\n    \"\"\"Invoice document.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n\n    invoice_number: str = Field(...)\n\n    # One invoice is issued by one organization\n    issued_by: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"The organization that issued this invoice\"\n    )\n\n    # One invoice is sent to one client\n    sent_to: Client = edge(\n        label=\"SENT_TO\",\n        description=\"The client receiving this invoice\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>Invoice-001 --ISSUED_BY--&gt; Acme Corp\nInvoice-001 --SENT_TO--&gt; Client A\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#list-relationships-one-to-many","title":"List Relationships (One-to-Many)","text":"<p>Use when an entity can have multiple related entities:</p> <pre><code>class Invoice(BaseModel):\n    \"\"\"Invoice document.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n\n    invoice_number: str = Field(...)\n\n    # One invoice contains many line items\n    contains_items: List[LineItem] = edge(\n        label=\"CONTAINS_ITEM\",\n        default_factory=list,  # Required!\n        description=\"Line items in this invoice\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>Invoice-001 --CONTAINS_ITEM--&gt; LineItem-1\nInvoice-001 --CONTAINS_ITEM--&gt; LineItem-2\nInvoice-001 --CONTAINS_ITEM--&gt; LineItem-3\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#optional-single-relationships","title":"Optional Single Relationships","text":"<p>Use <code>Optional[Type]</code> for relationships that may not exist:</p> <pre><code>class Document(BaseModel):\n    \"\"\"Document that may or may not have a verifier.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_id\"])\n\n    document_id: str = Field(...)\n\n    # Optional: document may not be verified\n    verified_by: Optional[Person] = edge(\n        label=\"VERIFIED_BY\",\n        description=\"Person who verified this document, if verified\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#edge-patterns-and-examples","title":"Edge Patterns and Examples","text":""},{"location":"fundamentals/schema-definition/relationships/#pattern-1-bidirectional-relationships","title":"Pattern 1: Bidirectional Relationships","text":"<p>Create meaningful relationships in both directions:</p> <pre><code>class Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n\n    # Organization has employees\n    employees: List[Person] = edge(\n        label=\"EMPLOYS\",\n        default_factory=list,\n        description=\"People employed by this organization\"\n    )\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\"])\n\n    first_name: str = Field(...)\n    last_name: str = Field(...)\n\n    # Person works for organization\n    employer: Optional[Organization] = edge(\n        label=\"EMPLOYED_BY\",\n        description=\"Organization employing this person\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>Organization --EMPLOYS--&gt; Person\nPerson --EMPLOYED_BY--&gt; Organization\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#pattern-2-shared-components","title":"Pattern 2: Shared Components","text":"<p>Multiple entities can reference the same component:</p> <pre><code>class Address(BaseModel):\n    \"\"\"Address component (shared).\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street: str = Field(...)\n    city: str = Field(...)\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\"])\n\n    first_name: str = Field(...)\n    last_name: str = Field(...)\n\n    addresses: List[Address] = edge(\n        label=\"LIVES_AT\",\n        default_factory=list,\n        description=\"Residential addresses\"\n    )\n\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n\n    addresses: List[Address] = edge(\n        label=\"LOCATED_AT\",\n        default_factory=list,\n        description=\"Business addresses\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>Person-1 --LIVES_AT--&gt; Address(123 Main St, Paris)\nPerson-2 --LIVES_AT--&gt; Address(123 Main St, Paris)  # Same address node\nOrganization-1 --LOCATED_AT--&gt; Address(123 Main St, Paris)  # Same address node\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#pattern-3-nested-relationships","title":"Pattern 3: Nested Relationships","text":"<p>Edges can point to entities that have their own edges:</p> <pre><code>class Material(BaseModel):\n    \"\"\"Material entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n\n    properties: List[MaterialProperty] = edge(\n        label=\"HAS_PROPERTY\",\n        default_factory=list,\n        description=\"Material properties\"\n    )\n\nclass Component(BaseModel):\n    \"\"\"Component entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"component_id\"])\n\n    component_id: str = Field(...)\n\n    material: Material = edge(\n        label=\"USES_MATERIAL\",\n        description=\"Material used in this component\"\n    )\n\nclass Assembly(BaseModel):\n    \"\"\"Assembly entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"assembly_id\"])\n\n    assembly_id: str = Field(...)\n\n    components: List[Component] = edge(\n        label=\"HAS_COMPONENT\",\n        default_factory=list,\n        description=\"Components in this assembly\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>Assembly --HAS_COMPONENT--&gt; Component --USES_MATERIAL--&gt; Material --HAS_PROPERTY--&gt; Property\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#pattern-4-multiple-edge-types-to-same-entity","title":"Pattern 4: Multiple Edge Types to Same Entity","text":"<p>An entity can have multiple types of relationships to the same target type:</p> <pre><code>class Document(BaseModel):\n    \"\"\"Document entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_id\"])\n\n    document_id: str = Field(...)\n\n    # Different relationship types to Person\n    created_by: Person = edge(\n        label=\"CREATED_BY\",\n        description=\"Person who created this document\"\n    )\n\n    reviewed_by: Optional[Person] = edge(\n        label=\"REVIEWED_BY\",\n        description=\"Person who reviewed this document\"\n    )\n\n    approved_by: Optional[Person] = edge(\n        label=\"APPROVED_BY\",\n        description=\"Person who approved this document\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>Document --CREATED_BY--&gt; Person-A\nDocument --REVIEWED_BY--&gt; Person-B\nDocument --APPROVED_BY--&gt; Person-C\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#complete-example-invoice-template","title":"Complete Example: Invoice Template","text":"<p>Here's a complete example showing various edge patterns:</p> <pre><code>\"\"\"Invoice extraction template with comprehensive edge definitions.\"\"\"\n\nfrom typing import Any, List, Optional\nfrom pydantic import BaseModel, ConfigDict, Field\n\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- Components ---\n\nclass Address(BaseModel):\n    \"\"\"Physical address component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street: str = Field(...)\n    city: str = Field(...)\n    postal_code: str = Field(...)\n\nclass MonetaryAmount(BaseModel):\n    \"\"\"Monetary value component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    value: float = Field(...)\n    currency: str = Field(...)\n\n# --- Entities ---\n\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n    tax_id: Optional[str] = Field(None)\n\n    # Edge to Address component\n    addresses: List[Address] = edge(\n        label=\"LOCATED_AT\",\n        default_factory=list,\n        description=\"Business addresses\"\n    )\n\nclass Client(BaseModel):\n    \"\"\"Client entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n    email: Optional[str] = Field(None)\n\n    # Edge to Address component\n    addresses: List[Address] = edge(\n        label=\"LIVES_AT\",\n        default_factory=list,\n        description=\"Client addresses\"\n    )\n\nclass LineItem(BaseModel):\n    \"\"\"Line item entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"description\", \"unit_price\"])\n\n    description: str = Field(...)\n    quantity: float = Field(...)\n    unit_price: float = Field(...)\n\n    # Edge to MonetaryAmount component\n    total: MonetaryAmount = edge(\n        label=\"HAS_TOTAL\",\n        description=\"Total amount for this line item\"\n    )\n\n# --- Root Document ---\n\nclass Invoice(BaseModel):\n    \"\"\"Invoice document (root).\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n\n    invoice_number: str = Field(...)\n    date: str = Field(...)\n\n    # Single edges to entities\n    issued_by: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Organization that issued this invoice\"\n    )\n\n    sent_to: Client = edge(\n        label=\"SENT_TO\",\n        description=\"Client receiving this invoice\"\n    )\n\n    # List edge to entities\n    contains_items: List[LineItem] = edge(\n        label=\"CONTAINS_ITEM\",\n        default_factory=list,\n        description=\"Line items in this invoice\"\n    )\n\n    # Edge to component\n    total_amount: MonetaryAmount = edge(\n        label=\"HAS_TOTAL\",\n        description=\"Total invoice amount\"\n    )\n</code></pre> <p>Resulting Graph: <pre><code>Invoice-001\n  \u251c\u2500 ISSUED_BY \u2192 Organization(Acme Corp)\n  \u2502               \u2514\u2500 LOCATED_AT \u2192 Address(123 Main St, Paris)\n  \u251c\u2500 SENT_TO \u2192 Client(John Doe)\n  \u2502             \u2514\u2500 LIVES_AT \u2192 Address(456 Oak Ave, London)\n  \u251c\u2500 CONTAINS_ITEM \u2192 LineItem-1\n  \u2502                   \u2514\u2500 HAS_TOTAL \u2192 MonetaryAmount(100, EUR)\n  \u251c\u2500 CONTAINS_ITEM \u2192 LineItem-2\n  \u2502                   \u2514\u2500 HAS_TOTAL \u2192 MonetaryAmount(200, EUR)\n  \u2514\u2500 HAS_TOTAL \u2192 MonetaryAmount(300, EUR)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/schema-definition/relationships/#1-use-descriptive-labels","title":"1. Use Descriptive Labels","text":"<pre><code># \u2705 Good - Clear and specific\nissued_by: Organization = edge(label=\"ISSUED_BY\")\ncontains_items: List[Item] = edge(label=\"CONTAINS_ITEM\")\n\n# \u274c Bad - Vague\nissued_by: Organization = edge(label=\"HAS\")\ncontains_items: List[Item] = edge(label=\"RELATED_TO\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#2-be-consistent","title":"2. Be Consistent","text":"<pre><code># \u2705 Good - Consistent pattern\nlives_at: Address = edge(label=\"LIVES_AT\")\nworks_at: Address = edge(label=\"WORKS_AT\")\nlocated_at: Address = edge(label=\"LOCATED_AT\")\n\n# \u274c Bad - Inconsistent\nlives_at: Address = edge(label=\"LIVES_AT\")\nworks_at: Address = edge(label=\"WORKS_IN\")\nlocated_at: Address = edge(label=\"HAS_LOCATION\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#3-always-use-default_factory-for-lists","title":"3. Always Use default_factory for Lists","text":"<pre><code># \u2705 Good\nitems: List[Item] = edge(\n    label=\"CONTAINS_ITEM\",\n    default_factory=list\n)\n\n# \u274c Bad - Missing default_factory\nitems: List[Item] = edge(label=\"CONTAINS_ITEM\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#4-provide-clear-descriptions","title":"4. Provide Clear Descriptions","text":"<pre><code># \u2705 Good - Explains the relationship\nissued_by: Organization = edge(\n    label=\"ISSUED_BY\",\n    description=\"The organization that created and issued this document\"\n)\n\n# \u274c Bad - No description\nissued_by: Organization = edge(label=\"ISSUED_BY\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#common-mistakes","title":"Common Mistakes","text":""},{"location":"fundamentals/schema-definition/relationships/#mistake-1-missing-default_factory","title":"\u274c Mistake 1: Missing default_factory","text":"<pre><code># Wrong\nitems: List[Item] = edge(label=\"CONTAINS_ITEM\")\n\n# Correct\nitems: List[Item] = edge(\n    label=\"CONTAINS_ITEM\",\n    default_factory=list\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#mistake-2-inconsistent-label-format","title":"\u274c Mistake 2: Inconsistent Label Format","text":"<pre><code># Wrong - Mixed formats\nissued_by: Org = edge(label=\"issuedBy\")\nsent_to: Client = edge(label=\"SENT_TO\")\nhas_items: List[Item] = edge(label=\"contains-item\")\n\n# Correct - Consistent ALL_CAPS_WITH_UNDERSCORES\nissued_by: Org = edge(label=\"ISSUED_BY\")\nsent_to: Client = edge(label=\"SENT_TO\")\nhas_items: List[Item] = edge(label=\"CONTAINS_ITEM\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#mistake-3-vague-labels","title":"\u274c Mistake 3: Vague Labels","text":"<pre><code># Wrong - Too vague\norg: Organization = edge(label=\"HAS\")\nitems: List[Item] = edge(label=\"RELATED\")\n\n# Correct - Descriptive\norg: Organization = edge(label=\"ISSUED_BY\")\nitems: List[Item] = edge(label=\"CONTAINS_ITEM\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#next-steps","title":"Next Steps","text":"<p>Now that you understand relationships:</p> <ol> <li>Validation \u2192 - Add validators for data quality</li> <li>Advanced Patterns - Complex relationship patterns</li> <li>Best Practices - Complete template checklist</li> </ol>"},{"location":"fundamentals/schema-definition/relationships/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/schema-definition/relationships/#edge-definition-template","title":"Edge Definition Template","text":"<pre><code># Single edge\nfield: TargetType = edge(\n    label=\"EDGE_LABEL\",\n    description=\"Relationship description\"\n)\n\n# Optional single edge\nfield: Optional[TargetType] = edge(\n    label=\"EDGE_LABEL\",\n    description=\"Relationship description\"\n)\n\n# List edge\nfield: List[TargetType] = edge(\n    label=\"EDGE_LABEL\",\n    default_factory=list,  # Required!\n    description=\"Relationship description\"\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#common-label-patterns","title":"Common Label Patterns","text":"<ul> <li>Authorship: <code>ISSUED_BY</code>, <code>CREATED_BY</code>, <code>AUTHORED_BY</code></li> <li>Recipients: <code>SENT_TO</code>, <code>ADDRESSED_TO</code>, <code>DELIVERED_TO</code></li> <li>Location: <code>LOCATED_AT</code>, <code>LIVES_AT</code>, <code>BASED_AT</code></li> <li>Composition: <code>CONTAINS_ITEM</code>, <code>HAS_COMPONENT</code>, <code>INCLUDES_PART</code></li> <li>Membership: <code>BELONGS_TO</code>, <code>PART_OF</code>, <code>MEMBER_OF</code></li> </ul>"},{"location":"fundamentals/schema-definition/template-basics/","title":"Template Basics","text":""},{"location":"fundamentals/schema-definition/template-basics/#overview","title":"Overview","text":"<p>Every Pydantic template for Docling Graph follows a standard structure with required imports, helper functions, and organization patterns. This ensures consistency and compatibility with the extraction pipeline.</p> <p>In this guide: - Required imports and their purposes - The mandatory <code>edge()</code> helper function - Standard file organization - Docstring conventions</p>"},{"location":"fundamentals/schema-definition/template-basics/#required-imports","title":"Required Imports","text":""},{"location":"fundamentals/schema-definition/template-basics/#standard-import-block","title":"Standard Import Block","text":"<p>Every template must include this import structure:</p> <pre><code>\"\"\"\nBrief description of what this template extracts.\nMention the document type and key domain features.\n\"\"\"\n\nfrom typing import Any, List, Optional, Union, Self, Type\nfrom pydantic import BaseModel, ConfigDict, Field, field_validator, model_validator\nfrom datetime import date, datetime  # Include based on domain needs\nfrom enum import Enum  # Include if using enums\nimport re  # Include if using regex validators\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#import-breakdown","title":"Import Breakdown","text":"Import Purpose When to Use <code>Any, List, Optional, Union</code> Type hints for fields Always <code>Self, Type</code> Advanced type hints for validators When using validators <code>BaseModel</code> Base class for all models Always <code>ConfigDict</code> Model configuration (graph_id_fields, is_entity) Always <code>Field</code> Field definitions with metadata Always <code>field_validator</code> Single-field validation When validating individual fields <code>model_validator</code> Cross-field validation When validating multiple fields together <code>date, datetime</code> Date/time types For temporal data <code>Enum</code> Enumerated types For controlled vocabularies <code>re</code> Regular expressions For pattern matching in validators"},{"location":"fundamentals/schema-definition/template-basics/#example-minimal-template","title":"Example: Minimal Template","text":"<pre><code>\"\"\"\nInvoice extraction template.\nExtracts invoice data including issuer, client, and line items.\n\"\"\"\n\nfrom typing import Any, List, Optional\nfrom pydantic import BaseModel, ConfigDict, Field\n\n# This is the minimal import set for a basic template\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#example-full-featured-template","title":"Example: Full-Featured Template","text":"<pre><code>\"\"\"\nResearch paper extraction template.\nExtracts scientific experiments, measurements, and materials.\n\"\"\"\n\nfrom typing import Any, List, Optional, Union, Self, Type\nfrom pydantic import BaseModel, ConfigDict, Field, field_validator, model_validator\nfrom datetime import date\nfrom enum import Enum\nimport re\n\n# This includes all common imports for complex templates\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#the-edge-helper-function","title":"The Edge Helper Function","text":""},{"location":"fundamentals/schema-definition/template-basics/#required-definition","title":"Required Definition","text":"<p>This function must be defined identically in every template:</p> <pre><code>def edge(label: str, **kwargs: Any) -&gt; Any:\n    \"\"\"\n    Helper function to create a Pydantic Field with edge metadata.\n    The 'edge_label' defines the type of relationship in the knowledge graph.\n    \"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#critical-rules","title":"Critical Rules","text":"<p>\u2705 DO: - Use lowercase <code>edge</code> (not <code>Edge</code> or <code>EDGE</code>) - Return <code>Field(...)</code> with <code>json_schema_extra={\"edge_label\": label}</code> - Accept <code>**kwargs</code> to pass through additional Field parameters - Include the docstring</p> <p>\u274c DON'T: - Change the function signature - Modify the <code>json_schema_extra</code> structure - Remove <code>**kwargs</code> support</p>"},{"location":"fundamentals/schema-definition/template-basics/#why-this-function","title":"Why This Function?","text":"<p>The <code>edge()</code> helper serves two purposes:</p> <ol> <li>Marks relationships - Tells the graph converter this field is an edge</li> <li>Provides metadata - The <code>edge_label</code> becomes the relationship type in the graph</li> </ol>"},{"location":"fundamentals/schema-definition/template-basics/#usage-examples","title":"Usage Examples","text":"<pre><code># Required single relationship\nissued_by: Organization = edge(\n    label=\"ISSUED_BY\",\n    description=\"The organization that issued this document\"\n)\n\n# Optional single relationship\nverified_by: Optional[Person] = edge(\n    label=\"VERIFIED_BY\",\n    description=\"Person who verified this document, if applicable\"\n)\n\n# Required list relationship (one-to-many)\ncontains_items: List[LineItem] = edge(\n    label=\"CONTAINS_ITEM\",\n    default_factory=list,  # REQUIRED for lists\n    description=\"Line items contained in this document\"\n)\n\n# Optional list relationship\naddresses: List[Address] = edge(\n    label=\"LOCATED_AT\",\n    default_factory=list,\n    description=\"Physical addresses for this entity\"\n)\n</code></pre> <p>Important: For list edges, you must provide <code>default_factory=list</code> in the <code>edge()</code> call.</p>"},{"location":"fundamentals/schema-definition/template-basics/#standard-file-organization","title":"Standard File Organization","text":""},{"location":"fundamentals/schema-definition/template-basics/#recommended-structure","title":"Recommended Structure","text":"<p>Organize your template in this exact order:</p> <pre><code>\"\"\"\nTemplate docstring describing purpose and domain\n\"\"\"\n\n# --- 1. Required Imports ---\nfrom pydantic import BaseModel, ConfigDict, Field, field_validator\nfrom typing import Any, List, Optional\n# ... additional imports\n\n# --- 2. Edge Helper Function ---\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- 3. Helper Functions (if needed) ---\n# Normalization, parsing, or utility functions\n\n# --- 4. Reusable Components ---\n# Value objects with is_entity=False\n\n# --- 5. Reusable Entities ---\n# Common entities like Person, Organization, Address\n\n# --- 6. Domain-Specific Models ---\n# Models unique to this document type\n\n# --- 7. Root Document Model ---\n# The main entry point (last in file)\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#example-invoice-template-structure","title":"Example: Invoice Template Structure","text":"<pre><code>\"\"\"\nInvoice extraction template.\nExtracts structured data from invoice documents.\n\"\"\"\n\n# --- 1. Imports ---\nfrom typing import Any, List, Optional\nfrom pydantic import BaseModel, ConfigDict, Field\n\n# --- 2. Edge Helper ---\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- 3. Helper Functions ---\n# (none needed for this simple template)\n\n# --- 4. Components ---\nclass Address(BaseModel):\n    \"\"\"Physical address component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    # ... fields\n\nclass MonetaryAmount(BaseModel):\n    \"\"\"Monetary value component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    # ... fields\n\n# --- 5. Reusable Entities ---\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n    # ... fields\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\"])\n    # ... fields\n\n# --- 6. Domain-Specific Models ---\nclass LineItem(BaseModel):\n    \"\"\"Invoice line item.\"\"\"\n    # ... fields\n\n# --- 7. Root Document ---\nclass Invoice(BaseModel):\n    \"\"\"Invoice document (root model).\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n    # ... fields\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#docstring-standards","title":"Docstring Standards","text":""},{"location":"fundamentals/schema-definition/template-basics/#module-docstring","title":"Module Docstring","text":"<p>Every template file should start with a clear module docstring:</p> <pre><code>\"\"\"\nPydantic templates for [Document Type] extraction.\n\nThese models extract [key information] from [document type] documents.\nThe schema is designed for automatic conversion to knowledge graphs.\n\nKey entities:\n- [Entity1]: [Description]\n- [Entity2]: [Description]\n\nKey relationships:\n- [Entity1] --[RELATIONSHIP]--&gt; [Entity2]\n\"\"\"\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#model-docstrings","title":"Model Docstrings","text":"<p>Each model should have a clear docstring:</p> <pre><code>class Person(BaseModel):\n    \"\"\"\n    A person entity.\n\n    Uniquely identified by first name, last name, and date of birth.\n    Represents individuals mentioned in documents.\n    \"\"\"\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#good-vs-bad-docstrings","title":"Good vs Bad Docstrings","text":"<p>\u2705 Good: <pre><code>class Address(BaseModel):\n    \"\"\"\n    Physical address component.\n\n    Deduplicated by content - identical addresses share the same node.\n    Used for both residential and business addresses.\n    \"\"\"\n</code></pre></p> <p>\u274c Bad: <pre><code>class Address(BaseModel):\n    \"\"\"Address.\"\"\"  # Too vague\n</code></pre></p>"},{"location":"fundamentals/schema-definition/template-basics/#complete-minimal-template","title":"Complete Minimal Template","text":"<p>Here's a complete, minimal template showing all required elements:</p> <pre><code>\"\"\"\nSimple document extraction template.\nExtracts basic document information.\n\"\"\"\n\nfrom typing import Any, List, Optional\nfrom pydantic import BaseModel, ConfigDict, Field\n\n# --- Edge Helper Function (REQUIRED) ---\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    \"\"\"Helper to create graph edges.\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- Component ---\nclass Address(BaseModel):\n    \"\"\"Physical address (value object).\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street: str = Field(\n        description=\"Street name and number\",\n        examples=[\"123 Main St\", \"45 Rue de la Paix\"]\n    )\n    city: str = Field(\n        description=\"City name\",\n        examples=[\"Paris\", \"London\"]\n    )\n\n# --- Entity ---\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(\n        description=\"Legal organization name\",\n        examples=[\"Acme Corp\", \"Tech Solutions Ltd\"]\n    )\n\n    # Edge to Address\n    located_at: Address = edge(\n        label=\"LOCATED_AT\",\n        description=\"Organization's physical address\"\n    )\n\n# --- Root Document ---\nclass Document(BaseModel):\n    \"\"\"Document entity (root model).\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_id\"])\n\n    document_id: str = Field(\n        description=\"Unique document identifier\",\n        examples=[\"DOC-2024-001\", \"12345\"]\n    )\n\n    # Edge to Organization\n    issued_by: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Organization that issued this document\"\n    )\n</code></pre> <p>This template includes: \u2705 Module docstring \u2705 Required imports \u2705 <code>edge()</code> helper function \u2705 Component with <code>is_entity=False</code> \u2705 Entity with <code>graph_id_fields</code> \u2705 Root document model \u2705 Clear field descriptions and examples \u2705 Graph relationships via <code>edge()</code></p>"},{"location":"fundamentals/schema-definition/template-basics/#testing-your-template-structure","title":"Testing Your Template Structure","text":""},{"location":"fundamentals/schema-definition/template-basics/#quick-validation","title":"Quick Validation","text":"<p>Test that your template is properly structured:</p> <pre><code># test_template_structure.py\nfrom my_template import Document, Organization, Address\n\n# 1. Check imports work\nprint(\"\u2713 Imports successful\")\n\n# 2. Check edge function exists\nfrom my_template import edge\nprint(\"\u2713 edge() function defined\")\n\n# 3. Create test instance\ndoc = Document(\n    document_id=\"TEST-001\",\n    issued_by=Organization(\n        name=\"Test Corp\",\n        located_at=Address(\n            street=\"123 Test St\",\n            city=\"Paris\"\n        )\n    )\n)\nprint(\"\u2713 Model instantiation works\")\n\n# 4. Check serialization\njson_data = doc.model_dump_json(indent=2)\nprint(\"\u2713 JSON serialization works\")\nprint(json_data)\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#run-with-uv","title":"Run with uv","text":"<pre><code># Save test to file\nuv run python test_template_structure.py\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#common-mistakes","title":"Common Mistakes","text":""},{"location":"fundamentals/schema-definition/template-basics/#mistake-1-wrong-edge-definition","title":"\u274c Mistake 1: Wrong edge() Definition","text":"<pre><code># WRONG - Missing **kwargs\ndef edge(label: str) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label})\n\n# WRONG - Wrong metadata key\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"label\": label}, **kwargs)\n\n# CORRECT\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#mistake-2-missing-default_factory-for-lists","title":"\u274c Mistake 2: Missing default_factory for Lists","text":"<pre><code># WRONG - List edge without default_factory\nitems: List[Item] = edge(\n    label=\"CONTAINS_ITEM\",\n    description=\"Items in document\"\n)\n\n# CORRECT\nitems: List[Item] = edge(\n    label=\"CONTAINS_ITEM\",\n    default_factory=list,  # Required!\n    description=\"Items in document\"\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#mistake-3-inconsistent-organization","title":"\u274c Mistake 3: Inconsistent Organization","text":"<pre><code># WRONG - Root model at the top\nclass Document(BaseModel):\n    \"\"\"Root document.\"\"\"\n    # ...\n\nclass Address(BaseModel):\n    \"\"\"Component used by Document.\"\"\"\n    # ...\n\n# CORRECT - Components before entities, root at end\nclass Address(BaseModel):\n    \"\"\"Component.\"\"\"\n    # ...\n\nclass Document(BaseModel):\n    \"\"\"Root document.\"\"\"\n    # ...\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#next-steps","title":"Next Steps","text":"<p>Now that you understand template basics:</p> <ol> <li>Entities vs Components \u2192 - Learn the critical distinction</li> <li>Field Definitions - Master field descriptions and examples</li> <li>Example Templates - See complete working examples</li> </ol>"},{"location":"fundamentals/schema-definition/template-basics/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/schema-definition/template-basics/#required-elements-checklist","title":"Required Elements Checklist","text":"<ul> <li> Module docstring</li> <li> Standard imports (<code>BaseModel</code>, <code>ConfigDict</code>, <code>Field</code>, etc.)</li> <li> <code>edge()</code> helper function (exact definition)</li> <li> Organized structure (components \u2192 entities \u2192 root)</li> <li> Model docstrings</li> <li> Field descriptions and examples</li> <li> Proper <code>model_config</code> for all models</li> </ul>"},{"location":"fundamentals/schema-definition/template-basics/#file-template","title":"File Template","text":"<pre><code>\"\"\"[Template description]\"\"\"\n\nfrom typing import Any, List, Optional\nfrom pydantic import BaseModel, ConfigDict, Field\n\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# Components (is_entity=False)\n# Entities (graph_id_fields=[...])\n# Root document\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/","title":"Validation and Normalization","text":""},{"location":"fundamentals/schema-definition/validation/#overview","title":"Overview","text":"<p>Validators ensure data quality and consistency in your extracted data. Pydantic provides powerful validation mechanisms that can transform, normalize, and validate field values before they're stored in your knowledge graph.</p> <p>In this guide: - Field validators for single-field validation - Model validators for cross-field validation - Pre-validators for data transformation - Common validation patterns - Normalization helpers</p>"},{"location":"fundamentals/schema-definition/validation/#field-validators","title":"Field Validators","text":""},{"location":"fundamentals/schema-definition/validation/#basic-field-validator","title":"Basic Field Validator","text":"<p>Use <code>@field_validator</code> to validate individual fields:</p> <pre><code>from pydantic import BaseModel, Field, field_validator\nfrom typing import Any\n\nclass MonetaryAmount(BaseModel):\n    \"\"\"Monetary value with validation.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    value: float = Field(...)\n    currency: Optional[str] = Field(None)\n\n    @field_validator(\"value\")\n    @classmethod\n    def validate_positive(cls, v: Any) -&gt; Any:\n        \"\"\"Ensure value is non-negative.\"\"\"\n        if v &lt; 0:\n            raise ValueError(\"Monetary amount must be non-negative\")\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#validator-anatomy","title":"Validator Anatomy","text":"<pre><code>@field_validator(\"field_name\")  # Field to validate\n@classmethod  # Must be classmethod\ndef validator_name(cls, v: Any) -&gt; Any:  # Takes value, returns value\n    \"\"\"Docstring explaining validation.\"\"\"\n    # Validation logic\n    if not valid:\n        raise ValueError(\"Error message\")\n    return v  # Return (possibly modified) value\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#pre-validators-modebefore","title":"Pre-Validators (mode='before')","text":""},{"location":"fundamentals/schema-definition/validation/#when-to-use-pre-validators","title":"When to Use Pre-Validators","text":"<p>Use <code>mode='before'</code> to transform input before type coercion:</p> <pre><code>@field_validator(\"email\", mode=\"before\")\n@classmethod\ndef normalize_email(cls, v: Any) -&gt; Any:\n    \"\"\"Convert email to lowercase and strip whitespace.\"\"\"\n    if v:\n        return v.lower().strip()\n    return v\n</code></pre> <p>Use cases: - Normalizing strings (lowercase, strip whitespace) - Converting types (string to list) - Parsing complex formats - Cleaning input data</p>"},{"location":"fundamentals/schema-definition/validation/#pre-validator-examples","title":"Pre-Validator Examples","text":""},{"location":"fundamentals/schema-definition/validation/#example-1-email-normalization","title":"Example 1: Email Normalization","text":"<pre><code>class Person(BaseModel):\n    \"\"\"Person with normalized email.\"\"\"\n\n    email: Optional[str] = Field(None)\n\n    @field_validator(\"email\", mode=\"before\")\n    @classmethod\n    def normalize_email(cls, v: Any) -&gt; Any:\n        \"\"\"Convert email to lowercase and strip whitespace.\"\"\"\n        if v:\n            return v.lower().strip()\n        return v\n</code></pre> <p>Input/Output: <pre><code>Person(email=\"  John.Doe@EMAIL.COM  \")\n# Result: email=\"john.doe@email.com\"\n</code></pre></p>"},{"location":"fundamentals/schema-definition/validation/#example-2-string-to-list-conversion","title":"Example 2: String to List Conversion","text":"<pre><code>class Person(BaseModel):\n    \"\"\"Person with flexible name input.\"\"\"\n\n    given_names: List[str] = Field(default_factory=list)\n\n    @field_validator(\"given_names\", mode=\"before\")\n    @classmethod\n    def ensure_list(cls, v: Any) -&gt; Any:\n        \"\"\"Ensure given_names is always a list.\"\"\"\n        if isinstance(v, str):\n            # Handle comma-separated names\n            if \",\" in v:\n                return [name.strip() for name in v.split(\",\")]\n            return [v]\n        return v\n</code></pre> <p>Input/Output: <pre><code>Person(given_names=\"John, Paul, George\")\n# Result: given_names=[\"John\", \"Paul\", \"George\"]\n\nPerson(given_names=\"John\")\n# Result: given_names=[\"John\"]\n\nPerson(given_names=[\"John\", \"Paul\"])\n# Result: given_names=[\"John\", \"Paul\"]\n</code></pre></p>"},{"location":"fundamentals/schema-definition/validation/#example-3-phone-number-cleaning","title":"Example 3: Phone Number Cleaning","text":"<pre><code>class Contact(BaseModel):\n    \"\"\"Contact with cleaned phone number.\"\"\"\n\n    phone: Optional[str] = Field(None)\n\n    @field_validator(\"phone\", mode=\"before\")\n    @classmethod\n    def clean_phone(cls, v: Any) -&gt; Any:\n        \"\"\"Remove non-numeric characters except + and spaces.\"\"\"\n        if v:\n            # Keep only digits, +, and spaces\n            import re\n            return re.sub(r'[^\\d\\s+]', '', v)\n        return v\n</code></pre> <p>Input/Output: <pre><code>Contact(phone=\"+33 (0)1-23-45-67-89\")\n# Result: phone=\"+33 01 23 45 67 89\"\n</code></pre></p>"},{"location":"fundamentals/schema-definition/validation/#post-validators-default-mode","title":"Post-Validators (Default Mode)","text":""},{"location":"fundamentals/schema-definition/validation/#when-to-use-post-validators","title":"When to Use Post-Validators","text":"<p>Use default mode (or <code>mode='after'</code>) to validate after type coercion:</p> <pre><code>@field_validator(\"currency\")\n@classmethod\ndef validate_currency_format(cls, v: Any) -&gt; Any:\n    \"\"\"Ensure currency is 3 uppercase letters (ISO 4217).\"\"\"\n    if v and not (len(v) == 3 and v.isupper()):\n        raise ValueError(\"Currency must be 3 uppercase letters (ISO 4217)\")\n    return v\n</code></pre> <p>Use cases: - Validating format constraints - Checking value ranges - Enforcing business rules - Verifying data integrity</p>"},{"location":"fundamentals/schema-definition/validation/#post-validator-examples","title":"Post-Validator Examples","text":""},{"location":"fundamentals/schema-definition/validation/#example-1-currency-code-validation","title":"Example 1: Currency Code Validation","text":"<pre><code>class MonetaryAmount(BaseModel):\n    \"\"\"Monetary amount with validated currency.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    value: float = Field(...)\n    currency: Optional[str] = Field(None)\n\n    @field_validator(\"currency\")\n    @classmethod\n    def validate_currency_format(cls, v: Any) -&gt; Any:\n        \"\"\"Ensure currency is 3 uppercase letters.\"\"\"\n        if v and not (len(v) == 3 and v.isupper()):\n            raise ValueError(\"Currency must be 3 uppercase letters (ISO 4217)\")\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#example-2-range-validation","title":"Example 2: Range Validation","text":"<pre><code>class Product(BaseModel):\n    \"\"\"Product with validated quantity.\"\"\"\n\n    quantity: int = Field(...)\n\n    @field_validator(\"quantity\")\n    @classmethod\n    def validate_quantity_range(cls, v: Any) -&gt; Any:\n        \"\"\"Ensure quantity is between 1 and 10000.\"\"\"\n        if v &lt; 1:\n            raise ValueError(\"Quantity must be at least 1\")\n        if v &gt; 10000:\n            raise ValueError(\"Quantity cannot exceed 10000\")\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#example-3-email-format-validation","title":"Example 3: Email Format Validation","text":"<pre><code>class Contact(BaseModel):\n    \"\"\"Contact with validated email.\"\"\"\n\n    email: Optional[str] = Field(None)\n\n    @field_validator(\"email\")\n    @classmethod\n    def validate_email_format(cls, v: Any) -&gt; Any:\n        \"\"\"Basic email format validation.\"\"\"\n        if v and \"@\" not in v:\n            raise ValueError(\"Invalid email format\")\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#model-validators","title":"Model Validators","text":""},{"location":"fundamentals/schema-definition/validation/#when-to-use-model-validators","title":"When to Use Model Validators","text":"<p>Use <code>@model_validator</code> for cross-field validation - when validation depends on multiple fields:</p> <pre><code>from pydantic import model_validator\nfrom typing_extensions import Self\n\nclass Measurement(BaseModel):\n    \"\"\"Measurement with cross-field validation.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    numeric_value: Optional[float] = Field(None)\n    numeric_value_min: Optional[float] = Field(None)\n    numeric_value_max: Optional[float] = Field(None)\n\n    @model_validator(mode=\"after\")\n    def validate_value_consistency(self) -&gt; Self:\n        \"\"\"Ensure value fields are used consistently.\"\"\"\n        has_single = self.numeric_value is not None\n        has_min = self.numeric_value_min is not None\n        has_max = self.numeric_value_max is not None\n\n        if has_single and has_min and has_max:\n            raise ValueError(\n                \"Cannot specify numeric_value, numeric_value_min, \"\n                \"and numeric_value_max simultaneously\"\n            )\n\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#model-validator-examples","title":"Model Validator Examples","text":""},{"location":"fundamentals/schema-definition/validation/#example-1-date-range-validation","title":"Example 1: Date Range Validation","text":"<pre><code>from datetime import date\n\nclass Event(BaseModel):\n    \"\"\"Event with validated date range.\"\"\"\n\n    start_date: Optional[date] = Field(None)\n    end_date: Optional[date] = Field(None)\n\n    @model_validator(mode=\"after\")\n    def validate_date_range(self) -&gt; Self:\n        \"\"\"Ensure end_date is after start_date.\"\"\"\n        if self.start_date and self.end_date:\n            if self.end_date &lt; self.start_date:\n                raise ValueError(\"end_date must be after start_date\")\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#example-2-conditional-required-fields","title":"Example 2: Conditional Required Fields","text":"<pre><code>class Document(BaseModel):\n    \"\"\"Document with conditional validation.\"\"\"\n\n    document_type: str = Field(...)\n    invoice_number: Optional[str] = Field(None)\n    receipt_number: Optional[str] = Field(None)\n\n    @model_validator(mode=\"after\")\n    def validate_document_numbers(self) -&gt; Self:\n        \"\"\"Ensure appropriate number field is present.\"\"\"\n        if self.document_type == \"invoice\" and not self.invoice_number:\n            raise ValueError(\"invoice_number required for invoice documents\")\n        if self.document_type == \"receipt\" and not self.receipt_number:\n            raise ValueError(\"receipt_number required for receipt documents\")\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#example-3-mutual-exclusivity","title":"Example 3: Mutual Exclusivity","text":"<pre><code>class Payment(BaseModel):\n    \"\"\"Payment with mutually exclusive fields.\"\"\"\n\n    cash_amount: Optional[float] = Field(None)\n    card_amount: Optional[float] = Field(None)\n    check_amount: Optional[float] = Field(None)\n\n    @model_validator(mode=\"after\")\n    def validate_single_payment_method(self) -&gt; Self:\n        \"\"\"Ensure only one payment method is used.\"\"\"\n        methods = [\n            self.cash_amount is not None,\n            self.card_amount is not None,\n            self.check_amount is not None\n        ]\n        if sum(methods) &gt; 1:\n            raise ValueError(\"Only one payment method can be specified\")\n        if sum(methods) == 0:\n            raise ValueError(\"At least one payment method must be specified\")\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#common-validation-patterns","title":"Common Validation Patterns","text":""},{"location":"fundamentals/schema-definition/validation/#pattern-1-positive-number-validation","title":"Pattern 1: Positive Number Validation","text":"<pre><code>@field_validator(\"amount\", \"quantity\", \"price\")\n@classmethod\ndef validate_positive(cls, v: Any) -&gt; Any:\n    \"\"\"Ensure value is positive.\"\"\"\n    if v is not None and v &lt; 0:\n        raise ValueError(f\"Value must be non-negative, got {v}\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#pattern-2-string-length-validation","title":"Pattern 2: String Length Validation","text":"<pre><code>@field_validator(\"postal_code\")\n@classmethod\ndef validate_postal_code_length(cls, v: Any) -&gt; Any:\n    \"\"\"Ensure postal code is 5 digits.\"\"\"\n    if v and len(v) != 5:\n        raise ValueError(\"Postal code must be 5 digits\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#pattern-3-enum-like-validation","title":"Pattern 3: Enum-like Validation","text":"<pre><code>@field_validator(\"status\")\n@classmethod\ndef validate_status(cls, v: Any) -&gt; Any:\n    \"\"\"Ensure status is one of allowed values.\"\"\"\n    allowed = [\"pending\", \"approved\", \"rejected\"]\n    if v and v not in allowed:\n        raise ValueError(f\"Status must be one of {allowed}\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#pattern-4-pattern-matching","title":"Pattern 4: Pattern Matching","text":"<pre><code>import re\n\n@field_validator(\"email\")\n@classmethod\ndef validate_email_pattern(cls, v: Any) -&gt; Any:\n    \"\"\"Validate email format using regex.\"\"\"\n    if v:\n        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n        if not re.match(pattern, v):\n            raise ValueError(\"Invalid email format\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#enum-normalization-helper","title":"Enum Normalization Helper","text":""},{"location":"fundamentals/schema-definition/validation/#the-problem","title":"The Problem","text":"<p>Enums can be tricky with LLM extraction - the model might return various formats:</p> <pre><code>from enum import Enum\n\nclass Status(str, Enum):\n    PENDING = \"Pending\"\n    APPROVED = \"Approved\"\n    REJECTED = \"Rejected\"\n\n# LLM might return: \"pending\", \"PENDING\", \"Pending\", \"approved\", etc.\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#the-solution","title":"The Solution","text":"<p>Use a normalization helper:</p> <pre><code>import re\nfrom enum import Enum\nfrom typing import Type, Any\n\ndef _normalize_enum(enum_cls: Type[Enum], v: Any) -&gt; Any:\n    \"\"\"\n    Accept enum instances, value strings, or member names.\n    Handles various formats: 'VALUE', 'value', 'Value', 'VALUE_NAME'.\n    Falls back to 'OTHER' member if present.\n    \"\"\"\n    if isinstance(v, enum_cls):\n        return v\n\n    if isinstance(v, str):\n        # Normalize to alphanumeric lowercase\n        key = re.sub(r\"[^A-Za-z0-9]+\", \"\", v).lower()\n\n        # Build mapping of normalized names/values to enum members\n        mapping = {}\n        for member in enum_cls:\n            normalized_name = re.sub(r\"[^A-Za-z0-9]+\", \"\", member.name).lower()\n            normalized_value = re.sub(r\"[^A-Za-z0-9]+\", \"\", member.value).lower()\n            mapping[normalized_name] = member\n            mapping[normalized_value] = member\n\n        if key in mapping:\n            return mapping[key]\n\n        # Last attempt: direct value match\n        try:\n            return enum_cls(v)\n        except Exception:\n            # Safe fallback to OTHER if present\n            if \"OTHER\" in enum_cls.__members__:\n                return enum_cls.OTHER\n            raise\n\n    raise ValueError(f\"Cannot normalize {v} to {enum_cls}\")\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#usage-example","title":"Usage Example","text":"<pre><code>class DocumentType(str, Enum):\n    INVOICE = \"Invoice\"\n    RECEIPT = \"Receipt\"\n    CREDIT_NOTE = \"Credit Note\"\n    OTHER = \"Other\"\n\nclass Document(BaseModel):\n    \"\"\"Document with normalized enum.\"\"\"\n\n    document_type: DocumentType = Field(...)\n\n    @field_validator(\"document_type\", mode=\"before\")\n    @classmethod\n    def normalize_document_type(cls, v: Any) -&gt; Any:\n        return _normalize_enum(DocumentType, v)\n</code></pre> <p>Handles all these inputs: <pre><code>Document(document_type=\"invoice\")  # \u2192 DocumentType.INVOICE\nDocument(document_type=\"INVOICE\")  # \u2192 DocumentType.INVOICE\nDocument(document_type=\"Invoice\")  # \u2192 DocumentType.INVOICE\nDocument(document_type=\"credit note\")  # \u2192 DocumentType.CREDIT_NOTE\nDocument(document_type=\"unknown\")  # \u2192 DocumentType.OTHER (fallback)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/validation/#measurement-parsing-helper","title":"Measurement Parsing Helper","text":""},{"location":"fundamentals/schema-definition/validation/#the-problem_1","title":"The Problem","text":"<p>LLMs might return measurements in various formats:</p> <pre><code>\"1.6 mPa.s\"\n\"2 mm\"\n\"80-90 \u00b0C\"\n\"High\"\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#the-solution_1","title":"The Solution","text":"<p>Use a parsing helper:</p> <pre><code>import re\nfrom typing import Any, Optional\n\ndef _parse_measurement_string(\n    s: str,\n    default_name: Optional[str] = None,\n    strict: bool = False\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Parse measurement strings into structured dict.\n\n    Examples:\n        \"1.6 mPa.s\" \u2192 {numeric_value: 1.6, unit: \"mPa.s\"}\n        \"80-90 \u00b0C\" \u2192 {numeric_value_min: 80, numeric_value_max: 90, unit: \"\u00b0C\"}\n        \"High\" \u2192 {text_value: \"High\"}\n    \"\"\"\n    if not isinstance(s, str):\n        return s\n\n    # Try to parse range (e.g., \"80-90 \u00b0C\")\n    range_match = re.match(\n        r\"^\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*-\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*([^\\d]+)?$\",\n        s\n    )\n    if range_match:\n        min_val = float(range_match.group(1))\n        max_val = float(range_match.group(2))\n        unit = (range_match.group(3) or \"\").strip() or None\n        return {\n            \"name\": default_name or \"Value\",\n            \"numeric_value\": None,\n            \"numeric_value_min\": min_val,\n            \"numeric_value_max\": max_val,\n            \"text_value\": None,\n            \"unit\": unit,\n        }\n\n    # Try to parse single value (e.g., \"1.6 mPa.s\")\n    single_match = re.match(r\"^\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*([^\\d]+)?$\", s)\n    if single_match:\n        num = float(single_match.group(1))\n        unit = (single_match.group(2) or \"\").strip() or None\n        return {\n            \"name\": default_name or \"Value\",\n            \"numeric_value\": num,\n            \"numeric_value_min\": None,\n            \"numeric_value_max\": None,\n            \"text_value\": None,\n            \"unit\": unit,\n        }\n\n    # No numeric part found\n    if strict:\n        raise ValueError(f\"Cannot parse '{s}' as measurement\")\n\n    # Fallback: keep raw as text\n    return {\n        \"name\": default_name or \"Value\",\n        \"numeric_value\": None,\n        \"numeric_value_min\": None,\n        \"numeric_value_max\": None,\n        \"text_value\": s.strip(),\n        \"unit\": None,\n    }\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#usage-example_1","title":"Usage Example","text":"<pre><code>class Measurement(BaseModel):\n    \"\"\"Flexible measurement model.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    name: str = Field(...)\n    numeric_value: Optional[float] = Field(None)\n    numeric_value_min: Optional[float] = Field(None)\n    numeric_value_max: Optional[float] = Field(None)\n    text_value: Optional[str] = Field(None)\n    unit: Optional[str] = Field(None)\n\n    @field_validator(\"numeric_value\", \"numeric_value_min\", \"numeric_value_max\", mode=\"before\")\n    @classmethod\n    def parse_if_string(cls, v: Any, info: ValidationInfo) -&gt; Any:\n        \"\"\"Parse measurement strings.\"\"\"\n        if isinstance(v, str):\n            field_name = info.field_name\n            parsed = _parse_measurement_string(v, default_name=field_name)\n            return parsed.get(field_name)\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/schema-definition/validation/#1-validate-early","title":"1. Validate Early","text":"<p>Use <code>mode='before'</code> for normalization, default mode for validation:</p> <pre><code>@field_validator(\"email\", mode=\"before\")\n@classmethod\ndef normalize_email(cls, v: Any) -&gt; Any:\n    \"\"\"Normalize before validation.\"\"\"\n    if v:\n        return v.lower().strip()\n    return v\n\n@field_validator(\"email\")\n@classmethod\ndef validate_email(cls, v: Any) -&gt; Any:\n    \"\"\"Validate after normalization.\"\"\"\n    if v and \"@\" not in v:\n        raise ValueError(\"Invalid email\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#2-provide-clear-error-messages","title":"2. Provide Clear Error Messages","text":"<pre><code># \u2705 Good - Specific error message\n@field_validator(\"quantity\")\n@classmethod\ndef validate_quantity(cls, v: Any) -&gt; Any:\n    if v &lt; 1:\n        raise ValueError(f\"Quantity must be at least 1, got {v}\")\n    return v\n\n# \u274c Bad - Vague error message\n@field_validator(\"quantity\")\n@classmethod\ndef validate_quantity(cls, v: Any) -&gt; Any:\n    if v &lt; 1:\n        raise ValueError(\"Invalid quantity\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#3-handle-none-values","title":"3. Handle None Values","text":"<pre><code>@field_validator(\"email\")\n@classmethod\ndef validate_email(cls, v: Any) -&gt; Any:\n    \"\"\"Validate email, allowing None.\"\"\"\n    if v is None:\n        return v  # Allow None for optional fields\n    if \"@\" not in v:\n        raise ValueError(\"Invalid email\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#4-use-type-guards","title":"4. Use Type Guards","text":"<pre><code>@field_validator(\"value\", mode=\"before\")\n@classmethod\ndef coerce_to_float(cls, v: Any) -&gt; Any:\n    \"\"\"Convert string to float if needed.\"\"\"\n    if isinstance(v, str):\n        try:\n            return float(v.replace(\",\", \"\"))\n        except ValueError:\n            raise ValueError(f\"Cannot convert '{v}' to float\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#testing-validators","title":"Testing Validators","text":""},{"location":"fundamentals/schema-definition/validation/#test-individual-validators","title":"Test Individual Validators","text":"<pre><code># test_validators.py\nfrom my_template import MonetaryAmount\nimport pytest\n\ndef test_positive_amount():\n    \"\"\"Test that negative amounts are rejected.\"\"\"\n    with pytest.raises(ValueError, match=\"non-negative\"):\n        MonetaryAmount(value=-100, currency=\"EUR\")\n\ndef test_valid_amount():\n    \"\"\"Test that positive amounts are accepted.\"\"\"\n    amount = MonetaryAmount(value=100, currency=\"EUR\")\n    assert amount.value == 100\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#test-with-uv","title":"Test with uv","text":"<pre><code>uv run pytest test_validators.py -v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#next-steps","title":"Next Steps","text":"<p>Now that you understand validation:</p> <ol> <li>Advanced Patterns \u2192 - Complex validation patterns</li> <li>Best Practices - Complete template checklist</li> <li>Examples - See validators in action</li> </ol>"},{"location":"fundamentals/schema-definition/validation/#quick-reference","title":"Quick Reference","text":""},{"location":"fundamentals/schema-definition/validation/#field-validator-template","title":"Field Validator Template","text":"<pre><code>@field_validator(\"field_name\", mode=\"before\")  # or default mode\n@classmethod\ndef validator_name(cls, v: Any) -&gt; Any:\n    \"\"\"Docstring.\"\"\"\n    # Validation/transformation logic\n    if not valid:\n        raise ValueError(\"Error message\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#model-validator-template","title":"Model Validator Template","text":"<pre><code>@model_validator(mode=\"after\")\ndef validator_name(self) -&gt; Self:\n    \"\"\"Docstring.\"\"\"\n    # Cross-field validation\n    if not valid:\n        raise ValueError(\"Error message\")\n    return self\n</code></pre>"},{"location":"introduction/","title":"Introduction to Docling Graph","text":"<p>Pipeline Stage: 1 - Introduction &amp; Concepts</p> <p>Welcome to Docling Graph! This section introduces you to the core concepts of knowledge graph extraction from documents.</p>"},{"location":"introduction/#what-is-docling-graph","title":"What is Docling Graph?","text":"<p>Docling Graph is a powerful toolkit that transforms unstructured documents into validated knowledge graphs with precise semantic relationships. Unlike traditional document processing that converts text to vectors or embeddings (losing exact relationships), Docling Graph preserves the explicit connections between entities.</p>"},{"location":"introduction/#the-problem-with-traditional-approaches","title":"The Problem with Traditional Approaches","text":"<p>Traditional document processing methods: - Convert text to embeddings/vectors - Lose precise semantic relationships - Cannot answer \"who issued what to whom\" - Lack explainability and audit trails</p>"},{"location":"introduction/#the-docling-graph-solution","title":"The Docling Graph Solution","text":"<p>Docling Graph addresses these limitations by:</p> <ol> <li>Extracting Structured Data: Uses Pydantic schemas to guide extraction</li> <li>Validating Information: Ensures data quality through type checking and validation</li> <li>Building Knowledge Graphs: Creates explicit entity-relationship graphs</li> <li>Preserving Relationships: Maintains exact connections (e.g., \"Document A was issued by Organization B to Person C\")</li> <li>Enabling Explainability: Provides clear audit trails showing how information connects</li> </ol>"},{"location":"introduction/#why-knowledge-graphs","title":"Why Knowledge Graphs?","text":"<p>Knowledge graphs are essential for complex domains where understanding exact entity connections is critical:</p>"},{"location":"introduction/#chemistry-materials-science","title":"Chemistry &amp; Materials Science","text":"<ul> <li>Track chemical compounds and their reactions</li> <li>Link materials to their properties and measurements</li> <li>Understand synthesis processes and conditions</li> </ul>"},{"location":"introduction/#finance-legal","title":"Finance &amp; Legal","text":"<ul> <li>Map financial instruments and their dependencies</li> <li>Track contractual relationships and obligations</li> <li>Maintain compliance and regulatory connections</li> </ul>"},{"location":"introduction/#research-academia","title":"Research &amp; Academia","text":"<ul> <li>Connect authors, papers, and citations</li> <li>Link methodologies to results</li> <li>Track experimental conditions and outcomes</li> </ul>"},{"location":"introduction/#healthcare","title":"Healthcare","text":"<ul> <li>Relate patients, treatments, and outcomes</li> <li>Connect diagnoses to medications</li> <li>Track clinical trial relationships</li> </ul>"},{"location":"introduction/#how-it-works-the-pipeline","title":"How It Works: The Pipeline","text":"<p>Docling Graph follows a clear pipeline flow:</p> <pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A(\"1. Install\")\n\n    B@{ shape: lin-proc, label: \"2. Define Schema\" }\n    C@{ shape: lin-proc, label: \"3. Configure Pipeline\" }\n\n    D@{ shape: procs, label: \"4. Extract Data\" }\n    E@{ shape: procs, label: \"5. Build Graph\" }\n\n    F@{ shape: tag-proc, label: \"6. Export &amp; Visualize\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,C config\n    class D,E process\n    class F output</code></pre>"},{"location":"introduction/#pipeline-stages","title":"Pipeline Stages","text":"<ol> <li>Installation: Set up your environment with <code>uv</code></li> <li>Schema Definition: Create Pydantic templates defining what to extract</li> <li>Pipeline Configuration: Configure extraction backend and processing mode</li> <li>Extraction Process: Run document conversion and data extraction</li> <li>Graph Management: Export graphs and create visualizations</li> </ol>"},{"location":"introduction/#key-features","title":"Key Features","text":""},{"location":"introduction/#flexible-extraction","title":"\ud83e\udde0 Flexible Extraction","text":"<ul> <li>VLM Backend: Local vision-language models for structured documents</li> <li>LLM Backend: Local (vLLM, Ollama) or remote (OpenAI, Mistral, Gemini, WatsonX) for complex documents</li> <li>Hybrid Chunking: Smart document segmentation for large files</li> <li>Processing Modes: Page-wise or whole-document strategies</li> </ul>"},{"location":"introduction/#graph-construction","title":"\ud83d\udd28 Graph Construction","text":"<ul> <li>Validated Data: Pydantic ensures type safety and data quality</li> <li>Stable Node IDs: Deterministic identifiers for consistent graphs</li> <li>Rich Relationships: Explicit edge labels with semantic meaning</li> <li>Smart Deduplication: Automatic entity and component merging</li> </ul>"},{"location":"introduction/#multiple-export-formats","title":"\ud83d\udce6 Multiple Export Formats","text":"<ul> <li>CSV: Neo4j-compatible bulk import</li> <li>Cypher: Script generation for graph databases</li> <li>JSON: General-purpose data exchange</li> <li>Docling: Original document preservation</li> <li>HTML: Interactive visualization</li> </ul>"},{"location":"introduction/#visualization","title":"\ud83d\udcca Visualization","text":"<ul> <li>Interactive Graphs: Cytoscape.js-powered exploration</li> <li>Detailed Reports: Markdown documentation with statistics</li> <li>Node Inspection: Click to see entity properties</li> <li>Relationship Tracking: Hover to view edge labels</li> </ul>"},{"location":"introduction/#core-concepts","title":"Core Concepts","text":"<p>Before diving into the pipeline, familiarize yourself with these key concepts:</p> <ul> <li>Key Concepts: Entities, components, nodes, edges, and graphs</li> <li>Use Cases: Domain-specific examples and patterns</li> <li>Architecture: System design and component interaction</li> </ul>"},{"location":"introduction/#quick-example","title":"Quick Example","text":"<p>Here's a minimal example to give you a taste:</p> <pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom pydantic import BaseModel, Field\n\n# 1. Define what to extract\nclass Person(BaseModel):\n    model_config = {'is_entity': True, 'graph_id_fields': ['name']}\n    name: str = Field(description=\"Person's full name\")\n    email: str = Field(description=\"Email address\")\n\n# 2. Configure pipeline\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=Person,\n    backend=\"llm\",\n    inference=\"remote\",\n    output_dir=\"outputs\"\n)\n\n# 3. Run extraction\nrun_pipeline(config)\n</code></pre> <p>Result: A knowledge graph with Person nodes, exported as CSV, Cypher, JSON, and interactive HTML!</p>"},{"location":"introduction/#next-steps","title":"Next Steps","text":"<p>Ready to get started? Follow the pipeline stages:</p> <ol> <li>Installation - Set up your environment</li> <li>Key Concepts - Understand the fundamentals</li> <li>Use Cases - See domain-specific examples</li> </ol>"},{"location":"introduction/#related-documentation","title":"Related Documentation","text":"<ul> <li>Examples: Working code examples</li> <li>CLI Reference: Command-line usage</li> <li>Python API: Programmatic usage</li> </ul> <p>Ready to transform your documents into knowledge graphs? Let's begin with installation!</p>"},{"location":"introduction/architecture/","title":"Architecture","text":"<p>Pipeline Stage: 1 - Introduction &amp; Concepts</p> <p>Prerequisites:  - Introduction - Key Concepts</p> <p>This page provides a high-level overview of Docling Graph's architecture and how components interact.</p>"},{"location":"introduction/architecture/#system-architecture","title":"System Architecture","text":"<p>Docling Graph follows a modular, pipeline-based architecture with clear separation of concerns:  <pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Source Input\" }\n    n2@{ shape: terminal, label: \"Config\" }\n    n3@{ shape: terminal, label: \"Pydantic Template\" }\n\n    n4@{ shape: procs, label: \"Docling Graph Pipeline\" }\n    n35@{ shape: lin-proc, label: \"Input Validator\" }\n    n37@{ shape: tag-proc, label: \"Multi-Input Handler\" }\n    n39@{ shape: tag-proc, label: \"DoclingDoc Loader\" }\n    n5@{ shape: tag-proc, label: \"Extraction Factory\" }\n\n    n6@{ shape: procs, label: \"Docling Pipeline\" }\n    %% Defined first to prioritize placement\n    n25@{ shape: lin-proc, label: \"Extract\" } \n    n7@{ shape: lin-proc, label: \"OCR\" }\n    n8@{ shape: lin-proc, label: \"Vision\" }\n    n9@{ shape: tag-proc, label: \"Markdown Processor\" }\n\n    n16@{ shape: terminal, label: \"Prompt\" }\n    n13@{ shape: procs, label: \"Extraction Backend\" }\n    n14@{ shape: lin-proc, label: \"LLM\" }\n    n15@{ shape: lin-proc, label: \"VLM\" }\n    n17@{ shape: terminal, label: \"Extracted Content\" }\n\n    n10@{ shape: procs, label: \"Conversion Strategy\" }\n    n11@{ shape: lin-proc, label: \"One To One\" }\n    n12@{ shape: lin-proc, label: \"Many To One\" }\n    n18@{ shape: tag-proc, label: \"Smart Template Merger\" }\n    n20@{ shape: terminal, label: \"Populated Pydantic Model(s)\" }\n\n    n21@{ shape: tag-proc, label: \"Graph Converter\" }\n    n22@{ shape: terminal, label: \"Knowledge Graph\" }\n\n    n23@{ shape: tag-proc, label: \"Exporter\" }\n    n29@{ shape: terminal, label: \"CSV\" }\n    n30@{ shape: terminal, label: \"Cypher\" }\n    n31@{ shape: terminal, label: \"JSON\" }\n    n34@{ shape: tag-proc, label: \"Batch Loader\" }\n    n33@{ shape: db, label: \"Knowledge Base\" }\n\n    n24@{ shape: tag-proc, label: \"Visualizer\" }\n    n28@{ shape: terminal, label: \"Images\" }\n    n27@{ shape: terminal, label: \"HTML\" }\n    n26@{ shape: terminal, label: \"Markdown\" }\n\n    %% 3. Define Connections\n    A &amp; n2 &amp; n3 --&gt; n4\n    n4 --&gt; n35\n    n35 --&gt; n37 &amp; n39\n\n    n37 --&gt; n5\n    n39 --&gt; n6\n\n    n5 --&gt; n6\n\n    %% n25 first to encourage left placement\n    n6 --&gt; n25 &amp; n7 &amp; n8\n\n    n7 &amp; n8 --&gt; n9\n    n9 --&gt; n16\n    n16 --&gt; n13\n\n    n13 --&gt; n14 &amp; n15\n    n14 &amp; n15 --&gt; n17\n    n17 --&gt; n10\n\n    n10 --&gt; n11 &amp; n12\n    n12 --&gt; n18\n    n11 &amp; n18 &amp; n25 --&gt; n20\n\n    n20 --&gt; n21\n    n21 --&gt; n22\n    n22 --&gt; n23 &amp; n24\n\n    n23 --&gt; n29 &amp; n30 &amp; n31 &amp; n33\n    n29 &amp; n30 &amp; n31 --&gt; n34\n    n34 --&gt; n33\n\n    n24 --&gt; n28 &amp; n27 &amp; n26\n\n    %% 4. Apply Classes\n    class A,n3 input\n    class n2,n16 config\n    class n4,n35,n6,n7,n8,n25,n13,n14,n15,n10,n11,n12,n33 process\n    class n37,n39,n5,n9,n18,n21,n23,n34,n24 operator\n    class n17,n20,n22,n29,n30,n31,n28,n27,n26 output</code></pre></p>"},{"location":"introduction/architecture/#core-components","title":"Core Components","text":""},{"location":"introduction/architecture/#1-document-processor","title":"1. Document Processor","text":"<p>Location: <code>docling_graph/core/extractors/document_processor.py</code></p> <p>Purpose: Converts documents to structured format using Docling</p> <p>Key Features: - Supports OCR and Vision pipelines - Extracts full markdown or per-page markdown - Preserves document structure (sections, tables, lists) - Stateless operation for scalability</p> <p>Pipeline Options: - OCR Pipeline: Classic OCR (most accurate for standard documents) - Vision Pipeline: VLM-based (best for complex layouts)</p>"},{"location":"introduction/architecture/#2-extraction-backends","title":"2. Extraction Backends","text":""},{"location":"introduction/architecture/#vlm-backend","title":"VLM Backend","text":"<p>Location: <code>docling_graph/core/extractors/backends/vlm_backend.py</code></p> <p>Purpose: Direct extraction from document images using vision-language models</p> <p>Characteristics: - Processes documents directly (no markdown needed) - Uses Docling's NuExtract models - Local inference only - Ideal for structured forms</p> <p>Flow: <pre><code>Document \u2192 VLM Model \u2192 Pydantic Validation \u2192 Validated Models\n</code></pre></p>"},{"location":"introduction/architecture/#llm-backend","title":"LLM Backend","text":"<p>Location: <code>docling_graph/core/extractors/backends/llm_backend.py</code></p> <p>Purpose: Extraction from markdown using language models</p> <p>Characteristics: - Requires markdown conversion first - Supports local (vLLM, Ollama) and remote (OpenAI, Mistral, Gemini, WatsonX) - Includes chunking for large documents - Better for complex narratives</p> <p>Flow: <pre><code>Document \u2192 Markdown \u2192 Chunking \u2192 LLM Extraction \u2192 Consolidation \u2192 Validated Models\n</code></pre></p>"},{"location":"introduction/architecture/#3-llm-clients","title":"3. LLM Clients","text":"<p>Location: <code>docling_graph/llm_clients/</code></p> <p>Purpose: Unified interface for multiple LLM providers</p> <p>Architecture:</p> <pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% Custom Subgraph Style (Transparent with dashed border)\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5,color:#969696\n\n    %% 2. Define Nodes\n    A@{ shape: procs, label: \"BaseLlmClient&lt;br&gt;Template Method Pattern\" }\n\n    subgraph subGraph0[\"Client Implementations\"]\n        B@{ shape: lin-proc, label: \"VLLMClient\" }\n        C@{ shape: lin-proc, label: \"OllamaClient\" }\n        D@{ shape: lin-proc, label: \"MistralClient\" }\n        E@{ shape: lin-proc, label: \"OpenAIClient\" }\n        F@{ shape: lin-proc, label: \"GeminiClient\" }\n        G@{ shape: lin-proc, label: \"WatsonXClient\" }\n    end\n\n    H@{ shape: tag-proc, label: \"ResponseHandler&lt;br&gt;JSON Parsing\" }\n    I(\"Config&lt;br&gt;models.yaml\")\n\n    %% 3. Define Connections\n    A --&gt; B\n    A --&gt; C\n    A --&gt; D\n    A --&gt; E\n    A --&gt; F\n    A --&gt; G\n    subGraph0 --&gt; H\n    subGraph0 --&gt; I\n\n    %% 4. Apply Classes\n    class A,B,C,D,E,F,G process\n    class H operator\n    class I config\n    class subGraph0 subgraph_style</code></pre> <p>Key Features: - Template method pattern for consistency - Centralized JSON parsing - YAML-based model configuration - Easy to add new providers</p>"},{"location":"introduction/architecture/#4-processing-strategies","title":"4. Processing Strategies","text":"<p>Location: <code>docling_graph/core/extractors/strategies/</code></p> <p>Purpose: Handle multi-page documents differently</p>"},{"location":"introduction/architecture/#one-to-one-strategy","title":"One-to-One Strategy","text":"<pre><code>Page 1 \u2192 Extract \u2192 Model 1\nPage 2 \u2192 Extract \u2192 Model 2\nPage 3 \u2192 Extract \u2192 Model 3\n\nResult: [Model 1, Model 2, Model 3]\n</code></pre> <p>Use Case: Independent pages (invoice batches, ID card scans)</p>"},{"location":"introduction/architecture/#many-to-one-strategy","title":"Many-to-One Strategy","text":"<pre><code>Page 1 \u2510\nPage 2 \u251c\u2192 Extract \u2192 Merge \u2192 Single Model\nPage 3 \u2518\n\nResult: [Merged Model]\n</code></pre> <p>Use Case: Related content across pages (research papers, reports)</p>"},{"location":"introduction/architecture/#5-document-chunker","title":"5. Document Chunker","text":"<p>Location: <code>docling_graph/core/extractors/document_chunker.py</code></p> <p>Purpose: Split large documents while preserving semantic coherence</p> <p>Hybrid Chunking Strategy:</p> <pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Full Document\" }\n\n    B@{ shape: procs, label: \"Docling&lt;br/&gt;Segmentation\" }\n    C@{ shape: lin-proc, label: \"Semantic&lt;br/&gt;Boundaries\" }\n    D@{ shape: tag-proc, label: \"Token-Aware&lt;br/&gt;Splitting\" }\n\n    E(\"Chunks with&lt;br/&gt;Context\")\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B,C process\n    class D operator\n    class E output</code></pre> <p>Features: - Respects document structure (sections, tables) - Semantic boundary detection - Token limit awareness - Context preservation</p>"},{"location":"introduction/architecture/#6-consolidation","title":"6. Consolidation","text":"<p>Location: <code>docling_graph/core/extractors/backends/llm_backend.py</code></p> <p>Purpose: Merge results from multiple chunks</p>"},{"location":"introduction/architecture/#programmatic-merge-fast","title":"Programmatic Merge (Fast)","text":"<pre><code># Rules:\n# - Lists: Concatenate + deduplicate\n# - Scalars: First non-null wins\n# - Objects: Recursive merge\n</code></pre>"},{"location":"introduction/architecture/#llm-consolidation-intelligent","title":"LLM Consolidation (Intelligent)","text":"<pre><code># LLM receives:\n# - All partial models\n# - Template schema\n# - Consolidation prompt\n# Returns: Intelligently merged model\n</code></pre>"},{"location":"introduction/architecture/#7-graph-converter","title":"7. Graph Converter","text":"<p>Location: <code>docling_graph/core/converters/graph_converter.py</code></p> <p>Purpose: Transform Pydantic models to NetworkX graphs</p> <p>Process:</p> <pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Pydantic Models\" }\n\n    B@{ shape: lin-proc, label: \"Node ID&lt;br/&gt;Generation\" }\n    C@{ shape: lin-proc, label: \"Node&lt;br/&gt;Creation\" }\n    D@{ shape: lin-proc, label: \"Edge&lt;br/&gt;Creation\" }\n    E@{ shape: tag-proc, label: \"Graph&lt;br/&gt;Validation\" }\n\n    F(\"NetworkX&lt;br/&gt;DiGraph\")\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D process\n    class E operator\n    class F output</code></pre> <p>Key Features: - Stable, deterministic node IDs - Entity vs component handling - Automatic deduplication - Rich metadata preservation</p>"},{"location":"introduction/architecture/#8-node-id-registry","title":"8. Node ID Registry","text":"<p>Location: <code>docling_graph/core/converters/node_id_registry.py</code></p> <p>Purpose: Ensure stable, unique node identifiers</p> <p>Features: - Deterministic ID generation - Collision detection - Cross-batch consistency - Type tracking</p> <p>ID Generation: <pre><code># For entities (with graph_id_fields)\nPerson(name=\"John\", dob=\"1990-01-15\")\n\u2192 \"Person_John_1990-01-15\"\n\n# For components (content-based)\nAddress(street=\"123 Main\", city=\"Boston\")\n\u2192 \"Address_{content_hash}\"\n</code></pre></p>"},{"location":"introduction/architecture/#9-exporters","title":"9. Exporters","text":"<p>Location: <code>docling_graph/core/exporters/</code></p> <p>Purpose: Export graphs in multiple formats</p> <pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5,color:#969696\n\n    %% 2. Define Nodes &amp; Subgraphs\n    A@{ shape: terminal, label: \"NetworkX Graph\" }\n\n    subgraph subGraph0[\"Export Modules\"]\n        B@{ shape: tag-proc, label: \"CSV Exporter\" }\n        C@{ shape: tag-proc, label: \"Cypher Exporter\" }\n        D@{ shape: tag-proc, label: \"JSON Exporter\" }\n        E@{ shape: tag-proc, label: \"Docling Exporter\" }\n    end\n\n    %% Output Files\n    F@{ shape: doc, label: \"nodes.csv\" }\n    n1@{ shape: doc, label: \"edges.csv\" }\n    G@{ shape: doc, label: \"graph.cypher\" }\n    H@{ shape: doc, label: \"graph.json\" }\n    I@{ shape: doc, label: \"docling.json\" }\n    n2@{ shape: doc, label: \"document.md\" }\n\n    %% 3. Define Connections\n    A --&gt; B &amp; C &amp; D &amp; E\n\n    B --&gt; F &amp; n1\n    C --&gt; G\n    D --&gt; H\n    E --&gt; I &amp; n2\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D,E operator\n    class F,n1,G,H,I,n2 output\n    class subGraph0 subgraph_style</code></pre> <p>Exporters: - CSV: Neo4j admin import - Cypher: Neo4j script execution - JSON: General-purpose data - Docling: Original document preservation</p>"},{"location":"introduction/architecture/#10-visualizers","title":"10. Visualizers","text":"<p>Location: <code>docling_graph/core/visualizers/</code></p> <p>Purpose: Generate human-readable outputs</p> <p>Components: - Interactive Visualizer: Cytoscape.js HTML graphs - Report Generator: Detailed markdown reports</p>"},{"location":"introduction/architecture/#data-flow","title":"Data Flow","text":""},{"location":"introduction/architecture/#complete-pipeline-flow","title":"Complete Pipeline Flow","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Input Source\" }\n    A1@{ shape: procs, label: \"1. Input Normalization&lt;br/&gt;Type Detection &amp; Validation\" }\n\n    A2{\"Input Type\"}\n\n    B@{ shape: procs, label: \"2. Docling Conversion&lt;br/&gt;OCR or Vision\" }\n    B2@{ shape: lin-proc, label: \"2b. Text Processing&lt;br/&gt;Direct to Markdown\" }\n    B3@{ shape: lin-proc, label: \"2c. Load DoclingDocument&lt;br/&gt;Skip Conversion\" }\n\n    C{\"3. Backend\"}\n\n    D@{ shape: lin-proc, label: \"4a. VLM Extraction&lt;br/&gt;Direct from Document\" }\n    E@{ shape: lin-proc, label: \"4b. Markdown Extraction\" }\n\n    F{\"5. Chunking\"}\n\n    G@{ shape: tag-proc, label: \"6a. Hybrid Chunking&lt;br/&gt;Semantic + Token-Aware\" }\n    H@{ shape: tag-proc, label: \"6b. Full Document\" }\n\n    I@{ shape: procs, label: \"7. Batch Extraction&lt;br/&gt;Process Each Chunk\" }\n    J@{ shape: tag-proc, label: \"8. Pydantic Validation&lt;br/&gt;Type Checking\" }\n\n    K{\"9. Consolidation\"}\n\n    L@{ shape: lin-proc, label: \"10a. Smart Merge&lt;br/&gt;Rule-Based\" }\n    M@{ shape: lin-proc, label: \"10b. LLM Consolidation&lt;br/&gt;Intelligent\" }\n\n    N@{ shape: procs, label: \"11. Graph Conversion&lt;br/&gt;Pydantic \u2192 NetworkX\" }\n    O@{ shape: tag-proc, label: \"12. Node ID Generation&lt;br/&gt;Stable Identifiers\" }\n\n    P@{ shape: tag-proc, label: \"13. Export&lt;br/&gt;CSV/Cypher/JSON\" }\n    Q@{ shape: tag-proc, label: \"14. Visualization&lt;br/&gt;HTML + Reports\" }\n\n    %% 3. Define Connections\n    A --&gt; A1\n    A1 --&gt; A2\n\n    A2 -- \"PDF/Image\" --&gt; B\n    A2 -- \"Text/Markdown\" --&gt; B2\n    A2 -- \"DoclingDocument\" --&gt; B3\n\n    B --&gt; C\n    B2 --&gt; C\n\n    B3 --&gt; E\n\n    C -- VLM --&gt; D\n    C -- LLM --&gt; E\n\n    E --&gt; F\n    F -- Yes --&gt; G\n    F -- No --&gt; H\n\n    G --&gt; I\n    H --&gt; I\n\n    D --&gt; J\n    I --&gt; J\n    J --&gt; K\n\n    K -- Programmatic --&gt; L\n    K -- LLM --&gt; M\n\n    L --&gt; N\n    M --&gt; N\n\n    N --&gt; O\n    O --&gt; P\n    P --&gt; Q\n\n    %% 4. Apply Classes\n    class A input\n    class A1,B,I,N process\n    class B2,B3,D,E,L,M process\n    class A2,C,F,K decision\n    class G,H,J,O operator\n    class P,Q output</code></pre>"},{"location":"introduction/architecture/#stage-by-stage-breakdown","title":"Stage-by-Stage Breakdown","text":""},{"location":"introduction/architecture/#stage-1-template-loading","title":"Stage 1: Template Loading","text":"<pre><code># Load Pydantic template\ntemplate = import_template(\"module.Template\")\n# Validate structure\nvalidate_template(template)\n</code></pre>"},{"location":"introduction/architecture/#stage-2-document-conversion","title":"Stage 2: Document Conversion","text":"<pre><code># Convert using Docling\ndoc = processor.convert_to_docling_doc(source)\n# Extract markdown\nmarkdown = processor.extract_full_markdown(doc)\n</code></pre>"},{"location":"introduction/architecture/#stage-3-extraction","title":"Stage 3: Extraction","text":"<pre><code># Choose backend\nif backend == \"vlm\":\n    models = vlm_backend.extract_from_document(source, template)\nelse:\n    models = llm_backend.extract_from_markdown(markdown, template)\n</code></pre>"},{"location":"introduction/architecture/#stage-4-consolidation-if-needed","title":"Stage 4: Consolidation (if needed)","text":"<pre><code>if len(models) &gt; 1:\n    if llm_consolidation:\n        final_model = llm_backend.consolidate(models, template)\n    else:\n        final_model = programmatic_merge(models)\n</code></pre>"},{"location":"introduction/architecture/#stage-5-graph-conversion","title":"Stage 5: Graph Conversion","text":"<pre><code># Convert to graph\ngraph, metadata = converter.pydantic_list_to_graph([final_model])\n</code></pre>"},{"location":"introduction/architecture/#stage-6-export","title":"Stage 6: Export","text":"<pre><code># Export in multiple formats\ncsv_exporter.export(graph, output_dir)\ncypher_exporter.export(graph, output_dir)\njson_exporter.export(graph, output_dir)\n</code></pre>"},{"location":"introduction/architecture/#protocol-based-design","title":"Protocol-Based Design","text":"<p>Docling Graph uses Python Protocols for type-safe, flexible interfaces:</p> <pre><code>class ExtractionBackendProtocol(Protocol):\n    \"\"\"Protocol for extraction backends\"\"\"\n    def extract_from_document(self, source: str, template: Type[BaseModel]) -&gt; List[BaseModel]: ...\n    def cleanup(self) -&gt; None: ...\n\nclass LLMClientProtocol(Protocol):\n    \"\"\"Protocol for LLM clients\"\"\"\n    @property\n    def context_limit(self) -&gt; int: ...\n    def get_json_response(self, prompt: str, schema_json: str) -&gt; Dict[str, Any]: ...\n</code></pre> <p>Benefits: - Type safety without rigid inheritance - Easy mocking for tests - Clear interface contracts - Flexible implementations</p>"},{"location":"introduction/architecture/#configuration-system","title":"Configuration System","text":"<p>Location: <code>docling_graph/config.py</code></p> <p>Purpose: Type-safe configuration using Pydantic</p> <pre><code>class PipelineConfig(BaseModel):\n    \"\"\"Single source of truth for all defaults\"\"\"\n    source: str\n    template: Union[str, Type[BaseModel]]\n    backend: Literal[\"llm\", \"vlm\"] = \"llm\"\n    inference: Literal[\"local\", \"remote\"] = \"local\"\n    processing_mode: Literal[\"one-to-one\", \"many-to-one\"] = \"many-to-one\"\n    use_chunking: bool = True\n    llm_consolidation: bool = False\n    export_format: Literal[\"csv\", \"cypher\"] = \"csv\"\n    output_dir: str = \"outputs\"\n    # ... additional settings\n</code></pre>"},{"location":"introduction/architecture/#error-handling","title":"Error Handling","text":"<p>Location: <code>docling_graph/exceptions.py</code></p> <p>Hierarchy: <pre><code>DoclingGraphError (base)\n\u251c\u2500\u2500 ConfigurationError\n\u251c\u2500\u2500 ClientError\n\u251c\u2500\u2500 ExtractionError\n\u251c\u2500\u2500 ValidationError\n\u251c\u2500\u2500 GraphError\n\u2514\u2500\u2500 PipelineError\n</code></pre></p> <p>Structured Errors: <pre><code>try:\n    run_pipeline(config)\nexcept ClientError as e:\n    print(f\"Error: {e.message}\")\n    print(f\"Details: {e.details}\")\n    print(f\"Cause: {e.cause}\")\n</code></pre></p>"},{"location":"introduction/architecture/#performance-considerations","title":"Performance Considerations","text":""},{"location":"introduction/architecture/#memory-management","title":"Memory Management","text":"<ul> <li>GPU Memory: Automatic cleanup after extraction</li> <li>Stateless Design: No internal caching</li> <li>Batch Processing: Configurable batch sizes</li> </ul>"},{"location":"introduction/architecture/#optimization-strategies","title":"Optimization Strategies","text":"<ul> <li>Chunking: Reduces memory footprint</li> <li>Lazy Loading: Import modules on-demand</li> <li>Resource Pooling: Reuse LLM clients</li> <li>Parallel Processing: Future optimization for one-to-one mode</li> </ul>"},{"location":"introduction/architecture/#extensibility-points","title":"Extensibility Points","text":""},{"location":"introduction/architecture/#adding-new-llm-providers","title":"Adding New LLM Providers","text":"<pre><code>from docling_graph.llm_clients.base import BaseLlmClient\n\nclass MyClient(BaseLlmClient):\n    def _provider_id(self) -&gt; str:\n        return \"my_provider\"\n\n    def _setup_client(self, **kwargs):\n        self.api_key = self._get_required_env(\"MY_API_KEY\")\n        self.client = MyAPI(api_key=self.api_key)\n\n    def _call_api(self, messages, **params):\n        return self.client.call(messages)\n</code></pre>"},{"location":"introduction/architecture/#adding-custom-pipeline-stages","title":"Adding Custom Pipeline Stages","text":"<pre><code>from docling_graph.pipeline import PipelineStage, PipelineContext\n\nclass ValidationStage(PipelineStage):\n    def name(self) -&gt; str:\n        return \"Validation\"\n\n    def execute(self, context: PipelineContext) -&gt; PipelineContext:\n        # Custom validation logic\n        return context\n</code></pre>"},{"location":"introduction/architecture/#adding-new-export-formats","title":"Adding New Export Formats","text":"<pre><code>from docling_graph.core.exporters.base import BaseExporter\n\nclass MyExporter(BaseExporter):\n    def export(self, graph: nx.DiGraph, output_dir: str) -&gt; None:\n        # Custom export logic\n        pass\n</code></pre>"},{"location":"introduction/architecture/#next-steps","title":"Next Steps","text":"<p>Now that you understand the architecture:</p> <ol> <li>Installation - Set up your environment</li> <li>Schema Definition - Create Pydantic templates</li> <li>Pipeline Configuration - Configure the pipeline</li> </ol>"},{"location":"introduction/architecture/#related-documentation","title":"Related Documentation","text":"<ul> <li>Key Concepts: Core terminology</li> <li>Use Cases: Domain-specific examples</li> <li>API Reference: Detailed API documentation</li> </ul> <p>Ready to dive deeper? Start with installation or explore examples!</p>"},{"location":"introduction/key-concepts/","title":"Key Concepts","text":"<p>Pipeline Stage: 1 - Introduction &amp; Concepts</p> <p>Prerequisites:  - Introduction</p> <p>This page explains the fundamental concepts you need to understand before using Docling Graph.</p>"},{"location":"introduction/key-concepts/#core-terminology","title":"Core Terminology","text":""},{"location":"introduction/key-concepts/#entity","title":"Entity","text":"<p>An entity is a unique, identifiable object that you want to track individually in your knowledge graph.</p> <p>Characteristics: - Has a stable identity (defined by <code>graph_id_fields</code>) - Represents real-world objects (people, organizations, documents) - Tracked individually even if properties are similar</p> <p>Example: <pre><code>class Person(BaseModel):\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['name', 'date_of_birth']\n    }\n    name: str\n    date_of_birth: str\n    email: str\n</code></pre></p> <p>Two persons with the same name but different birth dates are different entities.</p>"},{"location":"introduction/key-concepts/#component","title":"Component","text":"<p>A component is a value object that is deduplicated by its content.</p> <p>Characteristics: - No unique identity (set <code>is_entity=False</code>) - Represents shared values (addresses, amounts, measurements) - Identical components share the same graph node</p> <p>Example: <pre><code>class Address(BaseModel):\n    model_config = {'is_entity': False'}\n    street: str\n    city: str\n    postal_code: str\n</code></pre></p> <p>Two people at \"123 Main St, Boston, 02101\" share the same Address node.</p>"},{"location":"introduction/key-concepts/#node","title":"Node","text":"<p>A node is a vertex in the knowledge graph. Every Pydantic model instance becomes a node.</p> <p>Node Properties: - ID: Unique identifier (generated from <code>graph_id_fields</code> or content hash) - Type: The Pydantic class name (e.g., \"Person\", \"Organization\") - Attributes: All field values from the Pydantic model</p> <p>Example Node: <pre><code>ID: Person_JohnDoe_1990-01-15\nType: Person\nAttributes:\n  - name: \"John Doe\"\n  - date_of_birth: \"1990-01-15\"\n  - email: \"john@example.com\"\n</code></pre></p>"},{"location":"introduction/key-concepts/#edge","title":"Edge","text":"<p>An edge is a directed relationship between two nodes in the graph.</p> <p>Edge Properties: - Source: The node where the relationship starts - Target: The node where the relationship ends - Label: The relationship type (e.g., \"ISSUED_BY\", \"SENT_TO\") - Direction: Edges are directional (A \u2192 B is different from B \u2192 A)</p> <p>Example Edge: <pre><code>Source: Document_INV001\nLabel: ISSUED_BY\nTarget: Organization_AcmeCorp\n</code></pre></p> <p>This represents: \"Document INV001 was issued by Acme Corp\"</p>"},{"location":"introduction/key-concepts/#graph","title":"Graph","text":"<p>A graph is the complete network of nodes and edges representing your extracted knowledge.</p> <p>Graph Structure: <pre><code>Document_INV001\n  \u251c\u2500 ISSUED_BY \u2192 Organization_AcmeCorp\n  \u251c\u2500 SENT_TO \u2192 Person_JohnDoe\n  \u2514\u2500 CONTAINS_ITEM \u2192 LineItem_001\n      \u2514\u2500 HAS_PRODUCT \u2192 Product_Widget\n</code></pre></p>"},{"location":"introduction/key-concepts/#pydantic-templates","title":"Pydantic Templates","text":""},{"location":"introduction/key-concepts/#what-is-a-template","title":"What is a Template?","text":"<p>A Pydantic template is a Python class that serves three purposes:</p> <ol> <li>Extraction Schema: Tells the LLM/VLM what data to extract</li> <li>Validation Rules: Ensures data quality and consistency</li> <li>Graph Structure: Defines how entities and relationships map to nodes and edges</li> </ol>"},{"location":"introduction/key-concepts/#template-example","title":"Template Example","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import List\n\ndef edge(label: str, **kwargs):\n    \"\"\"Helper to define graph relationships\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\nclass Organization(BaseModel):\n    \"\"\"An organization entity\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['name']\n    }\n\n    name: str = Field(\n        description=\"Legal name of the organization\",\n        examples=[\"Acme Corp\", \"Tech Solutions Ltd\"]\n    )\n\n    tax_id: str = Field(\n        description=\"Tax identification number\",\n        examples=[\"123456789\", \"FR12345678901\"]\n    )\n\nclass Invoice(BaseModel):\n    \"\"\"An invoice document\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['invoice_number']\n    }\n\n    invoice_number: str = Field(\n        description=\"Unique invoice identifier\",\n        examples=[\"INV-2024-001\", \"INV-123456\"]\n    )\n\n    # This creates an edge in the graph\n    issuer: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Organization that issued this invoice\"\n    )\n</code></pre> <p>Result: When extracted, this creates: - An <code>Invoice</code> node - An <code>Organization</code> node - An <code>ISSUED_BY</code> edge connecting them</p>"},{"location":"introduction/key-concepts/#extraction-backends","title":"Extraction Backends","text":""},{"location":"introduction/key-concepts/#vlm-vision-language-model","title":"VLM (Vision-Language Model)","text":"<p>What: Uses Docling's NuExtract models to extract data directly from document images.</p> <p>Best For: - Structured forms (invoices, ID cards, receipts) - Documents with clear key-value pairs - Small documents (1-3 pages)</p> <p>Characteristics: - Processes documents directly (no markdown conversion) - Local inference only - Fast for small documents - Excellent for forms</p>"},{"location":"introduction/key-concepts/#llm-large-language-model","title":"LLM (Large Language Model)","text":"<p>What: Uses language models to extract data from markdown/text representations.</p> <p>Best For: - Complex narratives (research papers, reports) - Large documents (5+ pages) - Documents requiring deep understanding</p> <p>Characteristics: - Requires markdown conversion first - Local (vLLM, Ollama) or remote (OpenAI, Mistral, Gemini, WatsonX) - Supports chunking for large documents - Better for complex extraction</p>"},{"location":"introduction/key-concepts/#processing-modes","title":"Processing Modes","text":""},{"location":"introduction/key-concepts/#one-to-one","title":"One-to-One","text":"<p>What: Process each page independently, producing one Pydantic model per page.</p> <p>When to Use: - Each page contains independent information - Document is a batch of separate items (e.g., multiple invoices in one PDF) - You need page-level granularity</p> <p>Example: <pre><code>3-page PDF with 3 invoices\n\u2192 3 separate Invoice models\n\u2192 3 separate subgraphs\n</code></pre></p>"},{"location":"introduction/key-concepts/#many-to-one","title":"Many-to-One","text":"<p>What: Process all pages together, producing one merged Pydantic model for the entire document.</p> <p>When to Use: - Document spans multiple pages with related content - Information flows across pages - You want a document-level view</p> <p>Example: <pre><code>10-page research paper\n\u2192 1 merged ResearchPaper model\n\u2192 1 unified graph\n</code></pre></p>"},{"location":"introduction/key-concepts/#chunking","title":"Chunking","text":""},{"location":"introduction/key-concepts/#why-chunking","title":"Why Chunking?","text":"<p>Large documents may exceed LLM context limits. Chunking splits the document into manageable pieces while preserving semantic coherence.</p>"},{"location":"introduction/key-concepts/#hybrid-chunking-strategy","title":"Hybrid Chunking Strategy","text":"<p>Docling Graph uses a sophisticated approach:</p> <ol> <li>Docling Segmentation: Respects document structure (sections, tables, lists)</li> <li>Semantic Boundaries: Groups related content together</li> <li>Token-Aware: Respects LLM context limits</li> <li>Context Preservation: Maintains coherence across chunks</li> </ol>"},{"location":"introduction/key-concepts/#consolidation","title":"Consolidation","text":"<p>After extracting from multiple chunks, results must be merged:</p> <p>Programmatic Merge (Fast): - Lists: Concatenate and deduplicate - Scalars: First non-null value wins - Objects: Recursive merge</p> <p>LLM Consolidation (Intelligent): - Uses LLM to intelligently merge results - Better handles semantic duplicates - Slower but more accurate</p>"},{"location":"introduction/key-concepts/#graph-construction","title":"Graph Construction","text":""},{"location":"introduction/key-concepts/#node-id-generation","title":"Node ID Generation","text":"<p>For Entities (with <code>graph_id_fields</code>): <pre><code># Person with graph_id_fields=['name', 'dob']\nPerson(name=\"John Doe\", dob=\"1990-01-15\")\n\u2192 Node ID: \"Person_JohnDoe_1990-01-15\"\n</code></pre></p> <p>For Components (content-based): <pre><code># Address with is_entity=False\nAddress(street=\"123 Main St\", city=\"Boston\")\n\u2192 Node ID: \"Address_{content_hash}\"\n</code></pre></p>"},{"location":"introduction/key-concepts/#deduplication","title":"Deduplication","text":"<p>Entities: Deduplicated by <code>graph_id_fields</code> - Same ID fields \u2192 Same node</p> <p>Components: Deduplicated by content - Same field values \u2192 Same node</p>"},{"location":"introduction/key-concepts/#example-graph","title":"Example Graph","text":"<p>Given these models:</p> <pre><code>author1 = Author(name=\"Dr. Smith\")\nauthor2 = Author(name=\"Dr. Jones\")\npaper = Paper(\n    title=\"Advanced AI\",\n    authors=[author1, author2]\n)\n</code></pre> <p>Resulting graph:</p> <pre><code>Paper_AdvancedAI\n  \u251c\u2500 HAS_AUTHOR \u2192 Author_DrSmith\n  \u2514\u2500 HAS_AUTHOR \u2192 Author_DrJones\n</code></pre>"},{"location":"introduction/key-concepts/#export-formats","title":"Export Formats","text":""},{"location":"introduction/key-concepts/#csv","title":"CSV","text":"<ul> <li>Purpose: Neo4j bulk import</li> <li>Files: <code>nodes.csv</code>, <code>edges.csv</code></li> <li>Best For: Production database loading</li> </ul>"},{"location":"introduction/key-concepts/#cypher","title":"Cypher","text":"<ul> <li>Purpose: Neo4j script execution</li> <li>Files: <code>document_graph.cypher</code></li> <li>Best For: Development and incremental updates</li> </ul>"},{"location":"introduction/key-concepts/#json","title":"JSON","text":"<ul> <li>Purpose: General-purpose data exchange</li> <li>Files: <code>document_graph.json</code></li> <li>Best For: API integration, archival</li> </ul>"},{"location":"introduction/key-concepts/#html","title":"HTML","text":"<ul> <li>Purpose: Interactive visualization</li> <li>Files: <code>document_graph.html</code></li> <li>Best For: Exploration and presentation</li> </ul>"},{"location":"introduction/key-concepts/#next-steps","title":"Next Steps","text":"<p>Now that you understand the core concepts:</p> <ol> <li>Use Cases - See domain-specific examples</li> <li>Architecture - Understand system design</li> <li>Installation - Set up your environment</li> </ol>"},{"location":"introduction/key-concepts/#related-documentation","title":"Related Documentation","text":"<ul> <li>Schema Definition: Deep dive into Pydantic templates</li> <li>Pipeline Configuration: Configure extraction</li> <li>Graph Management: Export and visualize graphs</li> </ul> <p>Questions? Check out the examples or dive into schema definition!</p>"},{"location":"introduction/quickstart/","title":"Quickstart","text":""},{"location":"introduction/quickstart/#overview","title":"Overview","text":"<p>Get started with docling-graph in 5 minutes by extracting structured data from a simple invoice.</p> <p>What You'll Learn: - Basic template creation - Running your first extraction - Viewing results</p> <p>Prerequisites: - Python 3.10+ - <code>uv</code> package manager - A sample invoice (PDF or image)</p>"},{"location":"introduction/quickstart/#step-1-installation","title":"Step 1: Installation","text":"<pre><code># Install docling-graph with all features\nuv sync --extra all\n\n# Verify installation\nuv run docling-graph --version\n</code></pre>"},{"location":"introduction/quickstart/#step-2-create-a-template","title":"Step 2: Create a Template","text":"<p>Create a file <code>simple_invoice.py</code>:</p> <pre><code>\"\"\"Simple invoice template for quickstart.\"\"\"\n\nfrom pydantic import BaseModel, Field\n\nclass SimpleInvoice(BaseModel):\n    \"\"\"A simple invoice model.\"\"\"\n\n    invoice_number: str = Field(\n        description=\"The unique invoice identifier\",\n        examples=[\"INV-001\", \"2024-001\"]\n    )\n\n    date: str = Field(\n        description=\"Invoice date in any format\",\n        examples=[\"2024-01-15\", \"January 15, 2024\"]\n    )\n\n    total: float = Field(\n        description=\"Total amount to be paid\",\n        examples=[1234.56, 999.99]\n    )\n\n    currency: str = Field(\n        description=\"Currency code\",\n        examples=[\"USD\", \"EUR\", \"GBP\"]\n    )\n</code></pre>"},{"location":"introduction/quickstart/#step-3-run-extraction","title":"Step 3: Run Extraction","text":""},{"location":"introduction/quickstart/#option-a-using-cli","title":"Option A: Using CLI","text":"<pre><code># Process invoice\nuv run docling-graph convert invoice.pdf \\\n    --template \"simple_invoice.SimpleInvoice\" \\\n    --output-dir \"quickstart_output\"\n</code></pre>"},{"location":"introduction/quickstart/#option-b-using-python-api","title":"Option B: Using Python API","text":"<p>Create <code>run_quickstart.py</code>:</p> <pre><code>\"\"\"Quickstart extraction script.\"\"\"\n\nfrom docling_graph import PipelineConfig\n\n# Configure pipeline\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"simple_invoice.SimpleInvoice\",\n    output_dir=\"quickstart_output\"\n)\n\n# Run extraction\nprint(\"Processing invoice...\")\nconfig.run()\nprint(\"\u2713 Complete! Check quickstart_output/\")\n</code></pre> <p>Run it:</p> <pre><code>uv run python run_quickstart.py\n</code></pre>"},{"location":"introduction/quickstart/#step-4-view-results","title":"Step 4: View Results","text":""},{"location":"introduction/quickstart/#inspect-graph-visually","title":"Inspect Graph Visually","text":"<pre><code># Open interactive visualization\nuv run docling-graph inspect quickstart_output/\n</code></pre> <p>This opens an HTML visualization in your browser showing: - Extracted nodes (invoice data) - Relationships (if any) - Interactive exploration</p>"},{"location":"introduction/quickstart/#view-csv-data","title":"View CSV Data","text":"<pre><code># View nodes\ncat quickstart_output/nodes.csv\n\n# View edges\ncat quickstart_output/edges.csv\n</code></pre> <p>Example nodes.csv: <pre><code>id,label,type,invoice_number,date,total,currency\ninvoice_1,SimpleInvoice,SimpleInvoice,INV-001,2024-01-15,1234.56,USD\n</code></pre></p>"},{"location":"introduction/quickstart/#view-statistics","title":"View Statistics","text":"<pre><code># View graph statistics\ncat quickstart_output/graph_stats.json\n</code></pre> <p>Example output: <pre><code>{\n  \"node_count\": 1,\n  \"edge_count\": 0,\n  \"density\": 0.0,\n  \"avg_degree\": 0.0,\n  \"node_types\": {\n    \"SimpleInvoice\": 1\n  },\n  \"edge_types\": {}\n}\n</code></pre></p>"},{"location":"introduction/quickstart/#complete-example","title":"Complete Example","text":"<p>Here's everything together:</p>"},{"location":"introduction/quickstart/#1-create-template","title":"1. Create Template","text":"<p>File: <code>simple_invoice.py</code></p> <pre><code>from pydantic import BaseModel, Field\n\nclass SimpleInvoice(BaseModel):\n    \"\"\"A simple invoice model.\"\"\"\n\n    invoice_number: str = Field(\n        description=\"The unique invoice identifier\",\n        examples=[\"INV-001\", \"2024-001\"]\n    )\n\n    date: str = Field(\n        description=\"Invoice date\",\n        examples=[\"2024-01-15\"]\n    )\n\n    total: float = Field(\n        description=\"Total amount\",\n        examples=[1234.56]\n    )\n\n    currency: str = Field(\n        description=\"Currency code\",\n        examples=[\"USD\", \"EUR\"]\n    )\n</code></pre>"},{"location":"introduction/quickstart/#2-run-extraction","title":"2. Run Extraction","text":"<p>CLI: <pre><code>uv run docling-graph convert invoice.pdf \\\n    --template \"simple_invoice.SimpleInvoice\" \\\n    --output-dir \"quickstart_output\"\n</code></pre></p> <p>Python: <pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"simple_invoice.SimpleInvoice\",\n    output_dir=\"quickstart_output\"\n)\nconfig.run()\n</code></pre></p>"},{"location":"introduction/quickstart/#3-view-results","title":"3. View Results","text":"<pre><code># Interactive visualization\nuv run docling-graph inspect quickstart_output/\n\n# View data\ncat quickstart_output/nodes.csv\ncat quickstart_output/graph_stats.json\n</code></pre>"},{"location":"introduction/quickstart/#expected-output-structure","title":"Expected Output Structure","text":"<pre><code>quickstart_output/\n\u251c\u2500\u2500 nodes.csv                    # Extracted data\n\u251c\u2500\u2500 edges.csv                    # Relationships (empty for simple model)\n\u251c\u2500\u2500 graph.json                   # Complete graph\n\u251c\u2500\u2500 graph_stats.json             # Statistics\n\u251c\u2500\u2500 graph_visualization.html     # Interactive viz\n\u251c\u2500\u2500 markdown_report.md           # Summary report\n\u2514\u2500\u2500 full_document.md             # Markdown export\n</code></pre>"},{"location":"introduction/quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"introduction/quickstart/#issue-template-not-found","title":"Issue: Template Not Found","text":"<p>Error: <pre><code>ModuleNotFoundError: No module named 'simple_invoice'\n</code></pre></p> <p>Solution: <pre><code># Ensure template is in current directory\nls simple_invoice.py\n\n# Or use absolute path\nuv run docling-graph convert invoice.pdf \\\n    --template \"$(pwd)/simple_invoice.SimpleInvoice\"\n</code></pre></p>"},{"location":"introduction/quickstart/#issue-no-data-extracted","title":"Issue: No Data Extracted","text":"<p>Problem: Empty nodes.csv</p> <p>Solution: 1. Check template descriptions are clear 2. Verify document is readable 3. Try with verbose logging:</p> <pre><code>uv run docling-graph --verbose convert invoice.pdf \\\n    --template \"simple_invoice.SimpleInvoice\"\n</code></pre>"},{"location":"introduction/quickstart/#issue-api-key-error","title":"Issue: API Key Error","text":"<p>Error: <pre><code>ConfigurationError: API key not found\n</code></pre></p> <p>Solution: <pre><code># Use local inference (default)\nuv run docling-graph convert invoice.pdf \\\n    --template \"simple_invoice.SimpleInvoice\" \\\n    --inference local\n\n# Or set API key for remote\nexport MISTRAL_API_KEY=\"your-key\"\n</code></pre></p>"},{"location":"introduction/quickstart/#next-steps","title":"Next Steps","text":""},{"location":"introduction/quickstart/#improve-your-template","title":"Improve Your Template","text":"<p>Add more fields:</p> <pre><code>class ImprovedInvoice(BaseModel):\n    \"\"\"Improved invoice with more fields.\"\"\"\n\n    invoice_number: str = Field(description=\"Invoice number\")\n    date: str = Field(description=\"Invoice date\")\n    total: float = Field(description=\"Total amount\")\n    currency: str = Field(description=\"Currency\")\n\n    # New fields\n    issuer_name: str = Field(\n        description=\"Company that issued the invoice\",\n        examples=[\"Acme Corp\", \"ABC Company\"]\n    )\n\n    client_name: str = Field(\n        description=\"Client receiving the invoice\",\n        examples=[\"John Doe\", \"XYZ Inc\"]\n    )\n\n    subtotal: float = Field(\n        description=\"Amount before tax\",\n        examples=[1000.00]\n    )\n\n    tax_amount: float = Field(\n        description=\"Tax amount\",\n        examples=[234.56]\n    )\n</code></pre>"},{"location":"introduction/quickstart/#add-relationships","title":"Add Relationships","text":"<p>Create nested entities:</p> <pre><code>class Address(BaseModel):\n    \"\"\"Address component.\"\"\"\n    street: str\n    city: str\n    postal_code: str\n\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    name: str\n    address: Address\n\ndef edge(label: str, **kwargs):\n    \"\"\"Helper for graph edges.\"\"\"\n    from pydantic import Field\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\nclass Invoice(BaseModel):\n    \"\"\"Invoice with relationships.\"\"\"\n    invoice_number: str\n    total: float\n    issued_by: Organization = edge(label=\"ISSUED_BY\")\n</code></pre>"},{"location":"introduction/quickstart/#try-different-backends","title":"Try Different Backends","text":"<pre><code># VLM for images (faster)\nuv run docling-graph convert invoice.jpg \\\n    --template \"simple_invoice.SimpleInvoice\" \\\n    --backend vlm\n\n# LLM for complex documents\nuv run docling-graph convert invoice.pdf \\\n    --template \"simple_invoice.SimpleInvoice\" \\\n    --backend llm \\\n    --inference remote\n</code></pre>"},{"location":"introduction/quickstart/#learn-more","title":"Learn More","text":""},{"location":"introduction/quickstart/#complete-examples","title":"Complete Examples","text":"<ul> <li>Invoice Extraction \u2192 - Full invoice with relationships</li> <li>Research Paper \u2192 - Complex scientific documents</li> <li>ID Card \u2192 - Vision-based extraction</li> </ul>"},{"location":"introduction/quickstart/#documentation","title":"Documentation","text":"<ul> <li>Schema Definition \u2192 - Template creation guide</li> <li>CLI Reference \u2192 - All CLI commands</li> <li>Python API \u2192 - Programmatic usage</li> </ul>"},{"location":"introduction/quickstart/#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Custom Backends \u2192 - Create custom extractors</li> <li>Performance Tuning \u2192 - Optimize processing</li> <li>Testing \u2192 - Test your templates</li> </ul>"},{"location":"introduction/quickstart/#quick-reference","title":"Quick Reference","text":""},{"location":"introduction/quickstart/#minimal-template","title":"Minimal Template","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass MyTemplate(BaseModel):\n    field1: str = Field(description=\"Description\")\n    field2: float = Field(description=\"Description\")\n</code></pre>"},{"location":"introduction/quickstart/#run-extraction","title":"Run Extraction","text":"<pre><code># CLI\nuv run docling-graph convert doc.pdf -t \"template.MyTemplate\"\n\n# Python\nfrom docling_graph import PipelineConfig\nconfig = PipelineConfig(source=\"doc.pdf\", template=\"template.MyTemplate\")\nconfig.run()\n</code></pre>"},{"location":"introduction/quickstart/#view-results","title":"View Results","text":"<pre><code># Visualize\nuv run docling-graph inspect outputs/\n\n# View data\ncat outputs/nodes.csv\n</code></pre>"},{"location":"introduction/quickstart/#summary","title":"Summary","text":"<p>You've learned: \u2705 How to create a simple Pydantic template \u2705 How to run extraction (CLI and Python) \u2705 How to view and inspect results \u2705 Basic troubleshooting</p> <p>Time taken: ~5 minutes</p> <p>Next: Try the Invoice Extraction example for a more complete workflow!</p>"},{"location":"introduction/use-cases/","title":"Use Cases","text":"<p>Pipeline Stage: 1 - Introduction &amp; Concepts</p> <p>Prerequisites:  - Introduction - Key Concepts</p> <p>This page demonstrates how Docling Graph solves real-world problems across different domains.</p>"},{"location":"introduction/use-cases/#why-domain-specific-knowledge-graphs","title":"Why Domain-Specific Knowledge Graphs?","text":"<p>Different domains have unique requirements for knowledge representation:</p> <ul> <li>Chemistry: Track exact molecular structures and reaction conditions</li> <li>Finance: Map complex instrument dependencies and risk relationships</li> <li>Legal: Maintain precise contractual obligations and party relationships</li> <li>Research: Connect methodologies, results, and citations with full context</li> </ul> <p>Traditional text embeddings lose these precise relationships. Knowledge graphs preserve them.</p>"},{"location":"introduction/use-cases/#chemistry-materials-science","title":"Chemistry &amp; Materials Science","text":""},{"location":"introduction/use-cases/#challenge","title":"Challenge","text":"<p>Research papers contain complex information about materials, their properties, measurements, and synthesis processes. Understanding \"Material A has Property B measured at Condition C\" requires exact relationship tracking.</p>"},{"location":"introduction/use-cases/#solution-with-docling-graph","title":"Solution with Docling Graph","text":"<p>Template Structure: <pre><code>class Material(BaseModel):\n    \"\"\"A chemical material or compound\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['name', 'grade']}\n\n    name: str = Field(description=\"Material name or chemical formula\")\n    grade: Optional[str] = Field(None, description=\"Purity or grade\")\n    cas_number: Optional[str] = Field(None, description=\"CAS registry number\")\n\nclass Measurement(BaseModel):\n    \"\"\"A measured property\"\"\"\n    model_config = {'is_entity': False}\n\n    property_name: str = Field(description=\"Property being measured\")\n    value: float = Field(description=\"Measured value\")\n    unit: str = Field(description=\"Unit of measurement\")\n    conditions: Optional[str] = Field(None, description=\"Measurement conditions\")\n\nclass Experiment(BaseModel):\n    \"\"\"An experimental procedure\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['experiment_id']}\n\n    experiment_id: str\n    materials: List[Material] = edge(label=\"USES_MATERIAL\", default_factory=list)\n    measurements: List[Measurement] = edge(label=\"HAS_MEASUREMENT\", default_factory=list)\n    temperature: Optional[str] = Field(None, description=\"Process temperature\")\n</code></pre></p> <p>Resulting Graph: <pre><code>Experiment_EXP001\n  \u251c\u2500 USES_MATERIAL \u2192 Material_Lithium_99.9%\n  \u251c\u2500 USES_MATERIAL \u2192 Material_Graphite_Battery\n  \u251c\u2500 HAS_MEASUREMENT \u2192 Measurement_Viscosity_1.6mPa.s_25C\n  \u2514\u2500 HAS_MEASUREMENT \u2192 Measurement_Conductivity_10mS/cm_25C\n</code></pre></p> <p>Benefits: - Track exact material-property relationships - Query \"What materials were used at 25\u00b0C?\" - Find all experiments using Lithium - Compare measurements across conditions</p>"},{"location":"introduction/use-cases/#real-example-battery-research","title":"Real Example: Battery Research","text":"<p>Extract from: \"Rheological Properties of Lithium-Ion Battery Electrolytes\"</p> <p>Extracted Graph: - 15 Material nodes (electrolytes, solvents, salts) - 45 Measurement nodes (viscosity, conductivity, temperature) - 8 Experiment nodes - 120+ relationships</p> <p>Queries Enabled: - \"Which electrolytes have viscosity &lt; 2 mPa\u00b7s at 25\u00b0C?\" - \"What are all measurements for LiPF6-based electrolytes?\" - \"Which experiments used both EC and DMC solvents?\"</p>"},{"location":"introduction/use-cases/#finance-legal","title":"Finance &amp; Legal","text":""},{"location":"introduction/use-cases/#challenge_1","title":"Challenge","text":"<p>Financial documents contain complex instrument relationships, party obligations, and temporal dependencies. Understanding \"Entity A owes Entity B under Contract C with Condition D\" requires precise tracking.</p>"},{"location":"introduction/use-cases/#solution-with-docling-graph_1","title":"Solution with Docling Graph","text":"<p>Template Structure: <pre><code>class Party(BaseModel):\n    \"\"\"A legal or financial entity\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['name', 'tax_id']}\n\n    name: str = Field(description=\"Legal entity name\")\n    tax_id: Optional[str] = Field(None, description=\"Tax identification number\")\n    jurisdiction: Optional[str] = Field(None, description=\"Legal jurisdiction\")\n\nclass Obligation(BaseModel):\n    \"\"\"A contractual obligation\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['obligation_id']}\n\n    obligation_id: str\n    description: str = Field(description=\"Obligation description\")\n    amount: Optional[MonetaryAmount] = Field(None)\n    due_date: Optional[date] = Field(None)\n\n    obligor: Party = edge(label=\"OBLIGATED_BY\")\n    obligee: Party = edge(label=\"OBLIGATED_TO\")\n\nclass Contract(BaseModel):\n    \"\"\"A legal contract\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['contract_number']}\n\n    contract_number: str\n    effective_date: date\n    parties: List[Party] = edge(label=\"HAS_PARTY\", default_factory=list)\n    obligations: List[Obligation] = edge(label=\"CONTAINS_OBLIGATION\", default_factory=list)\n</code></pre></p> <p>Resulting Graph: <pre><code>Contract_2024-001\n  \u251c\u2500 HAS_PARTY \u2192 Party_AcmeCorp_123456789\n  \u251c\u2500 HAS_PARTY \u2192 Party_TechSolutions_987654321\n  \u2514\u2500 CONTAINS_OBLIGATION \u2192 Obligation_OBL001\n      \u251c\u2500 OBLIGATED_BY \u2192 Party_AcmeCorp_123456789\n      \u2514\u2500 OBLIGATED_TO \u2192 Party_TechSolutions_987654321\n</code></pre></p> <p>Benefits: - Track party-obligation relationships - Query \"What are all obligations of Acme Corp?\" - Find contracts expiring in Q1 2024 - Identify circular dependencies</p>"},{"location":"introduction/use-cases/#real-example-loan-agreement","title":"Real Example: Loan Agreement","text":"<p>Extract from: \"Commercial Loan Agreement\"</p> <p>Extracted Graph: - 4 Party nodes (borrower, lender, guarantors) - 12 Obligation nodes (payments, covenants, conditions) - 1 Contract node - 25+ relationships</p> <p>Queries Enabled: - \"Who guarantees this loan?\" - \"What are the payment obligations?\" - \"Which covenants apply to the borrower?\"</p>"},{"location":"introduction/use-cases/#research-academia","title":"Research &amp; Academia","text":""},{"location":"introduction/use-cases/#challenge_2","title":"Challenge","text":"<p>Research papers contain complex networks of authors, institutions, methodologies, results, and citations. Understanding \"Author A from Institution B used Method C to achieve Result D\" requires relationship tracking.</p>"},{"location":"introduction/use-cases/#solution-with-docling-graph_2","title":"Solution with Docling Graph","text":"<p>Template Structure: <pre><code>class Author(BaseModel):\n    \"\"\"A research author\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['name', 'affiliation']}\n\n    name: str = Field(description=\"Author's full name\")\n    affiliation: str = Field(description=\"Institution affiliation\")\n    email: Optional[str] = Field(None)\n\nclass Methodology(BaseModel):\n    \"\"\"A research methodology\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['name']}\n\n    name: str = Field(description=\"Methodology name\")\n    description: str = Field(description=\"Methodology description\")\n    parameters: Optional[str] = Field(None)\n\nclass Result(BaseModel):\n    \"\"\"A research finding\"\"\"\n    model_config = {'is_entity': False}\n\n    finding: str = Field(description=\"Key finding or result\")\n    metric: Optional[str] = Field(None)\n    value: Optional[str] = Field(None)\n\nclass ResearchPaper(BaseModel):\n    \"\"\"A research publication\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['title']}\n\n    title: str\n    abstract: str\n    year: int\n\n    authors: List[Author] = edge(label=\"HAS_AUTHOR\", default_factory=list)\n    methodologies: List[Methodology] = edge(label=\"USES_METHODOLOGY\", default_factory=list)\n    results: List[Result] = edge(label=\"HAS_RESULT\", default_factory=list)\n</code></pre></p> <p>Resulting Graph: <pre><code>ResearchPaper_AdvancedAI\n  \u251c\u2500 HAS_AUTHOR \u2192 Author_DrSmith_MIT\n  \u251c\u2500 HAS_AUTHOR \u2192 Author_DrJones_Stanford\n  \u251c\u2500 USES_METHODOLOGY \u2192 Methodology_DeepLearning\n  \u251c\u2500 USES_METHODOLOGY \u2192 Methodology_TransferLearning\n  \u251c\u2500 HAS_RESULT \u2192 Result_Accuracy95%\n  \u2514\u2500 HAS_RESULT \u2192 Result_TrainingTime50%Reduced\n</code></pre></p> <p>Benefits: - Track author collaboration networks - Query \"What methodologies did MIT researchers use?\" - Find papers with similar results - Identify research trends</p>"},{"location":"introduction/use-cases/#real-example-ai-research-paper","title":"Real Example: AI Research Paper","text":"<p>Extract from: \"Advances in Neural Architecture Search\"</p> <p>Extracted Graph: - 8 Author nodes - 5 Methodology nodes - 12 Result nodes - 1 Paper node - 35+ relationships</p> <p>Queries Enabled: - \"Who collaborated with Dr. Smith?\" - \"What methodologies achieved &gt;90% accuracy?\" - \"Which institutions are researching NAS?\"</p>"},{"location":"introduction/use-cases/#healthcare-medical","title":"Healthcare &amp; Medical","text":""},{"location":"introduction/use-cases/#challenge_3","title":"Challenge","text":"<p>Medical records contain patient information, diagnoses, treatments, medications, and outcomes. Understanding \"Patient A received Treatment B for Condition C with Outcome D\" requires precise tracking.</p>"},{"location":"introduction/use-cases/#solution-with-docling-graph_3","title":"Solution with Docling Graph","text":"<p>Template Structure: <pre><code>class Patient(BaseModel):\n    \"\"\"A patient (anonymized)\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['patient_id']}\n\n    patient_id: str = Field(description=\"Anonymized patient identifier\")\n    age: Optional[int] = Field(None)\n    gender: Optional[str] = Field(None)\n\nclass Diagnosis(BaseModel):\n    \"\"\"A medical diagnosis\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['code']}\n\n    code: str = Field(description=\"ICD-10 or similar code\")\n    description: str = Field(description=\"Diagnosis description\")\n    date: date\n\nclass Treatment(BaseModel):\n    \"\"\"A medical treatment\"\"\"\n    model_config = {'is_entity': False}\n\n    treatment_type: str = Field(description=\"Type of treatment\")\n    description: str\n    start_date: date\n    end_date: Optional[date] = Field(None)\n\nclass MedicalRecord(BaseModel):\n    \"\"\"A medical record\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['record_id']}\n\n    record_id: str\n    date: date\n\n    patient: Patient = edge(label=\"FOR_PATIENT\")\n    diagnoses: List[Diagnosis] = edge(label=\"HAS_DIAGNOSIS\", default_factory=list)\n    treatments: List[Treatment] = edge(label=\"HAS_TREATMENT\", default_factory=list)\n</code></pre></p> <p>Benefits: - Track patient-diagnosis-treatment relationships - Query \"What treatments were used for diagnosis X?\" - Find similar patient cases - Analyze treatment outcomes</p>"},{"location":"introduction/use-cases/#insurance-risk","title":"Insurance &amp; Risk","text":""},{"location":"introduction/use-cases/#challenge_4","title":"Challenge","text":"<p>Insurance policies contain coverage details, exclusions, parties, and conditions. Understanding \"Policy A covers Risk B for Party C under Condition D\" requires relationship tracking.</p>"},{"location":"introduction/use-cases/#solution-with-docling-graph_4","title":"Solution with Docling Graph","text":"<p>Template Structure: <pre><code>class Coverage(BaseModel):\n    \"\"\"An insurance coverage item\"\"\"\n    model_config = {'is_entity': False}\n\n    coverage_type: str = Field(description=\"Type of coverage\")\n    description: str\n    limit: Optional[MonetaryAmount] = Field(None)\n    deductible: Optional[MonetaryAmount] = Field(None)\n\nclass Exclusion(BaseModel):\n    \"\"\"A policy exclusion\"\"\"\n    model_config = {'is_entity': False}\n\n    description: str = Field(description=\"What is excluded\")\n    conditions: Optional[str] = Field(None)\n\nclass InsurancePolicy(BaseModel):\n    \"\"\"An insurance policy\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['policy_number']}\n\n    policy_number: str\n    effective_date: date\n    expiration_date: date\n\n    policyholder: Person = edge(label=\"HELD_BY\")\n    coverages: List[Coverage] = edge(label=\"PROVIDES_COVERAGE\", default_factory=list)\n    exclusions: List[Exclusion] = edge(label=\"HAS_EXCLUSION\", default_factory=list)\n</code></pre></p> <p>Benefits: - Track policy-coverage relationships - Query \"What policies cover fire damage?\" - Find coverage gaps - Analyze risk exposure</p>"},{"location":"introduction/use-cases/#common-patterns-across-domains","title":"Common Patterns Across Domains","text":""},{"location":"introduction/use-cases/#pattern-1-document-entities-properties","title":"Pattern 1: Document \u2192 Entities \u2192 Properties","text":"<pre><code>Document\n  \u251c\u2500 HAS_ENTITY \u2192 Entity1\n  \u2502   \u251c\u2500 HAS_PROPERTY \u2192 Property1\n  \u2502   \u2514\u2500 HAS_PROPERTY \u2192 Property2\n  \u2514\u2500 HAS_ENTITY \u2192 Entity2\n      \u2514\u2500 HAS_PROPERTY \u2192 Property3\n</code></pre> <p>Used in: Research papers, technical reports, specifications</p>"},{"location":"introduction/use-cases/#pattern-2-party-relationship-party","title":"Pattern 2: Party \u2192 Relationship \u2192 Party","text":"<pre><code>Party1 \u2500[RELATIONSHIP]\u2192 Party2\n</code></pre> <p>Used in: Contracts, agreements, organizational charts</p>"},{"location":"introduction/use-cases/#pattern-3-process-steps-outcomes","title":"Pattern 3: Process \u2192 Steps \u2192 Outcomes","text":"<pre><code>Process\n  \u251c\u2500 HAS_STEP \u2192 Step1\n  \u251c\u2500 HAS_STEP \u2192 Step2\n  \u2514\u2500 HAS_OUTCOME \u2192 Outcome\n</code></pre> <p>Used in: Procedures, experiments, workflows</p>"},{"location":"introduction/use-cases/#pattern-4-hierarchical-structures","title":"Pattern 4: Hierarchical Structures","text":"<pre><code>Parent\n  \u251c\u2500 HAS_CHILD \u2192 Child1\n  \u2502   \u2514\u2500 HAS_CHILD \u2192 Grandchild1\n  \u2514\u2500 HAS_CHILD \u2192 Child2\n</code></pre> <p>Used in: Organizational structures, document sections, taxonomies</p>"},{"location":"introduction/use-cases/#choosing-your-use-case","title":"Choosing Your Use Case","text":""},{"location":"introduction/use-cases/#questions-to-ask","title":"Questions to Ask","text":"<ol> <li>What entities do I need to track?</li> <li> <p>People, organizations, documents, materials, etc.</p> </li> <li> <p>What relationships matter?</p> </li> <li> <p>Who issued what? Who owns what? What contains what?</p> </li> <li> <p>What queries will I run?</p> </li> <li>\"Find all X related to Y\"</li> <li> <p>\"What are the properties of Z?\"</p> </li> <li> <p>What level of detail do I need?</p> </li> <li>High-level overview or detailed properties?</li> </ol>"},{"location":"introduction/use-cases/#decision-matrix","title":"Decision Matrix","text":"Domain Entity Types Key Relationships Complexity Chemistry Materials, Measurements USES, HAS_PROPERTY High Finance Parties, Obligations OWES, GUARANTEES Medium Research Authors, Papers, Methods AUTHORED_BY, CITES Medium Healthcare Patients, Diagnoses HAS_DIAGNOSIS, TREATED_WITH High Insurance Policies, Coverage COVERS, EXCLUDES Medium Legal Parties, Contracts PARTY_TO, OBLIGATED_BY High"},{"location":"introduction/use-cases/#next-steps","title":"Next Steps","text":"<p>Ready to implement your use case?</p> <ol> <li>Schema Definition - Create your Pydantic templates</li> <li>Examples - See complete working examples</li> <li>Architecture - Understand the system design</li> </ol>"},{"location":"introduction/use-cases/#related-documentation","title":"Related Documentation","text":"<ul> <li>Key Concepts: Understand entities, edges, and graphs</li> <li>Pipeline Configuration: Configure for your domain</li> <li>Graph Management: Export and query your graphs</li> </ul> <p>Have a unique use case? The patterns above can be adapted to any domain requiring precise relationship tracking!</p>"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#overview","title":"Overview","text":"<p>Complete API reference for docling-graph modules, classes, and functions.</p> <p>What's Included: - Pipeline API - Configuration classes - Protocol definitions - Exception hierarchy - Converter classes - Extractor classes - Exporter classes - LLM client interfaces</p>"},{"location":"reference/#quick-links","title":"Quick Links","text":""},{"location":"reference/#core-apis","title":"Core APIs","text":"<p>Pipeline API Main entry point for document processing.</p> <ul> <li><code>run_pipeline()</code> - Execute the pipeline</li> <li>Pipeline stages and orchestration</li> </ul> <p>Configuration API Type-safe configuration classes.</p> <ul> <li><code>PipelineConfig</code> - Main configuration class</li> <li><code>ModelConfig</code> - Model configuration</li> <li><code>LLMConfig</code> / <code>VLMConfig</code> - Backend configs</li> </ul> <p>Protocols Protocol definitions for type-safe interfaces.</p> <ul> <li><code>ExtractionBackendProtocol</code> - VLM backends</li> <li><code>TextExtractionBackendProtocol</code> - LLM backends</li> <li><code>LLMClientProtocol</code> - LLM clients</li> <li><code>ExtractorProtocol</code> - Extraction strategies</li> </ul> <p>Exceptions Exception hierarchy and error handling.</p> <ul> <li><code>DoclingGraphError</code> - Base exception</li> <li><code>ConfigurationError</code> - Config errors</li> <li><code>ClientError</code> - API errors</li> <li><code>ExtractionError</code> - Extraction failures</li> <li><code>ValidationError</code> - Data validation</li> <li><code>GraphError</code> - Graph operations</li> <li><code>PipelineError</code> - Pipeline execution</li> </ul>"},{"location":"reference/#processing-apis","title":"Processing APIs","text":"<p>Converters Graph conversion from Pydantic models.</p> <ul> <li><code>GraphConverter</code> - Convert models to graphs</li> <li><code>NodeIDRegistry</code> - Stable node IDs</li> <li>Graph construction utilities</li> </ul> <p>Extractors Document extraction strategies.</p> <ul> <li><code>OneToOne</code> - Per-page extraction</li> <li><code>ManyToOne</code> - Consolidated extraction</li> <li>Backend implementations</li> <li>Chunking and batching</li> </ul> <p>Exporters Graph export formats.</p> <ul> <li><code>CSVExporter</code> - Neo4j-compatible CSV</li> <li><code>CypherExporter</code> - Cypher scripts</li> <li><code>JSONExporter</code> - JSON format</li> <li><code>DoclingExporter</code> - Docling documents</li> </ul> <p>LLM Clients LLM client implementations.</p> <ul> <li><code>OllamaClient</code> - Ollama integration</li> <li><code>MistralClient</code> - Mistral AI</li> <li><code>OpenAIClient</code> - OpenAI</li> <li><code>GeminiClient</code> - Google Gemini</li> <li><code>VLLMClient</code> - vLLM server</li> </ul>"},{"location":"reference/#module-structure","title":"Module Structure","text":"<pre><code>docling_graph/\n\u251c\u2500\u2500 __init__.py              # Public API exports\n\u251c\u2500\u2500 pipeline.py              # run_pipeline()\n\u251c\u2500\u2500 config.py                # PipelineConfig\n\u251c\u2500\u2500 protocols.py             # Protocol definitions\n\u251c\u2500\u2500 exceptions.py            # Exception hierarchy\n\u2502\n\u251c\u2500\u2500 core/                    # Core processing\n\u2502   \u251c\u2500\u2500 converters/          # Graph conversion\n\u2502   \u251c\u2500\u2500 extractors/          # Extraction strategies\n\u2502   \u251c\u2500\u2500 exporters/           # Export formats\n\u2502   \u2514\u2500\u2500 visualizers/         # Visualization\n\u2502\n\u251c\u2500\u2500 llm_clients/             # LLM integrations\n\u2502   \u251c\u2500\u2500 base.py\n\u2502   \u251c\u2500\u2500 ollama.py\n\u2502   \u251c\u2500\u2500 mistral.py\n\u2502   \u251c\u2500\u2500 openai.py\n\u2502   \u251c\u2500\u2500 gemini.py\n\u2502   \u2514\u2500\u2500 vllm.py\n\u2502\n\u2514\u2500\u2500 pipeline/                # Pipeline orchestration\n    \u251c\u2500\u2500 context.py\n    \u251c\u2500\u2500 stages.py\n    \u2514\u2500\u2500 orchestrator.py\n</code></pre>"},{"location":"reference/#import-patterns","title":"Import Patterns","text":""},{"location":"reference/#basic-imports","title":"Basic Imports","text":"<pre><code># Main API\nfrom docling_graph import run_pipeline, PipelineConfig\n\n# Configuration classes\nfrom docling_graph import (\n    LLMConfig,\n    VLMConfig,\n    ModelConfig,\n    ModelsConfig\n)\n</code></pre>"},{"location":"reference/#advanced-imports","title":"Advanced Imports","text":"<pre><code># Protocols\nfrom docling_graph.protocols import (\n    ExtractionBackendProtocol,\n    TextExtractionBackendProtocol,\n    LLMClientProtocol\n)\n\n# Exceptions\nfrom docling_graph.exceptions import (\n    DoclingGraphError,\n    ConfigurationError,\n    ClientError,\n    ExtractionError,\n    ValidationError,\n    GraphError,\n    PipelineError\n)\n\n# Converters\nfrom docling_graph.core.converters import GraphConverter\n\n# Extractors\nfrom docling_graph.core.extractors import OneToOne, ManyToOne\n\n# Exporters\nfrom docling_graph.core.exporters import (\n    CSVExporter,\n    CypherExporter,\n    JSONExporter\n)\n</code></pre>"},{"location":"reference/#type-hints","title":"Type Hints","text":""},{"location":"reference/#common-types","title":"Common Types","text":"<pre><code>from typing import Any, Dict, List, Type, Union\nfrom pathlib import Path\nfrom pydantic import BaseModel\nimport networkx as nx\n\n# Configuration\nconfig: PipelineConfig\nconfig_dict: Dict[str, Any]\n\n# Templates\ntemplate: Type[BaseModel]\nmodel_instance: BaseModel\nmodels: List[BaseModel]\n\n# Graphs\ngraph: nx.MultiDiGraph\n\n# Paths\nsource: Union[str, Path]\noutput_dir: Path\n</code></pre>"},{"location":"reference/#version-information","title":"Version Information","text":"<pre><code>import docling_graph\n\n# Get version\nprint(docling_graph.__version__)  # e.g., \"0.3.0\"\n\n# Check available exports\nprint(docling_graph.__all__)\n# ['run_pipeline', 'PipelineConfig', 'LLMConfig', ...]\n</code></pre>"},{"location":"reference/#api-stability","title":"API Stability","text":""},{"location":"reference/#stable-apis","title":"\u2705 Stable APIs","text":"<p>These APIs are stable and safe to use:</p> <ul> <li><code>run_pipeline()</code></li> <li><code>PipelineConfig</code></li> <li>All configuration classes</li> <li>Exception hierarchy</li> <li>Public protocols</li> </ul>"},{"location":"reference/#internal-apis","title":"\u26a0\ufe0f Internal APIs","text":"<p>These are internal and may change:</p> <ul> <li><code>pipeline.orchestrator</code> internals</li> <li><code>core.extractors.backends</code> internals</li> <li><code>core.utils</code> modules</li> </ul>"},{"location":"reference/#experimental","title":"\ud83e\uddea Experimental","text":"<p>These are experimental:</p> <ul> <li>Custom stage APIs</li> <li>Advanced pipeline customization</li> </ul>"},{"location":"reference/#deprecation-policy","title":"Deprecation Policy","text":"<p>Deprecated features will:</p> <ol> <li>Be marked with <code>@deprecated</code> decorator</li> <li>Emit <code>DeprecationWarning</code></li> <li>Be documented in CHANGELOG</li> <li>Be removed after 2 minor versions</li> </ol> <p>Example:</p> <pre><code>import warnings\n\n@deprecated(\"Use PipelineConfig instead\")\ndef old_function():\n    warnings.warn(\n        \"old_function is deprecated, use PipelineConfig\",\n        DeprecationWarning,\n        stacklevel=2\n    )\n</code></pre>"},{"location":"reference/#api-design-principles","title":"API Design Principles","text":""},{"location":"reference/#1-type-safety","title":"1. Type Safety","text":"<p>All public APIs use type hints:</p> <pre><code>def run_pipeline(config: Union[PipelineConfig, Dict[str, Any]]) -&gt; None:\n    \"\"\"Type-safe function signature.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#2-pydantic-validation","title":"2. Pydantic Validation","text":"<p>Configuration uses Pydantic for validation:</p> <pre><code>config = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\"  # Validated at runtime\n)\n</code></pre>"},{"location":"reference/#3-protocol-based","title":"3. Protocol-Based","text":"<p>Extensibility through protocols:</p> <pre><code>class MyBackend(TextExtractionBackendProtocol):\n    \"\"\"Custom backend implementing protocol.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#4-structured-exceptions","title":"4. Structured Exceptions","text":"<p>Clear error hierarchy:</p> <pre><code>try:\n    run_pipeline(config)\nexcept ConfigurationError as e:\n    print(f\"Config error: {e.message}\")\n    print(f\"Details: {e.details}\")\n</code></pre>"},{"location":"reference/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"local\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"reference/#advanced-usage","title":"Advanced Usage","text":"<pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import ExtractionError\n\nconfig = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"model_override\": \"mistral-small-latest\",\n    \"use_chunking\": True,\n    \"llm_consolidation\": True,\n    \"export_format\": \"cypher\"\n}\n\ntry:\n    run_pipeline(config)\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e}\")\n</code></pre>"},{"location":"reference/#api-documentation-sections","title":"API Documentation Sections","text":"<ol> <li>Pipeline API \u2192 - Main entry point</li> <li>Configuration API \u2192 - Configuration classes</li> <li>Protocols \u2192 - Protocol definitions</li> <li>Exceptions \u2192 - Exception hierarchy</li> <li>Converters \u2192 - Graph conversion</li> <li>Extractors \u2192 - Extraction strategies</li> <li>Exporters \u2192 - Export formats</li> <li>LLM Clients \u2192 - LLM integrations</li> </ol>"},{"location":"reference/#contributing","title":"Contributing","text":"<p>See Development Guide for:</p> <ul> <li>Adding new APIs</li> <li>API design guidelines</li> <li>Documentation standards</li> <li>Testing requirements</li> </ul>"},{"location":"reference/config/","title":"Configuration API","text":""},{"location":"reference/config/#overview","title":"Overview","text":"<p>Type-safe configuration classes for the docling-graph pipeline.</p> <p>Module: <code>docling_graph.config</code></p>"},{"location":"reference/config/#pipelineconfig","title":"PipelineConfig","text":"<p>Main configuration class for pipeline execution.</p> <pre><code>class PipelineConfig(BaseModel):\n    \"\"\"Type-safe configuration for the docling-graph pipeline.\"\"\"\n</code></pre>"},{"location":"reference/config/#constructor","title":"Constructor","text":"<pre><code>config = PipelineConfig(\n    source: Union[str, Path] = \"\",\n    template: Union[str, Type[BaseModel]] = \"\",\n    backend: Literal[\"llm\", \"vlm\"] = \"llm\",\n    inference: Literal[\"local\", \"remote\"] = \"local\",\n    processing_mode: Literal[\"one-to-one\", \"many-to-one\"] = \"many-to-one\",\n    docling_config: Literal[\"ocr\", \"vision\"] = \"ocr\",\n    model_override: str | None = None,\n    provider_override: str | None = None,\n    models: ModelsConfig = ModelsConfig(),\n    use_chunking: bool = True,\n    llm_consolidation: bool = False,\n    max_batch_size: int = 1,\n    export_format: Literal[\"csv\", \"cypher\"] = \"csv\",\n    export_docling: bool = True,\n    export_docling_json: bool = True,\n    export_markdown: bool = True,\n    export_per_page_markdown: bool = False,\n    reverse_edges: bool = False,\n    output_dir: Union[str, Path] = \"outputs\"\n)\n</code></pre>"},{"location":"reference/config/#fields","title":"Fields","text":""},{"location":"reference/config/#required-fields","title":"Required Fields","text":"Field Type Description <code>source</code> <code>str</code> or <code>Path</code> Path to source document <code>template</code> <code>str</code> or <code>Type[BaseModel]</code> Pydantic template class or dotted path"},{"location":"reference/config/#backend-configuration","title":"Backend Configuration","text":"Field Type Default Description <code>backend</code> <code>\"llm\"</code> or <code>\"vlm\"</code> <code>\"llm\"</code> Extraction backend type <code>inference</code> <code>\"local\"</code> or <code>\"remote\"</code> <code>\"local\"</code> Inference location <code>model_override</code> <code>str</code> or <code>None</code> <code>None</code> Override default model <code>provider_override</code> <code>str</code> or <code>None</code> <code>None</code> Override default provider <code>models</code> <code>ModelsConfig</code> <code>ModelsConfig()</code> Model configurations"},{"location":"reference/config/#processing-configuration","title":"Processing Configuration","text":"Field Type Default Description <code>processing_mode</code> <code>\"one-to-one\"</code> or <code>\"many-to-one\"</code> <code>\"many-to-one\"</code> Processing strategy <code>docling_config</code> <code>\"ocr\"</code> or <code>\"vision\"</code> <code>\"ocr\"</code> Docling pipeline type <code>use_chunking</code> <code>bool</code> <code>True</code> Enable document chunking <code>llm_consolidation</code> <code>bool</code> <code>False</code> Use LLM for consolidation <code>max_batch_size</code> <code>int</code> <code>1</code> Maximum batch size"},{"location":"reference/config/#export-configuration","title":"Export Configuration","text":"Field Type Default Description <code>export_format</code> <code>\"csv\"</code> or <code>\"cypher\"</code> <code>\"csv\"</code> Graph export format <code>export_docling</code> <code>bool</code> <code>True</code> Export Docling outputs <code>export_docling_json</code> <code>bool</code> <code>True</code> Export Docling JSON <code>export_markdown</code> <code>bool</code> <code>True</code> Export markdown <code>export_per_page_markdown</code> <code>bool</code> <code>False</code> Export per-page markdown"},{"location":"reference/config/#graph-configuration","title":"Graph Configuration","text":"Field Type Default Description <code>reverse_edges</code> <code>bool</code> <code>False</code> Create reverse edges"},{"location":"reference/config/#output-configuration","title":"Output Configuration","text":"Field Type Default Description <code>output_dir</code> <code>str</code> or <code>Path</code> <code>\"outputs\"</code> Output directory path"},{"location":"reference/config/#methods","title":"Methods","text":""},{"location":"reference/config/#run","title":"run()","text":"<pre><code>def run(self) -&gt; None\n</code></pre> <p>Execute the pipeline with this configuration.</p> <p>Example:</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\"\n)\nconfig.run()\n</code></pre>"},{"location":"reference/config/#to_dict","title":"to_dict()","text":"<pre><code>def to_dict(self) -&gt; Dict[str, Any]\n</code></pre> <p>Convert configuration to dictionary format.</p> <p>Returns: Dictionary with all configuration values</p> <p>Example:</p> <pre><code>config = PipelineConfig(source=\"doc.pdf\", template=\"templates.MyTemplate\")\nconfig_dict = config.to_dict()\nprint(config_dict[\"backend\"])  # \"llm\"\n</code></pre>"},{"location":"reference/config/#generate_yaml_dict","title":"generate_yaml_dict()","text":"<pre><code>@classmethod\ndef generate_yaml_dict(cls) -&gt; Dict[str, Any]\n</code></pre> <p>Generate YAML-compatible configuration dictionary with defaults.</p> <p>Returns: Dictionary suitable for YAML serialization</p>"},{"location":"reference/config/#modelsconfig","title":"ModelsConfig","text":"<p>Configuration for all model types.</p> <pre><code>class ModelsConfig(BaseModel):\n    \"\"\"Complete models configuration.\"\"\"\n\n    llm: LLMConfig = Field(default_factory=LLMConfig)\n    vlm: VLMConfig = Field(default_factory=VLMConfig)\n</code></pre>"},{"location":"reference/config/#fields_1","title":"Fields","text":"Field Type Description <code>llm</code> <code>LLMConfig</code> LLM model configuration <code>vlm</code> <code>VLMConfig</code> VLM model configuration"},{"location":"reference/config/#llmconfig","title":"LLMConfig","text":"<p>Configuration for LLM models.</p> <pre><code>class LLMConfig(BaseModel):\n    \"\"\"LLM model configurations for local and remote inference.\"\"\"\n\n    local: ModelConfig = Field(default_factory=lambda: ModelConfig(\n        default_model=\"ibm-granite/granite-4.0-1b\",\n        provider=\"vllm\"\n    ))\n    remote: ModelConfig = Field(default_factory=lambda: ModelConfig(\n        default_model=\"mistral-small-latest\",\n        provider=\"mistral\"\n    ))\n</code></pre>"},{"location":"reference/config/#fields_2","title":"Fields","text":"Field Type Default Model Default Provider <code>local</code> <code>ModelConfig</code> <code>ibm-granite/granite-4.0-1b</code> <code>vllm</code> <code>remote</code> <code>ModelConfig</code> <code>mistral-small-latest</code> <code>mistral</code>"},{"location":"reference/config/#vlmconfig","title":"VLMConfig","text":"<p>Configuration for VLM models.</p> <pre><code>class VLMConfig(BaseModel):\n    \"\"\"VLM model configuration.\"\"\"\n\n    local: ModelConfig = Field(default_factory=lambda: ModelConfig(\n        default_model=\"numind/NuExtract-2.0-8B\",\n        provider=\"docling\"\n    ))\n</code></pre>"},{"location":"reference/config/#fields_3","title":"Fields","text":"Field Type Default Model Default Provider <code>local</code> <code>ModelConfig</code> <code>numind/NuExtract-2.0-8B</code> <code>docling</code> <p>Note: VLM only supports local inference.</p>"},{"location":"reference/config/#modelconfig","title":"ModelConfig","text":"<p>Configuration for a specific model.</p> <pre><code>class ModelConfig(BaseModel):\n    \"\"\"Configuration for a specific model.\"\"\"\n\n    default_model: str = Field(..., description=\"Model name/path\")\n    provider: str = Field(..., description=\"Provider name\")\n</code></pre>"},{"location":"reference/config/#fields_4","title":"Fields","text":"Field Type Description <code>default_model</code> <code>str</code> Model name or path <code>provider</code> <code>str</code> Provider name (e.g., \"vllm\", \"mistral\")"},{"location":"reference/config/#backendconfig","title":"BackendConfig","text":"<p>Configuration for extraction backend (internal use).</p> <pre><code>class BackendConfig(BaseModel):\n    \"\"\"Configuration for an extraction backend.\"\"\"\n\n    provider: str = Field(..., description=\"Backend provider\")\n    model: str = Field(..., description=\"Model name or path\")\n    api_key: str | None = Field(None, description=\"API key\")\n    base_url: str | None = Field(None, description=\"Base URL\")\n</code></pre>"},{"location":"reference/config/#extractorconfig","title":"ExtractorConfig","text":"<p>Configuration for extraction strategy (internal use).</p> <pre><code>class ExtractorConfig(BaseModel):\n    \"\"\"Configuration for the extraction strategy.\"\"\"\n\n    strategy: Literal[\"many-to-one\", \"one-to-one\"] = Field(default=\"many-to-one\")\n    docling_config: Literal[\"ocr\", \"vision\"] = Field(default=\"ocr\")\n    use_chunking: bool = Field(default=True)\n    llm_consolidation: bool = Field(default=False)\n    chunker_config: Dict[str, Any] | None = Field(default=None)\n</code></pre>"},{"location":"reference/config/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/config/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\"\n)\nconfig.run()\n</code></pre>"},{"location":"reference/config/#custom-backend","title":"Custom Backend","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\"\n)\nconfig.run()\n</code></pre>"},{"location":"reference/config/#custom-processing","title":"Custom Processing","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    processing_mode=\"one-to-one\",\n    use_chunking=False,\n    llm_consolidation=True\n)\nconfig.run()\n</code></pre>"},{"location":"reference/config/#custom-export","title":"Custom Export","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    export_format=\"cypher\",\n    export_docling_json=True,\n    export_markdown=True,\n    export_per_page_markdown=True,\n    output_dir=\"custom_outputs\"\n)\nconfig.run()\n</code></pre>"},{"location":"reference/config/#complete-configuration","title":"Complete Configuration","text":"<pre><code>from docling_graph import PipelineConfig, LLMConfig, ModelConfig\n\nconfig = PipelineConfig(\n    # Source\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n\n    # Backend\n    backend=\"llm\",\n    inference=\"remote\",\n    model_override=\"mistral-small-latest\",\n    provider_override=\"mistral\",\n\n    # Processing\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n    llm_consolidation=True,\n    max_batch_size=5,\n\n    # Export\n    export_format=\"csv\",\n    export_docling=True,\n    export_docling_json=True,\n    export_markdown=True,\n    export_per_page_markdown=False,\n\n    # Graph\n    reverse_edges=False,\n\n    # Output\n    output_dir=\"outputs/custom\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"reference/config/#validation","title":"Validation","text":""},{"location":"reference/config/#automatic-validation","title":"Automatic Validation","text":"<p>Pydantic validates all fields automatically:</p> <pre><code># \u2705 Valid\nconfig = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\"\n)\n\n# \u274c Invalid - raises ValidationError\nconfig = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"invalid\"  # Not \"llm\" or \"vlm\"\n)\n</code></pre>"},{"location":"reference/config/#custom-validation","title":"Custom Validation","text":"<p>VLM backend validation:</p> <pre><code># \u274c Invalid - VLM doesn't support remote\nconfig = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"vlm\",\n    inference=\"remote\"  # Raises ValueError\n)\n\n# \u2705 Valid\nconfig = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"vlm\",\n    inference=\"local\"\n)\n</code></pre>"},{"location":"reference/config/#type-safety","title":"Type Safety","text":""},{"location":"reference/config/#type-hints","title":"Type Hints","text":"<p>All fields have proper type hints:</p> <pre><code>from docling_graph import PipelineConfig\nfrom pathlib import Path\n\n# Type checker knows these are valid\nconfig = PipelineConfig(\n    source=\"doc.pdf\",  # str\n    template=\"templates.MyTemplate\",  # str\n    backend=\"llm\",  # Literal[\"llm\", \"vlm\"]\n    use_chunking=True  # bool\n)\n\n# Type checker knows output_dir is str\noutput: str = config.output_dir\n</code></pre>"},{"location":"reference/config/#ide-support","title":"IDE Support","text":"<p>IDEs provide autocomplete and type checking:</p> <pre><code>config = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"l\"  # IDE suggests \"llm\"\n)\n</code></pre>"},{"location":"reference/config/#default-values","title":"Default Values","text":"<p>All fields have sensible defaults:</p> <pre><code>config = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\"\n    # All other fields use defaults\n)\n\nprint(config.backend)  # \"llm\"\nprint(config.inference)  # \"local\"\nprint(config.processing_mode)  # \"many-to-one\"\nprint(config.use_chunking)  # True\nprint(config.export_format)  # \"csv\"\n</code></pre>"},{"location":"reference/config/#related-apis","title":"Related APIs","text":"<ul> <li>Pipeline API - run_pipeline() function</li> <li>Protocols - Protocol definitions</li> <li>Exceptions - Validation errors</li> </ul>"},{"location":"reference/config/#see-also","title":"See Also","text":"<ul> <li>Configuration Guide - Configuration overview</li> <li>Python API - Usage guide</li> <li>Examples - Example configurations</li> </ul>"},{"location":"reference/converters/","title":"Converters API","text":""},{"location":"reference/converters/#overview","title":"Overview","text":"<p>Graph conversion from Pydantic models to NetworkX graphs.</p> <p>Module: <code>docling_graph.core.converters</code></p>"},{"location":"reference/converters/#graphconverter","title":"GraphConverter","text":"<p>Main class for converting Pydantic models to knowledge graphs.</p> <pre><code>class GraphConverter:\n    \"\"\"Convert Pydantic models to NetworkX graphs.\"\"\"\n\n    def __init__(\n        self,\n        config: Optional[GraphConverterConfig] = None,\n        node_id_registry: Optional[NodeIDRegistry] = None\n    ):\n        \"\"\"Initialize converter.\"\"\"\n</code></pre>"},{"location":"reference/converters/#methods","title":"Methods","text":""},{"location":"reference/converters/#convert","title":"convert()","text":"<pre><code>def convert(\n    self,\n    models: List[BaseModel],\n    reverse_edges: bool = False\n) -&gt; nx.MultiDiGraph:\n    \"\"\"\n    Convert Pydantic models to graph.\n\n    Args:\n        models: List of Pydantic model instances\n        reverse_edges: Create reverse edges\n\n    Returns:\n        NetworkX MultiDiGraph\n    \"\"\"\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.core.converters import GraphConverter\n\nconverter = GraphConverter()\ngraph = converter.convert(models, reverse_edges=False)\n\nprint(f\"Nodes: {graph.number_of_nodes()}\")\nprint(f\"Edges: {graph.number_of_edges()}\")\n</code></pre>"},{"location":"reference/converters/#nodeidregistry","title":"NodeIDRegistry","text":"<p>Registry for stable node ID generation.</p> <pre><code>class NodeIDRegistry:\n    \"\"\"Generate and track stable node IDs.\"\"\"\n\n    def get_or_create_id(\n        self,\n        model: BaseModel,\n        node_type: str\n    ) -&gt; str:\n        \"\"\"\n        Get or create stable ID for model.\n\n        Args:\n            model: Pydantic model instance\n            node_type: Type of node\n\n        Returns:\n            Stable node ID\n        \"\"\"\n</code></pre> <p>Features: - Deterministic ID generation - Collision detection - Cross-batch consistency - Graph ID field support</p> <p>Example:</p> <pre><code>from docling_graph.core.converters import NodeIDRegistry\n\nregistry = NodeIDRegistry()\nnode_id = registry.get_or_create_id(person_model, \"Person\")\n</code></pre>"},{"location":"reference/converters/#graphconverterconfig","title":"GraphConverterConfig","text":"<p>Configuration for graph conversion.</p> <pre><code>class GraphConverterConfig(BaseModel):\n    \"\"\"Configuration for graph converter.\"\"\"\n\n    reverse_edges: bool = False\n    include_metadata: bool = True\n</code></pre>"},{"location":"reference/converters/#related-apis","title":"Related APIs","text":"<ul> <li>Graph Management - Usage guide</li> <li>Exporters - Export graphs</li> </ul>"},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#overview","title":"Overview","text":"<p>Unified exception hierarchy for structured error handling in docling-graph.</p> <p>Module: <code>docling_graph.exceptions</code></p> <p>All exceptions inherit from <code>DoclingGraphError</code> and provide structured error information including message, details, and cause.</p>"},{"location":"reference/exceptions/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>DoclingGraphError (base)\n\u251c\u2500\u2500 ConfigurationError      # Invalid configuration\n\u251c\u2500\u2500 ClientError            # LLM/API client errors\n\u251c\u2500\u2500 ExtractionError        # Document extraction failures\n\u251c\u2500\u2500 ValidationError        # Data validation failures\n\u251c\u2500\u2500 GraphError            # Graph operation failures\n\u2514\u2500\u2500 PipelineError         # Pipeline execution failures\n</code></pre>"},{"location":"reference/exceptions/#base-exception","title":"Base Exception","text":""},{"location":"reference/exceptions/#doclinggrapherror","title":"DoclingGraphError","text":"<p>Base exception for all docling-graph errors.</p> <pre><code>class DoclingGraphError(Exception):\n    \"\"\"Base exception for all docling-graph errors.\"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        *,\n        details: dict[str, Any] | None = None,\n        cause: Exception | None = None\n    ) -&gt; None:\n        \"\"\"Initialize exception with structured information.\"\"\"\n</code></pre> <p>Attributes:</p> Attribute Type Description <code>message</code> <code>str</code> Human-readable error description <code>details</code> <code>dict[str, Any]</code> Additional context dictionary <code>cause</code> <code>Exception</code> or <code>None</code> Underlying exception that caused this error <p>Methods:</p>"},{"location":"reference/exceptions/#__str__","title":"__str__()","text":"<pre><code>def __str__(self) -&gt; str\n</code></pre> <p>Format exception with all available information.</p> <p>Returns: Formatted error message with details and cause</p>"},{"location":"reference/exceptions/#__repr__","title":"__repr__()","text":"<pre><code>def __repr__(self) -&gt; str\n</code></pre> <p>Detailed representation for debugging.</p> <p>Returns: Detailed string representation</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import DoclingGraphError\n\ntry:\n    # Some operation\n    raise DoclingGraphError(\n        \"Operation failed\",\n        details={\"file\": \"doc.pdf\", \"stage\": \"extraction\"},\n        cause=ValueError(\"Invalid input\")\n    )\nexcept DoclingGraphError as e:\n    print(e.message)  # \"Operation failed\"\n    print(e.details)  # {\"file\": \"doc.pdf\", \"stage\": \"extraction\"}\n    print(e.cause)    # ValueError(\"Invalid input\")\n</code></pre>"},{"location":"reference/exceptions/#specific-exceptions","title":"Specific Exceptions","text":""},{"location":"reference/exceptions/#configurationerror","title":"ConfigurationError","text":"<p>Raised when configuration is invalid or missing.</p> <pre><code>class ConfigurationError(DoclingGraphError):\n    \"\"\"Raised when configuration is invalid or missing.\"\"\"\n</code></pre> <p>Common Causes: - Missing required environment variables - Invalid configuration file - Unsupported model or provider - Missing required parameters - Invalid parameter combinations</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import ConfigurationError\n\nraise ConfigurationError(\n    \"API key not found\",\n    details={\"env_var\": \"MISTRAL_API_KEY\"}\n)\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import PipelineConfig\nfrom docling_graph.exceptions import ConfigurationError\n\ntry:\n    config = PipelineConfig(\n        source=\"doc.pdf\",\n        template=\"templates.MyTemplate\",\n        backend=\"vlm\",\n        inference=\"remote\"  # VLM doesn't support remote!\n    )\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e.message}\")\n    print(f\"Details: {e.details}\")\n</code></pre>"},{"location":"reference/exceptions/#clienterror","title":"ClientError","text":"<p>Raised when LLM client operation fails.</p> <pre><code>class ClientError(DoclingGraphError):\n    \"\"\"Raised when LLM client operation fails.\"\"\"\n</code></pre> <p>Common Causes: - API authentication failure - Network timeout - Invalid API response - Rate limit exceeded - Model not available</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import ClientError\n\nraise ClientError(\n    \"API call failed\",\n    details={\n        \"provider\": \"mistral\",\n        \"model\": \"mistral-small-latest\",\n        \"status_code\": 429\n    },\n    cause=requests.exceptions.HTTPError(\"Rate limit exceeded\")\n)\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import ClientError\nimport time\n\ndef process_with_retry(config, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            run_pipeline(config)\n            return\n        except ClientError as e:\n            if \"rate limit\" in str(e).lower():\n                wait_time = 2 ** attempt\n                print(f\"Rate limited. Waiting {wait_time}s...\")\n                time.sleep(wait_time)\n            else:\n                raise\n</code></pre>"},{"location":"reference/exceptions/#extractionerror","title":"ExtractionError","text":"<p>Raised when document extraction fails.</p> <pre><code>class ExtractionError(DoclingGraphError):\n    \"\"\"Raised when document extraction fails.\"\"\"\n</code></pre> <p>Common Causes: - Document parsing failure - Empty extraction result - Invalid document format - Extraction timeout - Model inference failure</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import ExtractionError\n\nraise ExtractionError(\n    \"Failed to extract data from document\",\n    details={\n        \"source\": \"document.pdf\",\n        \"template\": \"MyTemplate\",\n        \"backend\": \"llm\"\n    },\n    cause=ValueError(\"Empty response from model\")\n)\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import ExtractionError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\"\n    })\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n\n    # Try fallback strategy\n    print(\"Trying with different backend...\")\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\",\n        \"backend\": \"vlm\"  # Fallback to VLM\n    })\n</code></pre>"},{"location":"reference/exceptions/#validationerror","title":"ValidationError","text":"<p>Raised when data validation fails.</p> <pre><code>class ValidationError(DoclingGraphError):\n    \"\"\"Raised when data validation fails.\"\"\"\n</code></pre> <p>Common Causes: - Pydantic validation error - Schema mismatch - Invalid data structure - Missing required fields - Type mismatch</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import ValidationError\nfrom pydantic import ValidationError as PydanticValidationError\n\ntry:\n    model = MyTemplate.model_validate(data)\nexcept PydanticValidationError as e:\n    raise ValidationError(\n        \"Data validation failed\",\n        details={\"errors\": e.errors()},\n        cause=e\n    )\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import ValidationError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.StrictTemplate\"\n    })\nexcept ValidationError as e:\n    print(f\"Validation failed: {e.message}\")\n\n    # Check Pydantic errors\n    if e.cause:\n        for error in e.cause.errors():\n            field = error['loc'][0]\n            msg = error['msg']\n            print(f\"  - {field}: {msg}\")\n</code></pre>"},{"location":"reference/exceptions/#grapherror","title":"GraphError","text":"<p>Raised when graph operation fails.</p> <pre><code>class GraphError(DoclingGraphError):\n    \"\"\"Raised when graph operation fails.\"\"\"\n</code></pre> <p>Common Causes: - Invalid graph structure - Node/edge creation failure - Graph validation error - Export failure - Circular dependencies</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import GraphError\n\nraise GraphError(\n    \"Failed to create graph edge\",\n    details={\n        \"source_node\": \"node_1\",\n        \"target_node\": \"node_2\",\n        \"edge_type\": \"RELATES_TO\"\n    }\n)\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import GraphError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\",\n        \"export_format\": \"cypher\"\n    })\nexcept GraphError as e:\n    print(f\"Graph error: {e.message}\")\n\n    # Try alternative export format\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\",\n        \"export_format\": \"csv\"  # Fallback to CSV\n    })\n</code></pre>"},{"location":"reference/exceptions/#pipelineerror","title":"PipelineError","text":"<p>Raised when pipeline execution fails.</p> <pre><code>class PipelineError(DoclingGraphError):\n    \"\"\"Raised when pipeline execution fails.\"\"\"\n</code></pre> <p>Common Causes: - Stage execution failure - Resource initialization error - Cleanup failure - Unexpected pipeline state</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import PipelineError\n\nraise PipelineError(\n    \"Pipeline stage failed\",\n    details={\n        \"stage\": \"ExtractionStage\",\n        \"source\": \"document.pdf\"\n    },\n    cause=RuntimeError(\"Backend initialization failed\")\n)\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import PipelineError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\"\n    })\nexcept PipelineError as e:\n    print(f\"Pipeline failed: {e.message}\")\n    print(f\"Stage: {e.details.get('stage', 'unknown')}\")\n\n    if e.cause:\n        print(f\"Caused by: {e.cause}\")\n</code></pre>"},{"location":"reference/exceptions/#error-handling-patterns","title":"Error Handling Patterns","text":""},{"location":"reference/exceptions/#catch-specific-exceptions","title":"Catch Specific Exceptions","text":"<pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import (\n    ConfigurationError,\n    ClientError,\n    ExtractionError\n)\n\ntry:\n    run_pipeline(config)\n\nexcept ConfigurationError as e:\n    print(f\"Fix your configuration: {e.message}\")\n\nexcept ClientError as e:\n    print(f\"API error: {e.message}\")\n    # Maybe retry\n\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n    # Maybe try different backend\n</code></pre>"},{"location":"reference/exceptions/#catch-base-exception","title":"Catch Base Exception","text":"<pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import DoclingGraphError\n\ntry:\n    run_pipeline(config)\n\nexcept DoclingGraphError as e:\n    print(f\"Error: {e.message}\")\n    print(f\"Type: {type(e).__name__}\")\n    print(f\"Details: {e.details}\")\n\n    if e.cause:\n        print(f\"Caused by: {e.cause}\")\n</code></pre>"},{"location":"reference/exceptions/#access-error-details","title":"Access Error Details","text":"<pre><code>from docling_graph.exceptions import ExtractionError\n\ntry:\n    # Some operation\n    pass\nexcept ExtractionError as e:\n    # Access structured information\n    message = e.message\n    details = e.details\n    cause = e.cause\n\n    # Log details\n    print(f\"Error: {message}\")\n    for key, value in details.items():\n        print(f\"  {key}: {value}\")\n</code></pre>"},{"location":"reference/exceptions/#re-raise-with-context","title":"Re-raise with Context","text":"<pre><code>from docling_graph.exceptions import ExtractionError\n\ndef my_function():\n    try:\n        # Some operation\n        result = extract_data()\n    except ValueError as e:\n        # Wrap in docling-graph exception\n        raise ExtractionError(\n            \"Data extraction failed\",\n            details={\"function\": \"my_function\"},\n            cause=e\n        )\n</code></pre>"},{"location":"reference/exceptions/#best-practices","title":"Best Practices","text":""},{"location":"reference/exceptions/#1-use-specific-exceptions","title":"1. Use Specific Exceptions","text":"<pre><code># \u2705 Good - Specific exception\nfrom docling_graph.exceptions import ConfigurationError\n\nif not api_key:\n    raise ConfigurationError(\n        \"API key not found\",\n        details={\"env_var\": \"MISTRAL_API_KEY\"}\n    )\n\n# \u274c Avoid - Generic exception\nif not api_key:\n    raise Exception(\"API key not found\")\n</code></pre>"},{"location":"reference/exceptions/#2-provide-details","title":"2. Provide Details","text":"<pre><code># \u2705 Good - Detailed error\nfrom docling_graph.exceptions import ExtractionError\n\nraise ExtractionError(\n    \"Extraction failed\",\n    details={\n        \"source\": source,\n        \"template\": template.__name__,\n        \"backend\": \"llm\",\n        \"stage\": \"markdown_extraction\"\n    }\n)\n\n# \u274c Avoid - No details\nraise ExtractionError(\"Extraction failed\")\n</code></pre>"},{"location":"reference/exceptions/#3-chain-exceptions","title":"3. Chain Exceptions","text":"<pre><code># \u2705 Good - Chain exceptions\nfrom docling_graph.exceptions import ClientError\n\ntry:\n    response = api.call()\nexcept requests.HTTPError as e:\n    raise ClientError(\n        \"API call failed\",\n        details={\"status\": e.response.status_code},\n        cause=e  # Preserve original exception\n    )\n\n# \u274c Avoid - Lose original exception\ntry:\n    response = api.call()\nexcept requests.HTTPError:\n    raise ClientError(\"API call failed\")\n</code></pre>"},{"location":"reference/exceptions/#4-log-before-raising","title":"4. Log Before Raising","text":"<pre><code># \u2705 Good - Log then raise\nimport logging\nfrom docling_graph.exceptions import ExtractionError\n\nlogger = logging.getLogger(__name__)\n\ntry:\n    result = extract()\nexcept Exception as e:\n    logger.error(f\"Extraction failed: {e}\", exc_info=True)\n    raise ExtractionError(\n        \"Extraction failed\",\n        cause=e\n    )\n</code></pre>"},{"location":"reference/exceptions/#related-apis","title":"Related APIs","text":"<ul> <li>Error Handling Guide - Error handling patterns</li> <li>Pipeline API - Pipeline exceptions</li> <li>Configuration API - Configuration validation</li> </ul>"},{"location":"reference/exceptions/#see-also","title":"See Also","text":"<ul> <li>Python Exceptions - Python error handling</li> <li>Pydantic Validation - Pydantic errors</li> </ul>"},{"location":"reference/exporters/","title":"Exporters API","text":""},{"location":"reference/exporters/#overview","title":"Overview","text":"<p>Graph export formats for knowledge graphs.</p> <p>Module: <code>docling_graph.core.exporters</code></p>"},{"location":"reference/exporters/#base-exporter","title":"Base Exporter","text":""},{"location":"reference/exporters/#baseexporter","title":"BaseExporter","text":"<p>Base class for all exporters.</p> <pre><code>class BaseExporter:\n    \"\"\"Base class for graph exporters.\"\"\"\n\n    def __init__(\n        self,\n        graph: nx.MultiDiGraph,\n        output_dir: Path\n    ):\n        \"\"\"\n        Initialize exporter.\n\n        Args:\n            graph: NetworkX graph to export\n            output_dir: Output directory\n        \"\"\"\n        self.graph = graph\n        self.output_dir = output_dir\n\n    def export(self) -&gt; None:\n        \"\"\"Export graph to target format.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/exporters/#csv-exporter","title":"CSV Exporter","text":""},{"location":"reference/exporters/#csvexporter","title":"CSVExporter","text":"<p>Export graphs to Neo4j-compatible CSV format.</p> <pre><code>class CSVExporter(BaseExporter):\n    \"\"\"Export graph to CSV format.\"\"\"\n\n    def export(self) -&gt; None:\n        \"\"\"\n        Export to CSV files.\n\n        Creates:\n            - nodes.csv: Node data\n            - edges.csv: Edge data\n        \"\"\"\n</code></pre> <p>Output Format:</p> <p>nodes.csv: <pre><code>id,label,type,property1,property2,...\nnode_1,John Doe,Person,30,john@example.com\n</code></pre></p> <p>edges.csv: <pre><code>source,target,type\nnode_1,node_2,WORKS_AT\n</code></pre></p> <p>Example:</p> <pre><code>from docling_graph.core.exporters import CSVExporter\nfrom pathlib import Path\n\nexporter = CSVExporter(graph, Path(\"outputs\"))\nexporter.export()\n\n# Files created:\n# - outputs/nodes.csv\n# - outputs/edges.csv\n</code></pre>"},{"location":"reference/exporters/#cypher-exporter","title":"Cypher Exporter","text":""},{"location":"reference/exporters/#cypherexporter","title":"CypherExporter","text":"<p>Export graphs to Cypher script format.</p> <pre><code>class CypherExporter(BaseExporter):\n    \"\"\"Export graph to Cypher script.\"\"\"\n\n    def export(self) -&gt; None:\n        \"\"\"\n        Export to Cypher script.\n\n        Creates:\n            - graph.cypher: Cypher CREATE statements\n        \"\"\"\n</code></pre> <p>Output Format:</p> <pre><code>CREATE (n1:Person {name: \"John Doe\", age: 30})\nCREATE (n2:Organization {name: \"ACME Corp\"})\nCREATE (n1)-[:WORKS_AT]-&gt;(n2)\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.core.exporters import CypherExporter\nfrom pathlib import Path\n\nexporter = CypherExporter(graph, Path(\"outputs\"))\nexporter.export()\n\n# File created: outputs/graph.cypher\n</code></pre>"},{"location":"reference/exporters/#json-exporter","title":"JSON Exporter","text":""},{"location":"reference/exporters/#jsonexporter","title":"JSONExporter","text":"<p>Export graphs to JSON format.</p> <pre><code>class JSONExporter(BaseExporter):\n    \"\"\"Export graph to JSON format.\"\"\"\n\n    def export(self) -&gt; None:\n        \"\"\"\n        Export to JSON.\n\n        Creates:\n            - graph.json: NetworkX node-link format\n        \"\"\"\n</code></pre> <p>Output Format:</p> <pre><code>{\n  \"directed\": true,\n  \"multigraph\": true,\n  \"nodes\": [\n    {\"id\": \"node_1\", \"type\": \"Person\", \"name\": \"John\"}\n  ],\n  \"links\": [\n    {\"source\": \"node_1\", \"target\": \"node_2\", \"type\": \"WORKS_AT\"}\n  ]\n}\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.core.exporters import JSONExporter\nfrom pathlib import Path\n\nexporter = JSONExporter(graph, Path(\"outputs\"))\nexporter.export()\n\n# File created: outputs/graph.json\n</code></pre>"},{"location":"reference/exporters/#docling-exporter","title":"Docling Exporter","text":""},{"location":"reference/exporters/#doclingexporter","title":"DoclingExporter","text":"<p>Export Docling document outputs.</p> <pre><code>class DoclingExporter:\n    \"\"\"Export Docling document outputs.\"\"\"\n\n    def export(\n        self,\n        document: Any,\n        output_dir: Path,\n        export_json: bool = True,\n        export_markdown: bool = True,\n        export_per_page: bool = False\n    ) -&gt; None:\n        \"\"\"\n        Export Docling outputs.\n\n        Args:\n            document: Docling document\n            output_dir: Output directory\n            export_json: Export JSON\n            export_markdown: Export markdown\n            export_per_page: Export per-page markdown\n        \"\"\"\n</code></pre> <p>Creates: - <code>docling_document.json</code> - Docling JSON - <code>markdown/full_document.md</code> - Full markdown - <code>markdown/pages/page_N.md</code> - Per-page markdown</p>"},{"location":"reference/exporters/#custom-exporters","title":"Custom Exporters","text":"<p>Create custom exporters by extending <code>BaseExporter</code>:</p> <pre><code>from docling_graph.core.exporters import BaseExporter\nfrom pathlib import Path\nimport networkx as nx\n\nclass MyExporter(BaseExporter):\n    \"\"\"Custom exporter.\"\"\"\n\n    def export(self) -&gt; None:\n        \"\"\"Export to custom format.\"\"\"\n        output_file = self.output_dir / \"custom.txt\"\n\n        with open(output_file, 'w') as f:\n            f.write(f\"Nodes: {self.graph.number_of_nodes()}\\n\")\n            f.write(f\"Edges: {self.graph.number_of_edges()}\\n\")\n</code></pre> <p>See Custom Exporters Guide for details.</p>"},{"location":"reference/exporters/#related-apis","title":"Related APIs","text":"<ul> <li>Export Formats - Usage guide</li> <li>Custom Exporters - Create exporters</li> <li>Converters - Graph conversion</li> </ul>"},{"location":"reference/extractors/","title":"Extractors API","text":""},{"location":"reference/extractors/#overview","title":"Overview","text":"<p>Document extraction strategies and backends.</p> <p>Module: <code>docling_graph.core.extractors</code></p> <p>Recent Improvements</p> <ul> <li>Model Capability Detection: Automatic tier detection and adaptive prompting</li> <li>Chain of Density: Multi-turn consolidation for ADVANCED tier models</li> <li>Zero Data Loss: Returns partial models instead of empty results on failures</li> <li>Real Tokenizers: Accurate token counting with 20% safety margins</li> <li>Enhanced GPU Cleanup: Better memory management for VLM backends</li> </ul>"},{"location":"reference/extractors/#extraction-strategies","title":"Extraction Strategies","text":""},{"location":"reference/extractors/#onetoone","title":"OneToOne","text":"<p>Per-page extraction strategy.</p> <pre><code>class OneToOne(ExtractorProtocol):\n    \"\"\"Extract data from each page separately.\"\"\"\n\n    def __init__(self, backend: Backend):\n        \"\"\"Initialize with backend.\"\"\"\n        self.backend = backend\n\n    def extract(\n        self,\n        source: str,\n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"\n        Extract from each page.\n\n        Returns:\n            List of models (one per page)\n        \"\"\"\n</code></pre> <p>Use Cases: - Multi-page documents with independent content - Page-level analysis - Parallel processing</p> <p>Example:</p> <pre><code>from docling_graph.core.extractors import OneToOne\nfrom docling_graph.core.extractors.backends import LLMBackend\n\nbackend = LLMBackend(model=\"llama-3.1-8b\")\nextractor = OneToOne(backend=backend)\n\nresults = extractor.extract(\"document.pdf\", MyTemplate)\nprint(f\"Extracted {len(results)} pages\")\n</code></pre>"},{"location":"reference/extractors/#manytoone","title":"ManyToOne","text":"<p>Consolidated extraction strategy with zero data loss.</p> <pre><code>class ManyToOne(ExtractorProtocol):\n    \"\"\"Extract and consolidate data from entire document.\"\"\"\n\n    def __init__(\n        self,\n        backend: Backend,\n        use_chunking: bool = True,\n        llm_consolidation: bool = False\n    ):\n        \"\"\"Initialize with backend and options.\"\"\"\n        self.backend = backend\n        self.use_chunking = use_chunking\n        self.llm_consolidation = llm_consolidation\n\n    def extract(\n        self,\n        source: str,\n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"\n        Extract and consolidate.\n\n        Returns:\n            List with single consolidated model (success)\n            or multiple partial models (merge failure - zero data loss)\n        \"\"\"\n</code></pre> <p>Use Cases: - Single entity across document - Consolidated information - Summary extraction</p> <p>Features: - Zero Data Loss: Returns partial models if consolidation fails - Adaptive Consolidation: Uses Chain of Density for ADVANCED tier models - Schema-Aware Chunking: Dynamically adjusts chunk size based on schema</p> <p>Example:</p> <pre><code>from docling_graph.core.extractors import ManyToOne\nfrom docling_graph.core.extractors.backends import LLMBackend\n\nbackend = LLMBackend(model=\"llama-3.1-8b\")\nextractor = ManyToOne(\n    backend=backend,\n    use_chunking=True,\n    llm_consolidation=True\n)\n\nresults = extractor.extract(\"document.pdf\", MyTemplate)\n\n# Check if consolidation succeeded\nif len(results) == 1:\n    print(f\"\u2713 Consolidated model: {results[0]}\")\nelse:\n    print(f\"\u26a0 Got {len(results)} partial models (data preserved)\")\n</code></pre>"},{"location":"reference/extractors/#backends","title":"Backends","text":""},{"location":"reference/extractors/#llmbackend","title":"LLMBackend","text":"<p>LLM-based extraction backend with adaptive prompting.</p> <pre><code>class LLMBackend(TextExtractionBackendProtocol):\n    \"\"\"LLM backend for text extraction.\"\"\"\n\n    def __init__(\n        self,\n        client: LLMClientProtocol,\n        model: str,\n        provider: str\n    ):\n        \"\"\"Initialize LLM backend.\"\"\"\n        self.client = client\n        self.model_capability = self._detect_capability()  # Auto-detect tier\n</code></pre> <p>Methods:</p> <ul> <li><code>extract_from_markdown(markdown, template, context, is_partial)</code> - Extract from markdown with adaptive prompting</li> <li><code>consolidate_from_pydantic_models(raw_models, programmatic_model, template)</code> - Consolidate models (uses Chain of Density for ADVANCED tier)</li> <li><code>cleanup()</code> - Clean up resources</li> </ul> <p>Model Capability Tiers:</p> Tier Model Size Prompt Style Consolidation SIMPLE 1B-7B Minimal Single-turn STANDARD 7B-13B Balanced Single-turn ADVANCED 13B+ Detailed Chain of Density (3 turns) <p>Example:</p> <pre><code>from docling_graph.core.extractors.backends import LLMBackend\nfrom docling_graph.llm_clients import OllamaClient\n\n# STANDARD tier model (7B-13B)\nclient = OllamaClient(model=\"llama3.1:8b\")\nbackend = LLMBackend(llm_client=client)\n\n# Automatically uses STANDARD tier prompts\nmodel = backend.extract_from_markdown(\n    markdown=markdown,\n    template=MyTemplate,\n    context=\"full document\",\n    is_partial=False\n)\n</code></pre>"},{"location":"reference/extractors/#vlmbackend","title":"VLMBackend","text":"<p>Vision-Language Model backend with enhanced GPU cleanup.</p> <pre><code>class VLMBackend(ExtractionBackendProtocol):\n    \"\"\"VLM backend for document extraction.\"\"\"\n\n    def __init__(self, model: str):\n        \"\"\"Initialize VLM backend.\"\"\"\n        self.model_name = model\n        self.model = None  # Loaded on first use\n</code></pre> <p>Methods:</p> <ul> <li><code>extract_from_document(source, template)</code> - Extract from document</li> <li><code>cleanup()</code> - Enhanced GPU memory cleanup</li> </ul> <p>Enhanced GPU Cleanup:</p> <p>The <code>cleanup()</code> method now includes: - Model-to-CPU transfer before deletion - Explicit CUDA cache clearing - Memory usage tracking and logging - Multi-GPU device support</p> <p>Example:</p> <pre><code>from docling_graph.core.extractors.backends import VLMBackend\n\nbackend = VLMBackend(model_name=\"numind/NuExtract-2.0-8B\")\n\ntry:\n    models = backend.extract_from_document(\"document.pdf\", MyTemplate)\nfinally:\n    backend.cleanup()  # Properly releases GPU memory\n</code></pre>"},{"location":"reference/extractors/#document-processing","title":"Document Processing","text":""},{"location":"reference/extractors/#documentprocessor","title":"DocumentProcessor","text":"<p>Handles document conversion and markdown extraction.</p> <pre><code>class DocumentProcessor(DocumentProcessorProtocol):\n    \"\"\"Process documents with Docling.\"\"\"\n\n    def convert_to_docling_doc(self, source: str) -&gt; Any:\n        \"\"\"Convert to Docling document.\"\"\"\n\n    def extract_full_markdown(self, document: Any) -&gt; str:\n        \"\"\"Extract full markdown.\"\"\"\n\n    def extract_page_markdowns(self, document: Any) -&gt; List[str]:\n        \"\"\"Extract per-page markdown.\"\"\"\n</code></pre>"},{"location":"reference/extractors/#chunking","title":"Chunking","text":""},{"location":"reference/extractors/#documentchunker","title":"DocumentChunker","text":"<p>Handles document chunking with real tokenizers and schema-aware sizing.</p> <pre><code>class DocumentChunker:\n    \"\"\"Chunk documents for processing.\"\"\"\n\n    def __init__(\n        self,\n        provider: str,\n        max_tokens: int = None,\n        tokenizer_name: str = None,\n        schema_size: int = 0\n    ):\n        \"\"\"\n        Initialize chunker.\n\n        Args:\n            provider: LLM provider (for tokenizer selection)\n            max_tokens: Maximum tokens per chunk\n            tokenizer_name: Specific tokenizer to use\n            schema_size: Schema size for dynamic adjustment\n        \"\"\"\n\n    def chunk_markdown(\n        self,\n        markdown: str,\n        max_tokens: int\n    ) -&gt; List[str]:\n        \"\"\"\n        Chunk markdown by tokens using real tokenizer.\n\n        Args:\n            markdown: Markdown content\n            max_tokens: Maximum tokens per chunk\n\n        Returns:\n            List of markdown chunks\n        \"\"\"\n\n    def update_schema_config(self, schema_size: int):\n        \"\"\"\n        Update schema configuration dynamically.\n\n        Args:\n            schema_size: New schema size in bytes\n        \"\"\"\n</code></pre> <p>Features:</p> <ul> <li>Real Tokenizers: Uses provider-specific tokenizers for accurate token counting</li> <li>Safety Margins: Applies 20% safety margin to prevent context overflows</li> <li>Schema-Aware: Dynamically adjusts chunk size based on schema complexity</li> <li>Provider-Specific: Optimized for each LLM provider</li> </ul> <p>Example:</p> <pre><code>from docling_graph.core.extractors import DocumentChunker\n\n# Create chunker with real tokenizer\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096,\n    schema_size=len(MyTemplate.model_json_schema())\n)\n\n# Chunk with accurate token counting\nchunks = chunker.chunk_markdown(markdown, max_tokens=4096)\n\n# Update for different schema\nchunker.update_schema_config(schema_size=8000)\n</code></pre>"},{"location":"reference/extractors/#factory","title":"Factory","text":""},{"location":"reference/extractors/#create_extractor","title":"create_extractor()","text":"<p>Factory function for creating extractors.</p> <pre><code>def create_extractor(\n    strategy: Literal[\"one-to-one\", \"many-to-one\"],\n    backend: Backend,\n    **kwargs\n) -&gt; ExtractorProtocol:\n    \"\"\"\n    Create extractor with strategy.\n\n    Args:\n        strategy: Extraction strategy\n        backend: Backend instance\n        **kwargs: Additional options\n\n    Returns:\n        Extractor instance\n    \"\"\"\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.core.extractors import create_extractor\n\nextractor = create_extractor(\n    strategy=\"many-to-one\",\n    backend=my_backend,\n    use_chunking=True\n)\n</code></pre>"},{"location":"reference/extractors/#new-features-summary","title":"New Features Summary","text":""},{"location":"reference/extractors/#model-capability-detection","title":"Model Capability Detection","text":"<p>Automatic detection of model capabilities based on parameter count:</p> <pre><code># Automatically detected\nbackend = LLMBackend(llm_client=client)\n# backend.model_capability = ModelCapability.STANDARD (for 8B model)\n</code></pre>"},{"location":"reference/extractors/#chain-of-density-consolidation","title":"Chain of Density Consolidation","text":"<p>Multi-turn consolidation for ADVANCED tier models (13B+):</p> <pre><code># Automatically enabled for large models\nbackend = LLMBackend(llm_client=openai_client)  # GPT-4\nfinal = backend.consolidate_from_pydantic_models(\n    raw_models=models,\n    programmatic_model=draft,\n    template=MyTemplate\n)\n# Uses 3-turn Chain of Density process\n</code></pre>"},{"location":"reference/extractors/#zero-data-loss","title":"Zero Data Loss","text":"<p>Returns partial models instead of empty results:</p> <pre><code>results = extractor.extract(\"document.pdf\", MyTemplate)\n\nif len(results) == 1:\n    # Success: merged model\n    model = results[0]\nelse:\n    # Partial: multiple models (data preserved!)\n    for model in results:\n        process_partial(model)\n</code></pre>"},{"location":"reference/extractors/#real-tokenizer-integration","title":"Real Tokenizer Integration","text":"<p>Accurate token counting with safety margins:</p> <pre><code>chunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096  # Uses real Mistral tokenizer\n)\n# Applies 20% safety margin automatically\n</code></pre>"},{"location":"reference/extractors/#related-apis","title":"Related APIs","text":"<ul> <li>Model Capabilities - Capability tiers</li> <li>Extraction Process - Usage guide</li> <li>Model Merging - Zero data loss</li> <li>Protocols - Backend protocols</li> <li>Custom Backends - Create backends</li> </ul>"},{"location":"reference/llm-clients/","title":"LLM Clients API","text":""},{"location":"reference/llm-clients/#overview","title":"Overview","text":"<p>LLM client implementations for various providers.</p> <p>Module: <code>docling_graph.llm_clients</code></p> <p>All clients implement <code>LLMClientProtocol</code>.</p>"},{"location":"reference/llm-clients/#base-client","title":"Base Client","text":""},{"location":"reference/llm-clients/#basellmclient","title":"BaseLLMClient","text":"<p>Base class for LLM clients with configurable generation limits and timeouts.</p> <pre><code>class BaseLLMClient(LLMClientProtocol):\n    \"\"\"Base LLM client implementation.\"\"\"\n\n    def __init__(\n        self,\n        model: str,\n        max_tokens: int | None = None,\n        timeout: int | None = None,\n        **kwargs\n    ):\n        \"\"\"\n        Initialize LLM client.\n\n        Args:\n            model: Model identifier\n            max_tokens: Maximum tokens to generate (overrides config, default: 8192)\n            timeout: Request timeout in seconds (overrides config, default: 300-600)\n            **kwargs: Provider-specific parameters\n        \"\"\"\n\n    @property\n    def context_limit(self) -&gt; int:\n        \"\"\"Return effective context limit in tokens.\"\"\"\n        raise NotImplementedError\n\n    @property\n    def max_tokens(self) -&gt; int:\n        \"\"\"Return maximum tokens to generate.\"\"\"\n        return self._max_tokens or 8192\n\n    @property\n    def timeout(self) -&gt; int:\n        \"\"\"Return request timeout in seconds.\"\"\"\n        return self._timeout or 300\n\n    def get_json_response(\n        self,\n        prompt: str | Mapping[str, str],\n        schema_json: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Execute LLM call and return parsed JSON.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/llm-clients/#configuration","title":"Configuration","text":"<p>All clients support <code>max_tokens</code> and <code>timeout</code> parameters:</p> <ul> <li><code>max_tokens</code>: Maximum tokens to generate in response (default: 8192)</li> <li>Prevents infinite generation loops</li> <li> <p>Configurable per-client or via <code>models.yaml</code></p> </li> <li> <p><code>timeout</code>: Request timeout in seconds</p> </li> <li>API providers: 300s (5 minutes) default</li> <li>Local providers: 600s (10 minutes) default</li> <li>Prevents indefinite hangs</li> </ul> <p>Example:</p> <pre><code>from docling_graph.llm_clients import VllmClient\n\n# Use defaults from models.yaml\nclient = VllmClient(model=\"qwen/Qwen2-7B\")\n\n# Override with custom values\nclient = VllmClient(\n    model=\"qwen/Qwen2-7B\",\n    max_tokens=4096,    # Limit response to 4K tokens\n    timeout=300         # 5 minute timeout\n)\n</code></pre>"},{"location":"reference/llm-clients/#local-clients","title":"Local Clients","text":""},{"location":"reference/llm-clients/#ollamaclient","title":"OllamaClient","text":"<p>Client for Ollama local inference.</p> <pre><code>class OllamaClient(BaseLLMClient):\n    \"\"\"Ollama LLM client.\"\"\"\n\n    def __init__(\n        self,\n        model: str = \"llama-3.1-8b\",\n        base_url: str = \"http://localhost:11434\"\n    ):\n        \"\"\"Initialize Ollama client.\"\"\"\n        self.model = model\n        self.base_url = base_url\n\n    @property\n    def context_limit(self) -&gt; int:\n        \"\"\"Return context limit.\"\"\"\n        return 8000  # Conservative\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.llm_clients import OllamaClient\n\nclient = OllamaClient(\n    model=\"llama-3.1-8b\",\n    base_url=\"http://localhost:11434\"\n)\n\nresponse = client.get_json_response(\n    prompt=\"Extract data from: ...\",\n    schema_json=schema\n)\n</code></pre>"},{"location":"reference/llm-clients/#vllmclient","title":"VLLMClient","text":"<p>Client for vLLM server with generation limits and timeout protection.</p> <pre><code>class VLLMClient(BaseLLMClient):\n    \"\"\"vLLM server client.\"\"\"\n\n    def __init__(\n        self,\n        model: str = \"ibm-granite/granite-4.0-1b\",\n        base_url: str = \"http://localhost:8000/v1\",\n        max_tokens: int | None = None,\n        timeout: int | None = None\n    ):\n        \"\"\"\n        Initialize vLLM client.\n\n        Args:\n            model: Model identifier\n            base_url: vLLM server URL\n            max_tokens: Maximum tokens to generate (default: 8192)\n            timeout: Request timeout in seconds (default: 600)\n        \"\"\"\n        self.model = model\n        self.base_url = base_url\n\n    @property\n    def context_limit(self) -&gt; int:\n        \"\"\"Return context limit.\"\"\"\n        return 8000\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.llm_clients import VLLMClient\n\n# Basic usage (uses defaults: max_tokens=8192, timeout=600s)\nclient = VLLMClient(\n    model=\"ibm-granite/granite-4.0-1b\",\n    base_url=\"http://localhost:8000/v1\"\n)\n\n# Custom limits to prevent hanging\nclient = VLLMClient(\n    model=\"qwen/Qwen2-7B\",\n    base_url=\"http://localhost:8000/v1\",\n    max_tokens=4096,    # Limit response length\n    timeout=300         # 5 minute timeout\n)\n</code></pre> <p>Timeout Protection</p> <p>vLLM client now includes timeout protection to prevent indefinite hangs. If a request exceeds the timeout (default: 10 minutes), it will raise a <code>ClientError</code>. This is especially important when processing documents that don't match your template schema.</p>"},{"location":"reference/llm-clients/#remote-clients","title":"Remote Clients","text":""},{"location":"reference/llm-clients/#mistralclient","title":"MistralClient","text":"<p>Client for Mistral AI API.</p> <pre><code>class MistralClient(BaseLLMClient):\n    \"\"\"Mistral AI client.\"\"\"\n\n    def __init__(\n        self,\n        model: str = \"mistral-small-latest\",\n        api_key: str | None = None\n    ):\n        \"\"\"\n        Initialize Mistral client.\n\n        Args:\n            model: Model name\n            api_key: API key (or set MISTRAL_API_KEY env var)\n        \"\"\"\n        self.model = model\n        self.api_key = api_key or os.getenv(\"MISTRAL_API_KEY\")\n\n    @property\n    def context_limit(self) -&gt; int:\n        \"\"\"Return context limit.\"\"\"\n        return 32000\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.llm_clients import MistralClient\nimport os\n\n# Set API key\nos.environ[\"MISTRAL_API_KEY\"] = \"your_key\"\n\nclient = MistralClient(model=\"mistral-small-latest\")\n</code></pre>"},{"location":"reference/llm-clients/#openaiclient","title":"OpenAIClient","text":"<p>Client for OpenAI API.</p> <pre><code>class OpenAIClient(BaseLLMClient):\n    \"\"\"OpenAI client.\"\"\"\n\n    def __init__(\n        self,\n        model: str = \"gpt-4-turbo\",\n        api_key: str | None = None\n    ):\n        \"\"\"\n        Initialize OpenAI client.\n\n        Args:\n            model: Model name\n            api_key: API key (or set OPENAI_API_KEY env var)\n        \"\"\"\n        self.model = model\n        self.api_key = api_key or os.getenv(\"OPENAI_API_KEY\")\n\n    @property\n    def context_limit(self) -&gt; int:\n        \"\"\"Return context limit.\"\"\"\n        return 128000  # GPT-4 Turbo\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.llm_clients import OpenAIClient\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"your_key\"\n\nclient = OpenAIClient(model=\"gpt-4-turbo\")\n</code></pre>"},{"location":"reference/llm-clients/#geminiclient","title":"GeminiClient","text":"<p>Client for Google Gemini API.</p> <pre><code>class GeminiClient(BaseLLMClient):\n    \"\"\"Google Gemini client.\"\"\"\n\n    def __init__(\n        self,\n        model: str = \"gemini-2.5-flash\",\n        api_key: str | None = None\n    ):\n        \"\"\"\n        Initialize Gemini client.\n\n        Args:\n            model: Model name\n            api_key: API key (or set GEMINI_API_KEY env var)\n        \"\"\"\n        self.model = model\n        self.api_key = api_key or os.getenv(\"GEMINI_API_KEY\")\n\n    @property\n    def context_limit(self) -&gt; int:\n        \"\"\"Return context limit.\"\"\"\n        return 1000000  # Gemini 2.5 Flash\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.llm_clients import GeminiClient\nimport os\n\nos.environ[\"GEMINI_API_KEY\"] = \"your_key\"\n\nclient = GeminiClient(model=\"gemini-2.5-flash\")\n</code></pre>"},{"location":"reference/llm-clients/#watsonxclient","title":"WatsonxClient","text":"<p>Client for IBM watsonx.ai API.</p> <pre><code>class WatsonxClient(BaseLLMClient):\n    \"\"\"IBM watsonx.ai client.\"\"\"\n\n    def __init__(\n        self,\n        model: str,\n        api_key: str | None = None,\n        project_id: str | None = None,\n        url: str | None = None\n    ):\n        \"\"\"\n        Initialize watsonx client.\n\n        Args:\n            model: Model name\n            api_key: API key (or set WATSONX_API_KEY)\n            project_id: Project ID (or set WATSONX_PROJECT_ID)\n            url: Service URL (or set WATSONX_URL)\n        \"\"\"\n        self.model = model\n        self.api_key = api_key or os.getenv(\"WATSONX_API_KEY\")\n        self.project_id = project_id or os.getenv(\"WATSONX_PROJECT_ID\")\n        self.url = url or os.getenv(\"WATSONX_URL\")\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.llm_clients import WatsonxClient\nimport os\n\nos.environ[\"WATSONX_API_KEY\"] = \"your_key\"\nos.environ[\"WATSONX_PROJECT_ID\"] = \"your_project\"\nos.environ[\"WATSONX_URL\"] = \"https://us-south.ml.cloud.ibm.com\"\n\nclient = WatsonxClient(model=\"ibm/granite-13b-chat-v2\")\n</code></pre>"},{"location":"reference/llm-clients/#client-configuration","title":"Client Configuration","text":""},{"location":"reference/llm-clients/#model-configuration","title":"Model Configuration","text":"<p>Models are configured in <code>models.yaml</code> with generation limits and timeouts:</p> <pre><code>providers:\n  mistral:\n    tokenizer: \"mistralai/Mistral-7B-Instruct-v0.2\"\n    default_max_tokens: 8192      # Default response limit\n    timeout_seconds: 300          # 5 minute timeout\n    models:\n      mistral-small-latest:\n        context_limit: 32000\n        max_new_tokens: 4096\n        max_tokens: 8192          # Optional model-specific override\n        timeout: 300              # Optional model-specific timeout\n\n  vllm:\n    tokenizer: \"sentence-transformers/all-MiniLM-L6-v2\"\n    default_max_tokens: 8192      # Prevents infinite generation\n    timeout_seconds: 600          # 10 minute timeout for local inference\n    models:\n      qwen/Qwen2-7B:\n        context_limit: 128000\n        max_new_tokens: 4096\n</code></pre>"},{"location":"reference/llm-clients/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<p>Configuration is loaded in this order (highest priority first):</p> <ol> <li>Constructor parameters: <code>VllmClient(max_tokens=4096, timeout=300)</code></li> <li>Model-specific config: <code>models.yaml</code> \u2192 <code>providers.vllm.models.qwen/Qwen2-7B.max_tokens</code></li> <li>Provider defaults: <code>models.yaml</code> \u2192 <code>providers.vllm.default_max_tokens</code></li> <li>Fallback defaults: <code>max_tokens=8192</code>, <code>timeout=300</code></li> </ol> <p>Example:</p> <pre><code># Uses provider default (8192 tokens, 600s timeout)\nclient = VllmClient(model=\"qwen/Qwen2-7B\")\n\n# Override with custom values\nclient = VllmClient(\n    model=\"qwen/Qwen2-7B\",\n    max_tokens=4096,\n    timeout=300\n)\n</code></pre>"},{"location":"reference/llm-clients/#timeout-defaults-by-provider","title":"Timeout Defaults by Provider","text":"Provider Default Timeout Reason OpenAI, Mistral, Gemini, Anthropic 300s (5 min) Fast API responses vLLM, Ollama, WatsonX 600s (10 min) Local/slower inference"},{"location":"reference/llm-clients/#api-key-management","title":"API Key Management","text":""},{"location":"reference/llm-clients/#environment-variables","title":"Environment Variables","text":"<p>Set API keys via environment variables:</p> <pre><code># Mistral\nexport MISTRAL_API_KEY=\"your_key\"\n\n# OpenAI\nexport OPENAI_API_KEY=\"your_key\"\n\n# Gemini\nexport GEMINI_API_KEY=\"your_key\"\n\n# watsonx\nexport WATSONX_API_KEY=\"your_key\"\nexport WATSONX_PROJECT_ID=\"your_project\"\nexport WATSONX_URL=\"https://us-south.ml.cloud.ibm.com\"\n</code></pre>"},{"location":"reference/llm-clients/#env-file","title":".env File","text":"<p>Or use a <code>.env</code> file:</p> <pre><code># .env\nMISTRAL_API_KEY=your_key\nOPENAI_API_KEY=your_key\nGEMINI_API_KEY=your_key\n</code></pre> <p>Load with:</p> <pre><code>from dotenv import load_dotenv\nload_dotenv()\n</code></pre>"},{"location":"reference/llm-clients/#usage-with-pipeline","title":"Usage with Pipeline","text":"<p>Clients are automatically selected based on configuration:</p> <pre><code>from docling_graph import PipelineConfig\n\n# Uses MistralClient automatically\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-small-latest\"\n)\nconfig.run()\n</code></pre>"},{"location":"reference/llm-clients/#custom-clients","title":"Custom Clients","text":"<p>Create custom clients by implementing <code>LLMClientProtocol</code>:</p> <pre><code>from docling_graph.protocols import LLMClientProtocol\nfrom typing import Dict, Any, Mapping\n\nclass MyCustomClient(LLMClientProtocol):\n    \"\"\"Custom LLM client.\"\"\"\n\n    @property\n    def context_limit(self) -&gt; int:\n        return 8000\n\n    def get_json_response(\n        self,\n        prompt: str | Mapping[str, str],\n        schema_json: str\n    ) -&gt; Dict[str, Any]:\n        # Your implementation\n        pass\n</code></pre>"},{"location":"reference/llm-clients/#error-handling","title":"Error Handling","text":"<p>All clients raise <code>ClientError</code> on failures, including timeouts:</p> <pre><code>from docling_graph.llm_clients import VllmClient\nfrom docling_graph.exceptions import ClientError\n\nclient = VllmClient(model=\"qwen/Qwen2-7B\", timeout=300)\n\ntry:\n    response = client.get_json_response(prompt, schema)\nexcept ClientError as e:\n    print(f\"Error: {e.message}\")\n    print(f\"Details: {e.details}\")\n\n    # Check if it was a timeout\n    if \"timeout\" in str(e).lower():\n        print(\"Request exceeded timeout limit\")\n        print(f\"Timeout was: {client.timeout}s\")\n</code></pre>"},{"location":"reference/llm-clients/#common-error-scenarios","title":"Common Error Scenarios","text":"<p>Timeout Error: <pre><code>ClientError: vLLM request timeout after 600s\nDetails: {\n    'model': 'qwen/Qwen2-7B',\n    'timeout': 600,\n    'max_tokens': 8192\n}\n</code></pre></p> <p>Infinite Generation (Fixed):</p> <p>Before the fix, vLLM could generate indefinitely when content didn't match the template. Now it's limited by <code>max_tokens</code>:</p> <pre><code># Old behavior: Could hang for hours\n# New behavior: Stops at 8192 tokens (or custom limit)\nclient = VllmClient(model=\"qwen/Qwen2-7B\", max_tokens=4096)\n</code></pre>"},{"location":"reference/llm-clients/#troubleshooting","title":"Troubleshooting","text":"<p>Problem: Request times out</p> <ul> <li>Increase timeout: <code>VllmClient(timeout=1200)</code> (20 minutes)</li> <li>Reduce max_tokens: <code>VllmClient(max_tokens=4096)</code></li> <li>Check if content matches template schema</li> </ul> <p>Problem: Response truncated</p> <ul> <li>Increase max_tokens: <code>VllmClient(max_tokens=16384)</code></li> <li>Simplify template to require less output</li> <li>Use chunking for large documents</li> </ul>"},{"location":"reference/llm-clients/#related-apis","title":"Related APIs","text":"<ul> <li>Protocols - LLMClientProtocol</li> <li>Exceptions - ClientError</li> <li>Model Configuration - Configure models</li> </ul>"},{"location":"reference/llm-clients/#recent-changes","title":"Recent Changes","text":""},{"location":"reference/llm-clients/#version-0xx-generation-limits-timeout-protection","title":"Version 0.x.x - Generation Limits &amp; Timeout Protection","text":"<p>Added <code>max_tokens</code> and <code>timeout</code> parameters to all LLM clients to prevent infinite generation and hanging requests.</p> <p>Key Changes:</p> <ol> <li><code>max_tokens</code> Parameter: Limits response generation (default: 8192 tokens)</li> <li>Prevents infinite generation loops</li> <li>Configurable per-client or via <code>models.yaml</code></li> <li> <p>Critical fix for vLLM client hanging issue</p> </li> <li> <p><code>timeout</code> Parameter: Request timeout protection</p> </li> <li>API providers: 300s (5 minutes)</li> <li>Local providers: 600s (10 minutes)</li> <li> <p>Prevents indefinite hangs</p> </li> <li> <p>Configuration Hierarchy:</p> </li> <li>Constructor \u2192 Model-specific \u2192 Provider default \u2192 Fallback</li> </ol> <p>Migration Guide:</p> <p>Existing code continues to work with sensible defaults:</p> <pre><code># Old code (still works)\nclient = VllmClient(model=\"qwen/Qwen2-7B\")\n\n# New code (with explicit limits)\nclient = VllmClient(\n    model=\"qwen/Qwen2-7B\",\n    max_tokens=8192,\n    timeout=600\n)\n</code></pre> <p>Why This Matters:</p> <p>Before this change, vLLM could hang indefinitely when processing documents that didn't match the template schema (e.g., bibliography pages). Now:</p> <ul> <li>\u2705 Generation stops at <code>max_tokens</code> limit</li> <li>\u2705 Requests timeout after configured duration</li> <li>\u2705 Clear error messages for debugging</li> <li>\u2705 Backward compatible with existing code</li> </ul>"},{"location":"reference/llm-clients/#see-also","title":"See Also","text":"<ul> <li>API Keys Setup - Configure API keys including WatsonX</li> <li>Model Configuration - Model setup</li> <li>Remote Inference - Backend selection</li> </ul>"},{"location":"reference/pipeline/","title":"Pipeline API","text":""},{"location":"reference/pipeline/#overview","title":"Overview","text":"<p>The Pipeline API provides the main entry point for document extraction and graph conversion.</p> <p>Module: <code>docling_graph.pipeline</code></p>"},{"location":"reference/pipeline/#functions","title":"Functions","text":""},{"location":"reference/pipeline/#run_pipeline","title":"run_pipeline()","text":"<pre><code>def run_pipeline(config: Union[PipelineConfig, Dict[str, Any]]) -&gt; None\n</code></pre> <p>Run the extraction and graph conversion pipeline.</p> <p>Parameters:</p> Parameter Type Description <code>config</code> <code>PipelineConfig</code> or <code>dict</code> Pipeline configuration <p>Returns: <code>None</code></p> <p>Raises:</p> Exception When <code>PipelineError</code> Pipeline execution fails <code>ConfigurationError</code> Configuration is invalid <code>ExtractionError</code> Document extraction fails <p>Example:</p> <pre><code>from docling_graph import run_pipeline\n\n# Using dict\nconfig = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n    \"backend\": \"llm\",\n    \"inference\": \"local\",\n    \"output_dir\": \"outputs\"\n}\nrun_pipeline(config)\n\n# Using PipelineConfig\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\"\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"reference/pipeline/#pipeline-stages","title":"Pipeline Stages","text":"<p>The pipeline executes the following stages in order:</p>"},{"location":"reference/pipeline/#1-template-loading","title":"1. Template Loading","text":"<p>Purpose: Load and validate Pydantic templates</p> <p>Actions: - Import template module - Validate template structure - Check for required fields</p> <p>Errors: - <code>ConfigurationError</code> if template not found - <code>ValidationError</code> if template invalid</p>"},{"location":"reference/pipeline/#2-extraction","title":"2. Extraction","text":"<p>Purpose: Extract structured data from documents</p> <p>Actions: - Convert document with Docling - Extract using backend (VLM or LLM) - Validate extracted data</p> <p>Errors: - <code>ExtractionError</code> if extraction fails - <code>ValidationError</code> if data invalid</p>"},{"location":"reference/pipeline/#3-docling-export-optional","title":"3. Docling Export (Optional)","text":"<p>Purpose: Export Docling document outputs</p> <p>Actions: - Export Docling JSON - Export markdown - Export per-page markdown</p> <p>Controlled by: - <code>export_docling</code> - <code>export_docling_json</code> - <code>export_markdown</code> - <code>export_per_page_markdown</code></p>"},{"location":"reference/pipeline/#4-graph-conversion","title":"4. Graph Conversion","text":"<p>Purpose: Convert extracted data to knowledge graphs</p> <p>Actions: - Create NetworkX graph - Generate stable node IDs - Create edges from relationships</p> <p>Errors: - <code>GraphError</code> if conversion fails</p>"},{"location":"reference/pipeline/#5-export","title":"5. Export","text":"<p>Purpose: Export graphs in multiple formats</p> <p>Actions: - Export to CSV (nodes.csv, edges.csv) - Export to Cypher (graph.cypher) - Export to JSON (graph.json)</p> <p>Controlled by: - <code>export_format</code></p>"},{"location":"reference/pipeline/#6-visualization","title":"6. Visualization","text":"<p>Purpose: Generate reports and interactive visualizations</p> <p>Actions: - Create HTML visualization - Generate markdown report - Calculate statistics</p> <p>Outputs: - <code>graph_visualization.html</code> - <code>extraction_report.md</code></p>"},{"location":"reference/pipeline/#pipeline-context","title":"Pipeline Context","text":"<p>Internal context object passed between stages:</p> <pre><code>@dataclass\nclass PipelineContext:\n    \"\"\"Shared context for pipeline stages.\"\"\"\n\n    # Configuration\n    config: Dict[str, Any]\n\n    # Paths\n    source: Path\n    output_dir: Path\n\n    # Pipeline state\n    template: Type[BaseModel] | None = None\n    docling_doc: Any = None\n    extracted_models: List[BaseModel] | None = None\n    graph: nx.MultiDiGraph | None = None\n\n    # Metadata\n    metadata: Dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"reference/pipeline/#configuration-options","title":"Configuration Options","text":""},{"location":"reference/pipeline/#required","title":"Required","text":"Option Type Description <code>source</code> <code>str</code> or <code>Path</code> Path to source document <code>template</code> <code>str</code> or <code>Type[BaseModel]</code> Pydantic template"},{"location":"reference/pipeline/#backend-selection","title":"Backend Selection","text":"Option Type Default Description <code>backend</code> <code>\"llm\"</code> or <code>\"vlm\"</code> <code>\"llm\"</code> Extraction backend <code>inference</code> <code>\"local\"</code> or <code>\"remote\"</code> <code>\"local\"</code> Inference location"},{"location":"reference/pipeline/#processing","title":"Processing","text":"Option Type Default Description <code>processing_mode</code> <code>\"one-to-one\"</code> or <code>\"many-to-one\"</code> <code>\"many-to-one\"</code> Processing strategy <code>use_chunking</code> <code>bool</code> <code>True</code> Enable chunking <code>llm_consolidation</code> <code>bool</code> <code>False</code> Use LLM for merge"},{"location":"reference/pipeline/#export","title":"Export","text":"Option Type Default Description <code>export_format</code> <code>\"csv\"</code> or <code>\"cypher\"</code> <code>\"csv\"</code> Graph export format <code>output_dir</code> <code>str</code> or <code>Path</code> <code>\"outputs\"</code> Output directory <p>See Configuration API for complete options.</p>"},{"location":"reference/pipeline/#usage-patterns","title":"Usage Patterns","text":""},{"location":"reference/pipeline/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\"\n})\n</code></pre>"},{"location":"reference/pipeline/#with-error-handling","title":"With Error Handling","text":"<pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import (\n    ConfigurationError,\n    ExtractionError,\n    PipelineError\n)\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\"\n    })\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e.message}\")\n    print(f\"Details: {e.details}\")\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\nexcept PipelineError as e:\n    print(f\"Pipeline error: {e.message}\")\n</code></pre>"},{"location":"reference/pipeline/#batch-processing","title":"Batch Processing","text":"<pre><code>from pathlib import Path\nfrom docling_graph import run_pipeline\n\ndocuments = Path(\"documents\").glob(\"*.pdf\")\n\nfor doc in documents:\n    print(f\"Processing {doc.name}...\")\n\n    run_pipeline({\n        \"source\": str(doc),\n        \"template\": \"templates.MyTemplate\",\n        \"output_dir\": f\"outputs/{doc.stem}\"\n    })\n\n    print(f\"\u2713 {doc.name} complete\")\n</code></pre>"},{"location":"reference/pipeline/#custom-configuration","title":"Custom Configuration","text":"<pre><code>from docling_graph import run_pipeline\n\nconfig = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n\n    # Backend\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"model_override\": \"mistral-small-latest\",\n    \"provider_override\": \"mistral\",\n\n    # Processing\n    \"processing_mode\": \"many-to-one\",\n    \"use_chunking\": True,\n    \"llm_consolidation\": True,\n\n    # Export\n    \"export_format\": \"cypher\",\n    \"export_docling_json\": True,\n    \"export_markdown\": True,\n\n    # Output\n    \"output_dir\": \"outputs/custom\"\n}\n\nrun_pipeline(config)\n</code></pre>"},{"location":"reference/pipeline/#output-structure","title":"Output Structure","text":"<p>After successful execution, the output directory contains:</p> <pre><code>outputs/\n\u251c\u2500\u2500 nodes.csv                    # Graph nodes (if CSV export)\n\u251c\u2500\u2500 edges.csv                    # Graph edges (if CSV export)\n\u251c\u2500\u2500 graph.cypher                 # Cypher script (if Cypher export)\n\u251c\u2500\u2500 graph.json                   # Graph JSON\n\u251c\u2500\u2500 graph_visualization.html     # Interactive visualization\n\u251c\u2500\u2500 extraction_report.md         # Extraction report\n\u251c\u2500\u2500 docling_document.json        # Docling output (if enabled)\n\u2514\u2500\u2500 markdown/                    # Markdown exports (if enabled)\n    \u251c\u2500\u2500 full_document.md\n    \u2514\u2500\u2500 pages/\n        \u251c\u2500\u2500 page_1.md\n        \u251c\u2500\u2500 page_2.md\n        \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"reference/pipeline/#performance-considerations","title":"Performance Considerations","text":""},{"location":"reference/pipeline/#memory-usage","title":"Memory Usage","text":"<pre><code># For large documents, use chunking\nrun_pipeline({\n    \"source\": \"large_document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n    \"use_chunking\": True,  # Reduces memory usage\n    \"processing_mode\": \"one-to-one\"  # Process page by page\n})\n</code></pre>"},{"location":"reference/pipeline/#speed-optimization","title":"Speed Optimization","text":"<pre><code># For faster processing\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n    \"backend\": \"llm\",\n    \"inference\": \"local\",  # Faster than remote\n    \"use_chunking\": False,  # Skip chunking for small docs\n    \"llm_consolidation\": False  # Skip LLM merge\n})\n</code></pre>"},{"location":"reference/pipeline/#debugging","title":"Debugging","text":""},{"location":"reference/pipeline/#enable-logging","title":"Enable Logging","text":"<pre><code>import logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# Run pipeline\nfrom docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\"\n})\n</code></pre>"},{"location":"reference/pipeline/#inspect-outputs","title":"Inspect Outputs","text":"<pre><code>from pathlib import Path\nimport json\n\n# Run pipeline\nfrom docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n    \"output_dir\": \"outputs\"\n})\n\n# Inspect graph\ngraph_path = Path(\"outputs/graph.json\")\nwith open(graph_path) as f:\n    graph_data = json.load(f)\n    print(f\"Nodes: {len(graph_data['nodes'])}\")\n    print(f\"Edges: {len(graph_data['links'])}\")\n</code></pre>"},{"location":"reference/pipeline/#related-apis","title":"Related APIs","text":"<ul> <li>Configuration API - PipelineConfig class</li> <li>Exceptions - Exception hierarchy</li> <li>Extractors - Extraction strategies</li> </ul>"},{"location":"reference/pipeline/#see-also","title":"See Also","text":"<ul> <li>Python API Guide - Usage guide</li> <li>CLI Reference - CLI equivalent</li> <li>Examples - Example usage</li> </ul>"},{"location":"reference/protocols/","title":"Protocols","text":""},{"location":"reference/protocols/#overview","title":"Overview","text":"<p>Protocol definitions for type-safe interfaces in docling-graph.</p> <p>Module: <code>docling_graph.protocols</code></p> <p>Protocols define expected interfaces without requiring inheritance, enabling duck typing with type safety.</p>"},{"location":"reference/protocols/#backend-protocols","title":"Backend Protocols","text":""},{"location":"reference/protocols/#extractionbackendprotocol","title":"ExtractionBackendProtocol","text":"<p>Protocol for VLM backends that process documents directly.</p> <pre><code>@runtime_checkable\nclass ExtractionBackendProtocol(Protocol):\n    \"\"\"Protocol for extraction backends that process entire documents.\"\"\"\n\n    def extract_from_document(\n        self, \n        source: str, \n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"Extract structured data from a document.\"\"\"\n        ...\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up backend resources.\"\"\"\n        ...\n</code></pre> <p>Methods:</p>"},{"location":"reference/protocols/#extract_from_document","title":"extract_from_document()","text":"<pre><code>def extract_from_document(\n    source: str,\n    template: Type[BaseModel]\n) -&gt; List[BaseModel]\n</code></pre> <p>Extract structured data from a document.</p> <p>Parameters: - <code>source</code> (<code>str</code>): Path to source document - <code>template</code> (<code>Type[BaseModel]</code>): Pydantic model template</p> <p>Returns: List of extracted Pydantic model instances</p> <p>Example:</p> <pre><code>class MyVLMBackend(ExtractionBackendProtocol):\n    def extract_from_document(self, source, template):\n        # Process document directly\n        result = self.model.process(source)\n        return [template.model_validate(result)]\n\n    def cleanup(self):\n        del self.model\n</code></pre>"},{"location":"reference/protocols/#textextractionbackendprotocol","title":"TextExtractionBackendProtocol","text":"<p>Protocol for LLM backends that process markdown/text.</p> <pre><code>@runtime_checkable\nclass TextExtractionBackendProtocol(Protocol):\n    \"\"\"Protocol for extraction backends that process markdown/text.\"\"\"\n\n    client: Any  # LLM client instance\n\n    def extract_from_markdown(\n        self,\n        markdown: str,\n        template: Type[BaseModel],\n        context: str = \"document\",\n        is_partial: bool = False\n    ) -&gt; BaseModel | None:\n        \"\"\"Extract structured data from markdown.\"\"\"\n        ...\n\n    def consolidate_from_pydantic_models(\n        self,\n        raw_models: List[BaseModel],\n        programmatic_model: BaseModel,\n        template: Type[BaseModel]\n    ) -&gt; BaseModel | None:\n        \"\"\"Consolidate multiple models using LLM.\"\"\"\n        ...\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up backend resources.\"\"\"\n        ...\n</code></pre> <p>Attributes: - <code>client</code> (<code>Any</code>): LLM client instance</p> <p>Methods:</p>"},{"location":"reference/protocols/#extract_from_markdown","title":"extract_from_markdown()","text":"<pre><code>def extract_from_markdown(\n    markdown: str,\n    template: Type[BaseModel],\n    context: str = \"document\",\n    is_partial: bool = False\n) -&gt; BaseModel | None\n</code></pre> <p>Extract structured data from markdown content.</p> <p>Parameters: - <code>markdown</code> (<code>str</code>): Markdown content - <code>template</code> (<code>Type[BaseModel]</code>): Pydantic model template - <code>context</code> (<code>str</code>): Context description (e.g., \"page 1\") - <code>is_partial</code> (<code>bool</code>): Whether this is partial extraction</p> <p>Returns: Extracted model instance or None</p>"},{"location":"reference/protocols/#consolidate_from_pydantic_models","title":"consolidate_from_pydantic_models()","text":"<pre><code>def consolidate_from_pydantic_models(\n    raw_models: List[BaseModel],\n    programmatic_model: BaseModel,\n    template: Type[BaseModel]\n) -&gt; BaseModel | None\n</code></pre> <p>Consolidate multiple models using LLM.</p> <p>Parameters: - <code>raw_models</code> (<code>List[BaseModel]</code>): List of extracted models - <code>programmatic_model</code> (<code>BaseModel</code>): Programmatically merged model - <code>template</code> (<code>Type[BaseModel]</code>): Target template</p> <p>Returns: Consolidated model instance or None</p> <p>Example:</p> <pre><code>class MyLLMBackend(TextExtractionBackendProtocol):\n    def __init__(self, client):\n        self.client = client\n\n    def extract_from_markdown(self, markdown, template, context=\"\", is_partial=False):\n        prompt = f\"Extract from: {markdown}\"\n        response = self.client.get_json_response(prompt, template.model_json_schema())\n        return template.model_validate(response)\n\n    def consolidate_from_pydantic_models(self, raw_models, programmatic_model, template):\n        # Use LLM to merge models\n        return programmatic_model\n\n    def cleanup(self):\n        self.client.close()\n</code></pre>"},{"location":"reference/protocols/#llm-client-protocol","title":"LLM Client Protocol","text":""},{"location":"reference/protocols/#llmclientprotocol","title":"LLMClientProtocol","text":"<p>Protocol for LLM clients (Ollama, Mistral, OpenAI, etc.).</p> <pre><code>@runtime_checkable\nclass LLMClientProtocol(Protocol):\n    \"\"\"Protocol for LLM clients.\"\"\"\n\n    @property\n    def context_limit(self) -&gt; int:\n        \"\"\"Return effective context limit in tokens.\"\"\"\n        ...\n\n    def get_json_response(\n        self,\n        prompt: str | Mapping[str, str],\n        schema_json: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Execute LLM call and return parsed JSON.\"\"\"\n        ...\n</code></pre> <p>Properties:</p>"},{"location":"reference/protocols/#context_limit","title":"context_limit","text":"<pre><code>@property\ndef context_limit(self) -&gt; int\n</code></pre> <p>Return the effective context limit in tokens.</p> <p>Returns: Conservative token limit</p> <p>Methods:</p>"},{"location":"reference/protocols/#get_json_response","title":"get_json_response()","text":"<pre><code>def get_json_response(\n    prompt: str | Mapping[str, str],\n    schema_json: str\n) -&gt; Dict[str, Any]\n</code></pre> <p>Execute LLM call and return parsed JSON.</p> <p>Parameters: - <code>prompt</code> (<code>str</code> or <code>Mapping[str, str]</code>): Prompt (legacy string or dict with 'system' and 'user') - <code>schema_json</code> (<code>str</code>): Pydantic schema as JSON string</p> <p>Returns: Parsed JSON dictionary</p> <p>Example:</p> <pre><code>class MyLLMClient(LLMClientProtocol):\n    @property\n    def context_limit(self) -&gt; int:\n        return 8000  # Conservative limit\n\n    def get_json_response(self, prompt, schema_json):\n        # Handle both formats\n        if isinstance(prompt, dict):\n            system = prompt.get(\"system\", \"\")\n            user = prompt.get(\"user\", \"\")\n        else:\n            system = \"\"\n            user = prompt\n\n        # Call LLM API\n        response = self.api.chat(system=system, user=user)\n        return json.loads(response)\n</code></pre>"},{"location":"reference/protocols/#extractor-protocol","title":"Extractor Protocol","text":""},{"location":"reference/protocols/#extractorprotocol","title":"ExtractorProtocol","text":"<p>Protocol for extraction strategies.</p> <pre><code>@runtime_checkable\nclass ExtractorProtocol(Protocol):\n    \"\"\"Protocol for extraction strategies.\"\"\"\n\n    backend: Any  # Backend instance\n\n    def extract(\n        self,\n        source: str,\n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"Extract structured data from source document.\"\"\"\n        ...\n</code></pre> <p>Attributes: - <code>backend</code> (<code>Any</code>): Backend instance (VLM or LLM)</p> <p>Methods:</p>"},{"location":"reference/protocols/#extract","title":"extract()","text":"<pre><code>def extract(\n    source: str,\n    template: Type[BaseModel]\n) -&gt; List[BaseModel]\n</code></pre> <p>Extract structured data from source document.</p> <p>Parameters: - <code>source</code> (<code>str</code>): Path to source document - <code>template</code> (<code>Type[BaseModel]</code>): Pydantic model template</p> <p>Returns: List of extracted Pydantic model instances - OneToOne: May contain N models (one per page) - ManyToOne: Contains 1 merged model</p> <p>Example:</p> <pre><code>class MyExtractor(ExtractorProtocol):\n    def __init__(self, backend):\n        self.backend = backend\n\n    def extract(self, source, template):\n        # Use backend to extract\n        return self.backend.extract_from_document(source, template)\n</code></pre>"},{"location":"reference/protocols/#document-processor-protocol","title":"Document Processor Protocol","text":""},{"location":"reference/protocols/#documentprocessorprotocol","title":"DocumentProcessorProtocol","text":"<p>Protocol for document processing and conversion.</p> <pre><code>@runtime_checkable\nclass DocumentProcessorProtocol(Protocol):\n    \"\"\"Protocol for document processing and conversion.\"\"\"\n\n    def convert_to_docling_doc(self, source: str) -&gt; Any:\n        \"\"\"Convert document to Docling document object.\"\"\"\n        ...\n\n    def extract_full_markdown(self, document: Any) -&gt; str:\n        \"\"\"Extract complete markdown from document.\"\"\"\n        ...\n\n    def extract_page_markdowns(self, document: Any) -&gt; List[str]:\n        \"\"\"Extract markdown for each page separately.\"\"\"\n        ...\n</code></pre> <p>Methods:</p>"},{"location":"reference/protocols/#convert_to_docling_doc","title":"convert_to_docling_doc()","text":"<pre><code>def convert_to_docling_doc(source: str) -&gt; Any\n</code></pre> <p>Convert document to Docling document object.</p> <p>Parameters: - <code>source</code> (<code>str</code>): Path to source document</p> <p>Returns: Docling document object</p>"},{"location":"reference/protocols/#extract_full_markdown","title":"extract_full_markdown()","text":"<pre><code>def extract_full_markdown(document: Any) -&gt; str\n</code></pre> <p>Extract complete markdown from document.</p> <p>Parameters: - <code>document</code> (<code>Any</code>): Docling document object</p> <p>Returns: Full markdown content as string</p>"},{"location":"reference/protocols/#extract_page_markdowns","title":"extract_page_markdowns()","text":"<pre><code>def extract_page_markdowns(document: Any) -&gt; List[str]\n</code></pre> <p>Extract markdown for each page separately.</p> <p>Parameters: - <code>document</code> (<code>Any</code>): Docling document object</p> <p>Returns: List of markdown strings, one per page</p>"},{"location":"reference/protocols/#type-checking-utilities","title":"Type Checking Utilities","text":""},{"location":"reference/protocols/#is_vlm_backend","title":"is_vlm_backend()","text":"<pre><code>def is_vlm_backend(backend: Any) -&gt; TypeGuard[ExtractionBackendProtocol]\n</code></pre> <p>Check if backend behaves like a VLM backend.</p> <p>Parameters: - <code>backend</code> (<code>Any</code>): Backend instance to check</p> <p>Returns: True if backend provides document-level extraction</p> <p>Example:</p> <pre><code>from docling_graph.protocols import is_vlm_backend\n\nif is_vlm_backend(my_backend):\n    # Use VLM-specific features\n    result = my_backend.extract_from_document(source, template)\n</code></pre>"},{"location":"reference/protocols/#is_llm_backend","title":"is_llm_backend()","text":"<pre><code>def is_llm_backend(backend: Any) -&gt; TypeGuard[TextExtractionBackendProtocol]\n</code></pre> <p>Check if backend behaves like an LLM backend.</p> <p>Parameters: - <code>backend</code> (<code>Any</code>): Backend instance to check</p> <p>Returns: True if backend provides markdown/text extraction</p> <p>Example:</p> <pre><code>from docling_graph.protocols import is_llm_backend\n\nif is_llm_backend(my_backend):\n    # Use LLM-specific features\n    result = my_backend.extract_from_markdown(markdown, template)\n</code></pre>"},{"location":"reference/protocols/#get_backend_type","title":"get_backend_type()","text":"<pre><code>def get_backend_type(backend: Any) -&gt; str\n</code></pre> <p>Get the backend type as a string.</p> <p>Parameters: - <code>backend</code> (<code>Any</code>): Backend instance</p> <p>Returns: \"vlm\", \"llm\", or \"unknown\"</p> <p>Example:</p> <pre><code>from docling_graph.protocols import get_backend_type\n\nbackend_type = get_backend_type(my_backend)\nprint(f\"Backend type: {backend_type}\")\n</code></pre>"},{"location":"reference/protocols/#type-aliases","title":"Type Aliases","text":"<p>Convenient type aliases for clarity:</p> <pre><code># Backend can be either VLM or LLM\nBackend = ExtractionBackendProtocol | TextExtractionBackendProtocol\n\n# Extractor strategies\nExtractor = ExtractorProtocol\n\n# LLM client\nLLMClient = LLMClientProtocol\n\n# Document processor\nDocumentProcessor = DocumentProcessorProtocol\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph.protocols import Backend, LLMClient\n\ndef process_with_backend(backend: Backend):\n    \"\"\"Process with any backend type.\"\"\"\n    pass\n\ndef create_client() -&gt; LLMClient:\n    \"\"\"Create an LLM client.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/protocols/#implementation-examples","title":"Implementation Examples","text":""},{"location":"reference/protocols/#custom-vlm-backend","title":"Custom VLM Backend","text":"<pre><code>from docling_graph.protocols import ExtractionBackendProtocol\nfrom typing import List, Type\nfrom pydantic import BaseModel\n\nclass CustomVLMBackend(ExtractionBackendProtocol):\n    \"\"\"Custom VLM backend implementation.\"\"\"\n\n    def __init__(self, model_name: str):\n        self.model = load_model(model_name)\n\n    def extract_from_document(\n        self,\n        source: str,\n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"Extract from document.\"\"\"\n        result = self.model.process(source)\n        return [template.model_validate(result)]\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        del self.model\n</code></pre>"},{"location":"reference/protocols/#custom-llm-backend","title":"Custom LLM Backend","text":"<pre><code>from docling_graph.protocols import TextExtractionBackendProtocol\nfrom typing import List, Type\nfrom pydantic import BaseModel\n\nclass CustomLLMBackend(TextExtractionBackendProtocol):\n    \"\"\"Custom LLM backend implementation.\"\"\"\n\n    def __init__(self, client):\n        self.client = client\n\n    def extract_from_markdown(\n        self,\n        markdown: str,\n        template: Type[BaseModel],\n        context: str = \"document\",\n        is_partial: bool = False\n    ) -&gt; BaseModel | None:\n        \"\"\"Extract from markdown.\"\"\"\n        schema = template.model_json_schema()\n        response = self.client.get_json_response(markdown, str(schema))\n        return template.model_validate(response)\n\n    def consolidate_from_pydantic_models(\n        self,\n        raw_models: List[BaseModel],\n        programmatic_model: BaseModel,\n        template: Type[BaseModel]\n    ) -&gt; BaseModel | None:\n        \"\"\"Consolidate models.\"\"\"\n        return programmatic_model\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        self.client.close()\n</code></pre>"},{"location":"reference/protocols/#runtime-checking","title":"Runtime Checking","text":"<p>All protocols are decorated with <code>@runtime_checkable</code>:</p> <pre><code>from docling_graph.protocols import ExtractionBackendProtocol\n\n# Check at runtime\nif isinstance(my_backend, ExtractionBackendProtocol):\n    print(\"Backend implements VLM protocol\")\n</code></pre>"},{"location":"reference/protocols/#related-apis","title":"Related APIs","text":"<ul> <li>Custom Backends - Implementation guide</li> <li>Extractors - Extractor implementations</li> <li>LLM Clients - Client implementations</li> </ul>"},{"location":"reference/protocols/#see-also","title":"See Also","text":"<ul> <li>Python Protocols - PEP 544</li> <li>Type Hints - Python typing</li> </ul>"},{"location":"usage/","title":"Usage","text":"<p>Welcome to the Usage section! This section covers practical guides for using Docling Graph through different interfaces and advanced techniques.</p>"},{"location":"usage/#what-youll-learn","title":"What You'll Learn","text":"<p>This section provides comprehensive guides for working with Docling Graph:</p> <ol> <li>CLI Reference - Command-line interface for quick document processing</li> <li>Python API - Programmatic usage and integration into your applications</li> <li>Examples - Working code examples and real-world templates</li> <li>Advanced Topics - Performance tuning, custom backends, and error handling</li> </ol>"},{"location":"usage/#quick-links","title":"Quick Links","text":"<ul> <li> <p>CLI Reference \u2192</p> <p>Use the command-line interface for document processing</p> </li> <li> <p>Python API \u2192</p> <p>Integrate Docling Graph into your Python applications</p> </li> <li> <p>Examples \u2192</p> <p>Explore working examples and template gallery</p> </li> <li> <p>Advanced Topics \u2192</p> <p>Optimize performance and implement custom solutions</p> </li> </ul>"},{"location":"usage/#choose-your-interface","title":"Choose Your Interface","text":""},{"location":"usage/#command-line-interface-cli","title":"Command-Line Interface (CLI)","text":"<p>Perfect for quick processing and scripting:</p> <pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"outputs/invoice\"\n</code></pre> <p>\u2192 Learn More About CLI</p>"},{"location":"usage/#python-api","title":"Python API","text":"<p>Ideal for programmatic integration:</p> <pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\nconfig.run()\n</code></pre> <p>\u2192 Learn More About Python API</p>"},{"location":"usage/#learning-path","title":"Learning Path","text":"<p>We recommend this approach:</p> <ol> <li>Start with Examples to see working code</li> <li>Choose Your Interface (CLI or Python API)</li> <li>Explore Advanced Topics for optimization</li> </ol>"},{"location":"usage/#next-steps","title":"Next Steps","text":"<ul> <li>New to Docling Graph? Start with Examples</li> <li>Prefer CLI? Check out CLI Reference</li> <li>Building an application? See Python API</li> <li>Need optimization? Explore Advanced Topics</li> </ul>"},{"location":"usage/advanced/","title":"Advanced Topics","text":""},{"location":"usage/advanced/#overview","title":"Overview","text":"<p>This section covers advanced topics for extending and optimizing docling-graph. These guides are for users who need to:</p> <ul> <li>Create custom extraction backends</li> <li>Build custom exporters</li> <li>Add pipeline stages</li> <li>Optimize performance</li> <li>Handle errors gracefully</li> <li>Test templates and pipelines</li> </ul>"},{"location":"usage/advanced/#topics","title":"Topics","text":""},{"location":"usage/advanced/#extensibility","title":"\ud83e\udde9 Extensibility","text":"<p>Custom Backends Create custom extraction backends for specialized models or APIs.</p> <ul> <li>Implement backend protocols</li> <li>VLM backend example</li> <li>LLM backend example</li> <li>Integration with pipeline</li> </ul> <p>Custom Exporters Build custom exporters for specialized output formats.</p> <ul> <li>Implement exporter protocol</li> <li>Graph data access</li> <li>Custom format generation</li> <li>Registration and usage</li> </ul> <p>Custom Stages Add custom stages to the pipeline for specialized processing.</p> <ul> <li>Pipeline stage protocol</li> <li>Stage implementation</li> <li>Context management</li> <li>Error handling</li> </ul>"},{"location":"usage/advanced/#optimization","title":"\ud83d\udcd0 Optimization","text":"<p>Performance Tuning Optimize extraction speed and resource usage.</p> <ul> <li>Model selection strategies</li> <li>Batch size optimization</li> <li>Memory management</li> <li>GPU utilization</li> <li>Caching strategies</li> </ul>"},{"location":"usage/advanced/#reliability","title":"\ud83d\udee1\ufe0f Reliability","text":"<p>Error Handling Handle errors gracefully and implement retry logic.</p> <ul> <li>Exception hierarchy</li> <li>Error recovery strategies</li> <li>Logging and debugging</li> <li>Retry mechanisms</li> </ul> <p>Testing Test templates, backends, and pipelines.</p> <ul> <li>Template validation</li> <li>Mock backends</li> <li>Integration testing</li> <li>CI/CD integration</li> </ul>"},{"location":"usage/advanced/#prerequisites","title":"Prerequisites","text":"<p>Before diving into advanced topics, ensure you understand:</p> <ol> <li>Schema Definition - Pydantic templates</li> <li>Pipeline Configuration - Configuration options</li> <li>Extraction Process - How extraction works</li> <li>Python API - Programmatic usage</li> </ol>"},{"location":"usage/advanced/#when-to-use-advanced-features","title":"When to Use Advanced Features","text":""},{"location":"usage/advanced/#custom-backends","title":"Custom Backends","text":"<p>Use when: \u2705 You have a specialized model not supported by default \u2705 You need to integrate with a proprietary API \u2705 You want to implement custom preprocessing \u2705 You need fine-grained control over extraction</p> <p>Don't use when: \u274c Default backends meet your needs \u274c You're just starting with docling-graph \u274c You don't need custom logic</p>"},{"location":"usage/advanced/#custom-exporters","title":"Custom Exporters","text":"<p>Use when: \u2705 You need a specialized output format \u2705 You're integrating with a specific database \u2705 You need custom data transformations \u2705 Default formats don't meet requirements</p> <p>Don't use when: \u274c CSV, Cypher, or JSON formats work \u274c You can post-process existing exports \u274c You're prototyping</p>"},{"location":"usage/advanced/#custom-stages","title":"Custom Stages","text":"<p>Use when: \u2705 You need custom preprocessing \u2705 You want to add validation steps \u2705 You need custom post-processing \u2705 You're building a specialized pipeline</p> <p>Don't use when: \u274c Default pipeline stages suffice \u274c You can achieve goals with configuration \u274c You're learning the system</p>"},{"location":"usage/advanced/#architecture","title":"Architecture","text":""},{"location":"usage/advanced/#extension-points","title":"Extension Points","text":"<p>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%% flowchart TB     %% 1. Define Classes     classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1     classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037     classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20     classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100     classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0     classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A     classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238</p> <pre><code>%% 2. Define Nodes\nA@{ shape: terminal, label: \"Input Source\" }\n\nB@{ shape: lin-proc, label: \"Custom Stage 1\" }\nC@{ shape: procs, label: \"Docling Conversion\" }\nD@{ shape: tag-proc, label: \"Custom Backend\" }\nE@{ shape: procs, label: \"Extraction\" }\nF@{ shape: lin-proc, label: \"Custom Stage 2\" }\nG@{ shape: procs, label: \"Graph Conversion\" }\nH@{ shape: tag-proc, label: \"Custom Exporter\" }\n\nI@{ shape: doc, label: \"Output\" }\n\n%% 3. Define Connections\nA --&gt; B\nB --&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; F\nF --&gt; G\nG --&gt; H\nH --&gt; I\n\n%% 4. Apply Classes\nclass A input\nclass B,F config\nclass C,E,G process\nclass D,H operator\nclass I output\n</code></pre> <p>```  Extension Points: - Custom Backends (blue): Replace extraction logic - Custom Exporters (blue): Replace export logic - Custom Stages (yellow): Add processing steps</p>"},{"location":"usage/advanced/#code-organization","title":"Code Organization","text":""},{"location":"usage/advanced/#project-structure-for-extensions","title":"Project Structure for Extensions","text":"<p><code>my_project/ \u251c\u2500\u2500 templates/              # Pydantic templates \u2502   \u2514\u2500\u2500 my_template.py \u251c\u2500\u2500 backends/               # Custom backends \u2502   \u251c\u2500\u2500 __init__.py \u2502   \u2514\u2500\u2500 my_backend.py \u251c\u2500\u2500 exporters/              # Custom exporters \u2502   \u251c\u2500\u2500 __init__.py \u2502   \u2514\u2500\u2500 my_exporter.py \u251c\u2500\u2500 stages/                 # Custom stages \u2502   \u251c\u2500\u2500 __init__.py \u2502   \u2514\u2500\u2500 my_stage.py \u251c\u2500\u2500 tests/                  # Tests \u2502   \u251c\u2500\u2500 test_backend.py \u2502   \u251c\u2500\u2500 test_exporter.py \u2502   \u2514\u2500\u2500 test_stage.py \u2514\u2500\u2500 main.py                 # Entry point</code></p>"},{"location":"usage/advanced/#development-workflow","title":"Development Workflow","text":""},{"location":"usage/advanced/#1-design","title":"1. Design","text":"<p>```python</p>"},{"location":"usage/advanced/#define-interface","title":"Define interface","text":"<p>from docling_graph.protocols import TextExtractionBackendProtocol  class MyBackend(TextExtractionBackendProtocol):     \"\"\"Custom backend implementation.\"\"\"     pass ```</p>"},{"location":"usage/advanced/#2-implement","title":"2. Implement","text":"<pre><code># Implement methods\ndef extract_from_markdown(self, markdown: str, template, context=\"\", is_partial=False):\n    \"\"\"Extract structured data.\"\"\"\n    # Your logic here\n    pass\n</code></pre>"},{"location":"usage/advanced/#3-test","title":"3. Test","text":"<pre><code># Write tests\ndef test_my_backend():\n    backend = MyBackend()\n    result = backend.extract_from_markdown(\"test\", MyTemplate)\n    assert result is not None\n</code></pre>"},{"location":"usage/advanced/#4-integrate","title":"4. Integrate","text":"<pre><code># Use in pipeline\nfrom docling_graph import PipelineConfig\nfrom my_backends import MyBackend\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    # Custom backend integration\n)\n</code></pre>"},{"location":"usage/advanced/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/#1-follow-protocols","title":"1. Follow Protocols","text":"<pre><code># \u2705 Good - Implement protocol\nfrom docling_graph.protocols import TextExtractionBackendProtocol\n\nclass MyBackend(TextExtractionBackendProtocol):\n    def extract_from_markdown(self, ...): ...\n    def consolidate_from_pydantic_models(self, ...): ...\n    def cleanup(self): ...\n\n# \u274c Avoid - Custom interface\nclass MyBackend:\n    def my_custom_method(self, ...): ...\n</code></pre>"},{"location":"usage/advanced/#2-handle-errors","title":"2. Handle Errors","text":"<pre><code># \u2705 Good - Use docling-graph exceptions\nfrom docling_graph.exceptions import ExtractionError\n\ndef extract(self, ...):\n    try:\n        result = self._process()\n        return result\n    except Exception as e:\n        raise ExtractionError(\n            \"Extraction failed\",\n            details={\"source\": source},\n            cause=e\n        )\n\n# \u274c Avoid - Generic exceptions\ndef extract(self, ...):\n    raise Exception(\"Something went wrong\")\n</code></pre>"},{"location":"usage/advanced/#3-write-tests","title":"3. Write Tests","text":"<pre><code># \u2705 Good - Comprehensive tests\ndef test_backend_success():\n    \"\"\"Test successful extraction.\"\"\"\n    pass\n\ndef test_backend_failure():\n    \"\"\"Test error handling.\"\"\"\n    pass\n\ndef test_backend_cleanup():\n    \"\"\"Test resource cleanup.\"\"\"\n    pass\n\n# \u274c Avoid - No tests\n# (No tests written)\n</code></pre>"},{"location":"usage/advanced/#4-document-code","title":"4. Document Code","text":"<pre><code># \u2705 Good - Clear documentation\nclass MyBackend:\n    \"\"\"\n    Custom backend for specialized extraction.\n\n    This backend uses a proprietary model to extract\n    structured data from documents.\n\n    Args:\n        api_key: API key for the service\n        model: Model name to use\n\n    Example:\n        &gt;&gt;&gt; backend = MyBackend(api_key=\"key\", model=\"model-v1\")\n        &gt;&gt;&gt; result = backend.extract_from_markdown(text, Template)\n    \"\"\"\n    pass\n\n# \u274c Avoid - No documentation\nclass MyBackend:\n    pass\n</code></pre>"},{"location":"usage/advanced/#performance-considerations","title":"Performance Considerations","text":""},{"location":"usage/advanced/#memory-management","title":"Memory Management","text":"<pre><code># \u2705 Good - Clean up resources\nclass MyBackend:\n    def cleanup(self):\n        \"\"\"Release resources.\"\"\"\n        if hasattr(self, 'model'):\n            del self.model\n        if hasattr(self, 'client'):\n            self.client.close()\n\n# \u274c Avoid - Memory leaks\nclass MyBackend:\n    def cleanup(self):\n        pass  # Resources not released\n</code></pre>"},{"location":"usage/advanced/#batch-processing","title":"Batch Processing","text":"<pre><code># \u2705 Good - Process in batches\ndef process_documents(docs):\n    batch_size = 10\n    for i in range(0, len(docs), batch_size):\n        batch = docs[i:i+batch_size]\n        process_batch(batch)\n\n# \u274c Avoid - Process all at once\ndef process_documents(docs):\n    process_all(docs)  # May run out of memory\n</code></pre>"},{"location":"usage/advanced/#security-considerations","title":"Security Considerations","text":""},{"location":"usage/advanced/#api-keys","title":"API Keys","text":"<pre><code># \u2705 Good - Use environment variables\nimport os\n\napi_key = os.getenv(\"MY_API_KEY\")\nif not api_key:\n    raise ValueError(\"MY_API_KEY not set\")\n\n# \u274c Avoid - Hardcoded keys\napi_key = \"sk-1234567890\"  # Never do this!\n</code></pre>"},{"location":"usage/advanced/#input-validation","title":"Input Validation","text":"<pre><code># \u2705 Good - Validate inputs\ndef extract(self, markdown: str, template):\n    if not markdown:\n        raise ValueError(\"Markdown cannot be empty\")\n    if not template:\n        raise ValueError(\"Template is required\")\n    # Process...\n\n# \u274c Avoid - No validation\ndef extract(self, markdown, template):\n    # Process without checks\n    pass\n</code></pre>"},{"location":"usage/advanced/#next-steps","title":"Next Steps","text":"<p>Choose a topic based on your needs:</p> <ol> <li>Custom Backends \u2192 - Extend extraction capabilities</li> <li>Custom Exporters \u2192 - Create custom output formats</li> <li>Custom Stages \u2192 - Add pipeline stages</li> <li>Performance Tuning \u2192 - Optimize performance</li> <li>Error Handling \u2192 - Handle errors gracefully</li> <li>Testing \u2192 - Test your extensions</li> </ol>"},{"location":"usage/advanced/#related-documentation","title":"Related Documentation","text":"<ul> <li>Protocols - Protocol definitions</li> <li>Exceptions - Exception hierarchy</li> <li>Pipeline Architecture - System design</li> </ul>"},{"location":"usage/advanced/custom-backends/","title":"Custom Backends","text":""},{"location":"usage/advanced/custom-backends/#overview","title":"Overview","text":"<p>Create custom extraction backends to integrate specialized models, APIs, or processing logic into the docling-graph pipeline.</p> <p>What You'll Learn: - Backend protocol implementation - VLM backend example - LLM backend example - Integration with pipeline - Testing strategies</p> <p>Prerequisites: - Understanding of Extraction Process - Familiarity with Python API - Knowledge of Pydantic models</p>"},{"location":"usage/advanced/custom-backends/#backend-types","title":"Backend Types","text":""},{"location":"usage/advanced/custom-backends/#vlm-backend-vision-language-model","title":"VLM Backend (Vision-Language Model)","text":"<p>Processes documents directly without markdown conversion.</p> <p>Protocol: <code>ExtractionBackendProtocol</code></p> <pre><code>from docling_graph.protocols import ExtractionBackendProtocol\n\nclass MyVLMBackend(ExtractionBackendProtocol):\n    def extract_from_document(self, source: str, template: Type[BaseModel]) -&gt; List[BaseModel]:\n        \"\"\"Extract from document directly.\"\"\"\n        pass\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        pass\n</code></pre>"},{"location":"usage/advanced/custom-backends/#llm-backend-language-model","title":"LLM Backend (Language Model)","text":"<p>Processes markdown/text content.</p> <p>Protocol: <code>TextExtractionBackendProtocol</code></p> <pre><code>from docling_graph.protocols import TextExtractionBackendProtocol\n\nclass MyLLMBackend(TextExtractionBackendProtocol):\n    client: Any  # LLM client instance\n\n    def extract_from_markdown(\n        self, \n        markdown: str, \n        template: Type[BaseModel],\n        context: str = \"document\",\n        is_partial: bool = False\n    ) -&gt; BaseModel | None:\n        \"\"\"Extract from markdown.\"\"\"\n        pass\n\n    def consolidate_from_pydantic_models(\n        self,\n        raw_models: List[BaseModel],\n        programmatic_model: BaseModel,\n        template: Type[BaseModel]\n    ) -&gt; BaseModel | None:\n        \"\"\"Consolidate multiple models.\"\"\"\n        pass\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        pass\n</code></pre>"},{"location":"usage/advanced/custom-backends/#complete-vlm-backend-example","title":"Complete VLM Backend Example","text":""},{"location":"usage/advanced/custom-backends/#implementation","title":"Implementation","text":"<pre><code>\"\"\"\nCustom VLM backend using a hypothetical vision model.\n\"\"\"\n\nfrom typing import Any, List, Type\nfrom pathlib import Path\nfrom pydantic import BaseModel\nfrom docling_graph.protocols import ExtractionBackendProtocol\nfrom docling_graph.exceptions import ExtractionError, ClientError\n\nclass CustomVLMBackend(ExtractionBackendProtocol):\n    \"\"\"\n    Custom VLM backend for specialized vision model.\n\n    Args:\n        model_name: Name of the vision model\n        api_key: API key for the service\n        base_url: Base URL for API (optional)\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name: str = \"vision-model-v1\",\n        api_key: str | None = None,\n        base_url: str | None = None\n    ):\n        self.model_name = model_name\n        self.api_key = api_key or self._get_api_key()\n        self.base_url = base_url or \"https://api.example.com/v1\"\n\n        # Initialize client\n        self.client = self._initialize_client()\n\n    def _get_api_key(self) -&gt; str:\n        \"\"\"Get API key from environment.\"\"\"\n        import os\n        api_key = os.getenv(\"CUSTOM_VLM_API_KEY\")\n        if not api_key:\n            raise ClientError(\n                \"API key not found\",\n                details={\"env_var\": \"CUSTOM_VLM_API_KEY\"}\n            )\n        return api_key\n\n    def _initialize_client(self) -&gt; Any:\n        \"\"\"Initialize the vision model client.\"\"\"\n        try:\n            # Your client initialization here\n            from my_vision_sdk import VisionClient\n            return VisionClient(\n                api_key=self.api_key,\n                base_url=self.base_url,\n                model=self.model_name\n            )\n        except Exception as e:\n            raise ClientError(\n                \"Failed to initialize client\",\n                details={\"model\": self.model_name},\n                cause=e\n            )\n\n    def extract_from_document(\n        self, \n        source: str, \n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"\n        Extract structured data from document.\n\n        Args:\n            source: Path to document (image or PDF)\n            template: Pydantic model template\n\n        Returns:\n            List of extracted model instances\n\n        Raises:\n            ExtractionError: If extraction fails\n        \"\"\"\n        try:\n            # Validate source\n            source_path = Path(source)\n            if not source_path.exists():\n                raise ExtractionError(\n                    \"Source file not found\",\n                    details={\"source\": source}\n                )\n\n            # Get schema\n            schema = template.model_json_schema()\n\n            # Call vision model\n            response = self.client.extract(\n                image_path=str(source_path),\n                schema=schema\n            )\n\n            # Parse response\n            extracted_data = response.get(\"data\", {})\n\n            # Validate with Pydantic\n            model_instance = template.model_validate(extracted_data)\n\n            return [model_instance]\n\n        except Exception as e:\n            raise ExtractionError(\n                \"Document extraction failed\",\n                details={\n                    \"source\": source,\n                    \"template\": template.__name__\n                },\n                cause=e\n            )\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        if hasattr(self, 'client') and self.client:\n            try:\n                self.client.close()\n            except Exception:\n                pass  # Best effort cleanup\n</code></pre>"},{"location":"usage/advanced/custom-backends/#usage","title":"Usage","text":"<pre><code>\"\"\"Use custom VLM backend.\"\"\"\n\nfrom docling_graph import PipelineConfig\nfrom my_backends import CustomVLMBackend\n\n# Create backend instance\nbackend = CustomVLMBackend(\n    model_name=\"vision-model-v1\",\n    api_key=\"your_api_key\"\n)\n\n# Note: Direct backend integration requires custom pipeline code\n# For now, use with extraction strategies directly\nfrom docling_graph.core.extractors.strategies import OneToOne\n\nextractor = OneToOne(backend=backend)\nresults = extractor.extract(\n    source=\"document.pdf\",\n    template=MyTemplate\n)\n</code></pre>"},{"location":"usage/advanced/custom-backends/#complete-llm-backend-example","title":"Complete LLM Backend Example","text":""},{"location":"usage/advanced/custom-backends/#implementation_1","title":"Implementation","text":"<pre><code>\"\"\"\nCustom LLM backend using a hypothetical language model.\n\"\"\"\n\nfrom typing import Any, Dict, List, Type\nfrom pydantic import BaseModel\nfrom docling_graph.protocols import TextExtractionBackendProtocol, LLMClientProtocol\nfrom docling_graph.exceptions import ExtractionError, ClientError\n\nclass CustomLLMClient(LLMClientProtocol):\n    \"\"\"Custom LLM client implementation.\"\"\"\n\n    def __init__(self, model: str, api_key: str):\n        self.model = model\n        self.api_key = api_key\n        self._context_limit = 8000  # Token limit\n\n    @property\n    def context_limit(self) -&gt; int:\n        \"\"\"Return context limit in tokens.\"\"\"\n        return self._context_limit\n\n    def get_json_response(\n        self, \n        prompt: str | Dict[str, str], \n        schema_json: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Execute LLM call and return parsed JSON.\n\n        Args:\n            prompt: System/user prompt or legacy string\n            schema_json: Pydantic schema as JSON string\n\n        Returns:\n            Parsed JSON dictionary\n        \"\"\"\n        try:\n            # Handle both formats\n            if isinstance(prompt, dict):\n                system_prompt = prompt.get(\"system\", \"\")\n                user_prompt = prompt.get(\"user\", \"\")\n            else:\n                system_prompt = \"\"\n                user_prompt = prompt\n\n            # Call your LLM API\n            from my_llm_sdk import LLMClient\n            client = LLMClient(api_key=self.api_key)\n\n            response = client.chat(\n                model=self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_prompt},\n                    {\"role\": \"user\", \"content\": user_prompt}\n                ],\n                response_format={\"type\": \"json_object\"},\n                schema=schema_json\n            )\n\n            # Parse JSON response\n            import json\n            return json.loads(response.content)\n\n        except Exception as e:\n            raise ClientError(\n                \"LLM call failed\",\n                details={\"model\": self.model},\n                cause=e\n            )\n\n\nclass CustomLLMBackend(TextExtractionBackendProtocol):\n    \"\"\"\n    Custom LLM backend for text extraction.\n\n    Args:\n        model: Model name\n        api_key: API key\n    \"\"\"\n\n    def __init__(self, model: str = \"custom-llm-v1\", api_key: str | None = None):\n        import os\n        self.model = model\n        self.api_key = api_key or os.getenv(\"CUSTOM_LLM_API_KEY\")\n\n        if not self.api_key:\n            raise ClientError(\n                \"API key not found\",\n                details={\"env_var\": \"CUSTOM_LLM_API_KEY\"}\n            )\n\n        # Initialize client\n        self.client = CustomLLMClient(\n            model=self.model,\n            api_key=self.api_key\n        )\n\n    def extract_from_markdown(\n        self,\n        markdown: str,\n        template: Type[BaseModel],\n        context: str = \"document\",\n        is_partial: bool = False\n    ) -&gt; BaseModel | None:\n        \"\"\"\n        Extract structured data from markdown.\n\n        Args:\n            markdown: Markdown content\n            template: Pydantic model template\n            context: Context description\n            is_partial: Whether this is a partial extraction\n\n        Returns:\n            Extracted model instance or None\n        \"\"\"\n        try:\n            # Build prompt\n            schema_json = template.model_json_schema()\n\n            system_prompt = (\n                \"You are a data extraction expert. \"\n                \"Extract structured information from the provided text \"\n                \"according to the given schema.\"\n            )\n\n            user_prompt = f\"\"\"\nExtract information from this {context}:\n\n{markdown}\n\nReturn a JSON object matching this schema:\n{schema_json}\n\"\"\"\n\n            # Call LLM\n            response = self.client.get_json_response(\n                prompt={\"system\": system_prompt, \"user\": user_prompt},\n                schema_json=str(schema_json)\n            )\n\n            # Validate with Pydantic\n            model_instance = template.model_validate(response)\n            return model_instance\n\n        except Exception as e:\n            raise ExtractionError(\n                \"Markdown extraction failed\",\n                details={\n                    \"context\": context,\n                    \"template\": template.__name__\n                },\n                cause=e\n            )\n\n    def consolidate_from_pydantic_models(\n        self,\n        raw_models: List[BaseModel],\n        programmatic_model: BaseModel,\n        template: Type[BaseModel]\n    ) -&gt; BaseModel | None:\n        \"\"\"\n        Consolidate multiple models using LLM.\n\n        Args:\n            raw_models: List of extracted models\n            programmatic_model: Programmatically merged model\n            template: Target template\n\n        Returns:\n            Consolidated model instance\n        \"\"\"\n        try:\n            # Convert models to JSON\n            models_json = [m.model_dump() for m in raw_models]\n            programmatic_json = programmatic_model.model_dump()\n\n            system_prompt = (\n                \"You are a data consolidation expert. \"\n                \"Merge multiple extractions into a single coherent result.\"\n            )\n\n            user_prompt = f\"\"\"\nConsolidate these extractions:\n\nRaw extractions:\n{models_json}\n\nProgrammatic merge:\n{programmatic_json}\n\nReturn the best consolidated result as JSON.\n\"\"\"\n\n            schema_json = template.model_json_schema()\n\n            response = self.client.get_json_response(\n                prompt={\"system\": system_prompt, \"user\": user_prompt},\n                schema_json=str(schema_json)\n            )\n\n            return template.model_validate(response)\n\n        except Exception as e:\n            raise ExtractionError(\n                \"Consolidation failed\",\n                details={\"num_models\": len(raw_models)},\n                cause=e\n            )\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        # Close any open connections\n        pass\n</code></pre>"},{"location":"usage/advanced/custom-backends/#usage_1","title":"Usage","text":"<pre><code>\"\"\"Use custom LLM backend.\"\"\"\n\nfrom my_backends import CustomLLMBackend\nfrom docling_graph.core.extractors.strategies import ManyToOne\n\n# Create backend\nbackend = CustomLLMBackend(\n    model=\"custom-llm-v1\",\n    api_key=\"your_api_key\"\n)\n\n# Use with extractor\nextractor = ManyToOne(backend=backend)\nresults = extractor.extract(\n    source=\"document.pdf\",\n    template=MyTemplate\n)\n\n# Clean up\nbackend.cleanup()\n</code></pre>"},{"location":"usage/advanced/custom-backends/#testing-custom-backends","title":"Testing Custom Backends","text":""},{"location":"usage/advanced/custom-backends/#unit-tests","title":"Unit Tests","text":"<pre><code>\"\"\"Test custom backend.\"\"\"\n\nimport pytest\nfrom pydantic import BaseModel, Field\nfrom my_backends import CustomLLMBackend\n\nclass TestTemplate(BaseModel):\n    \"\"\"Simple test template.\"\"\"\n    name: str = Field(..., description=\"Name\")\n    value: int = Field(..., description=\"Value\")\n\ndef test_backend_initialization():\n    \"\"\"Test backend can be initialized.\"\"\"\n    backend = CustomLLMBackend(\n        model=\"test-model\",\n        api_key=\"test-key\"\n    )\n    assert backend.model == \"test-model\"\n    assert backend.client is not None\n\ndef test_extract_from_markdown():\n    \"\"\"Test markdown extraction.\"\"\"\n    backend = CustomLLMBackend(\n        model=\"test-model\",\n        api_key=\"test-key\"\n    )\n\n    markdown = \"Name: John, Value: 42\"\n    result = backend.extract_from_markdown(\n        markdown=markdown,\n        template=TestTemplate\n    )\n\n    assert result is not None\n    assert isinstance(result, TestTemplate)\n    assert result.name == \"John\"\n    assert result.value == 42\n\ndef test_cleanup():\n    \"\"\"Test cleanup doesn't raise errors.\"\"\"\n    backend = CustomLLMBackend(\n        model=\"test-model\",\n        api_key=\"test-key\"\n    )\n    backend.cleanup()  # Should not raise\n</code></pre>"},{"location":"usage/advanced/custom-backends/#integration-tests","title":"Integration Tests","text":"<pre><code>\"\"\"Integration test with pipeline.\"\"\"\n\nfrom docling_graph.core.extractors.strategies import ManyToOne\nfrom my_backends import CustomLLMBackend\n\ndef test_backend_with_extractor():\n    \"\"\"Test backend works with extractor.\"\"\"\n    backend = CustomLLMBackend(\n        model=\"test-model\",\n        api_key=\"test-key\"\n    )\n\n    extractor = ManyToOne(backend=backend)\n\n    results = extractor.extract(\n        source=\"test_document.pdf\",\n        template=TestTemplate\n    )\n\n    assert len(results) &gt; 0\n    assert all(isinstance(r, TestTemplate) for r in results)\n\n    backend.cleanup()\n</code></pre>"},{"location":"usage/advanced/custom-backends/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/custom-backends/#1-implement-all-protocol-methods","title":"1. Implement All Protocol Methods","text":"<pre><code># \u2705 Good - Complete implementation\nclass MyBackend(TextExtractionBackendProtocol):\n    client: Any\n\n    def extract_from_markdown(self, ...): ...\n    def consolidate_from_pydantic_models(self, ...): ...\n    def cleanup(self): ...\n\n# \u274c Avoid - Missing methods\nclass MyBackend:\n    def extract_from_markdown(self, ...): ...\n    # Missing other methods!\n</code></pre>"},{"location":"usage/advanced/custom-backends/#2-use-structured-exceptions","title":"2. Use Structured Exceptions","text":"<pre><code># \u2705 Good - Structured errors\nfrom docling_graph.exceptions import ExtractionError, ClientError\n\ndef extract(self, ...):\n    try:\n        result = self._process()\n        return result\n    except APIError as e:\n        raise ClientError(\"API call failed\", cause=e)\n    except ValidationError as e:\n        raise ExtractionError(\"Validation failed\", cause=e)\n\n# \u274c Avoid - Generic exceptions\ndef extract(self, ...):\n    raise Exception(\"Something went wrong\")\n</code></pre>"},{"location":"usage/advanced/custom-backends/#3-clean-up-resources","title":"3. Clean Up Resources","text":"<pre><code># \u2705 Good - Proper cleanup\nclass MyBackend:\n    def __init__(self):\n        self.client = initialize_client()\n        self.model = load_model()\n\n    def cleanup(self):\n        if hasattr(self, 'client'):\n            self.client.close()\n        if hasattr(self, 'model'):\n            del self.model\n            import gc\n            gc.collect()\n\n# \u274c Avoid - No cleanup\nclass MyBackend:\n    def cleanup(self):\n        pass  # Resources leak!\n</code></pre>"},{"location":"usage/advanced/custom-backends/#4-validate-inputs","title":"4. Validate Inputs","text":"<pre><code># \u2705 Good - Input validation\ndef extract_from_markdown(self, markdown: str, template, ...):\n    if not markdown or not markdown.strip():\n        raise ValueError(\"Markdown cannot be empty\")\n    if not template:\n        raise ValueError(\"Template is required\")\n    # Process...\n\n# \u274c Avoid - No validation\ndef extract_from_markdown(self, markdown, template, ...):\n    # Process without checks\n    pass\n</code></pre>"},{"location":"usage/advanced/custom-backends/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/advanced/custom-backends/#issue-protocol-not-recognized","title":"Issue: Protocol Not Recognized","text":"<p>Problem: Backend not recognized by pipeline</p> <p>Solution: <pre><code># Ensure you implement the correct protocol\nfrom docling_graph.protocols import TextExtractionBackendProtocol\n\nclass MyBackend(TextExtractionBackendProtocol):\n    # Must have 'client' attribute for LLM backends\n    client: Any\n\n    # Must implement all required methods\n    def extract_from_markdown(self, ...): ...\n    def consolidate_from_pydantic_models(self, ...): ...\n    def cleanup(self): ...\n</code></pre></p>"},{"location":"usage/advanced/custom-backends/#issue-memory-leaks","title":"Issue: Memory Leaks","text":"<p>Problem: Memory usage grows over time</p> <p>Solution: <pre><code># Implement proper cleanup\ndef cleanup(self):\n    # Close connections\n    if hasattr(self, 'client'):\n        self.client.close()\n\n    # Delete large objects\n    if hasattr(self, 'model'):\n        del self.model\n\n    # Force garbage collection\n    import gc\n    gc.collect()\n</code></pre></p>"},{"location":"usage/advanced/custom-backends/#issue-api-rate-limits","title":"Issue: API Rate Limits","text":"<p>Problem: API calls fail due to rate limits</p> <p>Solution: <pre><code>import time\nfrom docling_graph.exceptions import ClientError\n\ndef _call_api_with_retry(self, *args, **kwargs):\n    \"\"\"Call API with exponential backoff.\"\"\"\n    max_retries = 3\n    base_delay = 1\n\n    for attempt in range(max_retries):\n        try:\n            return self.client.call(*args, **kwargs)\n        except RateLimitError as e:\n            if attempt == max_retries - 1:\n                raise ClientError(\"Rate limit exceeded\", cause=e)\n\n            delay = base_delay * (2 ** attempt)\n            time.sleep(delay)\n</code></pre></p>"},{"location":"usage/advanced/custom-backends/#next-steps","title":"Next Steps","text":"<ol> <li>Custom Exporters \u2192 - Create custom output formats</li> <li>Testing \u2192 - Test your backend</li> <li>Error Handling \u2192 - Handle errors gracefully</li> </ol>"},{"location":"usage/advanced/custom-backends/#related-documentation","title":"Related Documentation","text":"<ul> <li>Protocols Reference - Protocol definitions</li> <li>Exceptions Reference - Exception hierarchy</li> <li>Extraction Process - How extraction works</li> </ul>"},{"location":"usage/advanced/custom-exporters/","title":"Custom Exporters","text":""},{"location":"usage/advanced/custom-exporters/#overview","title":"Overview","text":"<p>Create custom exporters to output knowledge graphs in specialized formats for your specific use case or database system.</p> <p>What You'll Learn: - Exporter protocol implementation - Graph data access - Custom format generation - Registration and usage - Testing strategies</p> <p>Prerequisites: - Understanding of Graph Management - Familiarity with NetworkX graphs - Knowledge of target output format</p>"},{"location":"usage/advanced/custom-exporters/#exporter-protocol","title":"Exporter Protocol","text":"<p>All exporters must implement the <code>BaseExporter</code> protocol:</p> <pre><code>from pathlib import Path\nfrom typing import Any\nimport networkx as nx\n\nclass BaseExporter:\n    \"\"\"Base class for graph exporters.\"\"\"\n\n    def __init__(self, graph: nx.MultiDiGraph, output_dir: Path):\n        \"\"\"\n        Initialize exporter.\n\n        Args:\n            graph: NetworkX graph to export\n            output_dir: Directory for output files\n        \"\"\"\n        self.graph = graph\n        self.output_dir = output_dir\n\n    def export(self) -&gt; None:\n        \"\"\"Export the graph to the target format.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#complete-exporter-example","title":"Complete Exporter Example","text":""},{"location":"usage/advanced/custom-exporters/#graphml-exporter","title":"GraphML Exporter","text":"<pre><code>\"\"\"\nCustom exporter for GraphML format.\nGraphML is an XML-based format for graphs.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any\nimport networkx as nx\nfrom docling_graph.core.exporters.base import BaseExporter\nfrom docling_graph.exceptions import GraphError\n\nclass GraphMLExporter(BaseExporter):\n    \"\"\"\n    Export knowledge graph to GraphML format.\n\n    GraphML is widely supported by graph visualization tools\n    like Gephi, Cytoscape, and yEd.\n\n    Args:\n        graph: NetworkX graph to export\n        output_dir: Directory for output files\n        pretty_print: Whether to format XML with indentation\n    \"\"\"\n\n    def __init__(\n        self,\n        graph: nx.MultiDiGraph,\n        output_dir: Path,\n        pretty_print: bool = True\n    ):\n        super().__init__(graph, output_dir)\n        self.pretty_print = pretty_print\n\n    def export(self) -&gt; None:\n        \"\"\"\n        Export graph to GraphML format.\n\n        Creates a .graphml file in the output directory.\n\n        Raises:\n            GraphError: If export fails\n        \"\"\"\n        try:\n            # Ensure output directory exists\n            self.output_dir.mkdir(parents=True, exist_ok=True)\n\n            # Define output path\n            output_path = self.output_dir / \"graph.graphml\"\n\n            # Export using NetworkX\n            nx.write_graphml(\n                self.graph,\n                str(output_path),\n                prettyprint=self.pretty_print\n            )\n\n            print(f\"\u2713 GraphML exported to {output_path}\")\n\n        except Exception as e:\n            raise GraphError(\n                \"GraphML export failed\",\n                details={\"output_dir\": str(self.output_dir)},\n                cause=e\n            )\n\n    def get_statistics(self) -&gt; dict[str, Any]:\n        \"\"\"Get graph statistics for the export.\"\"\"\n        return {\n            \"num_nodes\": self.graph.number_of_nodes(),\n            \"num_edges\": self.graph.number_of_edges(),\n            \"node_types\": self._count_node_types(),\n            \"edge_types\": self._count_edge_types()\n        }\n\n    def _count_node_types(self) -&gt; dict[str, int]:\n        \"\"\"Count nodes by type.\"\"\"\n        type_counts: dict[str, int] = {}\n        for _, data in self.graph.nodes(data=True):\n            node_type = data.get(\"type\", \"Unknown\")\n            type_counts[node_type] = type_counts.get(node_type, 0) + 1\n        return type_counts\n\n    def _count_edge_types(self) -&gt; dict[str, int]:\n        \"\"\"Count edges by type.\"\"\"\n        type_counts: dict[str, int] = {}\n        for _, _, data in self.graph.edges(data=True):\n            edge_type = data.get(\"type\", \"Unknown\")\n            type_counts[edge_type] = type_counts.get(edge_type, 0) + 1\n        return type_counts\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#usage","title":"Usage","text":"<pre><code>\"\"\"Use custom GraphML exporter.\"\"\"\n\nfrom pathlib import Path\nimport networkx as nx\nfrom my_exporters import GraphMLExporter\n\n# Assume you have a graph from the pipeline\ngraph: nx.MultiDiGraph = ...  # From pipeline\n\n# Create exporter\nexporter = GraphMLExporter(\n    graph=graph,\n    output_dir=Path(\"outputs/graphml\"),\n    pretty_print=True\n)\n\n# Export\nexporter.export()\n\n# Get statistics\nstats = exporter.get_statistics()\nprint(f\"Exported {stats['num_nodes']} nodes and {stats['num_edges']} edges\")\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#advanced-exporter-example","title":"Advanced Exporter Example","text":""},{"location":"usage/advanced/custom-exporters/#rdfturtle-exporter","title":"RDF/Turtle Exporter","text":"<pre><code>\"\"\"\nExport knowledge graph to RDF Turtle format.\nUseful for semantic web applications and triple stores.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any\nimport networkx as nx\nfrom docling_graph.core.exporters.base import BaseExporter\nfrom docling_graph.exceptions import GraphError\n\nclass TurtleExporter(BaseExporter):\n    \"\"\"\n    Export knowledge graph to RDF Turtle format.\n\n    Args:\n        graph: NetworkX graph to export\n        output_dir: Directory for output files\n        namespace: Base namespace URI for entities\n        prefixes: Additional namespace prefixes\n    \"\"\"\n\n    def __init__(\n        self,\n        graph: nx.MultiDiGraph,\n        output_dir: Path,\n        namespace: str = \"http://example.org/kg/\",\n        prefixes: dict[str, str] | None = None\n    ):\n        super().__init__(graph, output_dir)\n        self.namespace = namespace\n        self.prefixes = prefixes or {\n            \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n            \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n            \"xsd\": \"http://www.w3.org/2001/XMLSchema#\"\n        }\n\n    def export(self) -&gt; None:\n        \"\"\"Export graph to Turtle format.\"\"\"\n        try:\n            self.output_dir.mkdir(parents=True, exist_ok=True)\n            output_path = self.output_dir / \"graph.ttl\"\n\n            with open(output_path, 'w', encoding='utf-8') as f:\n                # Write prefixes\n                self._write_prefixes(f)\n                f.write(\"\\n\")\n\n                # Write nodes (entities)\n                self._write_nodes(f)\n                f.write(\"\\n\")\n\n                # Write edges (relationships)\n                self._write_edges(f)\n\n            print(f\"\u2713 Turtle RDF exported to {output_path}\")\n\n        except Exception as e:\n            raise GraphError(\n                \"Turtle export failed\",\n                details={\"output_dir\": str(self.output_dir)},\n                cause=e\n            )\n\n    def _write_prefixes(self, f: Any) -&gt; None:\n        \"\"\"Write namespace prefixes.\"\"\"\n        f.write(f\"@prefix : &lt;{self.namespace}&gt; .\\n\")\n        for prefix, uri in self.prefixes.items():\n            f.write(f\"@prefix {prefix}: &lt;{uri}&gt; .\\n\")\n\n    def _write_nodes(self, f: Any) -&gt; None:\n        \"\"\"Write node definitions.\"\"\"\n        for node_id, data in self.graph.nodes(data=True):\n            # Create URI for node\n            node_uri = self._create_uri(node_id)\n\n            # Write type\n            node_type = data.get(\"type\", \"Entity\")\n            f.write(f\"{node_uri} rdf:type :{node_type} ;\\n\")\n\n            # Write properties\n            properties = []\n            for key, value in data.items():\n                if key not in [\"type\", \"id\"]:\n                    prop_line = self._format_property(key, value)\n                    if prop_line:\n                        properties.append(prop_line)\n\n            # Write properties with proper punctuation\n            for i, prop in enumerate(properties):\n                if i &lt; len(properties) - 1:\n                    f.write(f\"    {prop} ;\\n\")\n                else:\n                    f.write(f\"    {prop} .\\n\")\n\n            f.write(\"\\n\")\n\n    def _write_edges(self, f: Any) -&gt; None:\n        \"\"\"Write edge definitions.\"\"\"\n        for source, target, data in self.graph.edges(data=True):\n            source_uri = self._create_uri(source)\n            target_uri = self._create_uri(target)\n            edge_type = data.get(\"type\", \"relatedTo\")\n\n            f.write(f\"{source_uri} :{edge_type} {target_uri} .\\n\")\n\n    def _create_uri(self, node_id: str) -&gt; str:\n        \"\"\"Create URI for a node.\"\"\"\n        # Clean node ID for URI\n        clean_id = node_id.replace(\" \", \"_\").replace(\"/\", \"_\")\n        return f\":{clean_id}\"\n\n    def _format_property(self, key: str, value: Any) -&gt; str | None:\n        \"\"\"Format a property for Turtle output.\"\"\"\n        if value is None:\n            return None\n\n        # Handle different value types\n        if isinstance(value, bool):\n            return f':{key} \"{str(value).lower()}\"^^xsd:boolean'\n        elif isinstance(value, int):\n            return f':{key} \"{value}\"^^xsd:integer'\n        elif isinstance(value, float):\n            return f':{key} \"{value}\"^^xsd:decimal'\n        elif isinstance(value, str):\n            # Escape quotes in strings\n            escaped = value.replace('\"', '\\\\\"')\n            return f':{key} \"{escaped}\"'\n        else:\n            # Convert to string for other types\n            return f':{key} \"{str(value)}\"'\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#integration-with-pipeline","title":"Integration with Pipeline","text":""},{"location":"usage/advanced/custom-exporters/#method-1-post-processing","title":"Method 1: Post-Processing","text":"<pre><code>\"\"\"Export after pipeline completes.\"\"\"\n\nfrom pathlib import Path\nfrom docling_graph import PipelineConfig\nfrom my_exporters import GraphMLExporter, TurtleExporter\n\n# Run pipeline\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    output_dir=\"outputs\"\n)\nconfig.run()\n\n# Load the generated graph\nimport json\ngraph_path = Path(\"outputs/graph.json\")\nwith open(graph_path) as f:\n    graph_data = json.load(f)\n\n# Convert to NetworkX graph\nimport networkx as nx\ngraph = nx.node_link_graph(graph_data)\n\n# Export to custom formats\nGraphMLExporter(graph, Path(\"outputs/graphml\")).export()\nTurtleExporter(graph, Path(\"outputs/turtle\")).export()\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#method-2-custom-pipeline-stage","title":"Method 2: Custom Pipeline Stage","text":"<pre><code>\"\"\"Add custom export as pipeline stage.\"\"\"\n\nfrom docling_graph.pipeline.stages import PipelineStage\nfrom docling_graph.pipeline.context import PipelineContext\nfrom my_exporters import GraphMLExporter\n\nclass CustomExportStage(PipelineStage):\n    \"\"\"Custom export stage.\"\"\"\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"Execute custom export.\"\"\"\n        if context.graph is None:\n            return\n\n        # Export to GraphML\n        exporter = GraphMLExporter(\n            graph=context.graph,\n            output_dir=context.output_dir / \"graphml\"\n        )\n        exporter.export()\n\n        print(\"\u2713 Custom export complete\")\n\n# Use in custom pipeline orchestration\n# (Requires modifying pipeline code)\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#testing-custom-exporters","title":"Testing Custom Exporters","text":""},{"location":"usage/advanced/custom-exporters/#unit-tests","title":"Unit Tests","text":"<pre><code>\"\"\"Test custom exporter.\"\"\"\n\nimport pytest\nfrom pathlib import Path\nimport networkx as nx\nfrom my_exporters import GraphMLExporter\n\n@pytest.fixture\ndef sample_graph():\n    \"\"\"Create a sample graph for testing.\"\"\"\n    G = nx.MultiDiGraph()\n\n    # Add nodes\n    G.add_node(\"person_1\", type=\"Person\", name=\"John\", age=30)\n    G.add_node(\"org_1\", type=\"Organization\", name=\"ACME Corp\")\n\n    # Add edge\n    G.add_edge(\"person_1\", \"org_1\", type=\"WORKS_AT\")\n\n    return G\n\ndef test_exporter_initialization(sample_graph, tmp_path):\n    \"\"\"Test exporter can be initialized.\"\"\"\n    exporter = GraphMLExporter(\n        graph=sample_graph,\n        output_dir=tmp_path\n    )\n    assert exporter.graph == sample_graph\n    assert exporter.output_dir == tmp_path\n\ndef test_export_creates_file(sample_graph, tmp_path):\n    \"\"\"Test export creates output file.\"\"\"\n    exporter = GraphMLExporter(\n        graph=sample_graph,\n        output_dir=tmp_path\n    )\n    exporter.export()\n\n    output_file = tmp_path / \"graph.graphml\"\n    assert output_file.exists()\n    assert output_file.stat().st_size &gt; 0\n\ndef test_export_valid_format(sample_graph, tmp_path):\n    \"\"\"Test exported file is valid GraphML.\"\"\"\n    exporter = GraphMLExporter(\n        graph=sample_graph,\n        output_dir=tmp_path\n    )\n    exporter.export()\n\n    # Try to read it back\n    output_file = tmp_path / \"graph.graphml\"\n    loaded_graph = nx.read_graphml(str(output_file))\n\n    assert loaded_graph.number_of_nodes() == 2\n    assert loaded_graph.number_of_edges() == 1\n\ndef test_statistics(sample_graph, tmp_path):\n    \"\"\"Test statistics generation.\"\"\"\n    exporter = GraphMLExporter(\n        graph=sample_graph,\n        output_dir=tmp_path\n    )\n\n    stats = exporter.get_statistics()\n\n    assert stats[\"num_nodes\"] == 2\n    assert stats[\"num_edges\"] == 1\n    assert \"Person\" in stats[\"node_types\"]\n    assert \"Organization\" in stats[\"node_types\"]\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/custom-exporters/#1-handle-errors-gracefully","title":"1. Handle Errors Gracefully","text":"<pre><code># \u2705 Good - Structured error handling\nfrom docling_graph.exceptions import GraphError\n\ndef export(self):\n    try:\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        # Export logic...\n    except IOError as e:\n        raise GraphError(\"File write failed\", cause=e)\n    except Exception as e:\n        raise GraphError(\"Export failed\", cause=e)\n\n# \u274c Avoid - Silent failures\ndef export(self):\n    try:\n        # Export logic...\n        pass\n    except:\n        pass  # Error ignored!\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#2-validate-graph-data","title":"2. Validate Graph Data","text":"<pre><code># \u2705 Good - Validate before export\ndef export(self):\n    if self.graph.number_of_nodes() == 0:\n        raise GraphError(\"Cannot export empty graph\")\n\n    # Check for required attributes\n    for node_id, data in self.graph.nodes(data=True):\n        if \"type\" not in data:\n            raise GraphError(\n                f\"Node {node_id} missing 'type' attribute\"\n            )\n\n    # Proceed with export...\n\n# \u274c Avoid - No validation\ndef export(self):\n    # Export without checks\n    pass\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#3-provide-progress-feedback","title":"3. Provide Progress Feedback","text":"<pre><code># \u2705 Good - Progress updates\ndef export(self):\n    total_nodes = self.graph.number_of_nodes()\n    print(f\"Exporting {total_nodes} nodes...\")\n\n    # Export nodes\n    for i, (node_id, data) in enumerate(self.graph.nodes(data=True)):\n        self._export_node(node_id, data)\n        if (i + 1) % 100 == 0:\n            print(f\"  Processed {i + 1}/{total_nodes} nodes\")\n\n    print(\"\u2713 Export complete\")\n\n# \u274c Avoid - No feedback\ndef export(self):\n    # Silent export\n    pass\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#4-make-exporters-configurable","title":"4. Make Exporters Configurable","text":"<pre><code># \u2705 Good - Configurable options\nclass MyExporter(BaseExporter):\n    def __init__(\n        self,\n        graph: nx.MultiDiGraph,\n        output_dir: Path,\n        include_metadata: bool = True,\n        compress: bool = False,\n        encoding: str = \"utf-8\"\n    ):\n        super().__init__(graph, output_dir)\n        self.include_metadata = include_metadata\n        self.compress = compress\n        self.encoding = encoding\n\n# \u274c Avoid - Hardcoded behavior\nclass MyExporter(BaseExporter):\n    def __init__(self, graph, output_dir):\n        super().__init__(graph, output_dir)\n        # No configuration options\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#common-export-formats","title":"Common Export Formats","text":""},{"location":"usage/advanced/custom-exporters/#json-ld","title":"JSON-LD","text":"<pre><code>\"\"\"Export to JSON-LD for semantic web.\"\"\"\n\ndef export_jsonld(self) -&gt; None:\n    \"\"\"Export to JSON-LD format.\"\"\"\n    output = {\n        \"@context\": {\n            \"@vocab\": self.namespace,\n            \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n        },\n        \"@graph\": []\n    }\n\n    # Add nodes\n    for node_id, data in self.graph.nodes(data=True):\n        node_obj = {\n            \"@id\": node_id,\n            \"@type\": data.get(\"type\", \"Entity\")\n        }\n        # Add properties\n        for key, value in data.items():\n            if key not in [\"type\", \"id\"]:\n                node_obj[key] = value\n        output[\"@graph\"].append(node_obj)\n\n    # Write to file\n    import json\n    output_path = self.output_dir / \"graph.jsonld\"\n    with open(output_path, 'w') as f:\n        json.dump(output, f, indent=2)\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#dot-graphviz","title":"DOT (Graphviz)","text":"<pre><code>\"\"\"Export to DOT format for Graphviz.\"\"\"\n\ndef export_dot(self) -&gt; None:\n    \"\"\"Export to DOT format.\"\"\"\n    from networkx.drawing.nx_pydot import write_dot\n\n    output_path = self.output_dir / \"graph.dot\"\n    write_dot(self.graph, str(output_path))\n\n    print(f\"\u2713 DOT exported to {output_path}\")\n    print(\"  Visualize with: dot -Tpng graph.dot -o graph.png\")\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#next-steps","title":"Next Steps","text":"<ol> <li>Custom Stages \u2192 - Add pipeline stages</li> <li>Testing \u2192 - Test your exporter</li> <li>Graph Management \u2192 - Learn about graphs</li> </ol>"},{"location":"usage/advanced/custom-exporters/#related-documentation","title":"Related Documentation","text":"<ul> <li>Export Formats - Built-in formats</li> <li>Graph Conversion - How graphs are built</li> <li>Exporters API - API reference</li> </ul>"},{"location":"usage/advanced/custom-stages/","title":"Custom Pipeline Stages","text":""},{"location":"usage/advanced/custom-stages/#overview","title":"Overview","text":"<p>Add custom stages to the docling-graph pipeline for specialized preprocessing, validation, or post-processing tasks.</p> <p>What You'll Learn: - Pipeline stage protocol - Stage implementation - Context management - Integration with pipeline - Error handling</p> <p>Prerequisites: - Understanding of Pipeline Architecture - Familiarity with Python API - Knowledge of pipeline context</p>"},{"location":"usage/advanced/custom-stages/#pipeline-stage-protocol","title":"Pipeline Stage Protocol","text":"<p>Custom stages should follow this pattern:</p> <pre><code>from docling_graph.pipeline.context import PipelineContext\n\nclass CustomStage:\n    \"\"\"Custom pipeline stage.\"\"\"\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"\n        Execute the stage.\n\n        Args:\n            context: Pipeline context with shared state\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"usage/advanced/custom-stages/#pipeline-context","title":"Pipeline Context","text":"<p>The <code>PipelineContext</code> provides access to pipeline state:</p> <pre><code>@dataclass\nclass PipelineContext:\n    \"\"\"Shared context for pipeline stages.\"\"\"\n\n    # Configuration\n    config: Dict[str, Any]\n\n    # Paths\n    source: Path\n    output_dir: Path\n\n    # Pipeline state\n    template: Type[BaseModel] | None = None\n    docling_doc: Any = None\n    extracted_models: List[BaseModel] | None = None\n    graph: nx.MultiDiGraph | None = None\n\n    # Metadata\n    metadata: Dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"usage/advanced/custom-stages/#complete-stage-examples","title":"Complete Stage Examples","text":""},{"location":"usage/advanced/custom-stages/#1-preprocessing-stage","title":"1. Preprocessing Stage","text":"<pre><code>\"\"\"\nPreprocessing stage to validate and prepare documents.\n\"\"\"\n\nfrom pathlib import Path\nfrom docling_graph.pipeline.context import PipelineContext\nfrom docling_graph.exceptions import PipelineError\n\nclass DocumentValidationStage:\n    \"\"\"\n    Validate document before processing.\n\n    Checks:\n    - File exists and is readable\n    - File size is within limits\n    - File format is supported\n    \"\"\"\n\n    def __init__(\n        self,\n        max_size_mb: int = 50,\n        allowed_formats: list[str] | None = None\n    ):\n        self.max_size_mb = max_size_mb\n        self.allowed_formats = allowed_formats or ['.pdf', '.png', '.jpg', '.jpeg']\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"Execute validation.\"\"\"\n        print(\"\ud83d\udd0d Validating document...\")\n\n        # Check file exists\n        if not context.source.exists():\n            raise PipelineError(\n                \"Source file not found\",\n                details={\"source\": str(context.source)}\n            )\n\n        # Check file size\n        size_mb = context.source.stat().st_size / (1024 * 1024)\n        if size_mb &gt; self.max_size_mb:\n            raise PipelineError(\n                f\"File too large: {size_mb:.1f}MB (max: {self.max_size_mb}MB)\",\n                details={\"source\": str(context.source), \"size_mb\": size_mb}\n            )\n\n        # Check format\n        if context.source.suffix.lower() not in self.allowed_formats:\n            raise PipelineError(\n                f\"Unsupported format: {context.source.suffix}\",\n                details={\n                    \"source\": str(context.source),\n                    \"allowed\": self.allowed_formats\n                }\n            )\n\n        # Store metadata\n        context.metadata[\"validation\"] = {\n            \"size_mb\": size_mb,\n            \"format\": context.source.suffix,\n            \"validated\": True\n        }\n\n        print(f\"\u2713 Document validated ({size_mb:.1f}MB)\")\n</code></pre>"},{"location":"usage/advanced/custom-stages/#2-post-processing-stage","title":"2. Post-Processing Stage","text":"<pre><code>\"\"\"\nPost-processing stage to enrich extracted data.\n\"\"\"\n\nfrom typing import List\nfrom pydantic import BaseModel\nfrom docling_graph.pipeline.context import PipelineContext\nfrom docling_graph.exceptions import PipelineError\n\nclass DataEnrichmentStage:\n    \"\"\"\n    Enrich extracted data with additional information.\n\n    Examples:\n    - Add timestamps\n    - Normalize values\n    - Add computed fields\n    - Validate business rules\n    \"\"\"\n\n    def __init__(self, add_timestamps: bool = True):\n        self.add_timestamps = add_timestamps\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"Execute enrichment.\"\"\"\n        if not context.extracted_models:\n            print(\"\u26a0\ufe0f  No models to enrich\")\n            return\n\n        print(\"\ud83d\udd27 Enriching extracted data...\")\n\n        enriched_count = 0\n        for model in context.extracted_models:\n            if self._enrich_model(model):\n                enriched_count += 1\n\n        context.metadata[\"enrichment\"] = {\n            \"models_processed\": len(context.extracted_models),\n            \"models_enriched\": enriched_count\n        }\n\n        print(f\"\u2713 Enriched {enriched_count} models\")\n\n    def _enrich_model(self, model: BaseModel) -&gt; bool:\n        \"\"\"Enrich a single model.\"\"\"\n        enriched = False\n\n        # Add timestamp if enabled\n        if self.add_timestamps:\n            from datetime import datetime\n            if hasattr(model, '__dict__'):\n                # Add as metadata (not modifying Pydantic model)\n                if not hasattr(model, '_metadata'):\n                    model._metadata = {}\n                model._metadata['processed_at'] = datetime.now().isoformat()\n                enriched = True\n\n        # Add more enrichment logic here\n\n        return enriched\n</code></pre>"},{"location":"usage/advanced/custom-stages/#3-validation-stage","title":"3. Validation Stage","text":"<pre><code>\"\"\"\nValidation stage to check extracted data quality.\n\"\"\"\n\nfrom typing import List\nfrom pydantic import BaseModel\nfrom docling_graph.pipeline.context import PipelineContext\nfrom docling_graph.exceptions import ValidationError\n\nclass QualityCheckStage:\n    \"\"\"\n    Validate extracted data quality.\n\n    Checks:\n    - Required fields are populated\n    - Data meets business rules\n    - Relationships are valid\n    \"\"\"\n\n    def __init__(\n        self,\n        min_confidence: float = 0.7,\n        require_relationships: bool = True\n    ):\n        self.min_confidence = min_confidence\n        self.require_relationships = require_relationships\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"Execute quality checks.\"\"\"\n        if not context.extracted_models:\n            raise ValidationError(\"No models to validate\")\n\n        print(\"\u2705 Running quality checks...\")\n\n        issues = []\n\n        for i, model in enumerate(context.extracted_models):\n            model_issues = self._check_model(model, i)\n            issues.extend(model_issues)\n\n        if issues:\n            print(f\"\u26a0\ufe0f  Found {len(issues)} quality issues:\")\n            for issue in issues[:5]:  # Show first 5\n                print(f\"  - {issue}\")\n            if len(issues) &gt; 5:\n                print(f\"  ... and {len(issues) - 5} more\")\n\n        context.metadata[\"quality_check\"] = {\n            \"models_checked\": len(context.extracted_models),\n            \"issues_found\": len(issues),\n            \"passed\": len(issues) == 0\n        }\n\n        if issues and self._is_critical():\n            raise ValidationError(\n                f\"Quality check failed with {len(issues)} issues\",\n                details={\"issues\": issues[:10]}\n            )\n\n        print(f\"\u2713 Quality check complete ({len(issues)} issues)\")\n\n    def _check_model(self, model: BaseModel, index: int) -&gt; List[str]:\n        \"\"\"Check a single model.\"\"\"\n        issues = []\n\n        # Check for empty required fields\n        for field_name, field_info in model.model_fields.items():\n            if field_info.is_required():\n                value = getattr(model, field_name, None)\n                if value is None or (isinstance(value, str) and not value.strip()):\n                    issues.append(\n                        f\"Model {index}: Required field '{field_name}' is empty\"\n                    )\n\n        # Check relationships if required\n        if self.require_relationships:\n            has_relationships = self._has_relationships(model)\n            if not has_relationships:\n                issues.append(\n                    f\"Model {index}: No relationships found\"\n                )\n\n        return issues\n\n    def _has_relationships(self, model: BaseModel) -&gt; bool:\n        \"\"\"Check if model has any relationships.\"\"\"\n        for field_name, field_info in model.model_fields.items():\n            json_schema_extra = field_info.json_schema_extra or {}\n            if \"edge_label\" in json_schema_extra:\n                value = getattr(model, field_name, None)\n                if value is not None:\n                    return True\n        return False\n\n    def _is_critical(self) -&gt; bool:\n        \"\"\"Determine if issues are critical.\"\"\"\n        # Could be configurable\n        return False\n</code></pre>"},{"location":"usage/advanced/custom-stages/#4-logging-stage","title":"4. Logging Stage","text":"<pre><code>\"\"\"\nLogging stage to track pipeline execution.\n\"\"\"\n\nimport json\nfrom datetime import datetime\nfrom pathlib import Path\nfrom docling_graph.pipeline.context import PipelineContext\n\nclass PipelineLoggingStage:\n    \"\"\"\n    Log pipeline execution details.\n\n    Creates a log file with:\n    - Execution timestamp\n    - Configuration used\n    - Processing statistics\n    - Any errors or warnings\n    \"\"\"\n\n    def __init__(self, log_level: str = \"INFO\"):\n        self.log_level = log_level\n        self.start_time = None\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"Execute logging.\"\"\"\n        if self.start_time is None:\n            self.start_time = datetime.now()\n\n        log_entry = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"source\": str(context.source),\n            \"output_dir\": str(context.output_dir),\n            \"config\": self._sanitize_config(context.config),\n            \"metadata\": context.metadata,\n            \"statistics\": self._gather_statistics(context)\n        }\n\n        # Write log file\n        log_path = context.output_dir / \"pipeline.log.json\"\n        with open(log_path, 'w') as f:\n            json.dump(log_entry, f, indent=2)\n\n        print(f\"\ud83d\udcdd Log written to {log_path}\")\n\n    def _sanitize_config(self, config: dict) -&gt; dict:\n        \"\"\"Remove sensitive data from config.\"\"\"\n        sanitized = config.copy()\n        # Remove API keys\n        for key in list(sanitized.keys()):\n            if 'key' in key.lower() or 'token' in key.lower():\n                sanitized[key] = \"***REDACTED***\"\n        return sanitized\n\n    def _gather_statistics(self, context: PipelineContext) -&gt; dict:\n        \"\"\"Gather processing statistics.\"\"\"\n        stats = {}\n\n        if context.extracted_models:\n            stats[\"num_models\"] = len(context.extracted_models)\n\n        if context.graph:\n            stats[\"num_nodes\"] = context.graph.number_of_nodes()\n            stats[\"num_edges\"] = context.graph.number_of_edges()\n\n        if self.start_time:\n            duration = (datetime.now() - self.start_time).total_seconds()\n            stats[\"duration_seconds\"] = duration\n\n        return stats\n</code></pre>"},{"location":"usage/advanced/custom-stages/#integration-with-pipeline","title":"Integration with Pipeline","text":""},{"location":"usage/advanced/custom-stages/#method-1-wrapper-function","title":"Method 1: Wrapper Function","text":"<pre><code>\"\"\"\nWrap pipeline execution with custom stages.\n\"\"\"\n\nfrom docling_graph import PipelineConfig\nfrom docling_graph.pipeline.context import PipelineContext\nfrom my_stages import DocumentValidationStage, QualityCheckStage\n\ndef run_pipeline_with_stages(config: PipelineConfig):\n    \"\"\"Run pipeline with custom stages.\"\"\"\n\n    # Create context\n    context = PipelineContext(\n        config=config.to_dict(),\n        source=Path(config.source),\n        output_dir=Path(config.output_dir)\n    )\n\n    # Pre-processing stages\n    validation_stage = DocumentValidationStage(max_size_mb=100)\n    validation_stage.execute(context)\n\n    # Run main pipeline\n    config.run()\n\n    # Post-processing stages\n    # (Would need to load results from output_dir)\n    quality_stage = QualityCheckStage()\n    # quality_stage.execute(context)\n\n    print(\"\u2713 Pipeline with custom stages complete\")\n\n# Usage\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\"\n)\nrun_pipeline_with_stages(config)\n</code></pre>"},{"location":"usage/advanced/custom-stages/#method-2-custom-orchestrator","title":"Method 2: Custom Orchestrator","text":"<pre><code>\"\"\"\nCreate custom pipeline orchestrator.\n\"\"\"\n\nfrom typing import List\nfrom docling_graph.pipeline.context import PipelineContext\nfrom docling_graph.pipeline.stages import (\n    TemplateLoadingStage,\n    ExtractionStage,\n    GraphConversionStage,\n    ExportStage\n)\nfrom my_stages import DocumentValidationStage, QualityCheckStage\n\nclass CustomPipelineOrchestrator:\n    \"\"\"Custom pipeline with additional stages.\"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config\n        self.stages = self._build_stages()\n\n    def _build_stages(self) -&gt; List:\n        \"\"\"Build pipeline stages.\"\"\"\n        return [\n            DocumentValidationStage(),      # Custom pre-processing\n            TemplateLoadingStage(),         # Built-in\n            ExtractionStage(),              # Built-in\n            QualityCheckStage(),            # Custom validation\n            GraphConversionStage(),         # Built-in\n            ExportStage(),                  # Built-in\n        ]\n\n    def run(self) -&gt; None:\n        \"\"\"Execute pipeline.\"\"\"\n        context = PipelineContext(\n            config=self.config,\n            source=Path(self.config[\"source\"]),\n            output_dir=Path(self.config[\"output_dir\"])\n        )\n\n        for stage in self.stages:\n            stage_name = stage.__class__.__name__\n            print(f\"\\n{'='*60}\")\n            print(f\"Stage: {stage_name}\")\n            print(f\"{'='*60}\")\n\n            try:\n                stage.execute(context)\n            except Exception as e:\n                print(f\"\u274c Stage {stage_name} failed: {e}\")\n                raise\n\n        print(\"\\n\u2713 All stages complete\")\n</code></pre>"},{"location":"usage/advanced/custom-stages/#testing-custom-stages","title":"Testing Custom Stages","text":"<pre><code>\"\"\"Test custom pipeline stage.\"\"\"\n\nimport pytest\nfrom pathlib import Path\nfrom docling_graph.pipeline.context import PipelineContext\nfrom my_stages import DocumentValidationStage\n\n@pytest.fixture\ndef sample_context(tmp_path):\n    \"\"\"Create sample context.\"\"\"\n    # Create a test file\n    test_file = tmp_path / \"test.pdf\"\n    test_file.write_bytes(b\"PDF content\")\n\n    return PipelineContext(\n        config={},\n        source=test_file,\n        output_dir=tmp_path / \"output\"\n    )\n\ndef test_stage_execution(sample_context):\n    \"\"\"Test stage executes successfully.\"\"\"\n    stage = DocumentValidationStage(max_size_mb=1)\n\n    # Should not raise\n    stage.execute(sample_context)\n\n    # Check metadata was added\n    assert \"validation\" in sample_context.metadata\n    assert sample_context.metadata[\"validation\"][\"validated\"]\n\ndef test_stage_file_not_found():\n    \"\"\"Test stage handles missing file.\"\"\"\n    context = PipelineContext(\n        config={},\n        source=Path(\"nonexistent.pdf\"),\n        output_dir=Path(\"output\")\n    )\n\n    stage = DocumentValidationStage()\n\n    with pytest.raises(Exception):\n        stage.execute(context)\n\ndef test_stage_file_too_large(tmp_path):\n    \"\"\"Test stage rejects large files.\"\"\"\n    # Create large file\n    large_file = tmp_path / \"large.pdf\"\n    large_file.write_bytes(b\"x\" * (100 * 1024 * 1024))  # 100MB\n\n    context = PipelineContext(\n        config={},\n        source=large_file,\n        output_dir=tmp_path / \"output\"\n    )\n\n    stage = DocumentValidationStage(max_size_mb=50)\n\n    with pytest.raises(Exception):\n        stage.execute(context)\n</code></pre>"},{"location":"usage/advanced/custom-stages/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/custom-stages/#1-keep-stages-focused","title":"1. Keep Stages Focused","text":"<pre><code># \u2705 Good - Single responsibility\nclass ValidationStage:\n    \"\"\"Validate document format and size.\"\"\"\n    def execute(self, context): ...\n\nclass EnrichmentStage:\n    \"\"\"Enrich extracted data.\"\"\"\n    def execute(self, context): ...\n\n# \u274c Avoid - Multiple responsibilities\nclass ProcessingStage:\n    \"\"\"Validate, enrich, and export.\"\"\"\n    def execute(self, context): ...\n</code></pre>"},{"location":"usage/advanced/custom-stages/#2-handle-errors-gracefully","title":"2. Handle Errors Gracefully","text":"<pre><code># \u2705 Good - Structured error handling\nfrom docling_graph.exceptions import PipelineError\n\ndef execute(self, context):\n    try:\n        self._process(context)\n    except ValueError as e:\n        raise PipelineError(\"Validation failed\", cause=e)\n    except Exception as e:\n        raise PipelineError(\"Stage execution failed\", cause=e)\n\n# \u274c Avoid - Silent failures\ndef execute(self, context):\n    try:\n        self._process(context)\n    except:\n        pass  # Error ignored!\n</code></pre>"},{"location":"usage/advanced/custom-stages/#3-update-context-metadata","title":"3. Update Context Metadata","text":"<pre><code># \u2705 Good - Track stage execution\ndef execute(self, context):\n    start_time = time.time()\n\n    # Process...\n\n    context.metadata[self.__class__.__name__] = {\n        \"executed\": True,\n        \"duration\": time.time() - start_time,\n        \"items_processed\": count\n    }\n\n# \u274c Avoid - No tracking\ndef execute(self, context):\n    # Process without tracking\n    pass\n</code></pre>"},{"location":"usage/advanced/custom-stages/#4-make-stages-configurable","title":"4. Make Stages Configurable","text":"<pre><code># \u2705 Good - Configurable behavior\nclass MyStage:\n    def __init__(self, threshold: float = 0.8, strict: bool = False):\n        self.threshold = threshold\n        self.strict = strict\n\n# \u274c Avoid - Hardcoded behavior\nclass MyStage:\n    def __init__(self):\n        self.threshold = 0.8  # Cannot be changed\n</code></pre>"},{"location":"usage/advanced/custom-stages/#next-steps","title":"Next Steps","text":"<ol> <li>Performance Tuning \u2192 - Optimize pipeline</li> <li>Error Handling \u2192 - Handle errors</li> <li>Testing \u2192 - Test your stages</li> </ol>"},{"location":"usage/advanced/custom-stages/#related-documentation","title":"Related Documentation","text":"<ul> <li>Pipeline Architecture - System design</li> <li>Python API - Programmatic usage</li> <li>Exceptions - Exception hierarchy</li> </ul>"},{"location":"usage/advanced/error-handling/","title":"Error Handling","text":""},{"location":"usage/advanced/error-handling/#overview","title":"Overview","text":"<p>Handle errors gracefully in docling-graph pipelines with structured exception handling, retry logic, and debugging strategies.</p> <p>What You'll Learn: - Exception hierarchy - Error recovery strategies - Zero data loss patterns - Retry mechanisms - Logging and debugging - Validation errors - Best practices</p> <p>Prerequisites: - Understanding of Pipeline Architecture - Familiarity with Python API - Basic Python exception handling</p> <p>New: Zero Data Loss</p> <p>Docling Graph now implements zero data loss - extraction failures return partial models instead of empty results, ensuring you never lose successfully extracted data.</p>"},{"location":"usage/advanced/error-handling/#exception-hierarchy","title":"Exception Hierarchy","text":"<p>Docling-graph uses a structured exception hierarchy:</p> <pre><code>DoclingGraphError (base)\n\u251c\u2500\u2500 ConfigurationError      # Invalid configuration\n\u251c\u2500\u2500 ClientError            # LLM/API client errors\n\u251c\u2500\u2500 ExtractionError        # Document extraction failures\n\u251c\u2500\u2500 ValidationError        # Data validation failures\n\u251c\u2500\u2500 GraphError            # Graph operation failures\n\u2514\u2500\u2500 PipelineError         # Pipeline execution failures\n</code></pre>"},{"location":"usage/advanced/error-handling/#import-exceptions","title":"Import Exceptions","text":"<pre><code>from docling_graph.exceptions import (\n    DoclingGraphError,\n    ConfigurationError,\n    ClientError,\n    ExtractionError,\n    ValidationError,\n    GraphError,\n    PipelineError\n)\n</code></pre>"},{"location":"usage/advanced/error-handling/#common-error-scenarios","title":"Common Error Scenarios","text":""},{"location":"usage/advanced/error-handling/#1-configuration-errors","title":"1. Configuration Errors","text":"<pre><code>\"\"\"Handle configuration errors.\"\"\"\n\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import ConfigurationError\n\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.MyTemplate\",\n        backend=\"vlm\",\n        inference=\"remote\"  # VLM doesn't support remote!\n    )\n    config.run()\n\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e.message}\")\n    print(f\"Details: {e.details}\")\n    # Fix: Use local inference with VLM\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.MyTemplate\",\n        backend=\"vlm\",\n        inference=\"local\"  # Corrected\n    )\n    config.run()\n</code></pre>"},{"location":"usage/advanced/error-handling/#2-client-errors-api","title":"2. Client Errors (API)","text":"<pre><code>\"\"\"Handle API client errors.\"\"\"\n\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import ClientError\nimport time\n\ndef process_with_retry(source: str, max_retries: int = 3):\n    \"\"\"Process with retry on client errors.\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            config = PipelineConfig(\n                source=source,\n                template=\"templates.MyTemplate\",\n                backend=\"llm\",\n                inference=\"remote\"\n            )\n            config.run()\n            print(\"\u2713 Processing successful\")\n            return\n\n        except ClientError as e:\n            print(f\"Attempt {attempt + 1} failed: {e.message}\")\n\n            if \"rate limit\" in str(e).lower():\n                # Rate limit - wait and retry\n                wait_time = 2 ** attempt  # Exponential backoff\n                print(f\"Rate limited. Waiting {wait_time}s...\")\n                time.sleep(wait_time)\n\n            elif \"authentication\" in str(e).lower():\n                # Auth error - don't retry\n                print(\"Authentication failed. Check API key.\")\n                raise\n\n            elif attempt == max_retries - 1:\n                # Last attempt failed\n                print(\"Max retries reached\")\n                raise\n            else:\n                # Other error - retry\n                time.sleep(1)\n\n# Usage\nprocess_with_retry(\"document.pdf\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#3-extraction-errors","title":"3. Extraction Errors","text":"<pre><code>\"\"\"Handle extraction errors.\"\"\"\n\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import ExtractionError\n\ndef process_with_fallback(source: str):\n    \"\"\"Process with fallback strategy.\"\"\"\n\n    # Try VLM first (faster)\n    try:\n        print(\"Trying VLM extraction...\")\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\",\n            backend=\"vlm\",\n            inference=\"local\"\n        )\n        config.run()\n        print(\"\u2713 VLM extraction successful\")\n        return\n\n    except ExtractionError as e:\n        print(f\"VLM failed: {e.message}\")\n        print(\"Falling back to LLM...\")\n\n    # Fallback to LLM\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\",\n            backend=\"llm\",\n            inference=\"local\"\n        )\n        config.run()\n        print(\"\u2713 LLM extraction successful\")\n\n    except ExtractionError as e:\n        print(f\"Both methods failed: {e.message}\")\n        print(f\"Details: {e.details}\")\n        raise\n\n# Usage\nprocess_with_fallback(\"document.pdf\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#4-validation-errors","title":"4. Validation Errors","text":"<pre><code>\"\"\"Handle validation errors.\"\"\"\n\nfrom pydantic import BaseModel, Field, ValidationError as PydanticValidationError\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import ValidationError\n\nclass StrictTemplate(BaseModel):\n    \"\"\"Template with strict validation.\"\"\"\n    name: str = Field(..., min_length=1)\n    age: int = Field(..., ge=0, le=150)\n    email: str = Field(..., pattern=r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$')\n\ndef process_with_validation_handling(source: str):\n    \"\"\"Process with validation error handling.\"\"\"\n\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.StrictTemplate\"\n        )\n        config.run()\n\n    except ValidationError as e:\n        print(f\"Validation failed: {e.message}\")\n\n        # Check if it's a Pydantic validation error\n        if e.cause and isinstance(e.cause, PydanticValidationError):\n            print(\"\\nValidation errors:\")\n            for error in e.cause.errors():\n                field = error['loc'][0]\n                msg = error['msg']\n                print(f\"  - {field}: {msg}\")\n\n        # Option 1: Use more lenient template\n        print(\"\\nRetrying with lenient template...\")\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.LenientTemplate\"\n        )\n        config.run()\n\n# Usage\nprocess_with_validation_handling(\"document.pdf\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#5-graph-errors","title":"5. Graph Errors","text":"<pre><code>\"\"\"Handle graph construction errors.\"\"\"\n\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import GraphError\n\ndef process_with_graph_validation(source: str):\n    \"\"\"Process with graph validation.\"\"\"\n\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\",\n            export_format=\"cypher\"\n        )\n        config.run()\n\n    except GraphError as e:\n        print(f\"Graph error: {e.message}\")\n        print(f\"Details: {e.details}\")\n\n        # Try alternative export format\n        print(\"Trying CSV export instead...\")\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\",\n            export_format=\"csv\"  # Fallback format\n        )\n        config.run()\n\n# Usage\nprocess_with_graph_validation(\"document.pdf\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#retry-strategies","title":"Retry Strategies","text":""},{"location":"usage/advanced/error-handling/#exponential-backoff","title":"Exponential Backoff","text":"<pre><code>\"\"\"Implement exponential backoff for retries.\"\"\"\n\nimport time\nfrom typing import Callable, Any\nfrom docling_graph.exceptions import ClientError\n\ndef retry_with_backoff(\n    func: Callable,\n    max_retries: int = 3,\n    base_delay: float = 1.0,\n    max_delay: float = 60.0,\n    backoff_factor: float = 2.0\n) -&gt; Any:\n    \"\"\"\n    Retry function with exponential backoff.\n\n    Args:\n        func: Function to retry\n        max_retries: Maximum number of retries\n        base_delay: Initial delay in seconds\n        max_delay: Maximum delay in seconds\n        backoff_factor: Multiplier for delay\n\n    Returns:\n        Function result\n\n    Raises:\n        Exception from last attempt\n    \"\"\"\n    last_exception = None\n\n    for attempt in range(max_retries):\n        try:\n            return func()\n\n        except ClientError as e:\n            last_exception = e\n\n            if attempt == max_retries - 1:\n                # Last attempt\n                break\n\n            # Calculate delay\n            delay = min(base_delay * (backoff_factor ** attempt), max_delay)\n\n            print(f\"Attempt {attempt + 1} failed. Retrying in {delay:.1f}s...\")\n            time.sleep(delay)\n\n    # All retries failed\n    raise last_exception\n\n# Usage\ndef process_document():\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.MyTemplate\",\n        backend=\"llm\",\n        inference=\"remote\"\n    )\n    config.run()\n\nretry_with_backoff(process_document, max_retries=3)\n</code></pre>"},{"location":"usage/advanced/error-handling/#conditional-retry","title":"Conditional Retry","text":"<pre><code>\"\"\"Retry only for specific errors.\"\"\"\n\nfrom docling_graph.exceptions import ClientError, ConfigurationError\n\ndef should_retry(exception: Exception) -&gt; bool:\n    \"\"\"Determine if error is retryable.\"\"\"\n\n    # Don't retry configuration errors\n    if isinstance(exception, ConfigurationError):\n        return False\n\n    # Retry client errors\n    if isinstance(exception, ClientError):\n        error_msg = str(exception).lower()\n\n        # Don't retry auth errors\n        if \"authentication\" in error_msg or \"unauthorized\" in error_msg:\n            return False\n\n        # Retry rate limits and timeouts\n        if \"rate limit\" in error_msg or \"timeout\" in error_msg:\n            return True\n\n    # Default: don't retry\n    return False\n\ndef process_with_conditional_retry(source: str, max_retries: int = 3):\n    \"\"\"Process with conditional retry.\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            config = PipelineConfig(\n                source=source,\n                template=\"templates.MyTemplate\"\n            )\n            config.run()\n            return\n\n        except Exception as e:\n            if not should_retry(e) or attempt == max_retries - 1:\n                raise\n\n            print(f\"Retryable error. Attempt {attempt + 2}...\")\n            time.sleep(2 ** attempt)\n</code></pre>"},{"location":"usage/advanced/error-handling/#logging-and-debugging","title":"Logging and Debugging","text":""},{"location":"usage/advanced/error-handling/#enable-detailed-logging","title":"Enable Detailed Logging","text":"<pre><code>\"\"\"Configure logging for debugging.\"\"\"\n\nimport logging\nfrom docling_graph import PipelineConfig\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('pipeline.log'),\n        logging.StreamHandler()\n    ]\n)\n\nlogger = logging.getLogger('docling_graph')\n\n# Run pipeline with logging\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.MyTemplate\"\n    )\n    config.run()\n\nexcept Exception as e:\n    logger.error(f\"Pipeline failed: {e}\", exc_info=True)\n    raise\n</code></pre>"},{"location":"usage/advanced/error-handling/#debug-mode","title":"Debug Mode","text":"<pre><code>\"\"\"Run pipeline in debug mode.\"\"\"\n\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import DoclingGraphError\n\ndef debug_pipeline(source: str):\n    \"\"\"Run pipeline with detailed error information.\"\"\"\n\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\"\n        )\n        config.run()\n\n    except DoclingGraphError as e:\n        print(\"\\n\" + \"=\"*60)\n        print(\"ERROR DETAILS\")\n        print(\"=\"*60)\n        print(f\"Type: {type(e).__name__}\")\n        print(f\"Message: {e.message}\")\n\n        if e.details:\n            print(\"\\nDetails:\")\n            for key, value in e.details.items():\n                print(f\"  {key}: {value}\")\n\n        if e.cause:\n            print(f\"\\nCaused by: {type(e.cause).__name__}\")\n            print(f\"  {e.cause}\")\n\n        print(\"=\"*60)\n        raise\n\n# Usage\ndebug_pipeline(\"document.pdf\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#error-recovery-patterns","title":"Error Recovery Patterns","text":""},{"location":"usage/advanced/error-handling/#zero-data-loss","title":"Zero Data Loss","text":"<p>Zero data loss ensures extraction failures never result in completely empty results:</p> <pre><code>\"\"\"Handle extraction with zero data loss.\"\"\"\n\nfrom docling_graph import PipelineConfig\nfrom pathlib import Path\nimport json\n\ndef process_with_zero_data_loss(source: str):\n    \"\"\"Process document with zero data loss guarantee.\"\"\"\n\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.Invoice\",\n        processing_mode=\"many-to-one\",\n        output_dir=\"outputs\"\n    )\n\n    try:\n        results = config.run()\n\n        # Check result type\n        if len(results) == 1:\n            print(\"\u2713 Successfully merged into single model\")\n            return {\"status\": \"complete\", \"models\": results}\n        else:\n            print(f\"\u26a0 Got {len(results)} partial models (merge failed)\")\n            print(\"  But data is preserved!\")\n            return {\"status\": \"partial\", \"models\": results}\n\n    except Exception as e:\n        print(f\"Pipeline failed: {e}\")\n\n        # Even on failure, check for partial results\n        output_dir = Path(\"outputs\")\n        if output_dir.exists():\n            # Look for partial model files\n            model_files = list(output_dir.glob(\"*.json\"))\n            if model_files:\n                print(f\"\u2713 Found {len(model_files)} partial model files\")\n\n                # Load partial models\n                partial_models = []\n                for file in model_files:\n                    with open(file) as f:\n                        partial_models.append(json.load(f))\n\n                return {\"status\": \"recovered\", \"models\": partial_models}\n\n        return {\"status\": \"failed\", \"models\": []}\n\n# Usage\nresult = process_with_zero_data_loss(\"invoice.pdf\")\n\nif result[\"status\"] == \"complete\":\n    # Use merged model\n    model = result[\"models\"][0]\n    print(f\"Invoice: {model.get('invoice_number')}\")\n\nelif result[\"status\"] == \"partial\":\n    # Use partial models\n    print(\"Working with partial models:\")\n    for i, model in enumerate(result[\"models\"], 1):\n        print(f\"  Model {i}: {model.get('invoice_number', 'N/A')}\")\n\nelif result[\"status\"] == \"recovered\":\n    # Recovered from files\n    print(\"Recovered partial data from files\")\n\nelse:\n    print(\"No data available\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#partial-model-handling","title":"Partial Model Handling","text":"<pre><code>\"\"\"Work with partial models when merging fails.\"\"\"\n\nfrom docling_graph import PipelineConfig\nfrom typing import List, Dict, Any\n\ndef extract_with_partial_handling(source: str) -&gt; Dict[str, Any]:\n    \"\"\"Extract and handle partial models intelligently.\"\"\"\n\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.Invoice\",\n        processing_mode=\"many-to-one\",\n        llm_consolidation=True  # Try LLM consolidation\n    )\n\n    results = config.run()\n\n    if len(results) == 1:\n        # Success: single merged model\n        return {\n            \"status\": \"merged\",\n            \"invoice_number\": results[0].invoice_number,\n            \"total\": results[0].total,\n            \"line_items\": len(results[0].line_items or []),\n            \"completeness\": 100\n        }\n    else:\n        # Partial: multiple models\n        print(f\"\u26a0 Merge failed, got {len(results)} partial models\")\n\n        # Combine data from partial models\n        combined = {\n            \"status\": \"partial\",\n            \"invoice_number\": None,\n            \"total\": None,\n            \"line_items\": 0,\n            \"completeness\": 0\n        }\n\n        # Extract what we can\n        for model in results:\n            if model.invoice_number and not combined[\"invoice_number\"]:\n                combined[\"invoice_number\"] = model.invoice_number\n            if model.total and not combined[\"total\"]:\n                combined[\"total\"] = model.total\n            if model.line_items:\n                combined[\"line_items\"] += len(model.line_items)\n\n        # Calculate completeness\n        fields_found = sum([\n            bool(combined[\"invoice_number\"]),\n            bool(combined[\"total\"]),\n            bool(combined[\"line_items\"] &gt; 0)\n        ])\n        combined[\"completeness\"] = int((fields_found / 3) * 100)\n\n        return combined\n\n# Usage\nresult = extract_with_partial_handling(\"invoice.pdf\")\n\nprint(f\"Status: {result['status']}\")\nprint(f\"Invoice: {result['invoice_number'] or 'N/A'}\")\nprint(f\"Total: ${result['total'] or 0}\")\nprint(f\"Line items: {result['line_items']}\")\nprint(f\"Completeness: {result['completeness']}%\")\n\nif result['completeness'] &lt; 100:\n    print(\"\u26a0 Incomplete extraction - consider manual review\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>\"\"\"Degrade gracefully on errors.\"\"\"\n\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import ExtractionError\n\ndef process_with_degradation(source: str):\n    \"\"\"Process with graceful degradation.\"\"\"\n\n    results = {\n        \"success\": False,\n        \"method\": None,\n        \"output_dir\": None,\n        \"models\": []\n    }\n\n    # Try best method first\n    methods = [\n        (\"VLM Local\", {\"backend\": \"vlm\", \"inference\": \"local\"}),\n        (\"LLM Local\", {\"backend\": \"llm\", \"inference\": \"local\"}),\n        (\"LLM Remote\", {\"backend\": \"llm\", \"inference\": \"remote\"})\n    ]\n\n    for method_name, config_overrides in methods:\n        try:\n            print(f\"Trying {method_name}...\")\n\n            config = PipelineConfig(\n                source=source,\n                template=\"templates.MyTemplate\",\n                **config_overrides\n            )\n            models = config.run()\n\n            results[\"success\"] = True\n            results[\"method\"] = method_name\n            results[\"output_dir\"] = config.output_dir\n            results[\"models\"] = models\n\n            print(f\"\u2713 Success with {method_name}\")\n            print(f\"  Extracted {len(models)} model(s)\")\n            break\n\n        except ExtractionError as e:\n            print(f\"\u2717 {method_name} failed: {e.message}\")\n            continue\n\n    if not results[\"success\"]:\n        print(\"\u274c All methods failed\")\n\n    return results\n</code></pre>"},{"location":"usage/advanced/error-handling/#partial-success-handling","title":"Partial Success Handling","text":"<pre><code>\"\"\"Handle partial extraction success.\"\"\"\n\nfrom pathlib import Path\nimport json\nfrom docling_graph import PipelineConfig\n\ndef process_with_partial_success(source: str):\n    \"\"\"Process and handle partial results.\"\"\"\n\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\",\n            output_dir=\"outputs\"\n        )\n        models = config.run()\n\n        # Check completeness\n        if len(models) == 1:\n            return {\n                \"status\": \"complete\",\n                \"models\": models,\n                \"output_dir\": config.output_dir\n            }\n        else:\n            return {\n                \"status\": \"partial\",\n                \"models\": models,\n                \"output_dir\": config.output_dir,\n                \"warning\": f\"Got {len(models)} partial models instead of 1\"\n            }\n\n    except Exception as e:\n        print(f\"Pipeline failed: {e}\")\n\n        # Check if partial results exist\n        output_dir = Path(\"outputs\")\n        if output_dir.exists():\n            # Check for extracted data\n            nodes_file = output_dir / \"nodes.csv\"\n            if nodes_file.exists():\n                print(\"\u2713 Partial results available in files\")\n                print(f\"  Nodes: {nodes_file}\")\n\n                # Use partial results\n                return {\n                    \"status\": \"recovered\",\n                    \"models\": [],\n                    \"output_dir\": output_dir\n                }\n\n        return {\"status\": \"failed\", \"models\": [], \"output_dir\": None}\n</code></pre>"},{"location":"usage/advanced/error-handling/#validation-strategies","title":"Validation Strategies","text":""},{"location":"usage/advanced/error-handling/#pre-validation","title":"Pre-Validation","text":"<pre><code>\"\"\"Validate before processing.\"\"\"\n\nfrom pathlib import Path\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import ConfigurationError\n\ndef validate_and_process(source: str, template: str):\n    \"\"\"Validate configuration before processing.\"\"\"\n\n    # Validate source\n    source_path = Path(source)\n    if not source_path.exists():\n        raise ConfigurationError(\n            \"Source file not found\",\n            details={\"source\": source}\n        )\n\n    # Validate template\n    try:\n        # Try to import template\n        module_path, class_name = template.rsplit(\".\", 1)\n        import importlib\n        module = importlib.import_module(module_path)\n        template_class = getattr(module, class_name)\n    except Exception as e:\n        raise ConfigurationError(\n            \"Invalid template\",\n            details={\"template\": template},\n            cause=e\n        )\n\n    # Validate file size\n    size_mb = source_path.stat().st_size / (1024 * 1024)\n    if size_mb &gt; 100:\n        print(f\"\u26a0\ufe0f  Large file: {size_mb:.1f}MB\")\n\n    # Process\n    config = PipelineConfig(\n        source=source,\n        template=template\n    )\n    config.run()\n</code></pre>"},{"location":"usage/advanced/error-handling/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/error-handling/#1-use-specific-exceptions","title":"1. Use Specific Exceptions","text":"<pre><code># \u2705 Good - Catch specific exceptions\ntry:\n    config.run()\nexcept ClientError as e:\n    # Handle API errors\n    pass\nexcept ExtractionError as e:\n    # Handle extraction errors\n    pass\n\n# \u274c Avoid - Catch all exceptions\ntry:\n    config.run()\nexcept Exception:\n    pass  # What went wrong?\n</code></pre>"},{"location":"usage/advanced/error-handling/#2-provide-context","title":"2. Provide Context","text":"<pre><code># \u2705 Good - Detailed error context\nfrom docling_graph.exceptions import ExtractionError\n\ntry:\n    result = extract_data(source)\nexcept Exception as e:\n    raise ExtractionError(\n        \"Failed to extract data\",\n        details={\n            \"source\": source,\n            \"template\": template.__name__,\n            \"stage\": \"extraction\"\n        },\n        cause=e\n    )\n\n# \u274c Avoid - Generic errors\ntry:\n    result = extract_data(source)\nexcept Exception as e:\n    raise Exception(\"Extraction failed\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#3-log-before-raising","title":"3. Log Before Raising","text":"<pre><code># \u2705 Good - Log then raise\nimport logging\nlogger = logging.getLogger(__name__)\n\ntry:\n    config.run()\nexcept ExtractionError as e:\n    logger.error(f\"Extraction failed: {e}\", exc_info=True)\n    raise\n\n# \u274c Avoid - Silent failures\ntry:\n    config.run()\nexcept ExtractionError:\n    pass  # Error lost!\n</code></pre>"},{"location":"usage/advanced/error-handling/#4-clean-up-resources","title":"4. Clean Up Resources","text":"<pre><code># \u2705 Good - Always clean up\ntry:\n    config.run()\nfinally:\n    # Clean up even if error occurs\n    cleanup_resources()\n\n# \u274c Avoid - No cleanup on error\ntry:\n    config.run()\n    cleanup_resources()  # Not called if error!\nexcept:\n    pass\n</code></pre>"},{"location":"usage/advanced/error-handling/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"usage/advanced/error-handling/#common-errors","title":"Common Errors","text":"Error Cause Solution <code>ConfigurationError: VLM backend only supports local inference</code> VLM with remote Use <code>inference=\"local\"</code> <code>ClientError: API key not found</code> Missing API key Set environment variable <code>ExtractionError: Empty extraction result</code> Poor template Improve field descriptions <code>ValidationError: Field required</code> Missing data Make field optional <code>GraphError: Invalid graph structure</code> Bad relationships Check edge definitions"},{"location":"usage/advanced/error-handling/#zero-data-loss-best-practices","title":"Zero Data Loss Best Practices","text":""},{"location":"usage/advanced/error-handling/#1-always-check-result-count","title":"1. Always Check Result Count","text":"<pre><code># \u2705 Good - Check if merge succeeded\nresults = config.run()\n\nif len(results) == 1:\n    # Merged successfully\n    process_merged_model(results[0])\nelse:\n    # Got partial models\n    process_partial_models(results)\n</code></pre>"},{"location":"usage/advanced/error-handling/#2-handle-partial-models-gracefully","title":"2. Handle Partial Models Gracefully","text":"<pre><code># \u2705 Good - Extract what you can from partial models\ndef get_invoice_number(models: List) -&gt; str:\n    \"\"\"Get invoice number from any model that has it.\"\"\"\n    for model in models:\n        if model.invoice_number:\n            return model.invoice_number\n    return \"N/A\"\n</code></pre>"},{"location":"usage/advanced/error-handling/#3-log-partial-results","title":"3. Log Partial Results","text":"<pre><code># \u2705 Good - Log when you get partial results\nimport logging\nlogger = logging.getLogger(__name__)\n\nresults = config.run()\nif len(results) &gt; 1:\n    logger.warning(f\"Got {len(results)} partial models instead of 1\")\n    logger.info(\"Data preserved despite merge failure\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#4-provide-user-feedback","title":"4. Provide User Feedback","text":"<pre><code># \u2705 Good - Inform users about partial results\nresults = config.run()\n\nif len(results) == 1:\n    print(\"\u2713 Extraction complete\")\nelse:\n    print(f\"\u26a0 Extraction partially complete ({len(results)} fragments)\")\n    print(\"  All data preserved - manual review recommended\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#next-steps","title":"Next Steps","text":"<ol> <li>Model Merging \u2192 - Learn about zero data loss</li> <li>Testing \u2192 - Test error handling</li> <li>Exceptions Reference \u2192 - Full exception API</li> <li>Extraction Process \u2192 - Extraction guide</li> </ol>"},{"location":"usage/advanced/error-handling/#related-documentation","title":"Related Documentation","text":"<ul> <li>Model Merging - Zero data loss details</li> <li>Exceptions API - Exception reference</li> <li>Pipeline Architecture - System design</li> <li>Extraction Process - Extraction guide</li> </ul>"},{"location":"usage/advanced/performance-tuning/","title":"Performance Tuning","text":""},{"location":"usage/advanced/performance-tuning/#overview","title":"Overview","text":"<p>Optimize docling-graph pipeline performance for speed, memory efficiency, and resource utilization.</p> <p>What You'll Learn: - Model selection strategies - Batch size optimization - Memory management - GPU utilization - Provider-specific batching - Real tokenizer integration - Profiling techniques</p> <p>Prerequisites: - Understanding of Pipeline Configuration - Familiarity with Extraction Process - Basic knowledge of system resources</p> <p>New Performance Features</p> <p>Recent improvements include:</p> <ul> <li>Provider-Specific Batching: Optimized merge thresholds per provider</li> <li>Real Tokenizer Integration: Accurate token counting with safety margins</li> <li>Enhanced GPU Cleanup: Better memory management for VLM backends</li> <li>Model Capability Detection: Automatic prompt adaptation based on model size</li> </ul>"},{"location":"usage/advanced/performance-tuning/#performance-factors","title":"Performance Factors","text":""},{"location":"usage/advanced/performance-tuning/#key-metrics","title":"Key Metrics","text":"<ol> <li>Throughput: Documents processed per hour</li> <li>Latency: Time per document</li> <li>Memory Usage: RAM and VRAM consumption</li> <li>Cost: API costs for remote inference</li> </ol>"},{"location":"usage/advanced/performance-tuning/#model-selection","title":"Model Selection","text":""},{"location":"usage/advanced/performance-tuning/#local-vs-remote","title":"Local vs Remote","text":"<pre><code># \u2705 Fast - Local inference (no network latency)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"local\",  # Faster for small documents\n    model_override=\"ibm-granite/granite-4.0-1b\"  # Smaller = faster\n)\n\n# \u26a0\ufe0f Slower - Remote inference (network overhead)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"remote\",  # Better for complex documents\n    model_override=\"gpt-4-turbo\"  # More accurate but slower\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#model-size-trade-offs","title":"Model Size Trade-offs","text":"Model Size Speed Accuracy Memory Use Case 1B params \u26a1 Very Fast \ud83d\udfe1 Moderate Accuracy 2-4 GB Simple forms, fast processing 7-8B params \u26a1 Fast \ud83d\udfe2 Acceptable Accuracy 8-16 GB General documents 13B+ params \ud83d\udc22 Slow \ud83d\udc8e High Accuracy 16-32 GB Complex documents <p>Recommendation:</p> <pre><code># Simple documents (forms, invoices)\nmodel_override=\"ibm-granite/granite-4.0-1b\"  # Fast\n\n# General documents\nmodel_override=\"llama-3.1-8b\"  # Balanced\n\n# Complex documents (research papers, legal)\nmodel_override=\"mistral-small-latest\"  # Accurate (remote)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#model-capability-tiers","title":"Model Capability Tiers","text":"<p>Docling Graph automatically detects model capabilities and optimizes performance:</p> <pre><code>from docling_graph import PipelineConfig\n\n# Small model (1B-7B) - SIMPLE tier\n# - Minimal prompts (fewer tokens)\n# - Basic consolidation (faster)\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.2:3b\"  # Optimized for speed\n)\n\n# Medium model (7B-13B) - STANDARD tier\n# - Balanced prompts\n# - Standard consolidation\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\"  # Balanced performance\n)\n\n# Large model (13B+) - ADVANCED tier\n# - Detailed prompts (more tokens but better quality)\n# - Chain of Density consolidation (multi-turn)\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\"  # Optimized for quality\n)\n</code></pre> <p>Performance Impact:</p> Tier Prompt Tokens Consolidation Speed Quality SIMPLE ~200-300 Single-turn \u26a1 Fast \ud83d\udfe1 Good STANDARD ~400-500 Single-turn \u26a1 Fast \ud83d\udfe2 Better ADVANCED ~600-800 Multi-turn \ud83d\udc22 Slower \ud83d\udc8e Best <p>See Model Capabilities for details.</p>"},{"location":"usage/advanced/performance-tuning/#batch-processing","title":"Batch Processing","text":""},{"location":"usage/advanced/performance-tuning/#provider-specific-batching","title":"Provider-Specific Batching","text":"<p>Different providers have different optimal batching strategies:</p> <pre><code>from docling_graph import PipelineConfig\n\n# OpenAI - Aggressive batching (90% merge threshold)\n# Best for: High-volume processing with reliable API\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",\n    use_chunking=True  # Automatically uses threshold\n)\n\n# Ollama/Local - Conservative batching (75% threshold)\n# Best for: Variable performance local models\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n    use_chunking=True  # Automatically uses threshold\n)\n</code></pre> <p>Why Different Thresholds?</p> Provider Threshold Reason OpenAI 90% Robust to near-limit contexts Google 88% Good context handling Anthropic 85% More conservative approach Ollama/Local 75% Variable performance, safer margin <p>Performance Impact: - Higher threshold = Fewer API calls = Faster processing - Lower threshold = More safety margin = Better reliability</p>"},{"location":"usage/advanced/performance-tuning/#optimal-batch-sizes","title":"Optimal Batch Sizes","text":"<pre><code># \u2705 Good - Appropriate batch size\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=True,\n    max_batch_size=5  # Process 5 chunks at a time\n)\n\n# \u274c Avoid - Too large (memory issues)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=True,\n    max_batch_size=50  # May run out of memory\n)\n\n# \u274c Avoid - Too small (slow)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=True,\n    max_batch_size=1  # Underutilizes resources\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#batch-size-guidelines","title":"Batch Size Guidelines","text":"<p>For Local Inference:</p> <pre><code># GPU with 8GB VRAM\nmax_batch_size = 3\n\n# GPU with 16GB VRAM\nmax_batch_size = 5\n\n# GPU with 24GB+ VRAM\nmax_batch_size = 10\n\n# CPU only\nmax_batch_size = 1  # Parallel processing not beneficial\n</code></pre> <p>For Remote APIs:</p> <pre><code># Most APIs handle batching internally\nmax_batch_size = 1  # Send one request at a time\n\n# For APIs with batch endpoints\nmax_batch_size = 10  # Check API documentation\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#memory-management","title":"Memory Management","text":""},{"location":"usage/advanced/performance-tuning/#monitor-memory-usage","title":"Monitor Memory Usage","text":"<pre><code>\"\"\"Monitor memory during processing.\"\"\"\n\nimport psutil\nimport GPUtil\n\ndef log_memory_usage():\n    \"\"\"Log current memory usage.\"\"\"\n    # RAM\n    ram = psutil.virtual_memory()\n    print(f\"RAM: {ram.percent}% ({ram.used / 1e9:.1f}GB / {ram.total / 1e9:.1f}GB)\")\n\n    # GPU\n    try:\n        gpus = GPUtil.getGPUs()\n        for gpu in gpus:\n            print(f\"GPU {gpu.id}: {gpu.memoryUtil*100:.1f}% ({gpu.memoryUsed}MB / {gpu.memoryTotal}MB)\")\n    except:\n        print(\"No GPU detected\")\n\n# Use during pipeline\nfrom docling_graph import PipelineConfig\n\nlog_memory_usage()  # Before\nconfig = PipelineConfig(...)\nconfig.run()\nlog_memory_usage()  # After\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#reduce-memory-usage","title":"Reduce Memory Usage","text":"<pre><code># \u2705 Good - Process in smaller chunks\nconfig = PipelineConfig(\n    source=\"large_document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=True,  # Enable chunking\n    processing_mode=\"one-to-one\"  # Process page by page\n)\n\n# \u274c Avoid - Load entire document\nconfig = PipelineConfig(\n    source=\"large_document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=False,  # Load all at once\n    processing_mode=\"many-to-one\"\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#clean-up-resources","title":"Clean Up Resources","text":"<pre><code>\"\"\"Properly clean up after processing.\"\"\"\n\nfrom docling_graph import PipelineConfig\nimport gc\nimport torch\n\ndef process_with_cleanup(source: str):\n    \"\"\"Process document with proper cleanup.\"\"\"\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.MyTemplate\"\n    )\n\n    try:\n        config.run()\n    finally:\n        # Force garbage collection\n        gc.collect()\n\n        # Clear GPU cache if using PyTorch\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n# Process multiple documents\nfor doc in documents:\n    process_with_cleanup(doc)\n    # Memory is freed between documents\n</code></pre> <p>Enhanced GPU Cleanup for VLM</p> <p>VLM backends now include enhanced GPU memory management:</p> <pre><code>from docling_graph.core.extractors.backends import VlmBackend\n\nbackend = VlmBackend(model_name=\"numind/NuExtract-2.0-8B\")\ntry:\n    models = backend.extract_from_document(source, template)\nfinally:\n    backend.cleanup()  # Enhanced cleanup:\n    # 1. Moves model to CPU before deletion\n    # 2. Explicitly clears CUDA cache\n    # 3. Logs memory usage before/after\n    # 4. Handles multiple GPU devices\n</code></pre> <p>Memory Savings: Up to 8GB VRAM freed per cleanup cycle</p>"},{"location":"usage/advanced/performance-tuning/#gpu-utilization","title":"GPU Utilization","text":""},{"location":"usage/advanced/performance-tuning/#enable-gpu-acceleration","title":"Enable GPU Acceleration","text":"<pre><code># Install with GPU support\nuv sync --extra local\n\n# Verify GPU is available\nuv run python -c \"import torch; print(torch.cuda.is_available())\"\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#optimize-gpu-usage","title":"Optimize GPU Usage","text":"<pre><code># \u2705 Good - Use GPU for local inference\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"local\",  # Will use GPU if available\n    provider_override=\"vllm\"  # Optimized for GPU\n)\n\n# Monitor GPU utilization\nimport torch\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#multi-gpu-support","title":"Multi-GPU Support","text":"<pre><code>\"\"\"Use multiple GPUs for parallel processing.\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom docling_graph import PipelineConfig\n\ndef process_on_gpu(source: str, gpu_id: int):\n    \"\"\"Process document on specific GPU.\"\"\"\n    # Set GPU device\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.MyTemplate\",\n        output_dir=f\"outputs/gpu_{gpu_id}\"\n    )\n    config.run()\n\n# Process documents in parallel on different GPUs\nfrom concurrent.futures import ThreadPoolExecutor\n\ndocuments = [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\", \"doc4.pdf\"]\nwith ThreadPoolExecutor(max_workers=2) as executor:\n    # GPU 0 processes doc1 and doc3\n    # GPU 1 processes doc2 and doc4\n    futures = [\n        executor.submit(process_on_gpu, doc, i % 2)\n        for i, doc in enumerate(documents)\n    ]\n\n    for future in futures:\n        future.result()\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#real-tokenizer-integration","title":"Real Tokenizer Integration","text":""},{"location":"usage/advanced/performance-tuning/#accurate-token-counting","title":"Accurate Token Counting","text":"<p>Docling Graph now uses real tokenizers for accurate token counting:</p> <pre><code>from docling_graph import PipelineConfig\n\n# \u2705 Good - Real tokenizer with safety margin\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n    use_chunking=True  # Uses real tokenizer + 20% safety margin\n)\n</code></pre> <p>Benefits:</p> <ol> <li>Prevents Context Overflows: Accurate token counting prevents exceeding context limits</li> <li>Better Chunk Packing: More efficient use of context window</li> <li>Reduced API Calls: Optimal chunk sizes reduce number of requests</li> <li>Cost Savings: Fewer API calls = lower costs</li> </ol> <p>Performance Comparison:</p> Method Accuracy Context Overflows Chunk Efficiency Character Heuristic ~70% Occasional 60-70% Real Tokenizer 95%+ Rare 80-90%"},{"location":"usage/advanced/performance-tuning/#safety-margins","title":"Safety Margins","text":"<pre><code># Default: 20% safety margin\n# If model has 8192 token context:\n# - Effective limit: 6553 tokens (80% of 8192)\n# - Prevents edge cases and ensures reliability\n\n# For aggressive batching (not recommended):\n# Modify ChunkBatcher.batch_chunks merge_threshold\n# But this may cause context overflows\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#chunking-strategies","title":"Chunking Strategies","text":""},{"location":"usage/advanced/performance-tuning/#disable-chunking-for-small-documents","title":"Disable Chunking for Small Documents","text":"<pre><code># \u2705 Good - No chunking for small docs (&lt; 5 pages)\nconfig = PipelineConfig(\n    source=\"short_document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=False  # Faster for small docs\n)\n\n# \u2705 Good - Enable chunking for large docs (&gt; 5 pages)\nconfig = PipelineConfig(\n    source=\"long_document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=True  # Necessary for large docs\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#optimize-chunk-size","title":"Optimize Chunk Size","text":"<pre><code>\"\"\"Configure chunking for optimal performance.\"\"\"\n\nfrom docling_graph import PipelineConfig\n\n# For fast processing (may sacrifice accuracy)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=True,\n    # Larger chunks = fewer API calls but more memory\n)\n\n# For accurate processing (slower)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=True,\n    # Smaller chunks = more API calls but better accuracy\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#consolidation-strategies","title":"Consolidation Strategies","text":""},{"location":"usage/advanced/performance-tuning/#programmatic-vs-llm-consolidation","title":"Programmatic vs LLM Consolidation","text":"<pre><code># \u2705 Fast - Programmatic merge (no LLM call)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    processing_mode=\"many-to-one\",\n    llm_consolidation=False  # Fast merge\n)\n\n# \u26a0\ufe0f Slow - LLM consolidation (extra API call)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    processing_mode=\"many-to-one\",\n    llm_consolidation=True  # More accurate but slower\n)\n</code></pre> <p>When to Use Each:</p> Strategy Speed Accuracy Use Case Programmatic \u26a1 Very Fast \ud83d\udfe1 Moderate Accuracy Simple merging, lists LLM (Standard) \ud83d\udc22 Slow \ud83d\udfe2 High Accuracy Complex conflicts LLM (Chain of Density) \ud83d\udc0c Very Slow \ud83d\udc8e Highest Accuracy Critical documents"},{"location":"usage/advanced/performance-tuning/#chain-of-density-consolidation","title":"Chain of Density Consolidation","text":"<p>For ADVANCED tier models (13B+), consolidation uses a multi-turn approach:</p> <pre><code># Automatically enabled for large models\nconfig = PipelineConfig(\n    source=\"complex_document.pdf\",\n    template=\"templates.Contract\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",  # ADVANCED tier\n    processing_mode=\"many-to-one\",\n    llm_consolidation=True  # Uses Chain of Density\n)\n</code></pre> <p>Process: 1. Initial Merge (Turn 1): Create first consolidated version 2. Refinement (Turn 2): Identify and resolve conflicts 3. Final Polish (Turn 3): Ensure completeness and accuracy</p> <p>Performance Impact: - Token Usage: 3x more tokens than standard consolidation - Time: 3x longer processing time - Quality: Significantly better for complex documents - Cost: 3x API costs</p> <p>When to Use: - \u2705 Critical documents requiring highest accuracy - \u2705 Complex contracts or legal documents - \u2705 Documents with many conflicts - \u274c Simple forms or invoices (overkill) - \u274c High-volume batch processing (too slow)</p>"},{"location":"usage/advanced/performance-tuning/#profiling","title":"Profiling","text":""},{"location":"usage/advanced/performance-tuning/#profile-pipeline-execution","title":"Profile Pipeline Execution","text":"<pre><code>\"\"\"Profile pipeline to identify bottlenecks.\"\"\"\n\nimport time\nfrom docling_graph import PipelineConfig\n\ndef profile_pipeline(source: str):\n    \"\"\"Profile pipeline execution.\"\"\"\n    stages = {}\n\n    # Overall timing\n    start = time.time()\n\n    # Would need to instrument pipeline stages\n    # This is a simplified example\n\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.MyTemplate\"\n    )\n\n    config.run()\n\n    total_time = time.time() - start\n\n    print(f\"\\nProfiling Results:\")\n    print(f\"Total time: {total_time:.2f}s\")\n    print(f\"Throughput: {1/total_time:.2f} docs/sec\")\n\n# Profile\nprofile_pipeline(\"document.pdf\")\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#use-python-profiler","title":"Use Python Profiler","text":"<pre><code># Profile with cProfile\nuv run python -m cProfile -o profile.stats my_script.py\n\n# Analyze results\nuv run python -m pstats profile.stats\n# Then: sort cumtime, stats 20\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#optimization-checklist","title":"Optimization Checklist","text":""},{"location":"usage/advanced/performance-tuning/#before-processing","title":"Before Processing","text":"<ul> <li> Choose appropriate model size for task</li> <li> Enable GPU if available</li> <li> Set optimal batch size for hardware</li> <li> Disable chunking for small documents</li> <li> Use programmatic merge when possible</li> </ul>"},{"location":"usage/advanced/performance-tuning/#during-processing","title":"During Processing","text":"<ul> <li> Monitor memory usage</li> <li> Watch for GPU utilization</li> <li> Check for bottlenecks</li> <li> Log processing times</li> </ul>"},{"location":"usage/advanced/performance-tuning/#after-processing","title":"After Processing","text":"<ul> <li> Clean up GPU memory</li> <li> Force garbage collection</li> <li> Review performance metrics</li> <li> Identify optimization opportunities</li> </ul>"},{"location":"usage/advanced/performance-tuning/#performance-benchmarks","title":"Performance Benchmarks","text":""},{"location":"usage/advanced/performance-tuning/#typical-processing-times","title":"Typical Processing Times","text":"<p>Small Document (1-5 pages): - VLM Local: 5-15 seconds - LLM Local: 10-30 seconds - LLM Remote: 15-45 seconds</p> <p>Medium Document (10-20 pages): - VLM Local: 30-60 seconds - LLM Local: 1-3 minutes - LLM Remote: 2-5 minutes</p> <p>Large Document (50+ pages): - VLM Local: 2-5 minutes - LLM Local: 5-15 minutes - LLM Remote: 10-30 minutes</p> <p>Times vary based on hardware, model, and document complexity</p>"},{"location":"usage/advanced/performance-tuning/#cost-optimization","title":"Cost Optimization","text":""},{"location":"usage/advanced/performance-tuning/#reduce-api-costs","title":"Reduce API Costs","text":"<pre><code># \u2705 Good - Use local inference when possible\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"local\"  # No API costs\n)\n\n# \u2705 Good - Use smaller remote models\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"remote\",\n    model_override=\"mistral-small-latest\"  # Cheaper than large models\n)\n\n# \u274c Avoid - Unnecessary LLM consolidation\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    llm_consolidation=True  # Extra API call = extra cost\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#estimate-costs","title":"Estimate Costs","text":"<pre><code>\"\"\"Estimate API costs before processing.\"\"\"\n\ndef estimate_cost(num_pages: int, model: str = \"mistral-small-latest\"):\n    \"\"\"Estimate processing cost.\"\"\"\n    # Rough estimates (check provider pricing)\n    costs_per_page = {\n        \"mistral-small-latest\": 0.01,\n        \"gpt-4-turbo\": 0.05,\n        \"gemini-2.5-flash\": 0.005\n    }\n\n    cost_per_page = costs_per_page.get(model, 0.02)\n    total_cost = num_pages * cost_per_page\n\n    print(f\"Estimated cost: ${total_cost:.2f}\")\n    print(f\"Model: {model}\")\n    print(f\"Pages: {num_pages}\")\n\n    return total_cost\n\n# Estimate before processing\nestimate_cost(num_pages=100, model=\"mistral-small-latest\")\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/advanced/performance-tuning/#issue-slow-processing","title":"Issue: Slow Processing","text":"<p>Solutions: 1. Use smaller model 2. Enable GPU acceleration 3. Disable chunking for small docs 4. Use local inference 5. Increase batch size</p>"},{"location":"usage/advanced/performance-tuning/#issue-out-of-memory","title":"Issue: Out of Memory","text":"<p>Solutions: 1. Reduce batch size 2. Enable chunking 3. Use smaller model 4. Process one-to-one instead of many-to-one 5. Clean up between documents</p>"},{"location":"usage/advanced/performance-tuning/#issue-gpu-not-utilized","title":"Issue: GPU Not Utilized","text":"<p>Solutions: 1. Verify GPU installation: <code>torch.cuda.is_available()</code> 2. Install GPU dependencies: <code>uv sync --extra local</code> 3. Check CUDA version compatibility 4. Use vLLM provider for GPU optimization</p>"},{"location":"usage/advanced/performance-tuning/#performance-optimization-summary","title":"Performance Optimization Summary","text":""},{"location":"usage/advanced/performance-tuning/#quick-wins","title":"Quick Wins","text":"<ol> <li>Use Provider-Specific Batching: Automatic optimization per provider</li> <li>Enable Real Tokenizers: Accurate token counting prevents overflows</li> <li>Choose Right Model Tier: Match model size to task complexity</li> <li>Clean Up GPU Memory: Use enhanced cleanup for VLM backends</li> <li>Disable Chunking for Small Docs: Faster processing for &lt; 5 pages</li> </ol>"},{"location":"usage/advanced/performance-tuning/#advanced-optimizations","title":"Advanced Optimizations","text":"<ol> <li>Multi-GPU Processing: Parallel document processing</li> <li>Adaptive Consolidation: Chain of Density for critical documents</li> <li>Memory Profiling: Monitor and optimize resource usage</li> <li>Batch Size Tuning: Optimize for your hardware</li> </ol>"},{"location":"usage/advanced/performance-tuning/#next-steps","title":"Next Steps","text":"<ol> <li>Model Capabilities \u2192 - Learn about adaptive prompting</li> <li>Error Handling \u2192 - Handle errors gracefully</li> <li>Testing \u2192 - Test performance optimizations</li> <li>GPU Setup \u2192 - Configure GPU</li> </ol>"},{"location":"usage/advanced/performance-tuning/#related-documentation","title":"Related Documentation","text":"<ul> <li>Pipeline Configuration - Configuration options</li> <li>Extraction Process - How extraction works</li> <li>Model Capabilities - Adaptive prompting</li> <li>Extraction Backends - Backend selection</li> <li>GPU Setup - GPU configuration</li> </ul>"},{"location":"usage/advanced/testing/","title":"Testing","text":""},{"location":"usage/advanced/testing/#overview","title":"Overview","text":"<p>Test Pydantic templates, custom backends, and pipeline configurations to ensure reliable extraction and graph generation.</p> <p>What You'll Learn: - Template validation testing - Mock backends for testing - Integration testing - CI/CD integration - Test fixtures - Best practices</p> <p>Prerequisites: - Understanding of Schema Definition - Familiarity with Python API - Basic pytest knowledge</p>"},{"location":"usage/advanced/testing/#setup","title":"Setup","text":""},{"location":"usage/advanced/testing/#install-test-dependencies","title":"Install Test Dependencies","text":"<pre><code># Install with test dependencies\nuv sync --extra dev\n\n# Or install pytest separately\nuv add --dev pytest pytest-cov pytest-mock\n</code></pre>"},{"location":"usage/advanced/testing/#project-structure","title":"Project Structure","text":"<pre><code>my_project/\n\u251c\u2500\u2500 templates/\n\u2502   \u2514\u2500\u2500 my_template.py\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py              # Shared fixtures\n\u2502   \u251c\u2500\u2500 test_templates.py        # Template tests\n\u2502   \u251c\u2500\u2500 test_extraction.py       # Extraction tests\n\u2502   \u2514\u2500\u2500 test_integration.py      # End-to-end tests\n\u251c\u2500\u2500 pyproject.toml\n\u2514\u2500\u2500 pytest.ini\n</code></pre>"},{"location":"usage/advanced/testing/#template-testing","title":"Template Testing","text":""},{"location":"usage/advanced/testing/#basic-template-validation","title":"Basic Template Validation","text":"<pre><code>\"\"\"Test Pydantic template validation.\"\"\"\n\nimport pytest\nfrom pydantic import ValidationError\nfrom templates.my_template import Person, Organization\n\ndef test_person_valid():\n    \"\"\"Test valid person creation.\"\"\"\n    person = Person(\n        name=\"John Doe\",\n        age=30,\n        email=\"john@example.com\"\n    )\n\n    assert person.name == \"John Doe\"\n    assert person.age == 30\n    assert person.email == \"john@example.com\"\n\ndef test_person_invalid_age():\n    \"\"\"Test person with invalid age.\"\"\"\n    with pytest.raises(ValidationError) as exc_info:\n        Person(\n            name=\"John Doe\",\n            age=-5,  # Invalid\n            email=\"john@example.com\"\n        )\n\n    errors = exc_info.value.errors()\n    assert any(e['loc'] == ('age',) for e in errors)\n\ndef test_person_invalid_email():\n    \"\"\"Test person with invalid email.\"\"\"\n    with pytest.raises(ValidationError):\n        Person(\n            name=\"John Doe\",\n            age=30,\n            email=\"not-an-email\"  # Invalid\n        )\n\ndef test_person_optional_fields():\n    \"\"\"Test person with optional fields.\"\"\"\n    person = Person(\n        name=\"John Doe\",\n        age=30\n        # email is optional\n    )\n\n    assert person.email is None\n</code></pre>"},{"location":"usage/advanced/testing/#test-field-validators","title":"Test Field Validators","text":"<pre><code>\"\"\"Test custom field validators.\"\"\"\n\nfrom pydantic import BaseModel, Field, field_validator\n\nclass EmailTemplate(BaseModel):\n    \"\"\"Template with email validation.\"\"\"\n\n    email: str = Field(..., description=\"Email address\")\n\n    @field_validator(\"email\")\n    @classmethod\n    def validate_email(cls, v):\n        \"\"\"Validate email format.\"\"\"\n        if \"@\" not in v:\n            raise ValueError(\"Invalid email format\")\n        return v.lower()\n\ndef test_email_validator_valid():\n    \"\"\"Test valid email.\"\"\"\n    template = EmailTemplate(email=\"John@Example.com\")\n    assert template.email == \"john@example.com\"  # Lowercased\n\ndef test_email_validator_invalid():\n    \"\"\"Test invalid email.\"\"\"\n    with pytest.raises(ValidationError) as exc_info:\n        EmailTemplate(email=\"not-an-email\")\n\n    errors = exc_info.value.errors()\n    assert \"Invalid email format\" in str(errors)\n</code></pre>"},{"location":"usage/advanced/testing/#test-relationships","title":"Test Relationships","text":"<pre><code>\"\"\"Test entity relationships.\"\"\"\n\nfrom pydantic import BaseModel, Field, ConfigDict\n\ndef edge(label: str, **kwargs):\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\nclass Address(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    street: str\n    city: str\n\nclass Person(BaseModel):\n    name: str\n    address: Address = edge(label=\"LIVES_AT\")\n\ndef test_relationship_structure():\n    \"\"\"Test relationship is properly defined.\"\"\"\n    person = Person(\n        name=\"John\",\n        address=Address(street=\"123 Main St\", city=\"NYC\")\n    )\n\n    assert person.name == \"John\"\n    assert person.address.street == \"123 Main St\"\n    assert person.address.city == \"NYC\"\n\ndef test_relationship_metadata():\n    \"\"\"Test edge metadata is present.\"\"\"\n    field_info = Person.model_fields[\"address\"]\n    assert field_info.json_schema_extra is not None\n    assert field_info.json_schema_extra.get(\"edge_label\") == \"LIVES_AT\"\n</code></pre>"},{"location":"usage/advanced/testing/#mock-backends","title":"Mock Backends","text":""},{"location":"usage/advanced/testing/#create-mock-backend","title":"Create Mock Backend","text":"<pre><code>\"\"\"Mock backend for testing.\"\"\"\n\nfrom typing import List, Type\nfrom pydantic import BaseModel\n\nclass MockLLMBackend:\n    \"\"\"Mock LLM backend for testing.\"\"\"\n\n    def __init__(self, mock_response: dict | None = None):\n        self.mock_response = mock_response or {}\n        self.call_count = 0\n        self.last_markdown = None\n        self.last_template = None\n\n    def extract_from_markdown(\n        self,\n        markdown: str,\n        template: Type[BaseModel],\n        context: str = \"document\",\n        is_partial: bool = False\n    ) -&gt; BaseModel | None:\n        \"\"\"Mock extraction.\"\"\"\n        self.call_count += 1\n        self.last_markdown = markdown\n        self.last_template = template\n\n        # Return mock response\n        if self.mock_response:\n            return template.model_validate(self.mock_response)\n\n        return None\n\n    def consolidate_from_pydantic_models(\n        self,\n        raw_models: List[BaseModel],\n        programmatic_model: BaseModel,\n        template: Type[BaseModel]\n    ) -&gt; BaseModel | None:\n        \"\"\"Mock consolidation.\"\"\"\n        return programmatic_model\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Mock cleanup.\"\"\"\n        pass\n</code></pre>"},{"location":"usage/advanced/testing/#use-mock-backend","title":"Use Mock Backend","text":"<pre><code>\"\"\"Test extraction with mock backend.\"\"\"\n\nimport pytest\nfrom templates.my_template import Person\n\ndef test_extraction_with_mock():\n    \"\"\"Test extraction using mock backend.\"\"\"\n    # Create mock backend\n    mock_backend = MockLLMBackend(\n        mock_response={\n            \"name\": \"John Doe\",\n            \"age\": 30,\n            \"email\": \"john@example.com\"\n        }\n    )\n\n    # Use mock backend\n    result = mock_backend.extract_from_markdown(\n        markdown=\"Name: John Doe, Age: 30\",\n        template=Person\n    )\n\n    # Verify\n    assert result is not None\n    assert result.name == \"John Doe\"\n    assert result.age == 30\n    assert mock_backend.call_count == 1\n\ndef test_extraction_tracks_calls():\n    \"\"\"Test mock tracks method calls.\"\"\"\n    mock_backend = MockLLMBackend()\n\n    mock_backend.extract_from_markdown(\"test\", Person)\n    mock_backend.extract_from_markdown(\"test2\", Person)\n\n    assert mock_backend.call_count == 2\n    assert mock_backend.last_markdown == \"test2\"\n</code></pre>"},{"location":"usage/advanced/testing/#integration-testing","title":"Integration Testing","text":""},{"location":"usage/advanced/testing/#test-complete-pipeline","title":"Test Complete Pipeline","text":"<pre><code>\"\"\"Integration test for complete pipeline.\"\"\"\n\nimport pytest\nfrom pathlib import Path\nfrom docling_graph import PipelineConfig\n\n@pytest.fixture\ndef sample_document(tmp_path):\n    \"\"\"Create sample document for testing.\"\"\"\n    doc_path = tmp_path / \"test.pdf\"\n    # Create minimal PDF (or use existing test file)\n    doc_path.write_bytes(b\"%PDF-1.4\\n%Test PDF\")\n    return doc_path\n\n@pytest.fixture\ndef output_dir(tmp_path):\n    \"\"\"Create output directory.\"\"\"\n    output = tmp_path / \"outputs\"\n    output.mkdir()\n    return output\n\ndef test_pipeline_execution(sample_document, output_dir):\n    \"\"\"Test pipeline executes successfully.\"\"\"\n    config = PipelineConfig(\n        source=str(sample_document),\n        template=\"templates.my_template.Person\",\n        output_dir=str(output_dir)\n    )\n\n    # Should not raise\n    config.run()\n\n    # Verify outputs exist\n    assert (output_dir / \"nodes.csv\").exists()\n    assert (output_dir / \"edges.csv\").exists()\n\ndef test_pipeline_with_invalid_source():\n    \"\"\"Test pipeline handles invalid source.\"\"\"\n    config = PipelineConfig(\n        source=\"nonexistent.pdf\",\n        template=\"templates.my_template.Person\"\n    )\n\n    with pytest.raises(Exception):\n        config.run()\n</code></pre>"},{"location":"usage/advanced/testing/#test-with-real-documents","title":"Test with Real Documents","text":"<pre><code>\"\"\"Test with real document samples.\"\"\"\n\nimport pytest\nfrom pathlib import Path\nfrom docling_graph import PipelineConfig\n\n@pytest.fixture\ndef invoice_pdf():\n    \"\"\"Path to sample invoice.\"\"\"\n    return Path(\"tests/fixtures/sample_invoice.pdf\")\n\n@pytest.fixture\ndef research_paper_pdf():\n    \"\"\"Path to sample research paper.\"\"\"\n    return Path(\"tests/fixtures/sample_paper.pdf\")\n\ndef test_invoice_extraction(invoice_pdf, tmp_path):\n    \"\"\"Test invoice extraction.\"\"\"\n    if not invoice_pdf.exists():\n        pytest.skip(\"Sample invoice not available\")\n\n    config = PipelineConfig(\n        source=str(invoice_pdf),\n        template=\"templates.invoice.Invoice\",\n        output_dir=str(tmp_path)\n    )\n\n    config.run()\n\n    # Verify invoice-specific outputs\n    nodes_file = tmp_path / \"nodes.csv\"\n    assert nodes_file.exists()\n\n    # Check for expected node types\n    content = nodes_file.read_text()\n    assert \"Invoice\" in content\n    assert \"LineItem\" in content\n\ndef test_research_paper_extraction(research_paper_pdf, tmp_path):\n    \"\"\"Test research paper extraction.\"\"\"\n    if not research_paper_pdf.exists():\n        pytest.skip(\"Sample paper not available\")\n\n    config = PipelineConfig(\n        source=str(research_paper_pdf),\n        template=\"templates.research.ResearchPaper\",\n        output_dir=str(tmp_path),\n        use_chunking=True  # Large document\n    )\n\n    config.run()\n\n    # Verify outputs\n    assert (tmp_path / \"nodes.csv\").exists()\n    assert (tmp_path / \"edges.csv\").exists()\n</code></pre>"},{"location":"usage/advanced/testing/#test-fixtures","title":"Test Fixtures","text":""},{"location":"usage/advanced/testing/#shared-fixtures","title":"Shared Fixtures","text":"<pre><code>\"\"\"Shared test fixtures in conftest.py.\"\"\"\n\nimport pytest\nfrom pathlib import Path\nfrom pydantic import BaseModel, Field\n\n@pytest.fixture\ndef sample_template():\n    \"\"\"Sample template for testing.\"\"\"\n    class TestTemplate(BaseModel):\n        name: str = Field(..., description=\"Name\")\n        value: int = Field(..., description=\"Value\")\n\n    return TestTemplate\n\n@pytest.fixture\ndef sample_data():\n    \"\"\"Sample data for testing.\"\"\"\n    return {\n        \"name\": \"Test\",\n        \"value\": 42\n    }\n\n@pytest.fixture\ndef temp_output_dir(tmp_path):\n    \"\"\"Temporary output directory.\"\"\"\n    output_dir = tmp_path / \"outputs\"\n    output_dir.mkdir()\n    return output_dir\n\n@pytest.fixture\ndef mock_backend():\n    \"\"\"Mock backend for testing.\"\"\"\n    from tests.mocks import MockLLMBackend\n    return MockLLMBackend()\n</code></pre>"},{"location":"usage/advanced/testing/#use-fixtures","title":"Use Fixtures","text":"<pre><code>\"\"\"Use shared fixtures in tests.\"\"\"\n\ndef test_with_fixtures(sample_template, sample_data):\n    \"\"\"Test using fixtures.\"\"\"\n    instance = sample_template.model_validate(sample_data)\n\n    assert instance.name == \"Test\"\n    assert instance.value == 42\n\ndef test_with_output_dir(temp_output_dir):\n    \"\"\"Test with temporary output directory.\"\"\"\n    test_file = temp_output_dir / \"test.txt\"\n    test_file.write_text(\"test\")\n\n    assert test_file.exists()\n</code></pre>"},{"location":"usage/advanced/testing/#parametrized-tests","title":"Parametrized Tests","text":""},{"location":"usage/advanced/testing/#test-multiple-inputs","title":"Test Multiple Inputs","text":"<pre><code>\"\"\"Test with multiple parameter sets.\"\"\"\n\nimport pytest\nfrom templates.my_template import Person\n\n@pytest.mark.parametrize(\"name,age,valid\", [\n    (\"John\", 30, True),\n    (\"Jane\", 25, True),\n    (\"Bob\", -5, False),  # Invalid age\n    (\"\", 30, False),     # Empty name\n])\ndef test_person_validation(name, age, valid):\n    \"\"\"Test person validation with various inputs.\"\"\"\n    if valid:\n        person = Person(name=name, age=age)\n        assert person.name == name\n        assert person.age == age\n    else:\n        with pytest.raises(Exception):\n            Person(name=name, age=age)\n\n@pytest.mark.parametrize(\"backend,inference\", [\n    (\"llm\", \"local\"),\n    (\"llm\", \"remote\"),\n    (\"vlm\", \"local\"),\n])\ndef test_pipeline_configurations(backend, inference, tmp_path):\n    \"\"\"Test different pipeline configurations.\"\"\"\n    from docling_graph import PipelineConfig\n\n    config = PipelineConfig(\n        source=\"test.pdf\",\n        template=\"templates.my_template.Person\",\n        backend=backend,\n        inference=inference,\n        output_dir=str(tmp_path)\n    )\n\n    # Verify configuration\n    assert config.backend == backend\n    assert config.inference == inference\n</code></pre>"},{"location":"usage/advanced/testing/#coverage-testing","title":"Coverage Testing","text":""},{"location":"usage/advanced/testing/#run-with-coverage","title":"Run with Coverage","text":"<pre><code># Run tests with coverage\nuv run pytest --cov=templates --cov=my_module --cov-report=html\n\n# View coverage report\nopen htmlcov/index.html\n</code></pre>"},{"location":"usage/advanced/testing/#coverage-configuration","title":"Coverage Configuration","text":"<pre><code># pytest.ini\n[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\n\n# Coverage settings\n[coverage:run]\nsource = templates,my_module\nomit = tests/*,*/__pycache__/*\n\n[coverage:report]\nexclude_lines =\n    pragma: no cover\n    def __repr__\n    raise AssertionError\n    raise NotImplementedError\n    if __name__ == .__main__.:\n</code></pre>"},{"location":"usage/advanced/testing/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"usage/advanced/testing/#github-actions","title":"GitHub Actions","text":"<pre><code># .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Install uv\n      run: curl -LsSf https://astral.sh/uv/install.sh | sh\n\n    - name: Install dependencies\n      run: uv sync --extra dev\n\n    - name: Run tests\n      run: uv run pytest --cov --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\n</code></pre>"},{"location":"usage/advanced/testing/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/testing/#1-test-edge-cases","title":"1. Test Edge Cases","text":"<pre><code># \u2705 Good - Test edge cases\ndef test_empty_string():\n    \"\"\"Test with empty string.\"\"\"\n    with pytest.raises(ValidationError):\n        Person(name=\"\", age=30)\n\ndef test_boundary_values():\n    \"\"\"Test boundary values.\"\"\"\n    Person(name=\"A\", age=0)    # Minimum\n    Person(name=\"A\"*100, age=150)  # Maximum\n\n# \u274c Avoid - Only happy path\ndef test_person():\n    \"\"\"Test person.\"\"\"\n    person = Person(name=\"John\", age=30)\n    assert person.name == \"John\"\n</code></pre>"},{"location":"usage/advanced/testing/#2-use-descriptive-names","title":"2. Use Descriptive Names","text":"<pre><code># \u2705 Good - Descriptive test names\ndef test_person_validation_rejects_negative_age():\n    \"\"\"Test that negative ages are rejected.\"\"\"\n    pass\n\ndef test_invoice_extraction_handles_multiple_line_items():\n    \"\"\"Test extraction of invoices with multiple items.\"\"\"\n    pass\n\n# \u274c Avoid - Vague names\ndef test_person():\n    pass\n\ndef test_extraction():\n    pass\n</code></pre>"},{"location":"usage/advanced/testing/#3-keep-tests-independent","title":"3. Keep Tests Independent","text":"<pre><code># \u2705 Good - Independent tests\ndef test_create_person():\n    \"\"\"Test person creation.\"\"\"\n    person = Person(name=\"John\", age=30)\n    assert person.name == \"John\"\n\ndef test_validate_person():\n    \"\"\"Test person validation.\"\"\"\n    with pytest.raises(ValidationError):\n        Person(name=\"\", age=30)\n\n# \u274c Avoid - Dependent tests\nperson = None\n\ndef test_create():\n    global person\n    person = Person(name=\"John\", age=30)\n\ndef test_validate():\n    # Depends on test_create!\n    assert person.name == \"John\"\n</code></pre>"},{"location":"usage/advanced/testing/#4-mock-external-dependencies","title":"4. Mock External Dependencies","text":"<pre><code># \u2705 Good - Mock external APIs\n@pytest.fixture\ndef mock_api(monkeypatch):\n    \"\"\"Mock external API.\"\"\"\n    def mock_call(*args, **kwargs):\n        return {\"result\": \"success\"}\n\n    monkeypatch.setattr(\"my_module.api.call\", mock_call)\n\ndef test_with_mock_api(mock_api):\n    \"\"\"Test using mocked API.\"\"\"\n    result = my_function()\n    assert result == \"success\"\n\n# \u274c Avoid - Real API calls in tests\ndef test_with_real_api():\n    \"\"\"Test with real API.\"\"\"\n    result = api.call()  # Slow, unreliable, costs money\n    assert result\n</code></pre>"},{"location":"usage/advanced/testing/#troubleshooting-tests","title":"Troubleshooting Tests","text":""},{"location":"usage/advanced/testing/#issue-tests-fail-locally-but-pass-in-ci","title":"Issue: Tests Fail Locally But Pass in CI","text":"<p>Solution: <pre><code># Use tmp_path fixture for file operations\ndef test_file_operations(tmp_path):\n    \"\"\"Test file operations.\"\"\"\n    test_file = tmp_path / \"test.txt\"\n    test_file.write_text(\"test\")\n    assert test_file.exists()\n\n# Don't use hardcoded paths\n# \u274c test_file = Path(\"/tmp/test.txt\")\n</code></pre></p>"},{"location":"usage/advanced/testing/#issue-slow-tests","title":"Issue: Slow Tests","text":"<p>Solution: <pre><code># Mark slow tests\n@pytest.mark.slow\ndef test_large_document():\n    \"\"\"Test with large document.\"\"\"\n    pass\n\n# Run fast tests only\n# pytest -m \"not slow\"\n</code></pre></p>"},{"location":"usage/advanced/testing/#issue-flaky-tests","title":"Issue: Flaky Tests","text":"<p>Solution: <pre><code># Add retries for flaky tests\n@pytest.mark.flaky(reruns=3)\ndef test_api_call():\n    \"\"\"Test API call (may be flaky).\"\"\"\n    pass\n</code></pre></p>"},{"location":"usage/advanced/testing/#next-steps","title":"Next Steps","text":"<ol> <li>Advanced Topics Index - Back to overview</li> <li>Custom Backends \u2192 - Test custom backends</li> <li>Error Handling \u2192 - Test error scenarios</li> </ol>"},{"location":"usage/advanced/testing/#related-documentation","title":"Related Documentation","text":"<ul> <li>Schema Definition - Template creation</li> <li>Python API - API usage</li> <li>Examples - Example templates</li> </ul>"},{"location":"usage/api/","title":"Python API","text":""},{"location":"usage/api/#overview","title":"Overview","text":"<p>The docling-graph Python API provides programmatic access to the document-to-graph pipeline, enabling integration into Python applications, notebooks, and workflows.</p> <p>Key Components: - <code>run_pipeline()</code> - Main pipeline function - <code>PipelineConfig</code> - Type-safe configuration - Direct module imports for advanced usage</p>"},{"location":"usage/api/#quick-start","title":"Quick Start","text":""},{"location":"usage/api/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Configure pipeline\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    output_dir=\"outputs\"\n)\n\n# Run pipeline\nconfig.run()\n</code></pre>"},{"location":"usage/api/#using-run_pipeline","title":"Using run_pipeline()","text":"<pre><code>from docling_graph import run_pipeline\n\n# Run with dictionary config\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"my_templates.Invoice\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"output_dir\": \"outputs\"\n})\n</code></pre>"},{"location":"usage/api/#installation","title":"Installation","text":"<pre><code># Install with all features\nuv sync --extra all\n\n# Or specific features\nuv sync --extra remote  # Remote APIs\nuv sync --extra local   # Local inference\n</code></pre>"},{"location":"usage/api/#api-components","title":"API Components","text":""},{"location":"usage/api/#1-pipelineconfig","title":"1. PipelineConfig","text":"<p>Type-safe configuration class with validation.</p> <pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\n</code></pre> <p>Learn more: PipelineConfig \u2192</p>"},{"location":"usage/api/#2-run_pipeline","title":"2. run_pipeline()","text":"<p>Main pipeline execution function.</p> <pre><code>from docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\"\n})\n</code></pre> <p>Learn more: run_pipeline() \u2192</p>"},{"location":"usage/api/#3-direct-module-access","title":"3. Direct Module Access","text":"<p>For advanced usage, import modules directly.</p> <pre><code>from docling_graph.core.converters import GraphConverter\nfrom docling_graph.core.exporters import CSVExporter\nfrom docling_graph.core.visualizers import InteractiveVisualizer\n</code></pre> <p>Learn more: API Reference \u2192</p>"},{"location":"usage/api/#common-patterns","title":"Common Patterns","text":""},{"location":"usage/api/#pattern-1-simple-conversion","title":"Pattern 1: Simple Conversion","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.Invoice\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"usage/api/#pattern-2-custom-configuration","title":"Pattern 2: Custom Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"research.pdf\",\n    template=\"templates.Research\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    llm_consolidation=True,\n    output_dir=\"outputs/research\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"usage/api/#pattern-3-batch-processing","title":"Pattern 3: Batch Processing","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\n\ndocuments = Path(\"documents\").glob(\"*.pdf\")\n\nfor doc in documents:\n    config = PipelineConfig(\n        source=str(doc),\n        template=\"templates.Invoice\",\n        output_dir=f\"outputs/{doc.stem}\"\n    )\n\n    try:\n        config.run()\n        print(f\"\u2713 Processed: {doc.name}\")\n    except Exception as e:\n        print(f\"\u2717 Failed: {doc.name} - {e}\")\n</code></pre>"},{"location":"usage/api/#pattern-4-error-handling","title":"Pattern 4: Error Handling","text":"<pre><code>from docling_graph import PipelineConfig\nfrom docling_graph.exceptions import (\n    ConfigurationError,\n    ExtractionError,\n    PipelineError\n)\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\"\n)\n\ntry:\n    config.run()\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e.message}\")\n    print(f\"Details: {e.details}\")\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\nexcept PipelineError as e:\n    print(f\"Pipeline error: {e.message}\")\n</code></pre>"},{"location":"usage/api/#comparison-cli-vs-python-api","title":"Comparison: CLI vs Python API","text":"Feature CLI Python API Ease of Use Simple commands Requires Python code Flexibility Limited to options Full programmatic control Integration Shell scripts Python applications Batch Processing Shell loops Python loops with error handling Configuration YAML + flags PipelineConfig objects Best For Quick tasks, scripts Applications, notebooks, workflows"},{"location":"usage/api/#environment-setup","title":"Environment Setup","text":""},{"location":"usage/api/#api-keys","title":"API Keys","text":"<pre><code>import os\n\n# Set API keys programmatically\nos.environ[\"MISTRAL_API_KEY\"] = \"your-key\"\nos.environ[\"OPENAI_API_KEY\"] = \"your-key\"\n\n# Or use python-dotenv\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    inference=\"remote\"\n)\nconfig.run()\n</code></pre>"},{"location":"usage/api/#python-path","title":"Python Path","text":"<pre><code>import sys\nfrom pathlib import Path\n\n# Add project root to path\nproject_root = Path(__file__).parent.parent\nsys.path.append(str(project_root))\n\n# Now you can import templates\nfrom templates.invoice import Invoice\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=Invoice  # Pass class directly\n)\nconfig.run()\n</code></pre>"},{"location":"usage/api/#output-handling","title":"Output Handling","text":""},{"location":"usage/api/#access-output-files","title":"Access Output Files","text":"<pre><code>from pathlib import Path\nimport json\nimport pandas as pd\n\nfrom docling_graph import PipelineConfig\n\n# Run pipeline\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    output_dir=\"outputs\"\n)\nconfig.run()\n\n# Read outputs\nnodes = pd.read_csv(\"outputs/nodes.csv\")\nedges = pd.read_csv(\"outputs/edges.csv\")\n\nwith open(\"outputs/graph.json\") as f:\n    graph = json.load(f)\n\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nprint(f\"Nodes: {stats['node_count']}\")\nprint(f\"Edges: {stats['edge_count']}\")\n</code></pre>"},{"location":"usage/api/#integration-examples","title":"Integration Examples","text":""},{"location":"usage/api/#flask-web-application","title":"Flask Web Application","text":"<pre><code>from flask import Flask, request, jsonify\nfrom docling_graph import PipelineConfig\nfrom pathlib import Path\nimport uuid\n\napp = Flask(__name__)\n\n@app.route('/convert', methods=['POST'])\ndef convert_document():\n    # Get uploaded file\n    file = request.files['document']\n    template = request.form.get('template', 'templates.Invoice')\n\n    # Save temporarily\n    temp_id = str(uuid.uuid4())\n    temp_path = f\"temp/{temp_id}_{file.filename}\"\n    file.save(temp_path)\n\n    # Process\n    try:\n        config = PipelineConfig(\n            source=temp_path,\n            template=template,\n            output_dir=f\"outputs/{temp_id}\"\n        )\n        config.run()\n\n        return jsonify({\n            \"status\": \"success\",\n            \"output_dir\": f\"outputs/{temp_id}\"\n        })\n    except Exception as e:\n        return jsonify({\n            \"status\": \"error\",\n            \"message\": str(e)\n        }), 500\n    finally:\n        # Cleanup\n        Path(temp_path).unlink(missing_ok=True)\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"usage/api/#jupyter-notebook","title":"Jupyter Notebook","text":"<pre><code># Cell 1: Setup\nfrom docling_graph import PipelineConfig\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Cell 2: Process document\nconfig = PipelineConfig(\n    source=\"research.pdf\",\n    template=\"templates.Research\",\n    output_dir=\"outputs/research\"\n)\nconfig.run()\n\n# Cell 3: Analyze results\nnodes = pd.read_csv(\"outputs/research/nodes.csv\")\nedges = pd.read_csv(\"outputs/research/edges.csv\")\n\nprint(f\"Total nodes: {len(nodes)}\")\nprint(f\"Total edges: {len(edges)}\")\n\n# Cell 4: Visualize\nnode_types = nodes['type'].value_counts()\nnode_types.plot(kind='bar', title='Node Types')\nplt.show()\n</code></pre>"},{"location":"usage/api/#airflow-dag","title":"Airflow DAG","text":"<pre><code>from airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom datetime import datetime\nfrom docling_graph import PipelineConfig\n\ndef process_document(**context):\n    config = PipelineConfig(\n        source=context['params']['source'],\n        template=context['params']['template'],\n        output_dir=f\"outputs/{context['ds']}\"\n    )\n    config.run()\n\nwith DAG(\n    'document_processing',\n    start_date=datetime(2024, 1, 1),\n    schedule_interval='@daily'\n) as dag:\n\n    process_task = PythonOperator(\n        task_id='process_document',\n        python_callable=process_document,\n        params={\n            'source': 'documents/daily.pdf',\n            'template': 'templates.Invoice'\n        }\n    )\n</code></pre>"},{"location":"usage/api/#best-practices","title":"Best Practices","text":""},{"location":"usage/api/#1-use-type-safe-configuration","title":"1. Use Type-Safe Configuration","text":"<pre><code># \u2705 Good - Type-safe with validation\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\"  # Validated\n)\n\n# \u274c Avoid - Dictionary without validation\nconfig = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\",\n    \"backend\": \"invalid\"  # No validation\n}\n</code></pre>"},{"location":"usage/api/#2-handle-errors-gracefully","title":"2. Handle Errors Gracefully","text":"<pre><code># \u2705 Good - Specific error handling\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import ExtractionError\n\ntry:\n    config.run()\nexcept ExtractionError as e:\n    logger.error(f\"Extraction failed: {e.message}\")\n    # Implement retry logic or fallback\n\n# \u274c Avoid - Catching all exceptions\ntry:\n    config.run()\nexcept Exception:\n    pass  # Silent failure\n</code></pre>"},{"location":"usage/api/#3-organize-outputs","title":"3. Organize Outputs","text":"<pre><code># \u2705 Good - Organized structure\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    output_dir=f\"outputs/invoices/{timestamp}\"\n)\n\n# \u274c Avoid - Overwriting outputs\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    output_dir=\"outputs\"  # Same for all\n)\n</code></pre>"},{"location":"usage/api/#next-steps","title":"Next Steps","text":"<p>Explore the Python API in detail:</p> <ol> <li>run_pipeline() \u2192 - Pipeline function</li> <li>PipelineConfig \u2192 - Configuration class</li> <li>Programmatic Examples \u2192 - Code examples</li> <li>Batch Processing \u2192 - Batch patterns</li> </ol> <p>Or continue to: - Examples \u2192 - Real-world examples - API Reference \u2192 - Complete API docs</p>"},{"location":"usage/api/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/api/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\"\n)\nconfig.run()\n</code></pre>"},{"location":"usage/api/#with-options","title":"With Options","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    output_dir=\"outputs\"\n)\nconfig.run()\n</code></pre>"},{"location":"usage/api/#error-handling","title":"Error Handling","text":"<pre><code>from docling_graph.exceptions import PipelineError\n\ntry:\n    config.run()\nexcept PipelineError as e:\n    print(f\"Error: {e.message}\")\n</code></pre>"},{"location":"usage/api/batch-processing/","title":"Batch Processing","text":""},{"location":"usage/api/batch-processing/#overview","title":"Overview","text":"<p>Batch processing enables efficient processing of multiple documents with progress tracking, error handling, and result aggregation.</p> <p>Key Features: - Parallel processing - Progress tracking - Error recovery - Result aggregation - Resource management</p>"},{"location":"usage/api/batch-processing/#basic-batch-processing","title":"Basic Batch Processing","text":""},{"location":"usage/api/batch-processing/#simple-loop","title":"Simple Loop","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\n\ndocuments = Path(\"documents\").glob(\"*.pdf\")\n\nfor doc in documents:\n    config = PipelineConfig(\n        source=str(doc),\n        template=\"templates.Invoice\",\n        output_dir=f\"outputs/{doc.stem}\"\n    )\n\n    try:\n        config.run()\n        print(f\"\u2713 {doc.name}\")\n    except Exception as e:\n        print(f\"\u2717 {doc.name}: {e}\")\n</code></pre>"},{"location":"usage/api/batch-processing/#progress-tracking","title":"Progress Tracking","text":""},{"location":"usage/api/batch-processing/#using-tqdm","title":"Using tqdm","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\nfrom tqdm import tqdm\n\ndocuments = list(Path(\"documents\").glob(\"*.pdf\"))\n\nfor doc in tqdm(documents, desc=\"Processing\"):\n    config = PipelineConfig(\n        source=str(doc),\n        template=\"templates.Invoice\",\n        output_dir=f\"outputs/{doc.stem}\"\n    )\n\n    try:\n        config.run()\n    except Exception as e:\n        tqdm.write(f\"\u2717 {doc.name}: {e}\")\n</code></pre> <p>Install tqdm: <pre><code>uv add tqdm\n</code></pre></p>"},{"location":"usage/api/batch-processing/#error-handling","title":"Error Handling","text":""},{"location":"usage/api/batch-processing/#comprehensive-error-tracking","title":"Comprehensive Error Tracking","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import DoclingGraphError\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef batch_process(input_dir: str, template: str, output_base: str):\n    \"\"\"Process documents with error tracking.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    results = {\n        \"success\": [],\n        \"failed\": [],\n        \"skipped\": []\n    }\n\n    for doc in documents:\n        # Skip if already processed\n        output_dir = Path(output_base) / doc.stem\n        if output_dir.exists():\n            results[\"skipped\"].append(doc.name)\n            logger.info(f\"\u2298 Skipped (already processed): {doc.name}\")\n            continue\n\n        try:\n            config = PipelineConfig(\n                source=str(doc),\n                template=template,\n                output_dir=str(output_dir)\n            )\n\n            config.run()\n            results[\"success\"].append(doc.name)\n            logger.info(f\"\u2713 Success: {doc.name}\")\n\n        except DoclingGraphError as e:\n            results[\"failed\"].append({\n                \"document\": doc.name,\n                \"error\": e.message,\n                \"details\": e.details\n            })\n            logger.error(f\"\u2717 Failed: {doc.name} - {e.message}\")\n\n        except Exception as e:\n            results[\"failed\"].append({\n                \"document\": doc.name,\n                \"error\": str(e),\n                \"details\": None\n            })\n            logger.exception(f\"\u2717 Unexpected error: {doc.name}\")\n\n    # Summary\n    total = len(documents)\n    logger.info(f\"\\n{'='*50}\")\n    logger.info(f\"Total: {total}\")\n    logger.info(f\"Success: {len(results['success'])}\")\n    logger.info(f\"Failed: {len(results['failed'])}\")\n    logger.info(f\"Skipped: {len(results['skipped'])}\")\n\n    return results\n\n# Run batch processing\nresults = batch_process(\n    input_dir=\"documents/invoices\",\n    template=\"templates.invoice.Invoice\",\n    output_base=\"outputs/batch\"\n)\n</code></pre>"},{"location":"usage/api/batch-processing/#parallel-processing","title":"Parallel Processing","text":""},{"location":"usage/api/batch-processing/#using-threadpoolexecutor","title":"Using ThreadPoolExecutor","text":"<pre><code>from pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom docling_graph import PipelineConfig\nfrom tqdm import tqdm\n\ndef process_document(doc_path: Path, template: str, output_base: str):\n    \"\"\"Process single document.\"\"\"\n    try:\n        config = PipelineConfig(\n            source=str(doc_path),\n            template=template,\n            output_dir=f\"{output_base}/{doc_path.stem}\"\n        )\n        config.run()\n        return {\"status\": \"success\", \"document\": doc_path.name}\n    except Exception as e:\n        return {\"status\": \"error\", \"document\": doc_path.name, \"error\": str(e)}\n\ndef parallel_batch_process(\n    input_dir: str,\n    template: str,\n    output_base: str,\n    max_workers: int = 4\n):\n    \"\"\"Process documents in parallel.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    results = {\"success\": [], \"failed\": []}\n\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        # Submit all tasks\n        futures = {\n            executor.submit(process_document, doc, template, output_base): doc\n            for doc in documents\n        }\n\n        # Process results as they complete\n        for future in tqdm(as_completed(futures), total=len(documents), desc=\"Processing\"):\n            result = future.result()\n\n            if result[\"status\"] == \"success\":\n                results[\"success\"].append(result[\"document\"])\n            else:\n                results[\"failed\"].append({\n                    \"document\": result[\"document\"],\n                    \"error\": result[\"error\"]\n                })\n\n    # Summary\n    print(f\"\\nCompleted: {len(results['success'])} succeeded, {len(results['failed'])} failed\")\n    return results\n\n# Run parallel processing\nresults = parallel_batch_process(\n    input_dir=\"documents/invoices\",\n    template=\"templates.invoice.Invoice\",\n    output_base=\"outputs/parallel\",\n    max_workers=4\n)\n</code></pre>"},{"location":"usage/api/batch-processing/#result-aggregation","title":"Result Aggregation","text":""},{"location":"usage/api/batch-processing/#collecting-statistics","title":"Collecting Statistics","text":"<pre><code>from pathlib import Path\nimport json\nimport pandas as pd\nfrom docling_graph import PipelineConfig\n\ndef batch_with_stats(input_dir: str, template: str, output_base: str):\n    \"\"\"Process documents and collect statistics.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    all_stats = []\n\n    for doc in documents:\n        output_dir = Path(output_base) / doc.stem\n\n        try:\n            # Process document\n            config = PipelineConfig(\n                source=str(doc),\n                template=template,\n                output_dir=str(output_dir)\n            )\n            config.run()\n\n            # Load statistics\n            stats_file = output_dir / \"graph_stats.json\"\n            with open(stats_file) as f:\n                stats = json.load(f)\n                stats[\"document\"] = doc.name\n                stats[\"status\"] = \"success\"\n                all_stats.append(stats)\n\n        except Exception as e:\n            all_stats.append({\n                \"document\": doc.name,\n                \"status\": \"error\",\n                \"error\": str(e)\n            })\n\n    # Create summary DataFrame\n    df = pd.DataFrame(all_stats)\n\n    # Save summary\n    summary_file = Path(output_base) / \"batch_summary.csv\"\n    df.to_csv(summary_file, index=False)\n\n    # Print statistics\n    print(\"\\n=== Batch Statistics ===\")\n    print(f\"Total documents: {len(df)}\")\n    print(f\"Successful: {(df['status'] == 'success').sum()}\")\n    print(f\"Failed: {(df['status'] == 'error').sum()}\")\n\n    if 'node_count' in df.columns:\n        successful = df[df['status'] == 'success']\n        print(f\"\\nAverage nodes: {successful['node_count'].mean():.1f}\")\n        print(f\"Average edges: {successful['edge_count'].mean():.1f}\")\n        print(f\"Average density: {successful['density'].mean():.3f}\")\n\n    return df\n\n# Run with statistics\ndf = batch_with_stats(\n    input_dir=\"documents/invoices\",\n    template=\"templates.invoice.Invoice\",\n    output_base=\"outputs/batch_stats\"\n)\n\n# Analyze results\nprint(\"\\nTop 5 documents by node count:\")\nprint(df.nlargest(5, 'node_count')[['document', 'node_count', 'edge_count']])\n</code></pre>"},{"location":"usage/api/batch-processing/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"usage/api/batch-processing/#pattern-1-conditional-processing","title":"Pattern 1: Conditional Processing","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\n\ndef smart_batch_process(input_dir: str, output_base: str):\n    \"\"\"Process documents with template selection.\"\"\"\n    documents = Path(input_dir).glob(\"*\")\n\n    for doc in documents:\n        # Determine template based on filename\n        if \"invoice\" in doc.name.lower():\n            template = \"templates.invoice.Invoice\"\n            backend = \"vlm\"\n        elif \"research\" in doc.name.lower():\n            template = \"templates.research.Research\"\n            backend = \"llm\"\n        else:\n            print(f\"\u2298 Skipped (unknown type): {doc.name}\")\n            continue\n\n        # Process with appropriate config\n        config = PipelineConfig(\n            source=str(doc),\n            template=template,\n            backend=backend,\n            output_dir=f\"{output_base}/{doc.stem}\"\n        )\n\n        try:\n            config.run()\n            print(f\"\u2713 {doc.name}\")\n        except Exception as e:\n            print(f\"\u2717 {doc.name}: {e}\")\n\nsmart_batch_process(\"documents/mixed\", \"outputs/smart\")\n</code></pre>"},{"location":"usage/api/batch-processing/#pattern-2-retry-logic","title":"Pattern 2: Retry Logic","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\nimport time\n\ndef process_with_retry(\n    doc_path: Path,\n    template: str,\n    output_dir: str,\n    max_retries: int = 3,\n    delay: int = 5\n):\n    \"\"\"Process document with retry logic.\"\"\"\n    for attempt in range(1, max_retries + 1):\n        try:\n            config = PipelineConfig(\n                source=str(doc_path),\n                template=template,\n                output_dir=output_dir\n            )\n            config.run()\n            return {\"status\": \"success\", \"attempts\": attempt}\n\n        except Exception as e:\n            if attempt &lt; max_retries:\n                print(f\"Attempt {attempt} failed, retrying in {delay}s...\")\n                time.sleep(delay)\n            else:\n                return {\n                    \"status\": \"error\",\n                    \"attempts\": attempt,\n                    \"error\": str(e)\n                }\n\ndef batch_with_retry(input_dir: str, template: str, output_base: str):\n    \"\"\"Batch process with retry logic.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    results = []\n\n    for doc in documents:\n        result = process_with_retry(\n            doc_path=doc,\n            template=template,\n            output_dir=f\"{output_base}/{doc.stem}\",\n            max_retries=3\n        )\n        result[\"document\"] = doc.name\n        results.append(result)\n\n        status = \"\u2713\" if result[\"status\"] == \"success\" else \"\u2717\"\n        print(f\"{status} {doc.name} (attempts: {result['attempts']})\")\n\n    return results\n\nresults = batch_with_retry(\n    input_dir=\"documents/invoices\",\n    template=\"templates.invoice.Invoice\",\n    output_base=\"outputs/retry\"\n)\n</code></pre>"},{"location":"usage/api/batch-processing/#pattern-3-checkpoint-and-resume","title":"Pattern 3: Checkpoint and Resume","text":"<pre><code>from pathlib import Path\nimport json\nfrom docling_graph import PipelineConfig\n\ndef batch_with_checkpoint(\n    input_dir: str,\n    template: str,\n    output_base: str,\n    checkpoint_file: str = \"checkpoint.json\"\n):\n    \"\"\"Batch process with checkpoint support.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    checkpoint_path = Path(output_base) / checkpoint_file\n\n    # Load checkpoint\n    if checkpoint_path.exists():\n        with open(checkpoint_path) as f:\n            checkpoint = json.load(f)\n        processed = set(checkpoint.get(\"processed\", []))\n        print(f\"Resuming from checkpoint: {len(processed)} already processed\")\n    else:\n        processed = set()\n        checkpoint = {\"processed\": [], \"failed\": []}\n\n    # Process remaining documents\n    for doc in documents:\n        if doc.name in processed:\n            print(f\"\u2298 Skipped (already processed): {doc.name}\")\n            continue\n\n        try:\n            config = PipelineConfig(\n                source=str(doc),\n                template=template,\n                output_dir=f\"{output_base}/{doc.stem}\"\n            )\n            config.run()\n\n            # Update checkpoint\n            checkpoint[\"processed\"].append(doc.name)\n            print(f\"\u2713 {doc.name}\")\n\n        except Exception as e:\n            checkpoint[\"failed\"].append({\n                \"document\": doc.name,\n                \"error\": str(e)\n            })\n            print(f\"\u2717 {doc.name}: {e}\")\n\n        # Save checkpoint after each document\n        with open(checkpoint_path, 'w') as f:\n            json.dump(checkpoint, f, indent=2)\n\n    print(f\"\\nProcessed: {len(checkpoint['processed'])}\")\n    print(f\"Failed: {len(checkpoint['failed'])}\")\n\n    return checkpoint\n\n# Run with checkpoint\ncheckpoint = batch_with_checkpoint(\n    input_dir=\"documents/invoices\",\n    template=\"templates.invoice.Invoice\",\n    output_base=\"outputs/checkpoint\"\n)\n</code></pre>"},{"location":"usage/api/batch-processing/#resource-management","title":"Resource Management","text":""},{"location":"usage/api/batch-processing/#memory-management","title":"Memory Management","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\nimport gc\n\ndef batch_with_memory_management(\n    input_dir: str,\n    template: str,\n    output_base: str,\n    cleanup_interval: int = 10\n):\n    \"\"\"Batch process with memory cleanup.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n\n    for i, doc in enumerate(documents, 1):\n        config = PipelineConfig(\n            source=str(doc),\n            template=template,\n            output_dir=f\"{output_base}/{doc.stem}\"\n        )\n\n        try:\n            config.run()\n            print(f\"\u2713 {doc.name}\")\n        except Exception as e:\n            print(f\"\u2717 {doc.name}: {e}\")\n\n        # Periodic cleanup\n        if i % cleanup_interval == 0:\n            gc.collect()\n            print(f\"[Cleanup after {i} documents]\")\n\nbatch_with_memory_management(\n    input_dir=\"documents/large_batch\",\n    template=\"templates.invoice.Invoice\",\n    output_base=\"outputs/memory_managed\",\n    cleanup_interval=10\n)\n</code></pre>"},{"location":"usage/api/batch-processing/#complete-example","title":"Complete Example","text":""},{"location":"usage/api/batch-processing/#production-ready-batch-processor","title":"Production-Ready Batch Processor","text":"<pre><code>\"\"\"\nProduction-ready batch processor with all features.\n\"\"\"\n\nfrom pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import DoclingGraphError\nimport json\nimport logging\nfrom datetime import datetime\nfrom tqdm import tqdm\nimport pandas as pd\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\nclass BatchProcessor:\n    \"\"\"Production-ready batch document processor.\"\"\"\n\n    def __init__(\n        self,\n        input_dir: str,\n        template: str,\n        output_base: str,\n        max_workers: int = 4,\n        max_retries: int = 3\n    ):\n        self.input_dir = Path(input_dir)\n        self.template = template\n        self.output_base = Path(output_base)\n        self.max_workers = max_workers\n        self.max_retries = max_retries\n\n        # Create output directory\n        self.output_base.mkdir(parents=True, exist_ok=True)\n\n        # Initialize checkpoint\n        self.checkpoint_file = self.output_base / \"checkpoint.json\"\n        self.load_checkpoint()\n\n    def load_checkpoint(self):\n        \"\"\"Load processing checkpoint.\"\"\"\n        if self.checkpoint_file.exists():\n            with open(self.checkpoint_file) as f:\n                self.checkpoint = json.load(f)\n            logger.info(f\"Loaded checkpoint: {len(self.checkpoint['processed'])} processed\")\n        else:\n            self.checkpoint = {\n                \"processed\": [],\n                \"failed\": [],\n                \"started_at\": datetime.now().isoformat()\n            }\n\n    def save_checkpoint(self):\n        \"\"\"Save processing checkpoint.\"\"\"\n        with open(self.checkpoint_file, 'w') as f:\n            json.dump(self.checkpoint, f, indent=2)\n\n    def process_document(self, doc_path: Path):\n        \"\"\"Process single document with retry logic.\"\"\"\n        # Skip if already processed\n        if doc_path.name in self.checkpoint[\"processed\"]:\n            return {\"status\": \"skipped\", \"document\": doc_path.name}\n\n        # Retry loop\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                config = PipelineConfig(\n                    source=str(doc_path),\n                    template=self.template,\n                    output_dir=str(self.output_base / doc_path.stem)\n                )\n\n                config.run()\n\n                # Load statistics\n                stats_file = self.output_base / doc_path.stem / \"graph_stats.json\"\n                with open(stats_file) as f:\n                    stats = json.load(f)\n\n                return {\n                    \"status\": \"success\",\n                    \"document\": doc_path.name,\n                    \"attempts\": attempt,\n                    **stats\n                }\n\n            except DoclingGraphError as e:\n                if attempt &lt; self.max_retries:\n                    logger.warning(f\"Attempt {attempt} failed for {doc_path.name}, retrying...\")\n                    continue\n                else:\n                    return {\n                        \"status\": \"error\",\n                        \"document\": doc_path.name,\n                        \"attempts\": attempt,\n                        \"error\": e.message\n                    }\n            except Exception as e:\n                return {\n                    \"status\": \"error\",\n                    \"document\": doc_path.name,\n                    \"attempts\": attempt,\n                    \"error\": str(e)\n                }\n\n    def process_batch(self):\n        \"\"\"Process all documents in batch.\"\"\"\n        documents = list(self.input_dir.glob(\"*.pdf\"))\n        logger.info(f\"Found {len(documents)} documents to process\")\n\n        results = []\n\n        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n            futures = {\n                executor.submit(self.process_document, doc): doc\n                for doc in documents\n            }\n\n            for future in tqdm(as_completed(futures), total=len(documents), desc=\"Processing\"):\n                result = future.result()\n                results.append(result)\n\n                # Update checkpoint\n                if result[\"status\"] == \"success\":\n                    self.checkpoint[\"processed\"].append(result[\"document\"])\n                elif result[\"status\"] == \"error\":\n                    self.checkpoint[\"failed\"].append({\n                        \"document\": result[\"document\"],\n                        \"error\": result[\"error\"]\n                    })\n\n                self.save_checkpoint()\n\n        # Generate summary\n        self.generate_summary(results)\n\n        return results\n\n    def generate_summary(self, results):\n        \"\"\"Generate processing summary.\"\"\"\n        df = pd.DataFrame(results)\n\n        # Save detailed results\n        summary_file = self.output_base / \"batch_results.csv\"\n        df.to_csv(summary_file, index=False)\n\n        # Print summary\n        logger.info(\"\\n\" + \"=\"*50)\n        logger.info(\"BATCH PROCESSING SUMMARY\")\n        logger.info(\"=\"*50)\n        logger.info(f\"Total documents: {len(df)}\")\n        logger.info(f\"Successful: {(df['status'] == 'success').sum()}\")\n        logger.info(f\"Failed: {(df['status'] == 'error').sum()}\")\n        logger.info(f\"Skipped: {(df['status'] == 'skipped').sum()}\")\n\n        if 'node_count' in df.columns:\n            successful = df[df['status'] == 'success']\n            if len(successful) &gt; 0:\n                logger.info(f\"\\nAverage nodes: {successful['node_count'].mean():.1f}\")\n                logger.info(f\"Average edges: {successful['edge_count'].mean():.1f}\")\n                logger.info(f\"Average density: {successful['density'].mean():.3f}\")\n\n        logger.info(f\"\\nResults saved to: {summary_file}\")\n\n# Usage\nif __name__ == \"__main__\":\n    processor = BatchProcessor(\n        input_dir=\"documents/invoices\",\n        template=\"templates.invoice.Invoice\",\n        output_base=\"outputs/production_batch\",\n        max_workers=4,\n        max_retries=3\n    )\n\n    results = processor.process_batch()\n</code></pre> <p>Run: <pre><code>uv run python batch_processor.py\n</code></pre></p>"},{"location":"usage/api/batch-processing/#best-practices","title":"Best Practices","text":""},{"location":"usage/api/batch-processing/#1-use-progress-tracking","title":"1. Use Progress Tracking","text":"<pre><code># \u2705 Good - Visual progress\nfrom tqdm import tqdm\n\nfor doc in tqdm(documents, desc=\"Processing\"):\n    config.run()\n\n# \u274c Avoid - No feedback\nfor doc in documents:\n    config.run()\n</code></pre>"},{"location":"usage/api/batch-processing/#2-implement-error-recovery","title":"2. Implement Error Recovery","text":"<pre><code># \u2705 Good - Checkpoint and resume\ncheckpoint = load_checkpoint()\nfor doc in documents:\n    if doc.name not in checkpoint[\"processed\"]:\n        process(doc)\n        checkpoint[\"processed\"].append(doc.name)\n        save_checkpoint(checkpoint)\n\n# \u274c Avoid - Start from scratch on failure\nfor doc in documents:\n    process(doc)\n</code></pre>"},{"location":"usage/api/batch-processing/#3-aggregate-results","title":"3. Aggregate Results","text":"<pre><code># \u2705 Good - Collect statistics\nresults = []\nfor doc in documents:\n    result = process(doc)\n    results.append(result)\n\ndf = pd.DataFrame(results)\ndf.to_csv(\"summary.csv\")\n\n# \u274c Avoid - No summary\nfor doc in documents:\n    process(doc)\n</code></pre>"},{"location":"usage/api/batch-processing/#next-steps","title":"Next Steps","text":"<ol> <li>Examples \u2192 - Real-world examples</li> <li>Advanced Topics \u2192 - Custom backends</li> <li>API Reference \u2192 - Complete API docs</li> </ol>"},{"location":"usage/api/batch-processing/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/api/batch-processing/#basic-batch","title":"Basic Batch","text":"<pre><code>for doc in Path(\"documents\").glob(\"*.pdf\"):\n    config = PipelineConfig(\n        source=str(doc),\n        template=\"templates.Invoice\",\n        output_dir=f\"outputs/{doc.stem}\"\n    )\n    config.run()\n</code></pre>"},{"location":"usage/api/batch-processing/#with-progress","title":"With Progress","text":"<pre><code>from tqdm import tqdm\n\nfor doc in tqdm(documents, desc=\"Processing\"):\n    config.run()\n</code></pre>"},{"location":"usage/api/batch-processing/#parallel-processing_1","title":"Parallel Processing","text":"<pre><code>from concurrent.futures import ThreadPoolExecutor\n\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    futures = [executor.submit(process, doc) for doc in documents]\n    for future in as_completed(futures):\n        result = future.result()\n</code></pre>"},{"location":"usage/api/pipeline-config/","title":"PipelineConfig","text":""},{"location":"usage/api/pipeline-config/#overview","title":"Overview","text":"<p><code>PipelineConfig</code> is a type-safe configuration class built with Pydantic that provides validation, defaults, and IDE autocomplete for pipeline configuration.</p> <p>Key Features: - Type validation - Default values - IDE autocomplete - Validation errors - Convenience methods</p>"},{"location":"usage/api/pipeline-config/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Create configuration\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\n\n# Run pipeline\nconfig.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#constructor-parameters","title":"Constructor Parameters","text":""},{"location":"usage/api/pipeline-config/#required-parameters","title":"Required Parameters","text":"Parameter Type Description <code>source</code> <code>str | Path</code> Path to source document <code>template</code> <code>str | Type[BaseModel]</code> Pydantic template (dotted path or class)"},{"location":"usage/api/pipeline-config/#core-settings","title":"Core Settings","text":"Parameter Type Default Description <code>backend</code> <code>Literal[\"llm\", \"vlm\"]</code> <code>\"llm\"</code> Backend type <code>inference</code> <code>Literal[\"local\", \"remote\"]</code> <code>\"local\"</code> Inference mode <code>processing_mode</code> <code>Literal[\"one-to-one\", \"many-to-one\"]</code> <code>\"many-to-one\"</code> Processing strategy"},{"location":"usage/api/pipeline-config/#docling-settings","title":"Docling Settings","text":"Parameter Type Default Description <code>docling_config</code> <code>Literal[\"ocr\", \"vision\"]</code> <code>\"ocr\"</code> Docling pipeline type"},{"location":"usage/api/pipeline-config/#model-overrides","title":"Model Overrides","text":"Parameter Type Default Description <code>model_override</code> <code>str | None</code> <code>None</code> Override model name <code>provider_override</code> <code>str | None</code> <code>None</code> Override provider name"},{"location":"usage/api/pipeline-config/#extraction-settings","title":"Extraction Settings","text":"Parameter Type Default Description <code>use_chunking</code> <code>bool</code> <code>True</code> Enable document chunking <code>llm_consolidation</code> <code>bool</code> <code>False</code> Enable LLM consolidation <code>max_batch_size</code> <code>int</code> <code>1</code> Maximum batch size"},{"location":"usage/api/pipeline-config/#export-settings","title":"Export Settings","text":"Parameter Type Default Description <code>export_format</code> <code>Literal[\"csv\", \"cypher\"]</code> <code>\"csv\"</code> Export format <code>export_docling</code> <code>bool</code> <code>True</code> Export Docling outputs <code>export_docling_json</code> <code>bool</code> <code>True</code> Export Docling JSON <code>export_markdown</code> <code>bool</code> <code>True</code> Export markdown <code>export_per_page_markdown</code> <code>bool</code> <code>False</code> Export per-page markdown"},{"location":"usage/api/pipeline-config/#graph-settings","title":"Graph Settings","text":"Parameter Type Default Description <code>reverse_edges</code> <code>bool</code> <code>False</code> Create bidirectional edges"},{"location":"usage/api/pipeline-config/#output-settings","title":"Output Settings","text":"Parameter Type Default Description <code>output_dir</code> <code>str | Path</code> <code>\"outputs\"</code> Output directory path"},{"location":"usage/api/pipeline-config/#models-configuration","title":"Models Configuration","text":"Parameter Type Default Description <code>models</code> <code>ModelsConfig</code> Default models Models configuration"},{"location":"usage/api/pipeline-config/#methods","title":"Methods","text":""},{"location":"usage/api/pipeline-config/#run","title":"run()","text":"<p>Execute the pipeline with this configuration.</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\"\n)\n\nconfig.run()\n</code></pre> <p>Returns: <code>None</code></p> <p>Raises: <code>PipelineError</code>, <code>ConfigurationError</code>, <code>ExtractionError</code></p>"},{"location":"usage/api/pipeline-config/#to_dict","title":"to_dict()","text":"<p>Convert configuration to dictionary format.</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\"\n)\n\nconfig_dict = config.to_dict()\nprint(config_dict)\n# {\n#     \"source\": \"document.pdf\",\n#     \"template\": \"templates.Invoice\",\n#     \"backend\": \"llm\",\n#     ...\n# }\n</code></pre> <p>Returns: <code>Dict[str, Any]</code></p>"},{"location":"usage/api/pipeline-config/#complete-examples","title":"Complete Examples","text":""},{"location":"usage/api/pipeline-config/#example-1-minimal-configuration","title":"Example 1: Minimal Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Only required parameters\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.Invoice\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#example-2-remote-llm","title":"Example 2: Remote LLM","text":"<pre><code>import os\nfrom docling_graph import PipelineConfig\n\n# Set API key\nos.environ[\"MISTRAL_API_KEY\"] = \"your-key\"\n\n# Configure for remote inference\nconfig = PipelineConfig(\n    source=\"research.pdf\",\n    template=\"templates.Research\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    llm_consolidation=True,\n    output_dir=\"outputs/research\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#example-3-local-vlm","title":"Example 3: Local VLM","text":"<pre><code>from docling_graph import PipelineConfig\n\n# VLM for form extraction\nconfig = PipelineConfig(\n    source=\"form.jpg\",\n    template=\"templates.IDCard\",\n    backend=\"vlm\",\n    inference=\"local\",  # VLM only supports local\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\",\n    output_dir=\"outputs/form\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#example-4-template-as-class","title":"Example 4: Template as Class","text":"<pre><code>from pydantic import BaseModel, Field\nfrom docling_graph import PipelineConfig\n\n# Define template inline\nclass Invoice(BaseModel):\n    \"\"\"Invoice template.\"\"\"\n    invoice_number: str = Field(description=\"Invoice number\")\n    total: float = Field(description=\"Total amount\")\n\n# Pass class directly\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=Invoice,  # Class instead of string\n    output_dir=\"outputs/invoice\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#example-5-custom-models-configuration","title":"Example 5: Custom Models Configuration","text":"<pre><code>from docling_graph import PipelineConfig, ModelsConfig, ModelConfig\n\n# Custom models configuration\nmodels = ModelsConfig(\n    llm=LLMConfig(\n        remote=ModelConfig(\n            default_model=\"gpt-4-turbo\",\n            provider=\"openai\"\n        )\n    )\n)\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    models=models\n)\n\nconfig.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#validation","title":"Validation","text":""},{"location":"usage/api/pipeline-config/#automatic-validation","title":"Automatic Validation","text":"<p>PipelineConfig validates parameters at creation:</p> <pre><code>from docling_graph import PipelineConfig\n\n# This raises ValidationError\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.Invoice\",\n        backend=\"invalid\"  # Invalid value\n    )\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")\n</code></pre>"},{"location":"usage/api/pipeline-config/#vlm-constraints","title":"VLM Constraints","text":"<p>VLM backend only supports local inference:</p> <pre><code>from docling_graph import PipelineConfig\n\n# This raises ValidationError\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.Invoice\",\n        backend=\"vlm\",\n        inference=\"remote\"  # Not allowed for VLM\n    )\nexcept ValueError as e:\n    print(f\"VLM only supports local inference: {e}\")\n</code></pre>"},{"location":"usage/api/pipeline-config/#type-safety-benefits","title":"Type Safety Benefits","text":""},{"location":"usage/api/pipeline-config/#ide-autocomplete","title":"IDE Autocomplete","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\",  # IDE suggests: \"llm\" | \"vlm\"\n    inference=\"remote\",  # IDE suggests: \"local\" | \"remote\"\n    processing_mode=\"many-to-one\"  # IDE suggests valid options\n)\n</code></pre>"},{"location":"usage/api/pipeline-config/#type-checking","title":"Type Checking","text":"<pre><code>from docling_graph import PipelineConfig\n\n# mypy will catch this error\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    use_chunking=\"yes\"  # Error: expected bool, got str\n)\n</code></pre>"},{"location":"usage/api/pipeline-config/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/api/pipeline-config/#programmatic-configuration","title":"Programmatic Configuration","text":"<pre><code>from docling_graph import PipelineConfig\nfrom pathlib import Path\n\ndef create_config(source: str, template: str, use_remote: bool = False):\n    \"\"\"Factory function for creating configurations.\"\"\"\n    return PipelineConfig(\n        source=source,\n        template=template,\n        backend=\"llm\",\n        inference=\"remote\" if use_remote else \"local\",\n        provider_override=\"mistral\" if use_remote else \"ollama\",\n        output_dir=f\"outputs/{Path(source).stem}\"\n    )\n\n# Use factory\nconfig = create_config(\"document.pdf\", \"templates.Invoice\", use_remote=True)\nconfig.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#configuration-templates","title":"Configuration Templates","text":"<pre><code>from docling_graph import PipelineConfig\n\n# Base configuration\nBASE_CONFIG = {\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"provider_override\": \"mistral\",\n    \"use_chunking\": True,\n    \"llm_consolidation\": False\n}\n\n# Create specific configurations\ndef process_invoice(source: str):\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.Invoice\",\n        **BASE_CONFIG,\n        output_dir=f\"outputs/invoices/{Path(source).stem}\"\n    )\n    config.run()\n\ndef process_research(source: str):\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.Research\",\n        **BASE_CONFIG,\n        llm_consolidation=True,  # Override for research\n        output_dir=f\"outputs/research/{Path(source).stem}\"\n    )\n    config.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#dynamic-configuration","title":"Dynamic Configuration","text":"<pre><code>from docling_graph import PipelineConfig\nfrom pathlib import Path\n\ndef smart_config(source: str) -&gt; PipelineConfig:\n    \"\"\"Create configuration based on document characteristics.\"\"\"\n    path = Path(source)\n    file_size = path.stat().st_size\n\n    # Choose settings based on file size\n    if file_size &lt; 1_000_000:  # &lt; 1MB\n        use_chunking = False\n        processing = \"one-to-one\"\n    else:\n        use_chunking = True\n        processing = \"many-to-one\"\n\n    # Choose backend based on extension\n    if path.suffix.lower() in ['.jpg', '.png']:\n        backend = \"vlm\"\n    else:\n        backend = \"llm\"\n\n    return PipelineConfig(\n        source=source,\n        template=\"templates.Invoice\",\n        backend=backend,\n        processing_mode=processing,\n        use_chunking=use_chunking,\n        output_dir=f\"outputs/{path.stem}\"\n    )\n\n# Use smart configuration\nconfig = smart_config(\"document.pdf\")\nconfig.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#configuration-patterns","title":"Configuration Patterns","text":""},{"location":"usage/api/pipeline-config/#pattern-1-environment-based-configuration","title":"Pattern 1: Environment-Based Configuration","text":"<pre><code>import os\nfrom docling_graph import PipelineConfig\n\ndef get_config(source: str, template: str) -&gt; PipelineConfig:\n    \"\"\"Get configuration based on environment.\"\"\"\n    env = os.getenv(\"ENVIRONMENT\", \"development\")\n\n    if env == \"production\":\n        return PipelineConfig(\n            source=source,\n            template=template,\n            backend=\"llm\",\n            inference=\"remote\",\n            provider_override=\"mistral\",\n            model_override=\"mistral-large-latest\",\n            llm_consolidation=True\n        )\n    else:\n        return PipelineConfig(\n            source=source,\n            template=template,\n            backend=\"llm\",\n            inference=\"local\",\n            provider_override=\"ollama\",\n            llm_consolidation=False\n        )\n\nconfig = get_config(\"document.pdf\", \"templates.Invoice\")\nconfig.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#pattern-2-configuration-builder","title":"Pattern 2: Configuration Builder","text":"<pre><code>from docling_graph import PipelineConfig\n\nclass ConfigBuilder:\n    \"\"\"Builder pattern for PipelineConfig.\"\"\"\n\n    def __init__(self, source: str, template: str):\n        self.config_dict = {\n            \"source\": source,\n            \"template\": template\n        }\n\n    def with_remote_llm(self, provider: str, model: str):\n        self.config_dict.update({\n            \"backend\": \"llm\",\n            \"inference\": \"remote\",\n            \"provider_override\": provider,\n            \"model_override\": model\n        })\n        return self\n\n    def with_chunking(self, enabled: bool = True):\n        self.config_dict[\"use_chunking\"] = enabled\n        return self\n\n    def with_consolidation(self, enabled: bool = True):\n        self.config_dict[\"llm_consolidation\"] = enabled\n        return self\n\n    def with_output_dir(self, output_dir: str):\n        self.config_dict[\"output_dir\"] = output_dir\n        return self\n\n    def build(self) -&gt; PipelineConfig:\n        return PipelineConfig(**self.config_dict)\n\n# Use builder\nconfig = (ConfigBuilder(\"document.pdf\", \"templates.Invoice\")\n    .with_remote_llm(\"mistral\", \"mistral-large-latest\")\n    .with_chunking(True)\n    .with_consolidation(True)\n    .with_output_dir(\"outputs/research\")\n    .build())\n\nconfig.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#best-practices","title":"Best Practices","text":""},{"location":"usage/api/pipeline-config/#1-use-type-safe-configuration","title":"1. Use Type-Safe Configuration","text":"<pre><code># \u2705 Good - Type-safe with validation\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\"  # Validated at creation\n)\n\n# \u274c Avoid - Dictionary without validation\nconfig = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\",\n    \"backend\": \"invalid\"  # No validation\n}\n</code></pre>"},{"location":"usage/api/pipeline-config/#2-use-defaults-when-possible","title":"2. Use Defaults When Possible","text":"<pre><code># \u2705 Good - Rely on sensible defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\"\n    # Uses default backend, inference, etc.\n)\n\n# \u274c Avoid - Specifying every parameter\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\",\n    inference=\"local\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    # ... all defaults\n)\n</code></pre>"},{"location":"usage/api/pipeline-config/#3-organize-output-directories","title":"3. Organize Output Directories","text":"<pre><code># \u2705 Good - Organized structure\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    output_dir=f\"outputs/invoices/{timestamp}\"\n)\n\n# \u274c Avoid - Overwriting outputs\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    output_dir=\"outputs\"  # Same for all\n)\n</code></pre>"},{"location":"usage/api/pipeline-config/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/api/pipeline-config/#issue-validation-error","title":"Issue: Validation Error","text":"<p>Error: <pre><code>ValidationError: 1 validation error for PipelineConfig\nbackend\n  Input should be 'llm' or 'vlm'\n</code></pre></p> <p>Solution: <pre><code># Use valid values\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\"  # Valid: \"llm\" or \"vlm\"\n)\n</code></pre></p>"},{"location":"usage/api/pipeline-config/#issue-vlm-remote-inference","title":"Issue: VLM Remote Inference","text":"<p>Error: <pre><code>ValueError: VLM backend currently only supports local inference\n</code></pre></p> <p>Solution: <pre><code># VLM only supports local\nconfig = PipelineConfig(\n    source=\"form.jpg\",\n    template=\"templates.IDCard\",\n    backend=\"vlm\",\n    inference=\"local\"  # Must be local for VLM\n)\n</code></pre></p>"},{"location":"usage/api/pipeline-config/#next-steps","title":"Next Steps","text":"<ol> <li>Programmatic Examples \u2192 - More code examples</li> <li>Batch Processing \u2192 - Batch patterns</li> <li>API Reference \u2192 - Complete API docs</li> </ol>"},{"location":"usage/api/pipeline-config/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/api/pipeline-config/#minimal-configuration","title":"Minimal Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\"\n)\nconfig.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#common-options","title":"Common Options","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    llm_consolidation=True,\n    output_dir=\"outputs\"\n)\n</code></pre>"},{"location":"usage/api/pipeline-config/#all-parameters","title":"All Parameters","text":"<p>See Configuration Reference for complete parameter list.</p>"},{"location":"usage/api/programmatic-examples/","title":"Programmatic Examples","text":""},{"location":"usage/api/programmatic-examples/#overview","title":"Overview","text":"<p>This guide provides complete, ready-to-run Python examples for common document processing scenarios using the docling-graph API.</p> <p>All examples use <code>uv run python</code> for execution.</p>"},{"location":"usage/api/programmatic-examples/#quick-reference","title":"Quick Reference","text":"Example Use Case Backend Simple Invoice Basic extraction LLM (Remote) Local Processing Offline processing LLM (Local) VLM Form Extraction Image forms VLM (Local) Research Paper Complex documents LLM (Remote) Batch Processing Multiple documents Any Error Handling Production code Any Flask Integration Web application Any Jupyter Notebook Interactive analysis Any"},{"location":"usage/api/programmatic-examples/#example-1-simple-invoice-extraction","title":"Example 1: Simple Invoice Extraction","text":"<p>Use Case: Extract structured data from an invoice using remote LLM.</p> <p>File: <code>examples/simple_invoice.py</code></p> <pre><code>\"\"\"\nSimple invoice extraction using remote LLM.\n\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom docling_graph import PipelineConfig\n\n# Set API key\nos.environ[\"MISTRAL_API_KEY\"] = \"your-api-key\"\n\n# Configure pipeline\nconfig = PipelineConfig(\n    source=\"documents/invoice.pdf\",\n    template=\"templates.invoice.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-small-latest\",\n    output_dir=\"outputs/invoice\"\n)\n\n# Run pipeline\nprint(\"Processing invoice...\")\nconfig.run()\nprint(f\"\u2713 Complete! Results in: {config.output_dir}\")\n\n# Read results\nimport pandas as pd\nnodes = pd.read_csv(f\"{config.output_dir}/nodes.csv\")\nprint(f\"\\nExtracted {len(nodes)} nodes\")\nprint(nodes.head())\n</code></pre> <p>Run: <pre><code>uv run python examples/simple_invoice.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-2-local-processing-with-ollama","title":"Example 2: Local Processing with Ollama","text":"<p>Use Case: Process documents locally without API costs.</p> <p>File: <code>examples/local_ollama.py</code></p> <pre><code>\"\"\"\nLocal document processing using Ollama.\n\"\"\"\n\nfrom docling_graph import PipelineConfig\n\n# Ensure Ollama is running:\n# ollama serve\n# ollama pull llama3:8b\n\nconfig = PipelineConfig(\n    source=\"documents/research.pdf\",\n    template=\"templates.research.Research\",\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3:8b\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    llm_consolidation=False,  # Faster\n    output_dir=\"outputs/research\"\n)\n\nprint(\"Processing with Ollama...\")\ntry:\n    config.run()\n    print(\"\u2713 Complete!\")\nexcept Exception as e:\n    print(f\"\u2717 Error: {e}\")\n    print(\"Hint: Is Ollama running? (ollama serve)\")\n</code></pre> <p>Run: <pre><code># Start Ollama first\nollama serve\n\n# In another terminal\nuv run python examples/local_ollama.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-3-vlm-form-extraction","title":"Example 3: VLM Form Extraction","text":"<p>Use Case: Extract data from image forms using vision model.</p> <p>File: <code>examples/vlm_form.py</code></p> <pre><code>\"\"\"\nVLM extraction from image forms.\n\"\"\"\n\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"documents/id_card.jpg\",\n    template=\"templates.id_card.IDCard\",\n    backend=\"vlm\",\n    inference=\"local\",  # VLM only supports local\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\",\n    output_dir=\"outputs/id_card\"\n)\n\nprint(\"Extracting from image...\")\nconfig.run()\nprint(\"\u2713 Complete!\")\n\n# Display results\nimport json\nwith open(\"outputs/id_card/graph.json\") as f:\n    graph = json.load(f)\n    print(f\"\\nExtracted {len(graph['nodes'])} nodes\")\n    for node in graph['nodes'][:5]:\n        print(f\"  - {node['label']}: {node.get('properties', {})}\")\n</code></pre> <p>Run: <pre><code>uv run python examples/vlm_form.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-4-research-paper-with-consolidation","title":"Example 4: Research Paper with Consolidation","text":"<p>Use Case: High-accuracy extraction from complex documents.</p> <p>File: <code>examples/research_consolidation.py</code></p> <pre><code>\"\"\"\nResearch paper extraction with LLM consolidation.\n\"\"\"\n\nimport os\nfrom docling_graph import PipelineConfig\n\nos.environ[\"MISTRAL_API_KEY\"] = \"your-api-key\"\n\nconfig = PipelineConfig(\n    source=\"documents/research_paper.pdf\",\n    template=\"templates.research.Research\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    llm_consolidation=True,  # Higher accuracy\n    docling_config=\"vision\",  # Better for complex layouts\n    output_dir=\"outputs/research\"\n)\n\nprint(\"Processing research paper (this may take a few minutes)...\")\nconfig.run()\nprint(\"\u2713 Complete!\")\n\n# Analyze results\nimport json\nwith open(\"outputs/research/graph_stats.json\") as f:\n    stats = json.load(f)\n    print(f\"\\nGraph Statistics:\")\n    print(f\"  Nodes: {stats['node_count']}\")\n    print(f\"  Edges: {stats['edge_count']}\")\n    print(f\"  Density: {stats['density']:.3f}\")\n</code></pre> <p>Run: <pre><code>uv run python examples/research_consolidation.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-5-batch-processing","title":"Example 5: Batch Processing","text":"<p>Use Case: Process multiple documents with progress tracking.</p> <p>File: <code>examples/batch_process.py</code></p> <pre><code>\"\"\"\nBatch process multiple documents.\n\"\"\"\n\nfrom pathlib import Path\nfrom docling_graph import PipelineConfig\nfrom tqdm import tqdm\n\ndef process_batch(input_dir: str, template: str, output_base: str):\n    \"\"\"Process all PDFs in a directory.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    results = {\"success\": [], \"failed\": []}\n\n    print(f\"Processing {len(documents)} documents...\")\n\n    for doc in tqdm(documents, desc=\"Processing\"):\n        try:\n            config = PipelineConfig(\n                source=str(doc),\n                template=template,\n                output_dir=f\"{output_base}/{doc.stem}\"\n            )\n            config.run()\n            results[\"success\"].append(doc.name)\n\n        except Exception as e:\n            results[\"failed\"].append((doc.name, str(e)))\n            tqdm.write(f\"\u2717 {doc.name}: {e}\")\n\n    # Summary\n    print(f\"\\n{'='*50}\")\n    print(f\"Completed: {len(results['success'])} succeeded\")\n    print(f\"Failed: {len(results['failed'])}\")\n\n    if results[\"failed\"]:\n        print(\"\\nFailed documents:\")\n        for name, error in results[\"failed\"]:\n            print(f\"  - {name}: {error}\")\n\n    return results\n\nif __name__ == \"__main__\":\n    results = process_batch(\n        input_dir=\"documents/invoices\",\n        template=\"templates.invoice.Invoice\",\n        output_base=\"outputs/batch\"\n    )\n</code></pre> <p>Run: <pre><code>uv run python examples/batch_process.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-6-robust-error-handling","title":"Example 6: Robust Error Handling","text":"<p>Use Case: Production-ready code with comprehensive error handling.</p> <p>File: <code>examples/robust_processing.py</code></p> <pre><code>\"\"\"\nProduction-ready document processing with error handling.\n\"\"\"\n\nimport logging\nfrom pathlib import Path\nfrom typing import Optional\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import (\n    ConfigurationError,\n    ExtractionError,\n    PipelineError,\n    DoclingGraphError\n)\n\n# Setup logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\ndef process_document(\n    source: str,\n    template: str,\n    output_dir: Optional[str] = None,\n    max_retries: int = 3\n) -&gt; bool:\n    \"\"\"\n    Process document with retry logic and error handling.\n\n    Args:\n        source: Path to source document\n        template: Pydantic template path\n        output_dir: Output directory (auto-generated if None)\n        max_retries: Maximum retry attempts\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    if output_dir is None:\n        output_dir = f\"outputs/{Path(source).stem}\"\n\n    for attempt in range(1, max_retries + 1):\n        try:\n            logger.info(f\"Processing {source} (attempt {attempt}/{max_retries})\")\n\n            config = PipelineConfig(\n                source=source,\n                template=template,\n                output_dir=output_dir\n            )\n\n            config.run()\n            logger.info(f\"\u2713 Successfully processed: {source}\")\n            return True\n\n        except ConfigurationError as e:\n            logger.error(f\"Configuration error: {e.message}\")\n            if e.details:\n                logger.error(f\"Details: {e.details}\")\n            return False  # Don't retry configuration errors\n\n        except ExtractionError as e:\n            logger.error(f\"Extraction failed: {e.message}\")\n            if attempt &lt; max_retries:\n                logger.info(f\"Retrying... ({attempt}/{max_retries})\")\n                continue\n            return False\n\n        except PipelineError as e:\n            logger.error(f\"Pipeline error: {e.message}\")\n            if attempt &lt; max_retries:\n                logger.info(f\"Retrying... ({attempt}/{max_retries})\")\n                continue\n            return False\n\n        except DoclingGraphError as e:\n            logger.error(f\"Docling-graph error: {e.message}\")\n            return False\n\n        except Exception as e:\n            logger.exception(f\"Unexpected error: {e}\")\n            return False\n\n    return False\n\nif __name__ == \"__main__\":\n    # Process single document\n    success = process_document(\n        source=\"documents/invoice.pdf\",\n        template=\"templates.invoice.Invoice\"\n    )\n\n    if success:\n        print(\"Processing completed successfully\")\n    else:\n        print(\"Processing failed\")\n        exit(1)\n</code></pre> <p>Run: <pre><code>uv run python examples/robust_processing.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-7-flask-api-integration","title":"Example 7: Flask API Integration","text":"<p>Use Case: Web API for document processing.</p> <p>File: <code>examples/flask_api.py</code></p> <pre><code>\"\"\"\nFlask API for document processing.\n\"\"\"\n\nfrom flask import Flask, request, jsonify, send_file\nfrom werkzeug.utils import secure_filename\nfrom pathlib import Path\nimport uuid\nimport os\n\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import DoclingGraphError\n\napp = Flask(__name__)\napp.config['UPLOAD_FOLDER'] = 'temp'\napp.config['OUTPUT_FOLDER'] = 'outputs'\napp.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max\n\n# Ensure directories exist\nPath(app.config['UPLOAD_FOLDER']).mkdir(exist_ok=True)\nPath(app.config['OUTPUT_FOLDER']).mkdir(exist_ok=True)\n\n@app.route('/health', methods=['GET'])\ndef health():\n    \"\"\"Health check endpoint.\"\"\"\n    return jsonify({\"status\": \"healthy\"})\n\n@app.route('/process', methods=['POST'])\ndef process_document():\n    \"\"\"Process uploaded document.\"\"\"\n    # Validate request\n    if 'document' not in request.files:\n        return jsonify({\"error\": \"No document provided\"}), 400\n\n    file = request.files['document']\n    if file.filename == '':\n        return jsonify({\"error\": \"Empty filename\"}), 400\n\n    template = request.form.get('template', 'templates.invoice.Invoice')\n\n    # Save file\n    job_id = str(uuid.uuid4())\n    filename = secure_filename(file.filename)\n    temp_path = Path(app.config['UPLOAD_FOLDER']) / f\"{job_id}_{filename}\"\n    file.save(temp_path)\n\n    try:\n        # Process document\n        output_dir = Path(app.config['OUTPUT_FOLDER']) / job_id\n\n        config = PipelineConfig(\n            source=str(temp_path),\n            template=template,\n            output_dir=str(output_dir)\n        )\n\n        config.run()\n\n        return jsonify({\n            \"status\": \"success\",\n            \"job_id\": job_id,\n            \"output_dir\": str(output_dir),\n            \"files\": {\n                \"nodes\": f\"/download/{job_id}/nodes.csv\",\n                \"edges\": f\"/download/{job_id}/edges.csv\",\n                \"graph\": f\"/download/{job_id}/graph.json\",\n                \"visualization\": f\"/download/{job_id}/graph_visualization.html\"\n            }\n        })\n\n    except DoclingGraphError as e:\n        return jsonify({\n            \"status\": \"error\",\n            \"message\": e.message,\n            \"details\": e.details\n        }), 500\n\n    except Exception as e:\n        return jsonify({\n            \"status\": \"error\",\n            \"message\": str(e)\n        }), 500\n\n    finally:\n        # Cleanup temp file\n        temp_path.unlink(missing_ok=True)\n\n@app.route('/download/&lt;job_id&gt;/&lt;filename&gt;', methods=['GET'])\ndef download_file(job_id, filename):\n    \"\"\"Download processed file.\"\"\"\n    file_path = Path(app.config['OUTPUT_FOLDER']) / job_id / filename\n\n    if not file_path.exists():\n        return jsonify({\"error\": \"File not found\"}), 404\n\n    return send_file(file_path, as_attachment=True)\n\nif __name__ == '__main__':\n    app.run(debug=True, port=5000)\n</code></pre> <p>Run: <pre><code>uv run python examples/flask_api.py\n</code></pre></p> <p>Test: <pre><code># Upload and process document\ncurl -X POST http://localhost:5000/process \\\n    -F \"document=@invoice.pdf\" \\\n    -F \"template=templates.invoice.Invoice\"\n\n# Download results\ncurl -O http://localhost:5000/download/{job_id}/nodes.csv\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-8-jupyter-notebook-analysis","title":"Example 8: Jupyter Notebook Analysis","text":"<p>Use Case: Interactive document analysis in Jupyter.</p> <p>File: <code>examples/notebook_analysis.ipynb</code></p> <pre><code># Cell 1: Setup\nfrom docling_graph import PipelineConfig\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\n# Cell 2: Process Document\nconfig = PipelineConfig(\n    source=\"documents/research.pdf\",\n    template=\"templates.research.Research\",\n    output_dir=\"outputs/research\"\n)\n\nprint(\"Processing document...\")\nconfig.run()\nprint(\"\u2713 Complete!\")\n\n# Cell 3: Load Results\nnodes = pd.read_csv(\"outputs/research/nodes.csv\")\nedges = pd.read_csv(\"outputs/research/edges.csv\")\n\nprint(f\"Nodes: {len(nodes)}\")\nprint(f\"Edges: {len(edges)}\")\n\n# Cell 4: Analyze Node Types\nnode_counts = nodes['type'].value_counts()\nprint(\"\\nNode Type Distribution:\")\nprint(node_counts)\n\n# Visualize\nplt.figure(figsize=(10, 6))\nnode_counts.plot(kind='bar')\nplt.title('Node Types Distribution')\nplt.xlabel('Node Type')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# Cell 5: Analyze Relationships\nedge_counts = edges['type'].value_counts()\nprint(\"\\nRelationship Distribution:\")\nprint(edge_counts)\n\n# Visualize\nplt.figure(figsize=(10, 6))\nedge_counts.plot(kind='bar', color='coral')\nplt.title('Relationship Types Distribution')\nplt.xlabel('Relationship Type')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# Cell 6: Network Analysis\nimport networkx as nx\n\n# Create graph\nG = nx.DiGraph()\nfor _, edge in edges.iterrows():\n    G.add_edge(edge['source'], edge['target'], type=edge['type'])\n\nprint(f\"\\nNetwork Statistics:\")\nprint(f\"  Nodes: {G.number_of_nodes()}\")\nprint(f\"  Edges: {G.number_of_edges()}\")\nprint(f\"  Density: {nx.density(G):.3f}\")\nprint(f\"  Is connected: {nx.is_weakly_connected(G)}\")\n\n# Cell 7: Visualize Network\nplt.figure(figsize=(12, 8))\npos = nx.spring_layout(G, k=0.5, iterations=50)\nnx.draw(G, pos, \n        node_color='lightblue',\n        node_size=500,\n        with_labels=True,\n        font_size=8,\n        arrows=True,\n        edge_color='gray',\n        alpha=0.7)\nplt.title('Knowledge Graph Visualization')\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Run: <pre><code>jupyter notebook examples/notebook_analysis.ipynb\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#best-practices","title":"Best Practices","text":""},{"location":"usage/api/programmatic-examples/#1-use-environment-variables-for-secrets","title":"1. Use Environment Variables for Secrets","text":"<pre><code># \u2705 Good - Environment variables\nimport os\nos.environ[\"MISTRAL_API_KEY\"] = os.getenv(\"MISTRAL_API_KEY\")\n\n# \u274c Avoid - Hardcoded secrets\nos.environ[\"MISTRAL_API_KEY\"] = \"sk-1234...\"  # Don't commit!\n</code></pre>"},{"location":"usage/api/programmatic-examples/#2-handle-errors-gracefully","title":"2. Handle Errors Gracefully","text":"<pre><code># \u2705 Good - Specific error handling\nfrom docling_graph.exceptions import ExtractionError\n\ntry:\n    config.run()\nexcept ExtractionError as e:\n    logger.error(f\"Extraction failed: {e.message}\")\n    # Implement fallback\n\n# \u274c Avoid - Silent failures\ntry:\n    config.run()\nexcept:\n    pass\n</code></pre>"},{"location":"usage/api/programmatic-examples/#3-organize-outputs","title":"3. Organize Outputs","text":"<pre><code># \u2705 Good - Organized structure\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    output_dir=f\"outputs/invoices/{timestamp}\"\n)\n\n# \u274c Avoid - Overwriting\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    output_dir=\"outputs\"  # Same for all\n)\n</code></pre>"},{"location":"usage/api/programmatic-examples/#next-steps","title":"Next Steps","text":"<ol> <li>Batch Processing \u2192 - Advanced batch patterns</li> <li>Examples \u2192 - Real-world examples</li> <li>Advanced Topics \u2192 - Custom backends</li> </ol>"},{"location":"usage/api/programmatic-examples/#quick-reference_1","title":"Quick Reference","text":""},{"location":"usage/api/programmatic-examples/#run-examples","title":"Run Examples","text":"<pre><code># Simple example\nuv run python examples/simple_invoice.py\n\n# With dependencies\nuv sync --extra remote\nuv run python examples/simple_invoice.py\n\n# Batch processing\nuv run python examples/batch_process.py\n</code></pre>"},{"location":"usage/api/programmatic-examples/#common-patterns","title":"Common Patterns","text":"<pre><code># Basic processing\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\"\n)\nconfig.run()\n\n# With error handling\ntry:\n    config.run()\nexcept Exception as e:\n    print(f\"Error: {e}\")\n\n# Batch processing\nfor doc in Path(\"documents\").glob(\"*.pdf\"):\n    config = PipelineConfig(\n        source=str(doc),\n        template=\"templates.Invoice\",\n        output_dir=f\"outputs/{doc.stem}\"\n    )\n    config.run()\n</code></pre>"},{"location":"usage/api/run-pipeline/","title":"run_pipeline()","text":""},{"location":"usage/api/run-pipeline/#overview","title":"Overview","text":"<p>The <code>run_pipeline()</code> function is the main entry point for executing the document-to-graph pipeline programmatically.</p> <p>Function Signature: <pre><code>def run_pipeline(config: Union[PipelineConfig, Dict[str, Any]]) -&gt; None\n</code></pre></p>"},{"location":"usage/api/run-pipeline/#basic-usage","title":"Basic Usage","text":""},{"location":"usage/api/run-pipeline/#with-dictionary","title":"With Dictionary","text":"<pre><code>from docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"my_templates.Invoice\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"output_dir\": \"outputs\"\n})\n</code></pre>"},{"location":"usage/api/run-pipeline/#with-pipelineconfig","title":"With PipelineConfig","text":"<pre><code>from docling_graph import PipelineConfig, run_pipeline\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"my_templates.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/api/run-pipeline/#parameters","title":"Parameters","text":""},{"location":"usage/api/run-pipeline/#config","title":"config","text":"<p>Type: <code>PipelineConfig | Dict[str, Any]</code></p> <p>Required: Yes</p> <p>Description: Pipeline configuration as either: - <code>PipelineConfig</code> object (recommended) - Dictionary with configuration keys</p>"},{"location":"usage/api/run-pipeline/#configuration-keys","title":"Configuration Keys","text":""},{"location":"usage/api/run-pipeline/#required-keys","title":"Required Keys","text":"Key Type Description <code>source</code> <code>str</code> Path to source document <code>template</code> <code>str | Type[BaseModel]</code> Pydantic template (dotted path or class)"},{"location":"usage/api/run-pipeline/#optional-keys","title":"Optional Keys","text":"Key Type Default Description <code>backend</code> <code>str</code> <code>\"llm\"</code> Backend type: <code>\"llm\"</code> or <code>\"vlm\"</code> <code>inference</code> <code>str</code> <code>\"local\"</code> Inference mode: <code>\"local\"</code> or <code>\"remote\"</code> <code>processing_mode</code> <code>str</code> <code>\"many-to-one\"</code> Processing strategy <code>docling_config</code> <code>str</code> <code>\"ocr\"</code> Docling pipeline: <code>\"ocr\"</code> or <code>\"vision\"</code> <code>use_chunking</code> <code>bool</code> <code>True</code> Enable document chunking <code>llm_consolidation</code> <code>bool</code> <code>False</code> Enable LLM consolidation <code>export_format</code> <code>str</code> <code>\"csv\"</code> Export format: <code>\"csv\"</code> or <code>\"cypher\"</code> <code>output_dir</code> <code>str</code> <code>\"outputs\"</code> Output directory path <code>model_override</code> <code>str</code> <code>None</code> Override model name <code>provider_override</code> <code>str</code> <code>None</code> Override provider name <p>See PipelineConfig for complete list.</p>"},{"location":"usage/api/run-pipeline/#return-value","title":"Return Value","text":"<p>Type: <code>None</code></p> <p>The function doesn't return a value. Results are written to the output directory.</p>"},{"location":"usage/api/run-pipeline/#exceptions","title":"Exceptions","text":""},{"location":"usage/api/run-pipeline/#configurationerror","title":"ConfigurationError","text":"<p>Raised when configuration is invalid.</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import ConfigurationError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.Invoice\",\n        \"backend\": \"invalid\"  # Invalid backend\n    })\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e.message}\")\n    print(f\"Details: {e.details}\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#extractionerror","title":"ExtractionError","text":"<p>Raised when document extraction fails.</p> <pre><code>from docling_graph.exceptions import ExtractionError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.Missing\"  # Template not found\n    })\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#pipelineerror","title":"PipelineError","text":"<p>Raised when pipeline execution fails.</p> <pre><code>from docling_graph.exceptions import PipelineError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.Invoice\"\n    })\nexcept PipelineError as e:\n    print(f\"Pipeline error: {e.message}\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#complete-examples","title":"Complete Examples","text":""},{"location":"usage/api/run-pipeline/#example-1-minimal-configuration","title":"Example 1: Minimal Configuration","text":"<pre><code>from docling_graph import run_pipeline\n\n# Minimal required configuration\nrun_pipeline({\n    \"source\": \"invoice.pdf\",\n    \"template\": \"templates.Invoice\"\n})\n\n# Output: outputs/\n</code></pre>"},{"location":"usage/api/run-pipeline/#example-2-remote-llm","title":"Example 2: Remote LLM","text":"<pre><code>import os\nfrom docling_graph import run_pipeline\n\n# Set API key\nos.environ[\"MISTRAL_API_KEY\"] = \"your-key\"\n\n# Configure for remote inference\nrun_pipeline({\n    \"source\": \"research.pdf\",\n    \"template\": \"templates.Research\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"provider_override\": \"mistral\",\n    \"model_override\": \"mistral-large-latest\",\n    \"processing_mode\": \"many-to-one\",\n    \"use_chunking\": True,\n    \"llm_consolidation\": True,\n    \"output_dir\": \"outputs/research\"\n})\n</code></pre>"},{"location":"usage/api/run-pipeline/#example-3-local-vlm","title":"Example 3: Local VLM","text":"<pre><code>from docling_graph import run_pipeline\n\n# VLM for form extraction\nrun_pipeline({\n    \"source\": \"form.jpg\",\n    \"template\": \"templates.IDCard\",\n    \"backend\": \"vlm\",\n    \"inference\": \"local\",\n    \"processing_mode\": \"one-to-one\",\n    \"docling_config\": \"vision\",\n    \"output_dir\": \"outputs/form\"\n})\n</code></pre>"},{"location":"usage/api/run-pipeline/#example-4-with-error-handling","title":"Example 4: With Error Handling","text":"<pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import (\n    ConfigurationError,\n    ExtractionError,\n    PipelineError\n)\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef process_document(source: str, template: str) -&gt; bool:\n    \"\"\"Process document with comprehensive error handling.\"\"\"\n    try:\n        run_pipeline({\n            \"source\": source,\n            \"template\": template,\n            \"backend\": \"llm\",\n            \"inference\": \"remote\",\n            \"output_dir\": f\"outputs/{Path(source).stem}\"\n        })\n        logger.info(f\"\u2713 Successfully processed: {source}\")\n        return True\n\n    except ConfigurationError as e:\n        logger.error(f\"Configuration error for {source}: {e.message}\")\n        if e.details:\n            logger.error(f\"Details: {e.details}\")\n        return False\n\n    except ExtractionError as e:\n        logger.error(f\"Extraction failed for {source}: {e.message}\")\n        return False\n\n    except PipelineError as e:\n        logger.error(f\"Pipeline error for {source}: {e.message}\")\n        return False\n\n    except Exception as e:\n        logger.exception(f\"Unexpected error for {source}: {e}\")\n        return False\n\n# Use the function\nsuccess = process_document(\"invoice.pdf\", \"templates.Invoice\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#example-5-batch-processing","title":"Example 5: Batch Processing","text":"<pre><code>from pathlib import Path\nfrom docling_graph import run_pipeline\n\ndef batch_process(input_dir: str, template: str):\n    \"\"\"Process all PDFs in a directory.\"\"\"\n    documents = Path(input_dir).glob(\"*.pdf\")\n    results = {\"success\": [], \"failed\": []}\n\n    for doc in documents:\n        try:\n            run_pipeline({\n                \"source\": str(doc),\n                \"template\": template,\n                \"output_dir\": f\"outputs/{doc.stem}\"\n            })\n            results[\"success\"].append(doc.name)\n            print(f\"\u2713 {doc.name}\")\n\n        except Exception as e:\n            results[\"failed\"].append((doc.name, str(e)))\n            print(f\"\u2717 {doc.name}: {e}\")\n\n    # Summary\n    print(f\"\\nProcessed: {len(results['success'])} succeeded, {len(results['failed'])} failed\")\n    return results\n\n# Run batch processing\nresults = batch_process(\"documents/\", \"templates.Invoice\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/api/run-pipeline/#custom-models-configuration","title":"Custom Models Configuration","text":"<pre><code>from docling_graph import run_pipeline\n\n# Override models from config\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"models\": {\n        \"llm\": {\n            \"remote\": {\n                \"default_model\": \"gpt-4-turbo\",\n                \"provider\": \"openai\"\n            }\n        }\n    }\n})\n</code></pre>"},{"location":"usage/api/run-pipeline/#multiple-export-formats","title":"Multiple Export Formats","text":"<pre><code>from docling_graph import run_pipeline\n\n# Export as Cypher for Neo4j\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\",\n    \"export_format\": \"cypher\",\n    \"output_dir\": \"outputs/neo4j\"\n})\n\n# Then import to Neo4j\nimport subprocess\nsubprocess.run([\n    \"cypher-shell\",\n    \"-f\", \"outputs/neo4j/graph.cypher\"\n])\n</code></pre>"},{"location":"usage/api/run-pipeline/#conditional-processing","title":"Conditional Processing","text":"<pre><code>from pathlib import Path\nfrom docling_graph import run_pipeline\n\ndef smart_process(source: str):\n    \"\"\"Choose configuration based on document type.\"\"\"\n    path = Path(source)\n\n    # Determine template and config\n    if \"invoice\" in path.name.lower():\n        template = \"templates.Invoice\"\n        backend = \"vlm\"\n        processing = \"one-to-one\"\n    elif \"research\" in path.name.lower():\n        template = \"templates.Research\"\n        backend = \"llm\"\n        processing = \"many-to-one\"\n    else:\n        raise ValueError(f\"Unknown document type: {path.name}\")\n\n    # Process with appropriate config\n    run_pipeline({\n        \"source\": source,\n        \"template\": template,\n        \"backend\": backend,\n        \"processing_mode\": processing,\n        \"output_dir\": f\"outputs/{path.stem}\"\n    })\n\n# Use smart processing\nsmart_process(\"invoice_001.pdf\")\nsmart_process(\"research_paper.pdf\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#integration-patterns","title":"Integration Patterns","text":""},{"location":"usage/api/run-pipeline/#flask-api","title":"Flask API","text":"<pre><code>from flask import Flask, request, jsonify\nfrom docling_graph import run_pipeline\nfrom pathlib import Path\nimport uuid\n\napp = Flask(__name__)\n\n@app.route('/process', methods=['POST'])\ndef process_endpoint():\n    \"\"\"API endpoint for document processing.\"\"\"\n    file = request.files.get('document')\n    template = request.form.get('template', 'templates.Invoice')\n\n    if not file:\n        return jsonify({\"error\": \"No file provided\"}), 400\n\n    # Save temporarily\n    temp_id = str(uuid.uuid4())\n    temp_path = f\"temp/{temp_id}_{file.filename}\"\n    Path(\"temp\").mkdir(exist_ok=True)\n    file.save(temp_path)\n\n    try:\n        # Process\n        output_dir = f\"outputs/{temp_id}\"\n        run_pipeline({\n            \"source\": temp_path,\n            \"template\": template,\n            \"output_dir\": output_dir\n        })\n\n        return jsonify({\n            \"status\": \"success\",\n            \"output_dir\": output_dir,\n            \"id\": temp_id\n        })\n\n    except Exception as e:\n        return jsonify({\n            \"status\": \"error\",\n            \"message\": str(e)\n        }), 500\n\n    finally:\n        # Cleanup\n        Path(temp_path).unlink(missing_ok=True)\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"usage/api/run-pipeline/#celery-task","title":"Celery Task","text":"<pre><code>from celery import Celery\nfrom docling_graph import run_pipeline\nfrom pathlib import Path\n\napp = Celery('tasks', broker='redis://localhost:6379')\n\n@app.task\ndef process_document_task(source: str, template: str, output_dir: str):\n    \"\"\"Async document processing task.\"\"\"\n    try:\n        run_pipeline({\n            \"source\": source,\n            \"template\": template,\n            \"output_dir\": output_dir\n        })\n        return {\"status\": \"success\", \"output_dir\": output_dir}\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": str(e)}\n\n# Usage\nresult = process_document_task.delay(\n    \"document.pdf\",\n    \"templates.Invoice\",\n    \"outputs/task_001\"\n)\n</code></pre>"},{"location":"usage/api/run-pipeline/#airflow-operator","title":"Airflow Operator","text":"<pre><code>from airflow.operators.python import PythonOperator\nfrom docling_graph import run_pipeline\n\ndef process_document(**context):\n    \"\"\"Airflow task for document processing.\"\"\"\n    params = context['params']\n\n    run_pipeline({\n        \"source\": params['source'],\n        \"template\": params['template'],\n        \"output_dir\": f\"outputs/{context['ds']}\"\n    })\n\n# In DAG definition\nprocess_task = PythonOperator(\n    task_id='process_document',\n    python_callable=process_document,\n    params={\n        'source': 'documents/daily.pdf',\n        'template': 'templates.Invoice'\n    }\n)\n</code></pre>"},{"location":"usage/api/run-pipeline/#best-practices","title":"Best Practices","text":""},{"location":"usage/api/run-pipeline/#1-use-pipelineconfig-for-type-safety","title":"1. Use PipelineConfig for Type Safety","text":"<pre><code># \u2705 Good - Type-safe with validation\nfrom docling_graph import PipelineConfig, run_pipeline\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Invoice\",\n    backend=\"llm\"  # Validated at creation\n)\nrun_pipeline(config)\n\n# \u274c Avoid - No validation until runtime\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\",\n    \"backend\": \"invalid\"  # Error at runtime\n})\n</code></pre>"},{"location":"usage/api/run-pipeline/#2-handle-errors-explicitly","title":"2. Handle Errors Explicitly","text":"<pre><code># \u2705 Good - Specific error handling\nfrom docling_graph.exceptions import ExtractionError\n\ntry:\n    run_pipeline(config)\nexcept ExtractionError as e:\n    logger.error(f\"Extraction failed: {e.message}\")\n    # Implement retry or fallback\n\n# \u274c Avoid - Silent failures\ntry:\n    run_pipeline(config)\nexcept:\n    pass\n</code></pre>"},{"location":"usage/api/run-pipeline/#3-organize-outputs","title":"3. Organize Outputs","text":"<pre><code># \u2705 Good - Unique output directories\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\",\n    \"output_dir\": f\"outputs/{timestamp}\"\n})\n\n# \u274c Avoid - Overwriting outputs\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\",\n    \"output_dir\": \"outputs\"  # Same for all\n})\n</code></pre>"},{"location":"usage/api/run-pipeline/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/api/run-pipeline/#issue-template-not-found","title":"Issue: Template Not Found","text":"<p>Error: <pre><code>ModuleNotFoundError: No module named 'templates'\n</code></pre></p> <p>Solution: <pre><code>import sys\nfrom pathlib import Path\n\n# Add project root to path\nsys.path.append(str(Path.cwd()))\n\n# Now import works\nfrom docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\"\n})\n</code></pre></p>"},{"location":"usage/api/run-pipeline/#issue-api-key-not-found","title":"Issue: API Key Not Found","text":"<p>Error: <pre><code>ConfigurationError: API key not found for provider: mistral\n</code></pre></p> <p>Solution: <pre><code>import os\n\n# Set API key before running\nos.environ[\"MISTRAL_API_KEY\"] = \"your-key\"\n\nfrom docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\",\n    \"inference\": \"remote\"\n})\n</code></pre></p>"},{"location":"usage/api/run-pipeline/#next-steps","title":"Next Steps","text":"<ol> <li>PipelineConfig \u2192 - Configuration class</li> <li>Programmatic Examples \u2192 - More examples</li> <li>Batch Processing \u2192 - Batch patterns</li> </ol>"},{"location":"usage/api/run-pipeline/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/api/run-pipeline/#basic-call","title":"Basic Call","text":"<pre><code>from docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\"\n})\n</code></pre>"},{"location":"usage/api/run-pipeline/#with-options","title":"With Options","text":"<pre><code>run_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.Invoice\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"output_dir\": \"outputs\"\n})\n</code></pre>"},{"location":"usage/api/run-pipeline/#error-handling","title":"Error Handling","text":"<pre><code>from docling_graph.exceptions import PipelineError\n\ntry:\n    run_pipeline(config)\nexcept PipelineError as e:\n    print(f\"Error: {e.message}\")\n</code></pre>"},{"location":"usage/cli/","title":"CLI Reference","text":""},{"location":"usage/cli/#overview","title":"Overview","text":"<p>The docling-graph CLI provides command-line tools for document-to-graph conversion, configuration management, and graph visualization.</p> <p>Available Commands: - <code>init</code> - Create configuration files - <code>convert</code> - Convert documents to graphs - <code>inspect</code> - Visualize graphs in browser</p>"},{"location":"usage/cli/#quick-start","title":"Quick Start","text":""},{"location":"usage/cli/#installation","title":"Installation","text":"<pre><code># Install with all features\nuv sync --extra all\n\n# Verify installation\nuv run docling-graph --version\n</code></pre>"},{"location":"usage/cli/#basic-usage","title":"Basic Usage","text":"<pre><code># 1. Initialize configuration\nuv run docling-graph init\n\n# 2. Convert a document\nuv run docling-graph convert document.pdf \\\n    --template \"my_templates.Invoice\"\n\n# 3. Visualize the graph\nuv run docling-graph inspect outputs/\n</code></pre>"},{"location":"usage/cli/#global-options","title":"Global Options","text":"<p>Available with all commands:</p> Option Short Description <code>--verbose</code> <code>-v</code> Enable detailed logging <code>--version</code> Show version and exit <code>--help</code> <code>-h</code> Show help message"},{"location":"usage/cli/#examples","title":"Examples","text":"<pre><code># Show version\nuv run docling-graph --version\n\n# Enable verbose logging\nuv run docling-graph --verbose convert document.pdf -t \"templates.Invoice\"\n\n# Show help\nuv run docling-graph --help\nuv run docling-graph convert --help\n</code></pre>"},{"location":"usage/cli/#command-overview","title":"Command Overview","text":""},{"location":"usage/cli/#init","title":"init","text":"<p>Create a configuration file with interactive prompts.</p> <pre><code>uv run docling-graph init\n</code></pre> <p>Features: - Interactive configuration builder - Dependency validation - Provider-specific setup - API key guidance</p> <p>Learn more: init Command \u2192</p>"},{"location":"usage/cli/#convert","title":"convert","text":"<p>Convert documents to knowledge graphs.</p> <pre><code>uv run docling-graph convert SOURCE --template TEMPLATE [OPTIONS]\n</code></pre> <p>Features: - Multiple backend support (LLM/VLM) - Flexible processing modes - Configurable chunking - Multiple export formats</p> <p>Learn more: convert Command \u2192</p>"},{"location":"usage/cli/#inspect","title":"inspect","text":"<p>Visualize graphs in your browser.</p> <pre><code>uv run docling-graph inspect PATH [OPTIONS]\n</code></pre> <p>Features: - Interactive HTML visualization - CSV and JSON import - Node/edge exploration - Self-contained output</p> <p>Learn more: inspect Command \u2192</p>"},{"location":"usage/cli/#common-workflows","title":"Common Workflows","text":""},{"location":"usage/cli/#workflow-1-first-time-setup","title":"Workflow 1: First-Time Setup","text":"<pre><code># 1. Initialize configuration\nuv run docling-graph init\n\n# 2. Install dependencies (if prompted)\nuv sync --extra remote\n\n# 3. Set API key (if using remote)\nexport MISTRAL_API_KEY=\"your-key\"\n\n# 4. Convert first document\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\"\n</code></pre>"},{"location":"usage/cli/#workflow-2-batch-processing","title":"Workflow 2: Batch Processing","text":"<pre><code># Process multiple documents\nfor pdf in documents/*.pdf; do\n    uv run docling-graph convert \"$pdf\" \\\n        --template \"templates.Invoice\" \\\n        --output-dir \"outputs/$(basename $pdf .pdf)\"\ndone\n\n# Visualize results\nfor dir in outputs/*/; do\n    uv run docling-graph inspect \"$dir\" \\\n        --output \"${dir}/visualization.html\" \\\n        --no-open\ndone\n</code></pre>"},{"location":"usage/cli/#workflow-3-development-iteration","title":"Workflow 3: Development Iteration","text":"<pre><code># 1. Convert with verbose logging\nuv run docling-graph --verbose convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"test_output\"\n\n# 2. Inspect results\nuv run docling-graph inspect test_output/\n\n# 3. Iterate on template\n# Edit templates/invoice.py\n\n# 4. Re-run conversion\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"test_output\"\n</code></pre>"},{"location":"usage/cli/#configuration-priority","title":"Configuration Priority","text":"<p>The CLI uses the following priority order (highest to lowest):</p> <ol> <li>Command-line arguments (e.g., <code>--backend llm</code>)</li> <li>config.yaml (created by <code>init</code>)</li> <li>Built-in defaults (from PipelineConfig)</li> </ol>"},{"location":"usage/cli/#example","title":"Example","text":"<pre><code># config.yaml\ndefaults:\n  backend: llm\n  inference: local\n</code></pre> <pre><code># This uses remote inference (CLI overrides config)\nuv run docling-graph convert doc.pdf \\\n    --template \"templates.Invoice\" \\\n    --inference remote\n</code></pre>"},{"location":"usage/cli/#environment-variables","title":"Environment Variables","text":""},{"location":"usage/cli/#api-keys","title":"API Keys","text":"<pre><code># Remote providers\nexport MISTRAL_API_KEY=\"your-key\"\nexport OPENAI_API_KEY=\"your-key\"\nexport GEMINI_API_KEY=\"your-key\"\nexport WATSONX_API_KEY=\"your-key\"\n</code></pre>"},{"location":"usage/cli/#local-providers","title":"Local Providers","text":"<pre><code># vLLM base URL (default: http://localhost:8000/v1)\nexport VLLM_BASE_URL=\"http://custom-host:8000/v1\"\n\n# Ollama base URL (default: http://localhost:11434)\nexport OLLAMA_BASE_URL=\"http://custom-host:11434\"\n</code></pre>"},{"location":"usage/cli/#output-structure","title":"Output Structure","text":"<p>Default output directory structure:</p> <pre><code>outputs/\n\u251c\u2500\u2500 nodes.csv              # Node data\n\u251c\u2500\u2500 edges.csv              # Edge data\n\u251c\u2500\u2500 graph.json             # Complete graph\n\u251c\u2500\u2500 graph_stats.json       # Statistics\n\u251c\u2500\u2500 graph_visualization.html  # Interactive viz\n\u251c\u2500\u2500 markdown_report.md     # Summary report\n\u251c\u2500\u2500 docling_document.json  # Docling output\n\u2514\u2500\u2500 full_document.md       # Markdown export\n</code></pre>"},{"location":"usage/cli/#error-handling","title":"Error Handling","text":""},{"location":"usage/cli/#common-errors","title":"Common Errors","text":"<p>Configuration Error: <pre><code>[red]Configuration Error:[/red] Invalid backend type: 'invalid'\n</code></pre> Solution: Use <code>llm</code> or <code>vlm</code></p> <p>Extraction Error: <pre><code>[red]Extraction Error:[/red] Template not found: 'templates.Missing'\n</code></pre> Solution: Check template path and ensure it's importable</p> <p>Pipeline Error: <pre><code>[red]Pipeline Error:[/red] API key not found for provider: mistral\n</code></pre> Solution: Set <code>MISTRAL_API_KEY</code> environment variable</p>"},{"location":"usage/cli/#verbose-mode","title":"Verbose Mode","text":"<p>Enable verbose logging for debugging:</p> <pre><code>uv run docling-graph --verbose convert document.pdf \\\n    --template \"templates.Invoice\"\n</code></pre>"},{"location":"usage/cli/#best-practices","title":"Best Practices","text":""},{"location":"usage/cli/#1-use-configuration-files","title":"1. Use Configuration Files","text":"<pre><code># \u2705 Good - Reusable configuration\nuv run docling-graph init\nuv run docling-graph convert document.pdf -t \"templates.Invoice\"\n\n# \u274c Avoid - Repeating options\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider mistral \\\n    --model mistral-large-latest\n</code></pre>"},{"location":"usage/cli/#2-organize-output","title":"2. Organize Output","text":"<pre><code># \u2705 Good - Organized by document\nuv run docling-graph convert invoice_001.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"outputs/invoice_001\"\n\n# \u274c Avoid - Overwriting outputs\nuv run docling-graph convert invoice_001.pdf \\\n    --template \"templates.Invoice\"\n</code></pre>"},{"location":"usage/cli/#3-use-verbose-for-development","title":"3. Use Verbose for Development","text":"<pre><code># \u2705 Good - Debug during development\nuv run docling-graph --verbose convert document.pdf \\\n    --template \"templates.Invoice\"\n\n# \u2705 Good - Silent in production\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\"\n</code></pre>"},{"location":"usage/cli/#next-steps","title":"Next Steps","text":"<p>Explore each command in detail:</p> <ol> <li>init Command \u2192 - Configuration setup</li> <li>convert Command \u2192 - Document conversion</li> <li>inspect Command \u2192 - Graph visualization</li> <li>CLI Recipes \u2192 - Common patterns</li> </ol> <p>Or continue to: - Python API \u2192 - Programmatic usage - Examples \u2192 - Real-world examples</p>"},{"location":"usage/cli/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/cli/#essential-commands","title":"Essential Commands","text":"<pre><code># Initialize\nuv run docling-graph init\n\n# Convert\nuv run docling-graph convert SOURCE -t TEMPLATE\n\n# Inspect\nuv run docling-graph inspect PATH\n\n# Help\nuv run docling-graph --help\nuv run docling-graph COMMAND --help\n</code></pre>"},{"location":"usage/cli/#common-options","title":"Common Options","text":"<pre><code># Backend selection\n--backend llm|vlm\n\n# Inference mode\n--inference local|remote\n\n# Processing mode\n--processing-mode one-to-one|many-to-one\n\n# Export format\n--export-format csv|cypher\n\n# Output directory\n--output-dir PATH\n</code></pre>"},{"location":"usage/cli/cli-recipes/","title":"CLI Recipes","text":""},{"location":"usage/cli/cli-recipes/#overview","title":"Overview","text":"<p>This guide provides ready-to-use CLI recipes for common document processing scenarios. All examples use <code>uv</code> and can be run from your project root.</p>"},{"location":"usage/cli/cli-recipes/#quick-reference","title":"Quick Reference","text":"Recipe Backend Use Case VLM from Image VLM Forms, ID cards, structured layouts VLM from PDF Page VLM Single-page PDFs Remote LLM LLM (Remote) Text-heavy documents, API-based Local LLM LLM (Local) Privacy-focused, offline processing LLM with Consolidation LLM (Remote) High-accuracy extraction One-to-One Processing LLM Independent pages No Chunking LLM Small documents Vision Pipeline LLM Complex layouts with tables Cypher Export Any Neo4j import Batch Processing Any Multiple documents"},{"location":"usage/cli/cli-recipes/#recipe-1-vlm-from-image","title":"Recipe 1: VLM from Image","text":"<p>Use Case: Extract structured data from images (forms, ID cards, invoices)</p> <p>Requirements: <pre><code>uv sync --extra all\n</code></pre></p> <p>Command: <pre><code>uv run docling-graph convert \"docs/examples/data/invoice/sample_invoice.jpg\" \\\n    --template \"docs.examples.templates.invoice.Invoice\" \\\n    --output-dir \"outputs/recipe_01\" \\\n    --backend \"vlm\" \\\n    --processing-mode \"one-to-one\" \\\n    --docling-pipeline \"vision\"\n</code></pre></p> <p>When to Use: \u2705 Single-page forms \u2705 ID cards or badges \u2705 Structured layouts \u2705 Image files (JPG, PNG)</p> <p>Python Equivalent: <code>examples/scripts/01_vlm_from_image.py</code></p>"},{"location":"usage/cli/cli-recipes/#recipe-2-vlm-from-pdf-page","title":"Recipe 2: VLM from PDF Page","text":"<p>Use Case: Extract from single-page PDFs using vision model</p> <p>Requirements: <pre><code>uv sync --extra all\n</code></pre></p> <p>Command: <pre><code>uv run docling-graph convert \"docs/examples/data/invoice/sample_invoice.pdf\" \\\n    --template \"docs.examples.templates.invoice.Invoice\" \\\n    --output-dir \"outputs/recipe_02\" \\\n    --backend \"vlm\" \\\n    --processing-mode \"one-to-one\" \\\n    --docling-pipeline \"vision\"\n</code></pre></p> <p>When to Use: \u2705 Single-page PDFs \u2705 Forms in PDF format \u2705 High-quality scans</p> <p>Python Equivalent: <code>examples/scripts/02_vlm_from_pdf_page.py</code></p>"},{"location":"usage/cli/cli-recipes/#recipe-3-remote-llm-mistral","title":"Recipe 3: Remote LLM (Mistral)","text":"<p>Use Case: Process documents using Mistral AI API</p> <p>Requirements: <pre><code>uv sync --extra remote\nexport MISTRAL_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Command: <pre><code>uv run docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.Research\" \\\n    --output-dir \"outputs/recipe_03\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"mistral\" \\\n    --model \"mistral-large-latest\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking \\\n    --no-llm-consolidation\n</code></pre></p> <p>When to Use: \u2705 Multi-page documents \u2705 Text-heavy content \u2705 No local GPU \u2705 Cloud-based processing</p> <p>Cost: ~$0.01-0.10 per document (varies by model and length)</p> <p>Python Equivalent: <code>examples/scripts/03_llm_remote_api.py</code></p>"},{"location":"usage/cli/cli-recipes/#recipe-4-local-llm-ollama","title":"Recipe 4: Local LLM (Ollama)","text":"<p>Use Case: Process documents locally using Ollama</p> <p>Requirements: <pre><code>uv sync --extra local\n\n# Start Ollama server\nollama serve\n\n# Pull model\nollama pull llama3:8b\n</code></pre></p> <p>Command: <pre><code>uv run docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.Research\" \\\n    --output-dir \"outputs/recipe_04\" \\\n    --backend \"llm\" \\\n    --inference \"local\" \\\n    --provider \"ollama\" \\\n    --model \"llama3:8b\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking \\\n    --no-llm-consolidation\n</code></pre></p> <p>When to Use: \u2705 Privacy-sensitive documents \u2705 Offline processing \u2705 No API costs \u2705 Local development</p> <p>Python Equivalent: <code>examples/scripts/04_llm_local_ollama.py</code></p>"},{"location":"usage/cli/cli-recipes/#recipe-5-llm-with-consolidation","title":"Recipe 5: LLM with Consolidation","text":"<p>Use Case: High-accuracy extraction with LLM-based merging</p> <p>Requirements: <pre><code>uv sync --extra remote\nexport MISTRAL_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Command: <pre><code>uv run docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.Research\" \\\n    --output-dir \"outputs/recipe_05\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"mistral\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking \\\n    --llm-consolidation\n</code></pre></p> <p>When to Use: \u2705 Complex documents \u2705 Accuracy &gt; speed \u2705 Conflicting information across pages \u2705 Quality matters more than cost</p> <p>Trade-offs: \u26a0\ufe0f Slower processing \u26a0\ufe0f Higher API costs \u2705 Better accuracy</p> <p>Python Equivalent: <code>examples/scripts/05_llm_with_consolidation.py</code></p>"},{"location":"usage/cli/cli-recipes/#recipe-6-one-to-one-processing","title":"Recipe 6: One-to-One Processing","text":"<p>Use Case: Process each page independently</p> <p>Requirements: <pre><code>uv sync --extra remote\nexport MISTRAL_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Command: <pre><code>uv run docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.Research\" \\\n    --output-dir \"outputs/recipe_06\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"mistral\" \\\n    --processing-mode \"one-to-one\" \\\n    --use-chunking\n</code></pre></p> <p>When to Use: \u2705 Independent pages \u2705 Page-level analysis \u2705 Faster processing \u2705 Parallel processing possible</p> <p>Output: Multiple graphs (one per page)</p> <p>Python Equivalent: <code>examples/scripts/06_llm_one_to_one.py</code></p>"},{"location":"usage/cli/cli-recipes/#recipe-7-no-chunking","title":"Recipe 7: No Chunking","text":"<p>Use Case: Process small documents without chunking</p> <p>Requirements: <pre><code>uv sync --extra remote\nexport MISTRAL_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Command: <pre><code>uv run docling-graph convert \"docs/examples/data/invoice/sample_invoice.pdf\" \\\n    --template \"docs.examples.templates.invoice.Invoice\" \\\n    --output-dir \"outputs/recipe_07\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"mistral\" \\\n    --processing-mode \"many-to-one\" \\\n    --no-use-chunking\n</code></pre></p> <p>When to Use: \u2705 Small documents (&lt;5 pages) \u2705 Documents within context limit \u2705 Faster processing \u2705 Simpler pipeline</p> <p>Python Equivalent: <code>examples/scripts/07_llm_no_chunking.py</code></p>"},{"location":"usage/cli/cli-recipes/#recipe-8-vision-pipeline-hybrid","title":"Recipe 8: Vision Pipeline (Hybrid)","text":"<p>Use Case: Use vision-based document conversion with LLM extraction</p> <p>Requirements: <pre><code>uv sync --extra local\n\n# Start Ollama\nollama serve\nollama pull llama3:8b\n</code></pre></p> <p>Command: <pre><code>uv run docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.Research\" \\\n    --output-dir \"outputs/recipe_08\" \\\n    --backend \"llm\" \\\n    --inference \"local\" \\\n    --provider \"ollama\" \\\n    --model \"llama3:8b\" \\\n    --docling-pipeline \"vision\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking\n</code></pre></p> <p>When to Use: \u2705 Complex layouts \u2705 Tables and figures \u2705 Mixed content types \u2705 Better layout preservation</p> <p>Python Equivalent: <code>examples/scripts/08_llm_with_vision_config.py</code></p>"},{"location":"usage/cli/cli-recipes/#recipe-9-cypher-export","title":"Recipe 9: Cypher Export","text":"<p>Use Case: Export directly to Neo4j Cypher format</p> <p>Requirements: <pre><code>uv sync --extra all\n</code></pre></p> <p>Command: <pre><code>uv run docling-graph convert \"docs/examples/data/invoice/sample_invoice.jpg\" \\\n    --template \"docs.examples.templates.invoice.Invoice\" \\\n    --output-dir \"outputs/recipe_09\" \\\n    --backend \"vlm\" \\\n    --docling-pipeline \"vision\" \\\n    --export-format \"cypher\"\n</code></pre></p> <p>Import to Neo4j: <pre><code># Import the generated Cypher script\ncat outputs/recipe_09/graph.cypher | cypher-shell -u neo4j -p password\n</code></pre></p> <p>When to Use: \u2705 Direct Neo4j import \u2705 Graph database workflows \u2705 Production deployments</p> <p>Python Equivalent: <code>examples/scripts/09_export_to_cypher.py</code></p>"},{"location":"usage/cli/cli-recipes/#recipe-10-batch-processing","title":"Recipe 10: Batch Processing","text":"<p>Use Case: Process multiple documents</p> <p>Requirements: <pre><code>uv sync --extra remote\nexport MISTRAL_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Bash Script: <pre><code>#!/bin/bash\n# batch_process.sh\n\nTEMPLATE=\"docs.examples.templates.invoice.Invoice\"\nINPUT_DIR=\"documents\"\nOUTPUT_BASE=\"outputs\"\n\nfor file in \"$INPUT_DIR\"/*.pdf; do\n    filename=$(basename \"$file\" .pdf)\n    echo \"Processing: $filename\"\n\n    uv run docling-graph convert \"$file\" \\\n        --template \"$TEMPLATE\" \\\n        --output-dir \"$OUTPUT_BASE/$filename\" \\\n        --backend \"llm\" \\\n        --inference \"remote\" \\\n        --processing-mode \"many-to-one\"\n\n    echo \"Completed: $filename\"\ndone\n\necho \"All documents processed!\"\n</code></pre></p> <p>Parallel Processing: <pre><code># Using GNU parallel (faster)\nls documents/*.pdf | parallel -j 4 \\\n    uv run docling-graph convert {} \\\n        --template \"templates.Invoice\" \\\n        --output-dir \"outputs/{/.}\" \\\n        --backend llm \\\n        --inference remote\n</code></pre></p>"},{"location":"usage/cli/cli-recipes/#advanced-recipes","title":"Advanced Recipes","text":""},{"location":"usage/cli/cli-recipes/#recipe-11-custom-model-configuration","title":"Recipe 11: Custom Model Configuration","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"openai\" \\\n    --model \"gpt-4-turbo\" \\\n    --output-dir \"outputs/custom_model\"\n</code></pre>"},{"location":"usage/cli/cli-recipes/#recipe-12-minimal-export","title":"Recipe 12: Minimal Export","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend \"llm\" \\\n    --inference \"local\" \\\n    --no-docling-json \\\n    --no-markdown \\\n    --no-per-page \\\n    --output-dir \"outputs/minimal\"\n</code></pre>"},{"location":"usage/cli/cli-recipes/#recipe-13-reverse-edges","title":"Recipe 13: Reverse Edges","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --reverse-edges \\\n    --output-dir \"outputs/bidirectional\"\n</code></pre>"},{"location":"usage/cli/cli-recipes/#recipe-14-development-workflow","title":"Recipe 14: Development Workflow","text":"<pre><code># Enable verbose logging for debugging\nuv run docling-graph --verbose convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend \"llm\" \\\n    --inference \"local\" \\\n    --output-dir \"test_output\"\n\n# Inspect results\nuv run docling-graph inspect test_output/\n\n# Check statistics\ncat test_output/graph_stats.json | jq\n</code></pre>"},{"location":"usage/cli/cli-recipes/#provider-specific-recipes","title":"Provider-Specific Recipes","text":""},{"location":"usage/cli/cli-recipes/#openai","title":"OpenAI","text":"<pre><code>export OPENAI_API_KEY=\"your-key\"\n\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"openai\" \\\n    --model \"gpt-4-turbo\"\n</code></pre>"},{"location":"usage/cli/cli-recipes/#google-gemini","title":"Google Gemini","text":"<pre><code>export GEMINI_API_KEY=\"your-key\"\n\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"gemini\" \\\n    --model \"gemini-2.5-flash\"\n</code></pre>"},{"location":"usage/cli/cli-recipes/#ibm-watsonx","title":"IBM watsonx","text":"<pre><code>export WATSONX_API_KEY=\"your-key\"\n\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"watsonx\" \\\n    --model \"ibm/granite-13b-chat-v2\"\n</code></pre>"},{"location":"usage/cli/cli-recipes/#vllm-local-gpu","title":"vLLM (Local GPU)","text":"<pre><code># Start vLLM server\nuv run python -m vllm.entrypoints.openai.api_server \\\n    --model \"ibm-granite/granite-4.0-1b\" \\\n    --port 8000\n\n# Use with docling-graph\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend \"llm\" \\\n    --inference \"local\" \\\n    --provider \"vllm\"\n</code></pre>"},{"location":"usage/cli/cli-recipes/#workflow-recipes","title":"Workflow Recipes","text":""},{"location":"usage/cli/cli-recipes/#complete-development-workflow","title":"Complete Development Workflow","text":"<pre><code># 1. Initialize configuration\nuv run docling-graph init\n\n# 2. Create template\ncat &gt; templates/my_template.py &lt;&lt; 'EOF'\nfrom pydantic import BaseModel, Field\n\nclass MyTemplate(BaseModel):\n    \"\"\"My custom template.\"\"\"\n    title: str = Field(description=\"Document title\")\n    content: str = Field(description=\"Main content\")\nEOF\n\n# 3. Test extraction\nuv run docling-graph convert test.pdf \\\n    --template \"templates.my_template.MyTemplate\" \\\n    --output-dir \"test_output\"\n\n# 4. Inspect results\nuv run docling-graph inspect test_output/\n\n# 5. Iterate on template\n# Edit templates/my_template.py\n\n# 6. Re-run\nuv run docling-graph convert test.pdf \\\n    --template \"templates.my_template.MyTemplate\" \\\n    --output-dir \"test_output\"\n</code></pre>"},{"location":"usage/cli/cli-recipes/#production-deployment","title":"Production Deployment","text":"<pre><code># 1. Use configuration file\nuv run docling-graph init\n\n# 2. Process documents\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"production/$(date +%Y%m%d)\"\n\n# 3. Export to Neo4j\ncat production/$(date +%Y%m%d)/graph.cypher | \\\n    cypher-shell -u neo4j -p password\n\n# 4. Archive outputs\ntar -czf \"archive_$(date +%Y%m%d).tar.gz\" production/$(date +%Y%m%d)\n</code></pre>"},{"location":"usage/cli/cli-recipes/#best-practices","title":"Best Practices","text":""},{"location":"usage/cli/cli-recipes/#1-use-configuration-files","title":"1. Use Configuration Files","text":"<pre><code># \u2705 Good - Reusable configuration\nuv run docling-graph init\nuv run docling-graph convert doc.pdf -t \"templates.Invoice\"\n\n# \u274c Avoid - Repeating options\nuv run docling-graph convert doc.pdf -t \"templates.Invoice\" \\\n    --backend llm --inference remote --provider mistral\n</code></pre>"},{"location":"usage/cli/cli-recipes/#2-organize-outputs","title":"2. Organize Outputs","text":"<pre><code># \u2705 Good - Organized by document\nuv run docling-graph convert invoice_001.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"outputs/invoices/invoice_001\"\n\n# \u274c Avoid - Overwriting outputs\nuv run docling-graph convert invoice_001.pdf \\\n    --template \"templates.Invoice\"\n</code></pre>"},{"location":"usage/cli/cli-recipes/#3-use-appropriate-backend","title":"3. Use Appropriate Backend","text":"<pre><code># \u2705 Good - VLM for forms\nuv run docling-graph convert form.jpg \\\n    --template \"templates.IDCard\" \\\n    --backend vlm\n\n# \u2705 Good - LLM for documents\nuv run docling-graph convert research.pdf \\\n    --template \"templates.Research\" \\\n    --backend llm\n</code></pre>"},{"location":"usage/cli/cli-recipes/#next-steps","title":"Next Steps","text":"<ol> <li>Python API \u2192 - Programmatic usage</li> <li>Examples \u2192 - Real-world examples</li> <li>Advanced Topics \u2192 - Custom backends</li> </ol>"},{"location":"usage/cli/cli-recipes/#quick-reference_1","title":"Quick Reference","text":""},{"location":"usage/cli/cli-recipes/#common-patterns","title":"Common Patterns","text":"<pre><code># VLM from image\nuv run docling-graph convert image.jpg -t \"templates.Form\" --backend vlm\n\n# Remote LLM\nuv run docling-graph convert doc.pdf -t \"templates.Invoice\" \\\n    --backend llm --inference remote\n\n# Local LLM\nuv run docling-graph convert doc.pdf -t \"templates.Invoice\" \\\n    --backend llm --inference local --provider ollama\n\n# With consolidation\nuv run docling-graph convert doc.pdf -t \"templates.Research\" \\\n    --llm-consolidation\n\n# Cypher export\nuv run docling-graph convert doc.pdf -t \"templates.Invoice\" \\\n    --export-format cypher\n\n# Batch processing\nfor pdf in docs/*.pdf; do\n    uv run docling-graph convert \"$pdf\" -t \"templates.Invoice\" \\\n        --output-dir \"outputs/$(basename $pdf .pdf)\"\ndone\n</code></pre>"},{"location":"usage/cli/convert-command/","title":"convert Command","text":""},{"location":"usage/cli/convert-command/#overview","title":"Overview","text":"<p>The <code>convert</code> command transforms documents into knowledge graphs using configurable extraction pipelines.</p> <p>Key Features: - Multiple backend support (LLM/VLM) - Flexible processing modes - Configurable chunking - Multiple export formats - Batch processing support</p>"},{"location":"usage/cli/convert-command/#basic-usage","title":"Basic Usage","text":"<pre><code>uv run docling-graph convert SOURCE --template TEMPLATE [OPTIONS]\n</code></pre>"},{"location":"usage/cli/convert-command/#required-arguments","title":"Required Arguments","text":"Argument Description <code>SOURCE</code> Path to document (PDF, JPG, PNG, TXT, MD), URL, or DoclingDocument JSON <code>--template</code>, <code>-t</code> Dotted path to Pydantic template"},{"location":"usage/cli/convert-command/#examples","title":"Examples","text":"<pre><code># PDF document\nuv run docling-graph convert invoice.pdf \\\n    --template \"my_templates.Invoice\"\n\n# Text file\nuv run docling-graph convert notes.txt \\\n    --template \"my_templates.Report\" \\\n    --backend llm\n\n# URL\nuv run docling-graph convert https://example.com/doc.pdf \\\n    --template \"my_templates.Invoice\"\n\n# Markdown file\nuv run docling-graph convert README.md \\\n    --template \"my_templates.Documentation\" \\\n    --backend llm\n</code></pre>"},{"location":"usage/cli/convert-command/#core-options","title":"Core Options","text":""},{"location":"usage/cli/convert-command/#backend-selection","title":"Backend Selection","text":"<pre><code>--backend {llm|vlm}\n</code></pre> <p>LLM (Language Model): - Best for text-heavy documents - Supports chunking and consolidation - Works with local and remote providers</p> <p>VLM (Vision-Language Model): - Best for forms and structured layouts - Processes images directly - Local inference only</p> <p>Example: <pre><code># Use LLM backend\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm\n\n# Use VLM backend\nuv run docling-graph convert form.jpg \\\n    --template \"templates.IDCard\" \\\n    --backend vlm\n</code></pre></p>"},{"location":"usage/cli/convert-command/#inference-mode","title":"Inference Mode","text":"<pre><code>--inference {local|remote}\n</code></pre> <p>Local: - Run models on your machine - Requires GPU for best performance - No API costs</p> <p>Remote: - Use cloud API providers - Requires API key - Pay per request</p> <p>Example: <pre><code># Local inference\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --inference local\n\n# Remote inference\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --inference remote\n</code></pre></p>"},{"location":"usage/cli/convert-command/#processing-mode","title":"Processing Mode","text":"<pre><code>--processing-mode {one-to-one|many-to-one}\n</code></pre> <p>many-to-one (recommended): - Merge all pages into single graph - Better for multi-page documents - Enables consolidation</p> <p>one-to-one: - Create separate graph per page - Better for independent pages - Faster processing</p> <p>Example: <pre><code># Merge all pages\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --processing-mode many-to-one\n\n# Process pages separately\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --processing-mode one-to-one\n</code></pre></p>"},{"location":"usage/cli/convert-command/#model-configuration","title":"Model Configuration","text":""},{"location":"usage/cli/convert-command/#provider-override","title":"Provider Override","text":"<pre><code>--provider PROVIDER\n</code></pre> <p>Available providers: - Local: <code>vllm</code>, <code>ollama</code> - Remote: <code>mistral</code>, <code>openai</code>, <code>gemini</code>, <code>watsonx</code></p>"},{"location":"usage/cli/convert-command/#model-override","title":"Model Override","text":"<pre><code>--model MODEL\n</code></pre> <p>Example: <pre><code># Use specific model\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --provider mistral \\\n    --model mistral-large-latest\n</code></pre></p>"},{"location":"usage/cli/convert-command/#extraction-options","title":"Extraction Options","text":""},{"location":"usage/cli/convert-command/#chunking","title":"Chunking","text":"<pre><code>--use-chunking / --no-use-chunking\n</code></pre> <p>Enable chunking for: - Large documents (&gt;5 pages) - Documents exceeding context limits - Better extraction accuracy</p> <p>Disable chunking for: - Small documents - When full context is needed - Faster processing</p> <p>Example: <pre><code># Enable chunking (default)\nuv run docling-graph convert large_doc.pdf \\\n    --template \"templates.Research\" \\\n    --use-chunking\n\n# Disable chunking\nuv run docling-graph convert small_doc.pdf \\\n    --template \"templates.Invoice\" \\\n    --no-use-chunking\n</code></pre></p>"},{"location":"usage/cli/convert-command/#llm-consolidation","title":"LLM Consolidation","text":"<pre><code>--llm-consolidation / --no-llm-consolidation\n</code></pre> <p>Enable for: - Higher accuracy - Complex merging scenarios - When quality &gt; speed</p> <p>Disable for: - Faster processing - Lower API costs - Simple documents</p> <p>Example: <pre><code># Enable LLM consolidation\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Research\" \\\n    --llm-consolidation\n\n# Disable (use programmatic merge)\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --no-llm-consolidation\n</code></pre></p>"},{"location":"usage/cli/convert-command/#docling-configuration","title":"Docling Configuration","text":""},{"location":"usage/cli/convert-command/#pipeline-selection","title":"Pipeline Selection","text":"<pre><code>--docling-pipeline {ocr|vision}\n</code></pre> <p>OCR Pipeline: - Traditional OCR approach - Most accurate for standard documents - Faster processing</p> <p>Vision Pipeline: - Uses Granite-Docling VLM - Better for complex layouts - Handles tables and figures better</p> <p>Example: <pre><code># Use OCR pipeline (default)\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --docling-pipeline ocr\n\n# Use vision pipeline\nuv run docling-graph convert complex_doc.pdf \\\n    --template \"templates.Research\" \\\n    --docling-pipeline vision\n</code></pre></p>"},{"location":"usage/cli/convert-command/#export-options","title":"Export Options","text":""},{"location":"usage/cli/convert-command/#export-format","title":"Export Format","text":"<pre><code>--export-format {csv|cypher}\n</code></pre> <p>CSV: - For Neo4j import - Separate nodes.csv and edges.csv - Easy to analyze</p> <p>Cypher: - Direct Neo4j execution - Single .cypher file - Ready to import</p> <p>Example: <pre><code># Export as CSV\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --export-format csv\n\n# Export as Cypher\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --export-format cypher\n</code></pre></p>"},{"location":"usage/cli/convert-command/#docling-exports","title":"Docling Exports","text":"<pre><code>--export-docling-json / --no-docling-json\n--export-markdown / --no-markdown\n--export-per-page / --no-per-page\n</code></pre> <p>Example: <pre><code># Export all Docling outputs\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --export-docling-json \\\n    --export-markdown \\\n    --export-per-page\n\n# Minimal exports\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --no-docling-json \\\n    --no-markdown \\\n    --no-per-page\n</code></pre></p>"},{"location":"usage/cli/convert-command/#graph-options","title":"Graph Options","text":""},{"location":"usage/cli/convert-command/#reverse-edges","title":"Reverse Edges","text":"<pre><code>--reverse-edges\n</code></pre> <p>Creates bidirectional relationships in the graph.</p> <p>Example: <pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --reverse-edges\n</code></pre></p>"},{"location":"usage/cli/convert-command/#output-options","title":"Output Options","text":""},{"location":"usage/cli/convert-command/#output-directory","title":"Output Directory","text":"<pre><code>--output-dir PATH\n</code></pre> <p>Default: <code>outputs/</code></p> <p>Example: <pre><code># Custom output directory\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"results/invoice_001\"\n\n# Organize by date\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"outputs/$(date +%Y-%m-%d)\"\n</code></pre></p>"},{"location":"usage/cli/convert-command/#complete-examples","title":"Complete Examples","text":""},{"location":"usage/cli/convert-command/#example-1-simple-invoice-vlm","title":"Example 1: Simple Invoice (VLM)","text":"<pre><code>uv run docling-graph convert invoice.jpg \\\n    --template \"templates.Invoice\" \\\n    --backend vlm \\\n    --processing-mode one-to-one \\\n    --output-dir \"outputs/invoice\"\n</code></pre>"},{"location":"usage/cli/convert-command/#example-2-research-paper-remote-llm","title":"Example 2: Research Paper (Remote LLM)","text":"<pre><code>export MISTRAL_API_KEY=\"your-key\"\n\nuv run docling-graph convert research.pdf \\\n    --template \"templates.Research\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider mistral \\\n    --model mistral-large-latest \\\n    --processing-mode many-to-one \\\n    --use-chunking \\\n    --llm-consolidation \\\n    --output-dir \"outputs/research\"\n</code></pre>"},{"location":"usage/cli/convert-command/#example-3-local-processing-ollama","title":"Example 3: Local Processing (Ollama)","text":"<pre><code># Start Ollama server first\nollama serve\n\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm \\\n    --inference local \\\n    --provider ollama \\\n    --model llama3:8b \\\n    --processing-mode many-to-one \\\n    --use-chunking \\\n    --output-dir \"outputs/local\"\n</code></pre>"},{"location":"usage/cli/convert-command/#example-4-cypher-export-for-neo4j","title":"Example 4: Cypher Export for Neo4j","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm \\\n    --inference remote \\\n    --export-format cypher \\\n    --output-dir \"outputs/neo4j\"\n\n# Import to Neo4j\ncat outputs/neo4j/graph.cypher | cypher-shell\n</code></pre>"},{"location":"usage/cli/convert-command/#example-5-minimal-processing","title":"Example 5: Minimal Processing","text":"<pre><code>uv run docling-graph convert small_doc.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm \\\n    --inference local \\\n    --no-use-chunking \\\n    --no-llm-consolidation \\\n    --no-docling-json \\\n    --no-markdown \\\n    --output-dir \"outputs/minimal\"\n</code></pre>"},{"location":"usage/cli/convert-command/#batch-processing","title":"Batch Processing","text":""},{"location":"usage/cli/convert-command/#process-multiple-files","title":"Process Multiple Files","text":"<pre><code># Bash loop\nfor pdf in documents/*.pdf; do\n    uv run docling-graph convert \"$pdf\" \\\n        --template \"templates.Invoice\" \\\n        --output-dir \"outputs/$(basename $pdf .pdf)\"\ndone\n</code></pre>"},{"location":"usage/cli/convert-command/#parallel-processing","title":"Parallel Processing","text":"<pre><code># Using GNU parallel\nls documents/*.pdf | parallel -j 4 \\\n    uv run docling-graph convert {} \\\n        --template \"templates.Invoice\" \\\n        --output-dir \"outputs/{/.}\"\n</code></pre>"},{"location":"usage/cli/convert-command/#batch-script","title":"Batch Script","text":"<pre><code>#!/bin/bash\n# batch_convert.sh\n\nTEMPLATE=\"templates.Invoice\"\nINPUT_DIR=\"documents\"\nOUTPUT_BASE=\"outputs\"\n\nfor file in \"$INPUT_DIR\"/*.pdf; do\n    filename=$(basename \"$file\" .pdf)\n    echo \"Processing: $filename\"\n\n    uv run docling-graph convert \"$file\" \\\n        --template \"$TEMPLATE\" \\\n        --output-dir \"$OUTPUT_BASE/$filename\" \\\n        --backend llm \\\n        --inference remote\n\n    echo \"Completed: $filename\"\ndone\n</code></pre>"},{"location":"usage/cli/convert-command/#configuration-priority","title":"Configuration Priority","text":"<p>Options are resolved in this order (highest to lowest):</p> <ol> <li>Command-line arguments</li> <li>config.yaml (from <code>init</code>)</li> <li>Built-in defaults</li> </ol>"},{"location":"usage/cli/convert-command/#example","title":"Example","text":"<pre><code># config.yaml\ndefaults:\n  backend: llm\n  inference: local\n  processing_mode: many-to-one\n</code></pre> <pre><code># This uses remote inference (CLI overrides config)\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --inference remote\n</code></pre>"},{"location":"usage/cli/convert-command/#output-structure","title":"Output Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 nodes.csv                    # Node data\n\u251c\u2500\u2500 edges.csv                    # Edge data\n\u251c\u2500\u2500 graph.json                   # Complete graph\n\u251c\u2500\u2500 graph_stats.json             # Statistics\n\u251c\u2500\u2500 graph_visualization.html     # Interactive viz\n\u251c\u2500\u2500 markdown_report.md           # Summary report\n\u251c\u2500\u2500 docling_document.json        # Docling output (optional)\n\u251c\u2500\u2500 full_document.md             # Markdown export (optional)\n\u2514\u2500\u2500 per_page/                    # Per-page markdown (optional)\n    \u251c\u2500\u2500 page_1.md\n    \u251c\u2500\u2500 page_2.md\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"usage/cli/convert-command/#error-handling","title":"Error Handling","text":""},{"location":"usage/cli/convert-command/#configuration-errors","title":"Configuration Errors","text":"<pre><code>[red]Configuration Error:[/red] Invalid backend type: 'invalid'\n</code></pre> <p>Solution: Use <code>llm</code> or <code>vlm</code></p>"},{"location":"usage/cli/convert-command/#extraction-errors","title":"Extraction Errors","text":"<pre><code>[red]Extraction Error:[/red] Template not found: 'templates.Missing'\n</code></pre> <p>Solution: Check template path and ensure it's importable</p>"},{"location":"usage/cli/convert-command/#api-errors","title":"API Errors","text":"<pre><code>[red]Pipeline Error:[/red] API key not found for provider: mistral\n</code></pre> <p>Solution: <pre><code>export MISTRAL_API_KEY=\"your-key\"\n</code></pre></p>"},{"location":"usage/cli/convert-command/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/cli/convert-command/#issue-template-not-found","title":"Issue: Template Not Found","text":"<p>Error: <pre><code>ModuleNotFoundError: No module named 'templates'\n</code></pre></p> <p>Solution: <pre><code># Ensure template is in Python path\nexport PYTHONPATH=\"${PYTHONPATH}:$(pwd)\"\n\n# Or use absolute path\nuv run docling-graph convert document.pdf \\\n    --template \"my_project.templates.Invoice\"\n</code></pre></p>"},{"location":"usage/cli/convert-command/#issue-out-of-memory","title":"Issue: Out of Memory","text":"<p>Error: <pre><code>CUDA out of memory\n</code></pre></p> <p>Solution: <pre><code># Enable chunking\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --use-chunking\n\n# Or use smaller model\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --model \"ibm-granite/granite-4.0-1b\"\n</code></pre></p>"},{"location":"usage/cli/convert-command/#issue-slow-processing","title":"Issue: Slow Processing","text":"<p>Solution: <pre><code># Disable LLM consolidation\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --no-llm-consolidation\n\n# Or disable chunking for small docs\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --no-use-chunking\n</code></pre></p>"},{"location":"usage/cli/convert-command/#best-practices","title":"Best Practices","text":""},{"location":"usage/cli/convert-command/#1-use-configuration-files","title":"1. Use Configuration Files","text":"<pre><code># \u2705 Good - Reusable configuration\nuv run docling-graph init\nuv run docling-graph convert document.pdf -t \"templates.Invoice\"\n\n# \u274c Avoid - Repeating options\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --backend llm --inference remote --provider mistral\n</code></pre>"},{"location":"usage/cli/convert-command/#2-organize-outputs","title":"2. Organize Outputs","text":"<pre><code># \u2705 Good - Organized by document\nuv run docling-graph convert invoice_001.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"outputs/invoice_001\"\n\n# \u274c Avoid - Overwriting outputs\nuv run docling-graph convert invoice_001.pdf \\\n    --template \"templates.Invoice\"\n</code></pre>"},{"location":"usage/cli/convert-command/#3-use-appropriate-backend","title":"3. Use Appropriate Backend","text":"<pre><code># \u2705 Good - VLM for forms\nuv run docling-graph convert id_card.jpg \\\n    --template \"templates.IDCard\" \\\n    --backend vlm\n\n# \u2705 Good - LLM for documents\nuv run docling-graph convert research.pdf \\\n    --template \"templates.Research\" \\\n    --backend llm\n</code></pre>"},{"location":"usage/cli/convert-command/#next-steps","title":"Next Steps","text":"<ol> <li>inspect Command \u2192 - Visualize results</li> <li>CLI Recipes \u2192 - Common patterns</li> <li>Examples \u2192 - Real-world examples</li> </ol>"},{"location":"usage/cli/convert-command/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/cli/convert-command/#minimal-command","title":"Minimal Command","text":"<pre><code>uv run docling-graph convert SOURCE -t TEMPLATE\n</code></pre>"},{"location":"usage/cli/convert-command/#common-options","title":"Common Options","text":"<pre><code># Backend and inference\n--backend llm --inference remote\n\n# Processing\n--processing-mode many-to-one --use-chunking\n\n# Export\n--export-format csv --output-dir PATH\n\n# Model\n--provider mistral --model mistral-large-latest\n</code></pre>"},{"location":"usage/cli/convert-command/#all-options","title":"All Options","text":"<pre><code>uv run docling-graph convert SOURCE \\\n    --template TEMPLATE \\\n    --backend {llm|vlm} \\\n    --inference {local|remote} \\\n    --processing-mode {one-to-one|many-to-one} \\\n    --docling-pipeline {ocr|vision} \\\n    --provider PROVIDER \\\n    --model MODEL \\\n    --use-chunking / --no-use-chunking \\\n    --llm-consolidation / --no-llm-consolidation \\\n    --export-format {csv|cypher} \\\n    --export-docling-json / --no-docling-json \\\n    --export-markdown / --no-markdown \\\n    --export-per-page / --no-per-page \\\n    --reverse-edges \\\n    --output-dir PATH\n</code></pre>"},{"location":"usage/cli/init-command/","title":"init Command","text":""},{"location":"usage/cli/init-command/#overview","title":"Overview","text":"<p>The <code>init</code> command creates a <code>config.yaml</code> file in your current directory through an interactive setup process.</p> <p>Purpose: - Generate configuration files - Validate dependencies - Guide API key setup - Provide next steps</p>"},{"location":"usage/cli/init-command/#basic-usage","title":"Basic Usage","text":"<pre><code>uv run docling-graph init\n</code></pre> <p>This launches an interactive wizard that guides you through: 1. Backend selection (LLM/VLM) 2. Inference mode (local/remote) 3. Provider selection 4. Model selection 5. Processing mode 6. Export format</p>"},{"location":"usage/cli/init-command/#interactive-setup","title":"Interactive Setup","text":""},{"location":"usage/cli/init-command/#step-1-backend-selection","title":"Step 1: Backend Selection","text":"<pre><code>Choose your backend:\n1. LLM (Language Model) - Best for text-heavy documents\n2. VLM (Vision-Language Model) - Best for forms and structured layouts\n\nYour choice [1-2]:\n</code></pre>"},{"location":"usage/cli/init-command/#step-2-inference-mode","title":"Step 2: Inference Mode","text":"<pre><code>Choose inference mode:\n1. Local - Run models on your machine\n2. Remote - Use API providers (requires API key)\n\nYour choice [1-2]:\n</code></pre>"},{"location":"usage/cli/init-command/#step-3-provider-selection","title":"Step 3: Provider Selection","text":"<p>For Local LLM: <pre><code>Choose local LLM provider:\n1. vLLM (recommended for GPU)\n2. Ollama (recommended for CPU)\n\nYour choice [1-2]:\n</code></pre></p> <p>For Remote LLM: <pre><code>Choose remote provider:\n1. Mistral AI\n2. OpenAI\n3. Google Gemini\n4. IBM watsonx\n\nYour choice [1-4]:\n</code></pre></p>"},{"location":"usage/cli/init-command/#step-4-model-selection","title":"Step 4: Model Selection","text":"<pre><code>Available models for Mistral AI:\n1. mistral-small-latest (fast, cost-effective)\n2. mistral-large-latest (most capable)\n\nYour choice [1-2]:\n</code></pre>"},{"location":"usage/cli/init-command/#step-5-processing-mode","title":"Step 5: Processing Mode","text":"<pre><code>Choose processing mode:\n1. many-to-one - Merge all pages into single graph (recommended)\n2. one-to-one - Create separate graph per page\n\nYour choice [1-2]:\n</code></pre>"},{"location":"usage/cli/init-command/#step-6-export-format","title":"Step 6: Export Format","text":"<pre><code>Choose export format:\n1. CSV (for Neo4j import)\n2. Cypher (for direct Neo4j execution)\n\nYour choice [1-2]:\n</code></pre>"},{"location":"usage/cli/init-command/#generated-configuration","title":"Generated Configuration","text":""},{"location":"usage/cli/init-command/#example-remote-llm-mistral","title":"Example: Remote LLM (Mistral)","text":"<pre><code># config.yaml\ndefaults:\n  processing_mode: many-to-one\n  backend: llm\n  inference: remote\n  export_format: csv\n\ndocling:\n  pipeline: ocr\n  export:\n    docling_json: true\n    markdown: true\n    per_page_markdown: false\n\nmodels:\n  llm:\n    local:\n      default_model: ibm-granite/granite-4.0-1b\n      provider: vllm\n    remote:\n      default_model: mistral-small-latest\n      provider: mistral\n  vlm:\n    local:\n      default_model: numind/NuExtract-2.0-8B\n      provider: docling\n\noutput:\n  directory: outputs\n</code></pre>"},{"location":"usage/cli/init-command/#example-local-llm-ollama","title":"Example: Local LLM (Ollama)","text":"<pre><code>defaults:\n  processing_mode: many-to-one\n  backend: llm\n  inference: local\n  export_format: csv\n\nmodels:\n  llm:\n    local:\n      default_model: llama3:8b\n      provider: ollama\n    remote:\n      default_model: mistral-small-latest\n      provider: mistral\n  vlm:\n    local:\n      default_model: numind/NuExtract-2.0-8B\n      provider: docling\n\noutput:\n  directory: outputs\n</code></pre>"},{"location":"usage/cli/init-command/#example-vlm-local","title":"Example: VLM (Local)","text":"<pre><code>defaults:\n  processing_mode: one-to-one\n  backend: vlm\n  inference: local\n  export_format: csv\n\ndocling:\n  pipeline: vision\n\nmodels:\n  llm:\n    local:\n      default_model: ibm-granite/granite-4.0-1b\n      provider: vllm\n    remote:\n      default_model: mistral-small-latest\n      provider: mistral\n  vlm:\n    local:\n      default_model: numind/NuExtract-2.0-8B\n      provider: docling\n\noutput:\n  directory: outputs\n</code></pre>"},{"location":"usage/cli/init-command/#dependency-validation","title":"Dependency Validation","text":"<p>After configuration, <code>init</code> validates required dependencies:</p>"},{"location":"usage/cli/init-command/#all-dependencies-installed","title":"All Dependencies Installed","text":"<pre><code>\u2713 All required dependencies are installed\n</code></pre>"},{"location":"usage/cli/init-command/#missing-dependencies","title":"Missing Dependencies","text":"<pre><code>\u26a0 Missing dependencies for remote inference\nRun: uv sync --extra remote\n</code></pre> <p>Common dependency groups: - <code>--extra local</code> - Local inference (vLLM, Ollama) - <code>--extra remote</code> - Remote APIs (Mistral, OpenAI, Gemini) - <code>--extra watsonx</code> - IBM watsonx support - <code>--extra all</code> - All features</p>"},{"location":"usage/cli/init-command/#next-steps-guidance","title":"Next Steps Guidance","text":""},{"location":"usage/cli/init-command/#remote-provider-setup","title":"Remote Provider Setup","text":"<pre><code>Next steps:\n1. Install dependencies:\n   uv sync --extra remote\n\n2. Set your API key:\n   export MISTRAL_API_KEY=\"your-api-key-here\"\n\n3. Run your first conversion:\n   uv run docling-graph convert document.pdf \\\n       --template \"my_templates.Invoice\"\n</code></pre>"},{"location":"usage/cli/init-command/#local-provider-setup","title":"Local Provider Setup","text":"<pre><code>Next steps:\n1. Install dependencies:\n   uv sync --extra local\n\n2. Start Ollama server:\n   ollama serve\n\n3. Pull the model:\n   ollama pull llama3:8b\n\n4. Run your first conversion:\n   uv run docling-graph convert document.pdf \\\n       --template \"my_templates.Invoice\"\n</code></pre>"},{"location":"usage/cli/init-command/#overwriting-configuration","title":"Overwriting Configuration","text":"<p>If <code>config.yaml</code> already exists:</p> <pre><code>A configuration file: 'config.yaml' already exists.\nOverwrite it? [y/N]:\n</code></pre> <ul> <li>y - Replace existing configuration</li> <li>N - Cancel and keep existing file</li> </ul>"},{"location":"usage/cli/init-command/#non-interactive-mode","title":"Non-Interactive Mode","text":"<p>If interactive mode is unavailable (e.g., in CI/CD):</p> <pre><code>uv run docling-graph init\n# Falls back to default configuration\n</code></pre> <p>Default configuration uses: - Backend: <code>llm</code> - Inference: <code>local</code> - Provider: <code>vllm</code> - Processing: <code>many-to-one</code> - Export: <code>csv</code></p>"},{"location":"usage/cli/init-command/#complete-examples","title":"Complete Examples","text":""},{"location":"usage/cli/init-command/#example-1-first-time-setup","title":"Example 1: First-Time Setup","text":"<pre><code># Initialize configuration\nuv run docling-graph init\n\n# Follow prompts:\n# 1. Choose LLM backend\n# 2. Choose remote inference\n# 3. Choose Mistral provider\n# 4. Choose mistral-small-latest model\n# 5. Choose many-to-one processing\n# 6. Choose CSV export\n\n# Install dependencies\nuv sync --extra remote\n\n# Set API key\nexport MISTRAL_API_KEY=\"your-key\"\n\n# Test conversion\nuv run docling-graph convert test.pdf \\\n    --template \"templates.Invoice\"\n</code></pre>"},{"location":"usage/cli/init-command/#example-2-local-development-setup","title":"Example 2: Local Development Setup","text":"<pre><code># Initialize for local development\nuv run docling-graph init\n\n# Follow prompts:\n# 1. Choose LLM backend\n# 2. Choose local inference\n# 3. Choose Ollama provider\n# 4. Choose llama3:8b model\n# 5. Choose many-to-one processing\n# 6. Choose CSV export\n\n# Install dependencies\nuv sync --extra local\n\n# Start Ollama\nollama serve\n\n# Pull model\nollama pull llama3:8b\n\n# Test conversion\nuv run docling-graph convert test.pdf \\\n    --template \"templates.Invoice\"\n</code></pre>"},{"location":"usage/cli/init-command/#example-3-vlm-setup","title":"Example 3: VLM Setup","text":"<pre><code># Initialize for VLM\nuv run docling-graph init\n\n# Follow prompts:\n# 1. Choose VLM backend\n# 2. Choose local inference (only option for VLM)\n# 3. Choose one-to-one processing\n# 4. Choose CSV export\n\n# Install dependencies\nuv sync --extra all\n\n# Test conversion\nuv run docling-graph convert form.jpg \\\n    --template \"templates.IDCard\"\n</code></pre>"},{"location":"usage/cli/init-command/#configuration-file-location","title":"Configuration File Location","text":"<p>The <code>config.yaml</code> file is created in your current working directory:</p> <pre><code># Create config in project root\ncd /path/to/project\nuv run docling-graph init\n\n# Creates: /path/to/project/config.yaml\n</code></pre> <p>Best Practice: Run <code>init</code> from your project root directory.</p>"},{"location":"usage/cli/init-command/#manual-configuration","title":"Manual Configuration","text":"<p>You can also create <code>config.yaml</code> manually:</p> <pre><code># Minimal configuration\ndefaults:\n  backend: llm\n  inference: remote\n\nmodels:\n  llm:\n    remote:\n      default_model: mistral-small-latest\n      provider: mistral\n</code></pre> <p>Or use the template:</p> <pre><code># Copy template\ncp docling_graph/config_template.yaml config.yaml\n\n# Edit as needed\nnano config.yaml\n</code></pre>"},{"location":"usage/cli/init-command/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/cli/init-command/#issue-interactive-mode-not-available","title":"Issue: Interactive Mode Not Available","text":"<p>Error: <pre><code>Interactive mode not available. Using default configuration.\n</code></pre></p> <p>Solution: - Running in non-interactive environment (CI/CD) - Default configuration will be used - Manually edit <code>config.yaml</code> if needed</p>"},{"location":"usage/cli/init-command/#issue-permission-denied","title":"Issue: Permission Denied","text":"<p>Error: <pre><code>Error saving config: Permission denied\n</code></pre></p> <p>Solution: <pre><code># Check directory permissions\nls -la\n\n# Run from writable directory\ncd ~/projects/my-project\nuv run docling-graph init\n</code></pre></p>"},{"location":"usage/cli/init-command/#issue-invalid-configuration","title":"Issue: Invalid Configuration","text":"<p>Error: <pre><code>Error creating config: Invalid backend type\n</code></pre></p> <p>Solution: - Restart <code>init</code> command - Choose valid options (llm/vlm) - Check for typos in manual edits</p>"},{"location":"usage/cli/init-command/#best-practices","title":"Best Practices","text":""},{"location":"usage/cli/init-command/#1-initialize-per-project","title":"1. Initialize Per Project","text":"<pre><code># \u2705 Good - One config per project\ncd project1/\nuv run docling-graph init\n\ncd project2/\nuv run docling-graph init\n\n# \u274c Avoid - Shared config across projects\ncd ~/\nuv run docling-graph init\n</code></pre>"},{"location":"usage/cli/init-command/#2-version-control","title":"2. Version Control","text":"<pre><code># \u2705 Good - Track configuration\ngit add config.yaml\ngit commit -m \"Add docling-graph configuration\"\n\n# Add to .gitignore if it contains secrets\necho \"config.yaml\" &gt;&gt; .gitignore\n</code></pre>"},{"location":"usage/cli/init-command/#3-environment-specific-configs","title":"3. Environment-Specific Configs","text":"<pre><code># Development\ncp config.yaml config.dev.yaml\n\n# Production\ncp config.yaml config.prod.yaml\n\n# Use specific config\ncp config.prod.yaml config.yaml\nuv run docling-graph convert document.pdf -t \"templates.Invoice\"\n</code></pre>"},{"location":"usage/cli/init-command/#next-steps","title":"Next Steps","text":"<p>Now that you have a configuration:</p> <ol> <li>convert Command \u2192 - Convert documents</li> <li>CLI Recipes \u2192 - Common patterns</li> <li>Configuration Guide \u2192 - Advanced config</li> </ol>"},{"location":"usage/cli/init-command/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/cli/init-command/#basic-command","title":"Basic Command","text":"<pre><code>uv run docling-graph init\n</code></pre>"},{"location":"usage/cli/init-command/#overwrite-existing","title":"Overwrite Existing","text":"<pre><code># Will prompt for confirmation\nuv run docling-graph init\n</code></pre>"},{"location":"usage/cli/init-command/#check-generated-config","title":"Check Generated Config","text":"<pre><code>cat config.yaml\n</code></pre>"},{"location":"usage/cli/init-command/#validate-dependencies","title":"Validate Dependencies","text":"<pre><code># After init, install as prompted\nuv sync --extra remote  # or local, watsonx, all\n</code></pre>"},{"location":"usage/cli/inspect-command/","title":"inspect Command","text":""},{"location":"usage/cli/inspect-command/#overview","title":"Overview","text":"<p>The <code>inspect</code> command creates interactive HTML visualizations of your knowledge graphs that open in your browser.</p> <p>Key Features: - Interactive node/edge exploration - CSV and JSON import - Self-contained HTML output - Automatic browser opening - Shareable visualizations</p>"},{"location":"usage/cli/inspect-command/#basic-usage","title":"Basic Usage","text":"<pre><code>uv run docling-graph inspect PATH [OPTIONS]\n</code></pre>"},{"location":"usage/cli/inspect-command/#required-arguments","title":"Required Arguments","text":"Argument Description <code>PATH</code> Path to graph data (directory for CSV, file for JSON)"},{"location":"usage/cli/inspect-command/#example","title":"Example","text":"<pre><code># Visualize CSV output\nuv run docling-graph inspect outputs/\n\n# Visualize JSON output\nuv run docling-graph inspect outputs/graph.json --format json\n</code></pre>"},{"location":"usage/cli/inspect-command/#input-formats","title":"Input Formats","text":""},{"location":"usage/cli/inspect-command/#csv-format-default","title":"CSV Format (Default)","text":"<p>For CSV format, provide a directory containing: - <code>nodes.csv</code> - Node data - <code>edges.csv</code> - Edge data</p> <pre><code>uv run docling-graph inspect outputs/\n</code></pre> <p>Directory structure: <pre><code>outputs/\n\u251c\u2500\u2500 nodes.csv\n\u251c\u2500\u2500 edges.csv\n\u2514\u2500\u2500 ... (other files)\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#json-format","title":"JSON Format","text":"<p>For JSON format, provide a file path to the graph JSON:</p> <pre><code>uv run docling-graph inspect outputs/graph.json --format json\n</code></pre>"},{"location":"usage/cli/inspect-command/#options","title":"Options","text":""},{"location":"usage/cli/inspect-command/#input-format","title":"Input Format","text":"<pre><code>--format {csv|json}\n</code></pre> <p>Default: <code>csv</code></p> <p>Example: <pre><code># CSV format (default)\nuv run docling-graph inspect outputs/\n\n# JSON format\nuv run docling-graph inspect outputs/graph.json --format json\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#output-file","title":"Output File","text":"<pre><code>--output PATH\n</code></pre> <p>Specify where to save the HTML visualization.</p> <p>Default: Temporary file</p> <p>Example: <pre><code># Save to specific location\nuv run docling-graph inspect outputs/ \\\n    --output visualization.html\n\n# Save with timestamp\nuv run docling-graph inspect outputs/ \\\n    --output \"viz_$(date +%Y%m%d_%H%M%S).html\"\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#browser-control","title":"Browser Control","text":"<pre><code>--open / --no-open\n</code></pre> <p>Control whether to automatically open the visualization in your browser.</p> <p>Default: <code>--open</code> (opens automatically)</p> <p>Example: <pre><code># Open automatically (default)\nuv run docling-graph inspect outputs/\n\n# Don't open browser\nuv run docling-graph inspect outputs/ \\\n    --no-open \\\n    --output visualization.html\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#complete-examples","title":"Complete Examples","text":""},{"location":"usage/cli/inspect-command/#example-1-quick-visualization","title":"Example 1: Quick Visualization","text":"<pre><code># Convert document\nuv run docling-graph convert invoice.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"outputs/invoice\"\n\n# Visualize immediately\nuv run docling-graph inspect outputs/invoice/\n</code></pre>"},{"location":"usage/cli/inspect-command/#example-2-save-for-later","title":"Example 2: Save for Later","text":"<pre><code># Create visualization without opening\nuv run docling-graph inspect outputs/ \\\n    --output graph_viz.html \\\n    --no-open\n\n# Open later\nopen graph_viz.html  # macOS\nxdg-open graph_viz.html  # Linux\nstart graph_viz.html  # Windows\n</code></pre>"},{"location":"usage/cli/inspect-command/#example-3-json-format","title":"Example 3: JSON Format","text":"<pre><code># Visualize JSON graph\nuv run docling-graph inspect outputs/graph.json \\\n    --format json \\\n    --output interactive_graph.html\n</code></pre>"},{"location":"usage/cli/inspect-command/#example-4-batch-visualization","title":"Example 4: Batch Visualization","text":"<pre><code># Create visualizations for multiple outputs\nfor dir in outputs/*/; do\n    name=$(basename \"$dir\")\n    uv run docling-graph inspect \"$dir\" \\\n        --output \"visualizations/${name}.html\" \\\n        --no-open\ndone\n\necho \"Created visualizations in visualizations/\"\n</code></pre>"},{"location":"usage/cli/inspect-command/#example-5-share-visualization","title":"Example 5: Share Visualization","text":"<pre><code># Create self-contained HTML\nuv run docling-graph inspect outputs/ \\\n    --output shared_graph.html \\\n    --no-open\n\n# Share the HTML file\n# The file contains all data and can be opened anywhere\n</code></pre>"},{"location":"usage/cli/inspect-command/#interactive-features","title":"Interactive Features","text":""},{"location":"usage/cli/inspect-command/#node-exploration","title":"Node Exploration","text":"<p>Click on a node to: - View node properties - Highlight connected edges - See relationship details - Filter by node type</p>"},{"location":"usage/cli/inspect-command/#edge-exploration","title":"Edge Exploration","text":"<p>Click on an edge to: - View relationship type - See source and target nodes - View edge properties</p>"},{"location":"usage/cli/inspect-command/#graph-navigation","title":"Graph Navigation","text":"<p>Controls: - Zoom: Mouse wheel or pinch - Pan: Click and drag - Reset: Double-click background - Search: Use search box to find nodes</p>"},{"location":"usage/cli/inspect-command/#layout-options","title":"Layout Options","text":"<p>Available layouts: - Force-directed: Automatic positioning - Hierarchical: Top-down structure - Circular: Nodes in a circle - Grid: Regular grid layout</p>"},{"location":"usage/cli/inspect-command/#output-structure","title":"Output Structure","text":""},{"location":"usage/cli/inspect-command/#html-file-contents","title":"HTML File Contents","text":"<p>The generated HTML file is self-contained and includes: - Complete graph data - Interactive visualization library - Styling and controls - No external dependencies</p> <p>File size: Typically 100KB - 2MB depending on graph size</p>"},{"location":"usage/cli/inspect-command/#sharing","title":"Sharing","text":"<pre><code># Create visualization\nuv run docling-graph inspect outputs/ \\\n    --output graph.html \\\n    --no-open\n\n# Share via email, cloud storage, or web hosting\n# Recipients can open directly in any modern browser\n</code></pre>"},{"location":"usage/cli/inspect-command/#validation","title":"Validation","text":""},{"location":"usage/cli/inspect-command/#csv-validation","title":"CSV Validation","text":"<p>The command validates that required files exist:</p> <pre><code>uv run docling-graph inspect outputs/\n</code></pre> <p>Checks: - Directory exists - <code>nodes.csv</code> exists - <code>edges.csv</code> exists</p> <p>Error if missing: <pre><code>[bold red]Error:[/bold red] nodes.csv not found in outputs/\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#json-validation","title":"JSON Validation","text":"<pre><code>uv run docling-graph inspect graph.json --format json\n</code></pre> <p>Checks: - File exists - File has <code>.json</code> extension - Valid JSON format</p> <p>Error if invalid: <pre><code>[bold red]Error:[/bold red] For JSON format, path must be a .json file\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/cli/inspect-command/#issue-files-not-found","title":"Issue: Files Not Found","text":"<p>Error: <pre><code>[bold red]Error:[/bold red] nodes.csv not found in outputs/\n</code></pre></p> <p>Solution: <pre><code># Check directory contents\nls outputs/\n\n# Ensure convert completed successfully\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"outputs\"\n\n# Then inspect\nuv run docling-graph inspect outputs/\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#issue-browser-doesnt-open","title":"Issue: Browser Doesn't Open","text":"<p>Error: <pre><code>Browser failed to open\n</code></pre></p> <p>Solution: <pre><code># Save to file and open manually\nuv run docling-graph inspect outputs/ \\\n    --output graph.html \\\n    --no-open\n\n# Open manually\nopen graph.html  # macOS\nxdg-open graph.html  # Linux\nstart graph.html  # Windows\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#issue-large-graph-performance","title":"Issue: Large Graph Performance","text":"<p>Problem: Visualization is slow with large graphs</p> <p>Solution: <pre><code># Filter graph before visualization\n# Use Python to create smaller subset\n\n# Or use Neo4j for large graphs\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --export-format cypher\n\n# Import to Neo4j and use Neo4j Browser\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#integration-workflows","title":"Integration Workflows","text":""},{"location":"usage/cli/inspect-command/#workflow-1-development-cycle","title":"Workflow 1: Development Cycle","text":"<pre><code># 1. Convert document\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"test_output\"\n\n# 2. Inspect results\nuv run docling-graph inspect test_output/\n\n# 3. Iterate on template\n# Edit templates/invoice.py\n\n# 4. Re-convert and inspect\nuv run docling-graph convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"test_output\"\n\nuv run docling-graph inspect test_output/\n</code></pre>"},{"location":"usage/cli/inspect-command/#workflow-2-batch-processing-with-visualization","title":"Workflow 2: Batch Processing with Visualization","text":"<pre><code>#!/bin/bash\n# process_and_visualize.sh\n\nINPUT_DIR=\"documents\"\nOUTPUT_BASE=\"outputs\"\nVIZ_DIR=\"visualizations\"\n\nmkdir -p \"$VIZ_DIR\"\n\nfor pdf in \"$INPUT_DIR\"/*.pdf; do\n    name=$(basename \"$pdf\" .pdf)\n    output_dir=\"$OUTPUT_BASE/$name\"\n\n    echo \"Processing: $name\"\n\n    # Convert\n    uv run docling-graph convert \"$pdf\" \\\n        --template \"templates.Invoice\" \\\n        --output-dir \"$output_dir\"\n\n    # Visualize\n    uv run docling-graph inspect \"$output_dir\" \\\n        --output \"$VIZ_DIR/${name}.html\" \\\n        --no-open\n\n    echo \"Completed: $name\"\ndone\n\necho \"All visualizations saved to $VIZ_DIR/\"\n</code></pre>"},{"location":"usage/cli/inspect-command/#workflow-3-quality-assurance","title":"Workflow 3: Quality Assurance","text":"<pre><code># Convert with verbose logging\nuv run docling-graph --verbose convert document.pdf \\\n    --template \"templates.Invoice\" \\\n    --output-dir \"qa_output\"\n\n# Inspect graph structure\nuv run docling-graph inspect qa_output/\n\n# Check statistics\ncat qa_output/graph_stats.json\n\n# Review markdown report\ncat qa_output/markdown_report.md\n</code></pre>"},{"location":"usage/cli/inspect-command/#comparison-with-other-tools","title":"Comparison with Other Tools","text":""},{"location":"usage/cli/inspect-command/#inspect-vs-neo4j-browser","title":"inspect vs Neo4j Browser","text":"Feature inspect Neo4j Browser Setup No setup required Requires Neo4j installation Sharing Self-contained HTML Requires Neo4j access Performance Good for small/medium graphs Excellent for large graphs Querying Basic filtering Full Cypher queries Best for Quick visualization, sharing Production, complex queries"},{"location":"usage/cli/inspect-command/#when-to-use-inspect","title":"When to Use inspect","text":"<p>\u2705 Use inspect for: - Quick visualization during development - Sharing results with non-technical users - Small to medium graphs (&lt;1000 nodes) - No database setup required</p> <p>\u274c Use Neo4j for: - Large graphs (&gt;1000 nodes) - Complex queries - Production deployments - Team collaboration</p>"},{"location":"usage/cli/inspect-command/#best-practices","title":"Best Practices","text":""},{"location":"usage/cli/inspect-command/#1-save-important-visualizations","title":"1. Save Important Visualizations","text":"<pre><code># \u2705 Good - Save with descriptive name\nuv run docling-graph inspect outputs/ \\\n    --output \"invoice_001_graph.html\" \\\n    --no-open\n\n# \u274c Avoid - Temporary files get lost\nuv run docling-graph inspect outputs/\n</code></pre>"},{"location":"usage/cli/inspect-command/#2-organize-visualizations","title":"2. Organize Visualizations","text":"<pre><code># \u2705 Good - Organized structure\nmkdir -p visualizations/invoices\nuv run docling-graph inspect outputs/invoice_001/ \\\n    --output \"visualizations/invoices/invoice_001.html\" \\\n    --no-open\n\n# \u274c Avoid - Cluttered directory\nuv run docling-graph inspect outputs/ \\\n    --output \"viz1.html\" \\\n    --no-open\n</code></pre>"},{"location":"usage/cli/inspect-command/#3-use-for-development","title":"3. Use for Development","text":"<pre><code># \u2705 Good - Quick feedback loop\nuv run docling-graph convert test.pdf -t \"templates.Invoice\" -o \"test\"\nuv run docling-graph inspect test/\n\n# \u2705 Good - Iterate quickly\n# Edit template, re-run, inspect\n</code></pre>"},{"location":"usage/cli/inspect-command/#next-steps","title":"Next Steps","text":"<ol> <li>CLI Recipes \u2192 - Common CLI patterns</li> <li>Visualization Guide \u2192 - Advanced visualization</li> <li>Neo4j Integration \u2192 - Database visualization</li> </ol>"},{"location":"usage/cli/inspect-command/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/cli/inspect-command/#basic-commands","title":"Basic Commands","text":"<pre><code># Visualize CSV (default)\nuv run docling-graph inspect outputs/\n\n# Visualize JSON\nuv run docling-graph inspect graph.json --format json\n\n# Save to file\nuv run docling-graph inspect outputs/ --output viz.html\n\n# Don't open browser\nuv run docling-graph inspect outputs/ --no-open\n</code></pre>"},{"location":"usage/cli/inspect-command/#common-patterns","title":"Common Patterns","text":"<pre><code># Convert and inspect\nuv run docling-graph convert doc.pdf -t \"templates.Invoice\" -o \"out\"\nuv run docling-graph inspect out/\n\n# Batch visualization\nfor dir in outputs/*/; do\n    uv run docling-graph inspect \"$dir\" \\\n        --output \"viz/$(basename $dir).html\" \\\n        --no-open\ndone\n\n# Share visualization\nuv run docling-graph inspect outputs/ \\\n    --output shared.html \\\n    --no-open\n</code></pre>"},{"location":"usage/cli/inspect-command/#all-options","title":"All Options","text":"<pre><code>uv run docling-graph inspect PATH \\\n    --format {csv|json} \\\n    --output PATH \\\n    --open / --no-open\n</code></pre>"},{"location":"usage/examples/","title":"Examples","text":""},{"location":"usage/examples/#overview","title":"Overview","text":"<p>This section provides complete, end-to-end examples organized by both input format and domain/use case. Each example demonstrates how to process different types of documents through the Docling Graph pipeline.</p> <p>What's Covered: - Complete Pydantic templates - CLI and Python API usage - Expected outputs and graph structures - Troubleshooting tips - Best practices</p>"},{"location":"usage/examples/#quick-navigation","title":"Quick Navigation","text":""},{"location":"usage/examples/#by-input-format","title":"By Input Format","text":"Example Input Type Backend Quickstart PDF/Image VLM/LLM URL URL (PDF) LLM Markdown Markdown LLM DoclingDocument JSON LLM"},{"location":"usage/examples/#by-domainuse-case","title":"By Domain/Use Case","text":"Example Domain Input Type Invoice Extraction Business PDF/Image ID Card Identity Image Insurance Policy Legal PDF Research Paper Academic PDF"},{"location":"usage/examples/#section-1-examples-by-input-format","title":"Section 1: Examples by Input Format","text":"<p>Learn how to work with different input types and understand the pipeline's flexibility.</p>"},{"location":"usage/examples/#1-quickstart","title":"1. Quickstart","text":"<p>5-Minute Introduction</p> <p>Get started quickly with a simple document extraction example using traditional PDF or image inputs.</p> <ul> <li>Input: PDF or Image file</li> <li>Use Case: Invoice extraction</li> <li>Backend: VLM (recommended) or LLM</li> <li>Features: Basic extraction, graph visualization</li> </ul> <p>Perfect for: First-time users wanting a quick introduction.</p>"},{"location":"usage/examples/#2-url-input","title":"2. URL Input","text":"<p>Processing Documents from URLs</p> <p>Learn how to process documents directly from URLs without manual downloads.</p> <ul> <li>Input: URL (e.g., <code>https://arxiv.org/pdf/2207.02720</code>)</li> <li>Use Case: Research paper analysis</li> <li>Backend: LLM</li> <li>Features: Automatic download, content type detection, remote processing</li> </ul> <p>What You'll Learn: - URL-based workflows - Automatic content type detection - Download configuration (timeout, size limits) - Network error handling</p> <p>Perfect for: Processing documents from web sources, automated pipelines.</p>"},{"location":"usage/examples/#3-markdown-input","title":"3. Markdown Input","text":"<p>Processing Markdown Documents</p> <p>Extract structured data from Markdown files like README.md or documentation.</p> <ul> <li>Input: Markdown file (<code>.md</code>)</li> <li>Use Case: Documentation analysis</li> <li>Backend: LLM (required)</li> <li>Features: Text-only processing, no OCR needed, fast extraction</li> </ul> <p>What You'll Learn: - Text-only extraction workflow - Processing documentation - Markdown structure preservation - Batch processing multiple files</p> <p>Perfect for: Documentation analysis, knowledge base extraction.</p>"},{"location":"usage/examples/#4-doclingdocument-input","title":"4. DoclingDocument Input","text":"<p>Reprocessing Pre-Converted Documents</p> <p>Use pre-processed DoclingDocument JSON files for fast reprocessing without OCR.</p> <ul> <li>Input: DoclingDocument JSON file</li> <li>Use Case: Invoice reprocessing</li> <li>Backend: LLM or VLM</li> <li>Features: Skip OCR, fast reprocessing, template experimentation</li> </ul> <p>What You'll Learn: - Creating DoclingDocument files - Two-stage processing workflows - Template experimentation - Batch reprocessing</p> <p>Perfect for: Reprocessing documents, A/B testing templates, incremental workflows.</p>"},{"location":"usage/examples/#section-2-examples-by-domainuse-case","title":"Section 2: Examples by Domain/Use Case","text":"<p>Explore complete, domain-specific examples with production-ready templates.</p>"},{"location":"usage/examples/#5-invoice-extraction","title":"5. Invoice Extraction","text":"<p>Complete Invoice Processing</p> <p>Extract structured data from invoices including issuer, client, line items, and totals.</p> <ul> <li>Domain: Business/Finance</li> <li>Input: PDF or Image</li> <li>Backend: VLM (recommended) or LLM</li> <li>Features: Nested entities, relationships, validation</li> </ul> <p>What You'll Learn: - Creating entity and component models - Defining graph relationships - Using edge() helper - Handling addresses and line items</p> <p>Perfect for: Business document processing, accounting automation.</p>"},{"location":"usage/examples/#6-id-card","title":"6. ID Card","text":"<p>Identity Document Extraction</p> <p>Extract personal information from ID cards and identity documents.</p> <ul> <li>Domain: Identity/Government</li> <li>Input: Image (photo of ID card)</li> <li>Backend: VLM (recommended)</li> <li>Features: Structured personal data, validation</li> </ul> <p>What You'll Learn: - Processing identity documents - Handling personal information - Data validation and formatting - Privacy considerations</p> <p>Perfect for: KYC processes, identity verification systems.</p>"},{"location":"usage/examples/#7-insurance-policy","title":"7. Insurance Policy","text":"<p>Legal Document Analysis</p> <p>Extract structured information from insurance policies and legal documents.</p> <ul> <li>Domain: Legal/Insurance</li> <li>Input: PDF (multi-page)</li> <li>Backend: LLM with chunking</li> <li>Features: Complex document structure, multi-page processing</li> </ul> <p>What You'll Learn: - Processing long documents - Handling complex legal terminology - Multi-page extraction strategies - Document consolidation</p> <p>Perfect for: Legal document processing, insurance automation.</p>"},{"location":"usage/examples/#8-research-paper","title":"8. Research Paper","text":"<p>Scientific Document Analysis</p> <p>Extract structured data from academic papers including authors, methodology, and findings.</p> <ul> <li>Domain: Academic/Research</li> <li>Input: PDF (scientific paper)</li> <li>Backend: LLM with chunking</li> <li>Features: Complex structure, citations, methodology</li> </ul> <p>What You'll Learn: - Processing scientific documents - Extracting methodology and findings - Handling citations and references - Academic document structure</p> <p>Perfect for: Research automation, literature review systems.</p>"},{"location":"usage/examples/#input-format-comparison","title":"Input Format Comparison","text":"Format OCR Required Processing Speed Backend Support Best For PDF \u2705 Yes \ud83d\udc22 Slow LLM + VLM Scanned documents, forms Image \u2705 Yes \ud83d\udc22 Slow LLM + VLM Photos, scans URL Depends \u26a1 Variable LLM + VLM Remote documents Markdown \u274c No \u26a1 Fast LLM only Documentation, notes DoclingDocument \u274c No \u26a1 Very Fast LLM only Reprocessing, experimentation"},{"location":"usage/examples/#choosing-the-right-example","title":"Choosing the Right Example","text":""},{"location":"usage/examples/#start-here","title":"Start Here","text":"<p>New to Docling Graph? \u2192 Start with Quickstart</p>"},{"location":"usage/examples/#by-input-format_1","title":"By Input Format","text":"<p>Processing web documents? \u2192 See URL Input</p> <p>Working with documentation? \u2192 See Markdown Input</p> <p>Need to reprocess documents? \u2192 See DoclingDocument Input</p>"},{"location":"usage/examples/#by-domainuse-case_1","title":"By Domain/Use Case","text":"<p>Business Documents: - Invoice Extraction - Invoices, receipts, financial documents</p> <p>Identity Verification: - ID Card - ID cards, passports, identity documents</p> <p>Legal Documents: - Insurance Policy - Policies, contracts, legal agreements</p> <p>Academic Research: - Research Paper - Scientific papers, academic documents - URL Input - Process from arXiv, PubMed, etc.</p> <p>Documentation: - Markdown Input - README files, project documentation</p> <p>Workflow Optimization: - DoclingDocument Input - Fast reprocessing, template testing</p>"},{"location":"usage/examples/#common-workflows","title":"Common Workflows","text":""},{"location":"usage/examples/#workflow-1-url-extract-visualize","title":"Workflow 1: URL \u2192 Extract \u2192 Visualize","text":"<pre><code># Download and process in one step\nuv run docling-graph convert \"https://arxiv.org/pdf/2207.02720\" \\\n    --template \"templates.research.Research\" \\\n    --processing-mode \"many-to-one\"\n\n# Visualize results\nuv run docling-graph inspect outputs\n</code></pre>"},{"location":"usage/examples/#workflow-2-pdf-doclingdocument-reprocess","title":"Workflow 2: PDF \u2192 DoclingDocument \u2192 Reprocess","text":"<pre><code># Step 1: Initial processing with DoclingDocument export\nuv run docling-graph convert invoice.pdf \\\n    --template \"templates.invoice.BasicInvoice\" \\\n    --export-docling-json\n\n# Step 2: Reprocess with different template (no OCR)\nuv run docling-graph convert outputs/invoice_docling.json \\\n    --template \"templates.invoice.DetailedInvoice\"\n</code></pre>"},{"location":"usage/examples/#workflow-3-batch-markdown-processing","title":"Workflow 3: Batch Markdown Processing","text":"<pre><code># Process all markdown files\nfor file in docs/**/*.md; do\n    uv run docling-graph convert \"$file\" \\\n        --template \"templates.documentation.Documentation\" \\\n        --backend llm \\\n        --output-dir \"outputs/$(basename $file .md)\"\ndone\n</code></pre>"},{"location":"usage/examples/#template-examples","title":"Template Examples","text":"<p>All examples use Pydantic templates. Here's a quick reference:</p>"},{"location":"usage/examples/#simple-entity","title":"Simple Entity","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['name']\n    }\n\n    name: str = Field(description=\"Person's name\")\n    email: str = Field(description=\"Email address\")\n</code></pre>"},{"location":"usage/examples/#with-relationships","title":"With Relationships","text":"<pre><code>from docling_graph.utils import edge\n\nclass Organization(BaseModel):\n    \"\"\"Organization with employees.\"\"\"\n    model_config = {'is_entity': True}\n\n    name: str = Field(description=\"Organization name\")\n    employees: list[Person] = edge(\n        \"EMPLOYS\",\n        description=\"Organization employees\"\n    )\n</code></pre>"},{"location":"usage/examples/#complete-examples","title":"Complete Examples","text":"<p>See individual example pages for complete, domain-specific templates.</p>"},{"location":"usage/examples/#additional-resources","title":"Additional Resources","text":""},{"location":"usage/examples/#documentation","title":"Documentation","text":"<ul> <li>Input Formats Guide - Complete input format reference</li> <li>Backend Selection - Choose LLM vs VLM</li> <li>Processing Modes - One-to-one vs many-to-one</li> </ul>"},{"location":"usage/examples/#api-reference","title":"API Reference","text":"<ul> <li>PipelineConfig - Configuration options</li> <li>run_pipeline - Pipeline execution</li> <li>Batch Processing - Process multiple documents</li> </ul>"},{"location":"usage/examples/#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Performance Tuning - Optimize processing</li> <li>Error Handling - Handle failures gracefully</li> <li>Custom Backends - Extend functionality</li> </ul>"},{"location":"usage/examples/#getting-help","title":"Getting Help","text":""},{"location":"usage/examples/#common-issues","title":"Common Issues","text":"<p>\"VLM backend does not support text-only inputs\" \u2192 Use <code>--backend llm</code> for Markdown and text files</p> <p>\"URL download timeout\" \u2192 Increase timeout or download manually first</p> <p>\"Text input is empty\" \u2192 Check file content and encoding</p> <p>\"Invalid DoclingDocument schema\" \u2192 Verify <code>schema_name</code> and <code>version</code> fields</p>"},{"location":"usage/examples/#support","title":"Support","text":"<ul> <li>Documentation: https://ibm.github.io/docling-graph</li> <li>GitHub Issues: https://github.com/IBM/docling-graph/issues</li> <li>Discussions: https://github.com/IBM/docling-graph/discussions</li> </ul>"},{"location":"usage/examples/#next-steps","title":"Next Steps","text":"<ol> <li>Explore Input Formats - Learn about all supported formats</li> <li>Read Advanced Topics - Optimize your workflows</li> </ol>"},{"location":"usage/examples/docling-document-input/","title":"DoclingDocument Input Example","text":""},{"location":"usage/examples/docling-document-input/#overview","title":"Overview","text":"<p>This example demonstrates how to process pre-converted DoclingDocument JSON files, enabling reprocessing of documents without re-running OCR or document conversion.</p> <p>What You'll Learn: - Using DoclingDocument JSON files - Skipping document conversion - Reprocessing workflows - Integration with external Docling pipelines</p> <p>Time: 10 minutes</p>"},{"location":"usage/examples/docling-document-input/#use-case-invoice-reprocessing","title":"Use Case: Invoice Reprocessing","text":"<p>Reprocess a previously converted invoice document with a different template or extraction strategy, without re-running expensive OCR operations.</p>"},{"location":"usage/examples/docling-document-input/#document-source","title":"Document Source","text":"<p>File: <code>invoice_docling.json</code></p> <p>Type: DoclingDocument JSON</p> <p>Content: Pre-processed invoice with structure, text, and layout information.</p>"},{"location":"usage/examples/docling-document-input/#creating-doclingdocument-files","title":"Creating DoclingDocument Files","text":""},{"location":"usage/examples/docling-document-input/#method-1-export-from-docling-graph","title":"Method 1: Export from Docling Graph","text":"<pre><code># First run: Convert PDF and export DoclingDocument\nuv run docling-graph convert invoice.pdf \\\n    --template \"templates.invoice.Invoice\" \\\n    --export-docling-json\n\n# This creates: outputs/invoice_docling.json\n</code></pre>"},{"location":"usage/examples/docling-document-input/#method-2-use-docling-directly","title":"Method 2: Use Docling Directly","text":"<pre><code>from docling.document_converter import DocumentConverter\n\n# Convert document with Docling\nconverter = DocumentConverter()\nresult = converter.convert(\"invoice.pdf\")\n\n# Export DoclingDocument\nwith open(\"invoice_docling.json\", \"w\") as f:\n    f.write(result.document.model_dump_json(indent=2))\n</code></pre>"},{"location":"usage/examples/docling-document-input/#method-3-custom-pipeline","title":"Method 3: Custom Pipeline","text":"<pre><code>from docling_core.types.doc import DoclingDocument\nimport json\n\n# Create custom DoclingDocument\ndoc = DoclingDocument(\n    schema_name=\"DoclingDocument\",\n    version=\"1.0.0\",\n    name=\"custom_invoice\",\n    # ... add pages, body, furniture\n)\n\n# Save to JSON\nwith open(\"custom_docling.json\", \"w\") as f:\n    json.dump(doc.model_dump(), f, indent=2)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#template-definition","title":"Template Definition","text":"<p>We'll use an invoice template for this example.</p> <pre><code>from pydantic import BaseModel, Field\nfrom docling_graph.utils import edge\n\nclass Address(BaseModel):\n    \"\"\"Address component.\"\"\"\n    model_config = {'is_entity': False}\n\n    street: str = Field(description=\"Street address\")\n    city: str = Field(description=\"City\")\n    postal_code: str = Field(description=\"Postal code\")\n    country: str = Field(description=\"Country\")\n\nclass Company(BaseModel):\n    \"\"\"Company entity.\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['name']\n    }\n\n    name: str = Field(description=\"Company name\")\n    address: Address = Field(description=\"Company address\")\n    tax_id: str | None = Field(default=None, description=\"Tax ID\")\n\nclass LineItem(BaseModel):\n    \"\"\"Invoice line item.\"\"\"\n    model_config = {'is_entity': False}\n\n    description: str = Field(description=\"Item description\")\n    quantity: float = Field(description=\"Quantity\")\n    unit_price: float = Field(description=\"Unit price\")\n    total: float = Field(description=\"Line total\")\n\nclass Invoice(BaseModel):\n    \"\"\"Complete invoice structure.\"\"\"\n    model_config = {'is_entity': True}\n\n    invoice_number: str = Field(description=\"Invoice number\")\n    date: str = Field(description=\"Invoice date\")\n    issuer: Company = edge(\"ISSUED_BY\", description=\"Issuing company\")\n    client: Company = edge(\"BILLED_TO\", description=\"Client company\")\n    line_items: list[LineItem] = Field(description=\"Invoice line items\")\n    subtotal: float = Field(description=\"Subtotal amount\")\n    tax: float = Field(description=\"Tax amount\")\n    total: float = Field(description=\"Total amount\")\n</code></pre> <p>Save as: <code>templates/invoice.py</code></p>"},{"location":"usage/examples/docling-document-input/#processing-with-cli","title":"Processing with CLI","text":""},{"location":"usage/examples/docling-document-input/#basic-doclingdocument-processing","title":"Basic DoclingDocument Processing","text":"<pre><code># Process DoclingDocument JSON\nuv run docling-graph convert invoice_docling.json \\\n    --template \"templates.invoice.Invoice\" \\\n    --backend llm \\\n    --inference remote\n</code></pre>"},{"location":"usage/examples/docling-document-input/#reprocess-with-different-template","title":"Reprocess with Different Template","text":"<pre><code># First extraction\nuv run docling-graph convert invoice.pdf \\\n    --template \"templates.invoice.BasicInvoice\" \\\n    --export-docling-json\n\n# Reprocess with detailed template (no OCR needed)\nuv run docling-graph convert outputs/invoice_docling.json \\\n    --template \"templates.invoice.DetailedInvoice\" \\\n    --output-dir \"outputs/detailed\"\n</code></pre>"},{"location":"usage/examples/docling-document-input/#batch-reprocessing","title":"Batch Reprocessing","text":"<pre><code># Reprocess multiple DoclingDocument files\nfor file in outputs/*_docling.json; do\n    uv run docling-graph convert \"$file\" \\\n        --template \"templates.invoice.Invoice\" \\\n        --output-dir \"outputs/reprocessed\"\ndone\n</code></pre>"},{"location":"usage/examples/docling-document-input/#processing-with-python-api","title":"Processing with Python API","text":""},{"location":"usage/examples/docling-document-input/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import PipelineConfig\nfrom templates.invoice import Invoice\n\n# Configure pipeline for DoclingDocument input\nconfig = PipelineConfig(\n    source=\"invoice_docling.json\",\n    template=Invoice,\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\",\n    output_dir=\"outputs/invoice\"\n)\n\n# Run pipeline (skips document conversion)\nconfig.run()\n</code></pre>"},{"location":"usage/examples/docling-document-input/#two-stage-processing","title":"Two-Stage Processing","text":"<pre><code>from docling_graph import PipelineConfig\nfrom templates.invoice import BasicInvoice, DetailedInvoice\n\n# Stage 1: Initial extraction with basic template\nstage1_config = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=BasicInvoice,\n    backend=\"llm\",\n    inference=\"remote\",\n    export_docling_json=True,\n    output_dir=\"outputs/stage1\"\n)\nstage1_config.run()\n\n# Stage 2: Detailed extraction from DoclingDocument\nstage2_config = PipelineConfig(\n    source=\"outputs/stage1/invoice_docling.json\",\n    template=DetailedInvoice,\n    backend=\"llm\",\n    inference=\"remote\",\n    output_dir=\"outputs/stage2\"\n)\nstage2_config.run()\n</code></pre>"},{"location":"usage/examples/docling-document-input/#batch-reprocessing_1","title":"Batch Reprocessing","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\nfrom templates.invoice import Invoice\n\n# Find all DoclingDocument files\ndocling_files = Path(\"outputs\").glob(\"*_docling.json\")\n\nfor doc_file in docling_files:\n    print(f\"Reprocessing: {doc_file}\")\n\n    config = PipelineConfig(\n        source=str(doc_file),\n        template=Invoice,\n        backend=\"llm\",\n        inference=\"remote\",\n        output_dir=f\"outputs/reprocessed/{doc_file.stem}\"\n    )\n\n    try:\n        config.run()\n        print(f\"\u2713 Completed: {doc_file}\")\n    except Exception as e:\n        print(f\"\u2717 Failed: {doc_file} - {e}\")\n</code></pre>"},{"location":"usage/examples/docling-document-input/#expected-output","title":"Expected Output","text":""},{"location":"usage/examples/docling-document-input/#graph-structure","title":"Graph Structure","text":"<pre><code>Invoice (root node)\n\u251c\u2500\u2500 ISSUED_BY \u2192 Company (Acme Corp)\n\u2502   \u2514\u2500\u2500 address (embedded)\n\u251c\u2500\u2500 BILLED_TO \u2192 Company (Client Inc)\n\u2502   \u2514\u2500\u2500 address (embedded)\n\u2514\u2500\u2500 line_items (list)\n    \u251c\u2500\u2500 LineItem 1\n    \u251c\u2500\u2500 LineItem 2\n    \u2514\u2500\u2500 LineItem 3\n</code></pre>"},{"location":"usage/examples/docling-document-input/#processing-benefits","title":"Processing Benefits","text":"<p>With DoclingDocument Input: - \u26a1 Faster: Skips OCR and document conversion - \ud83d\udcb0 Cheaper: No OCR processing costs - \ud83d\udd04 Reusable: Process same document with different templates - \ud83c\udfaf Consistent: Same document structure every time</p> <p>Comparison:</p> Operation PDF Input DoclingDocument Input OCR \u2705 Required \u274c Skipped Conversion \u2705 Required \u274c Skipped Extraction \u2705 Yes \u2705 Yes Graph Build \u2705 Yes \u2705 Yes Time ~30s ~5s"},{"location":"usage/examples/docling-document-input/#doclingdocument-structure","title":"DoclingDocument Structure","text":""},{"location":"usage/examples/docling-document-input/#required-fields","title":"Required Fields","text":"<pre><code>{\n  \"schema_name\": \"DoclingDocument\",  // Required\n  \"version\": \"1.0.0\",                // Required\n  \"name\": \"document_name\",\n  \"pages\": {\n    \"0\": {\n      \"page_no\": 0,\n      \"size\": {\"width\": 612, \"height\": 792}\n    }\n  },\n  \"body\": {\n    \"self_ref\": \"#/body\",\n    \"children\": []\n  },\n  \"furniture\": {}\n}\n</code></pre>"},{"location":"usage/examples/docling-document-input/#validation","title":"Validation","text":"<p>The pipeline validates: \u2705 <code>schema_name</code> must be \"DoclingDocument\" \u2705 <code>version</code> field must be present \u2705 Valid JSON structure \u2705 Required fields present</p>"},{"location":"usage/examples/docling-document-input/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/docling-document-input/#issue-invalid-schema","title":"Issue: Invalid Schema","text":"<p>Error: <pre><code>ValidationError: schema_name must be 'DoclingDocument', got 'CustomDocument'\n</code></pre></p> <p>Solution: <pre><code>{\n  \"schema_name\": \"DoclingDocument\",  // Must be exactly this\n  \"version\": \"1.0.0\",\n  ...\n}\n</code></pre></p>"},{"location":"usage/examples/docling-document-input/#issue-missing-version","title":"Issue: Missing Version","text":"<p>Error: <pre><code>ValidationError: Missing required field: version\n</code></pre></p> <p>Solution: <pre><code>{\n  \"schema_name\": \"DoclingDocument\",\n  \"version\": \"1.0.0\",  // Add version field\n  ...\n}\n</code></pre></p>"},{"location":"usage/examples/docling-document-input/#issue-invalid-json","title":"Issue: Invalid JSON","text":"<p>Error: <pre><code>ValidationError: Invalid JSON in DoclingDocument file\n</code></pre></p> <p>Solution: <pre><code># Validate JSON syntax\npython -m json.tool invoice_docling.json\n\n# Or use jq\njq . invoice_docling.json\n</code></pre></p>"},{"location":"usage/examples/docling-document-input/#issue-file-not-found","title":"Issue: File Not Found","text":"<p>Error: <pre><code>ConfigurationError: File not found: invoice_docling.json\n</code></pre></p> <p>Solution: <pre><code># Check file exists\nls -la invoice_docling.json\n\n# Check file path\npwd\n# Use absolute path if needed\nuv run docling-graph convert /full/path/to/invoice_docling.json ...\n</code></pre></p>"},{"location":"usage/examples/docling-document-input/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/docling-document-input/#1-version-your-doclingdocuments","title":"1. Version Your DoclingDocuments","text":"<pre><code># Add version to filename\ndoc_file = f\"invoice_v{version}_docling.json\"\n\n# Or in metadata\ndoc = DoclingDocument(\n    schema_name=\"DoclingDocument\",\n    version=\"1.0.0\",\n    name=f\"invoice_v{version}\",\n    ...\n)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#2-store-metadata","title":"2. Store Metadata","text":"<pre><code>{\n  \"schema_name\": \"DoclingDocument\",\n  \"version\": \"1.0.0\",\n  \"name\": \"invoice_001\",\n  \"metadata\": {\n    \"source_file\": \"invoice.pdf\",\n    \"processed_date\": \"2024-01-15\",\n    \"ocr_engine\": \"docling\",\n    \"template_version\": \"2.0\"\n  },\n  ...\n}\n</code></pre>"},{"location":"usage/examples/docling-document-input/#3-validate-before-processing","title":"3. Validate Before Processing","text":"<pre><code>from docling_graph.core.input.validators import DoclingDocumentValidator\nimport json\n\n# Validate DoclingDocument\nvalidator = DoclingDocumentValidator()\n\nwith open(\"invoice_docling.json\") as f:\n    content = f.read()\n\ntry:\n    validator.validate(content)\n    print(\"\u2713 Valid DoclingDocument\")\nexcept ValidationError as e:\n    print(f\"\u2717 Invalid: {e.message}\")\n</code></pre>"},{"location":"usage/examples/docling-document-input/#4-archive-original-pdfs","title":"4. Archive Original PDFs","text":"<pre><code>from pathlib import Path\nimport shutil\n\n# Keep original PDF alongside DoclingDocument\npdf_file = Path(\"invoice.pdf\")\ndocling_file = Path(\"invoice_docling.json\")\narchive_dir = Path(\"archive\")\n\n# Archive structure\narchive_dir.mkdir(exist_ok=True)\nshutil.copy(pdf_file, archive_dir / pdf_file.name)\nshutil.copy(docling_file, archive_dir / docling_file.name)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/examples/docling-document-input/#custom-doclingdocument-creation","title":"Custom DoclingDocument Creation","text":"<pre><code>from docling_core.types.doc import DoclingDocument, Page, Size\nimport json\n\n# Create custom DoclingDocument\ndoc = DoclingDocument(\n    schema_name=\"DoclingDocument\",\n    version=\"1.0.0\",\n    name=\"custom_invoice\",\n    pages={\n        \"0\": Page(\n            page_no=0,\n            size=Size(width=612, height=792)\n        )\n    },\n    body={\n        \"self_ref\": \"#/body\",\n        \"children\": []\n    },\n    furniture={}\n)\n\n# Save\nwith open(\"custom_docling.json\", \"w\") as f:\n    json.dump(doc.model_dump(), f, indent=2)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#merging-multiple-doclingdocuments","title":"Merging Multiple DoclingDocuments","text":"<pre><code>from docling_core.types.doc import DoclingDocument\nimport json\n\n# Load multiple documents\ndocs = []\nfor file in [\"doc1_docling.json\", \"doc2_docling.json\"]:\n    with open(file) as f:\n        docs.append(json.load(f))\n\n# Merge (simplified example)\nmerged = docs[0].copy()\nfor doc in docs[1:]:\n    # Merge pages, body, etc.\n    merged[\"pages\"].update(doc[\"pages\"])\n\n# Save merged document\nwith open(\"merged_docling.json\", \"w\") as f:\n    json.dump(merged, f, indent=2)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#extracting-specific-pages","title":"Extracting Specific Pages","text":"<pre><code>import json\n\n# Load DoclingDocument\nwith open(\"multi_page_docling.json\") as f:\n    doc = json.load(f)\n\n# Extract specific pages\npages_to_keep = [\"0\", \"2\", \"4\"]  # Keep pages 0, 2, 4\ndoc[\"pages\"] = {\n    k: v for k, v in doc[\"pages\"].items()\n    if k in pages_to_keep\n}\n\n# Save filtered document\nwith open(\"filtered_docling.json\", \"w\") as f:\n    json.dump(doc, f, indent=2)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#use-cases","title":"Use Cases","text":""},{"location":"usage/examples/docling-document-input/#1-template-experimentation","title":"1. Template Experimentation","text":"<p>Test different templates without re-running OCR:</p> <pre><code>templates = [\n    \"templates.invoice.BasicInvoice\",\n    \"templates.invoice.DetailedInvoice\",\n    \"templates.invoice.MinimalInvoice\"\n]\n\nfor template in templates:\n    config = PipelineConfig(\n        source=\"invoice_docling.json\",\n        template=template,\n        output_dir=f\"outputs/{template.split('.')[-1]}\"\n    )\n    config.run()\n</code></pre>"},{"location":"usage/examples/docling-document-input/#2-ab-testing-extraction-strategies","title":"2. A/B Testing Extraction Strategies","text":"<pre><code># Test different backends\nfor backend in [\"llm\", \"vlm\"]:\n    config = PipelineConfig(\n        source=\"invoice_docling.json\",\n        template=Invoice,\n        backend=backend,\n        output_dir=f\"outputs/{backend}\"\n    )\n    config.run()\n</code></pre>"},{"location":"usage/examples/docling-document-input/#3-incremental-processing","title":"3. Incremental Processing","text":"<pre><code># Process in stages\nstages = [\n    (\"basic\", BasicTemplate),\n    (\"detailed\", DetailedTemplate),\n    (\"enriched\", EnrichedTemplate)\n]\n\nsource = \"invoice_docling.json\"\nfor stage_name, template in stages:\n    config = PipelineConfig(\n        source=source,\n        template=template,\n        output_dir=f\"outputs/{stage_name}\"\n    )\n    config.run()\n</code></pre>"},{"location":"usage/examples/docling-document-input/#next-steps","title":"Next Steps","text":"<ul> <li>Input Formats Guide - Complete input format reference</li> <li>Examples Index - Browse all examples</li> </ul>"},{"location":"usage/examples/id-card/","title":"ID Card Extraction","text":""},{"location":"usage/examples/id-card/#overview","title":"Overview","text":"<p>Extract personal information from ID cards and identity documents using vision-based extraction.</p> <p>What You'll Learn: - Vision-based extraction (VLM) - Date field handling - Address parsing - Field validators - Graph ID configuration</p> <p>Document Type: ID Card (Image) Time: 15 minutes Backend: VLM (recommended)</p>"},{"location":"usage/examples/id-card/#prerequisites","title":"Prerequisites","text":"<pre><code># Install with all features\nuv sync --extra all\n</code></pre>"},{"location":"usage/examples/id-card/#template-definition","title":"Template Definition","text":""},{"location":"usage/examples/id-card/#complete-template","title":"Complete Template","text":"<p>File: <code>id_card_template.py</code></p> <pre><code>\"\"\"\nID Card extraction template.\nDemonstrates date parsing, validators, and graph IDs.\n\"\"\"\n\nimport re\nfrom datetime import date\nfrom typing import List\nfrom pydantic import BaseModel, ConfigDict, Field, field_validator\n\ndef edge(label: str, **kwargs):\n    \"\"\"Helper for graph edges.\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- Address Component ---\n\nclass Address(BaseModel):\n    \"\"\"Physical address.\"\"\"\n\n    model_config = ConfigDict(is_entity=False)\n\n    street_address: str | None = Field(\n        None,\n        description=\"Street name and number\",\n        examples=[\"123 Main Street\", \"456 Oak Avenue\"]\n    )\n\n    city: str | None = Field(\n        None,\n        description=\"City name\",\n        examples=[\"New York\", \"Los Angeles\"]\n    )\n\n    state_or_province: str | None = Field(\n        None,\n        description=\"State or province\",\n        examples=[\"NY\", \"California\"]\n    )\n\n    postal_code: str | None = Field(\n        None,\n        description=\"Postal or ZIP code\",\n        examples=[\"10001\", \"90210\"]\n    )\n\n    country: str | None = Field(\n        None,\n        description=\"Country name\",\n        examples=[\"USA\", \"United States\"]\n    )\n\n# --- Person Entity ---\n\nclass Person(BaseModel):\n    \"\"\"Person entity with unique identification.\"\"\"\n\n    # Graph ID: Unique by name + date of birth\n    model_config = ConfigDict(\n        graph_id_fields=[\"given_names\", \"last_name\", \"date_of_birth\"]\n    )\n\n    given_names: List[str] | None = Field(\n        default=None,\n        description=\"List of given names (first names)\",\n        examples=[[\"John\"], [\"Mary\", \"Jane\"], [\"Pierre\", \"Louis\"]]\n    )\n\n    last_name: str | None = Field(\n        None,\n        description=\"Family name (surname)\",\n        examples=[\"Smith\", \"Johnson\", \"Doe\"]\n    )\n\n    alternate_name: str | None = Field(\n        None,\n        description=\"Alternate or maiden name\",\n        examples=[\"Doe\", \"MJ\"]\n    )\n\n    date_of_birth: date | None = Field(\n        None,\n        description=\"Date of birth in YYYY-MM-DD format\",\n        examples=[\"1990-05-15\", \"1985-12-01\"]\n    )\n\n    place_of_birth: str | None = Field(\n        None,\n        description=\"City and/or country of birth\",\n        examples=[\"New York, USA\", \"Paris, France\"]\n    )\n\n    gender: str | None = Field(\n        None,\n        description=\"Gender\",\n        examples=[\"M\", \"F\", \"Male\", \"Female\"]\n    )\n\n    # Relationship\n    lives_at: Address | None = edge(\n        label=\"LIVES_AT\",\n        description=\"Home address\"\n    )\n\n    # --- Validators ---\n\n    @field_validator(\"given_names\", mode=\"before\")\n    @classmethod\n    def ensure_list(cls, v):\n        \"\"\"Ensure given_names is a list.\"\"\"\n        if isinstance(v, str):\n            # Handle comma or space separated\n            if \",\" in v:\n                return [name.strip() for name in v.split(\",\")]\n            return [v]\n        return v\n\n    @field_validator(\"lives_at\", mode=\"before\")\n    @classmethod\n    def parse_address(cls, v):\n        \"\"\"Parse address string into Address object.\"\"\"\n        if v is None or isinstance(v, dict):\n            return v\n\n        if isinstance(v, str):\n            # Simple parsing\n            parts = [p.strip() for p in v.split(\",\")]\n            return {\n                \"street_address\": parts[0] if len(parts) &gt; 0 else None,\n                \"city\": parts[1] if len(parts) &gt; 1 else None,\n                \"country\": parts[-1] if len(parts) &gt; 2 else None\n            }\n        return v\n\n# --- Root Entity: IDCard ---\n\nclass IDCard(BaseModel):\n    \"\"\"Identity document.\"\"\"\n\n    # Graph ID: Unique by document number\n    model_config = ConfigDict(graph_id_fields=[\"document_number\"])\n\n    document_number: str = Field(\n        ...,\n        description=\"Unique document identifier\",\n        examples=[\"A12345678\", \"123456789\", \"AB1234567\"]\n    )\n\n    issuing_country: str | None = Field(\n        None,\n        description=\"Country that issued the document\",\n        examples=[\"USA\", \"France\", \"United Kingdom\"]\n    )\n\n    issue_date: date | None = Field(\n        None,\n        description=\"Date document was issued (YYYY-MM-DD)\",\n        examples=[\"2023-10-20\", \"2020-05-15\"]\n    )\n\n    expiry_date: date | None = Field(\n        None,\n        description=\"Date document expires (YYYY-MM-DD)\",\n        examples=[\"2033-10-19\", \"2030-05-14\"]\n    )\n\n    # Relationship\n    holder: Person = edge(\n        label=\"BELONGS_TO\",\n        description=\"Person this ID belongs to\"\n    )\n</code></pre>"},{"location":"usage/examples/id-card/#processing","title":"Processing","text":""},{"location":"usage/examples/id-card/#using-cli","title":"Using CLI","text":"<pre><code># Process ID card image with VLM\nuv run docling-graph convert id_card.jpg \\\n    --template \"id_card_template.IDCard\" \\\n    --backend vlm \\\n    --processing-mode one-to-one \\\n    --docling-pipeline vision \\\n    --output-dir \"outputs/id_card\"\n</code></pre>"},{"location":"usage/examples/id-card/#using-python-api","title":"Using Python API","text":"<pre><code>\"\"\"Process ID card.\"\"\"\n\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"id_card.jpg\",\n    template=\"id_card_template.IDCard\",\n    backend=\"vlm\",\n    inference=\"local\",  # VLM only supports local\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\",\n    output_dir=\"outputs/id_card\"\n)\n\nprint(\"Processing ID card...\")\nconfig.run()\nprint(\"\u2713 Complete!\")\n</code></pre>"},{"location":"usage/examples/id-card/#expected-results","title":"Expected Results","text":""},{"location":"usage/examples/id-card/#graph-structure","title":"Graph Structure","text":"<pre><code>IDCard (A12345678)\n\u2514\u2500\u2500 BELONGS_TO \u2192 Person (John Smith, 1990-05-15)\n    \u2514\u2500\u2500 LIVES_AT \u2192 Address (123 Main St, NYC)\n</code></pre>"},{"location":"usage/examples/id-card/#nodes-csv","title":"Nodes CSV","text":"<pre><code>id,label,type,document_number,issuing_country,issue_date,expiry_date\nid_1,A12345678,IDCard,A12345678,USA,2023-10-20,2033-10-19\nperson_1,John Smith,Person,,,,\naddr_1,123 Main St,Address,,,,\n</code></pre>"},{"location":"usage/examples/id-card/#edges-csv","title":"Edges CSV","text":"<pre><code>source,target,type\nid_1,person_1,BELONGS_TO\nperson_1,addr_1,LIVES_AT\n</code></pre>"},{"location":"usage/examples/id-card/#key-features","title":"Key Features","text":""},{"location":"usage/examples/id-card/#1-date-parsing","title":"1. Date Parsing","text":"<pre><code># Pydantic automatically parses dates\ndate_of_birth: date | None = Field(\n    None,\n    description=\"Date in YYYY-MM-DD format\"\n)\n\n# Accepts: \"1990-05-15\", \"1990/05/15\", \"05-15-1990\"\n# Converts to: date(1990, 5, 15)\n</code></pre>"},{"location":"usage/examples/id-card/#2-graph-id-configuration","title":"2. Graph ID Configuration","text":"<pre><code># Person uniquely identified by name + DOB\nmodel_config = ConfigDict(\n    graph_id_fields=[\"given_names\", \"last_name\", \"date_of_birth\"]\n)\n\n# Same person in multiple documents = same node\n</code></pre>"},{"location":"usage/examples/id-card/#3-list-handling","title":"3. List Handling","text":"<pre><code># Validator converts string to list\ngiven_names: List[str] = Field(...)\n\n@field_validator(\"given_names\", mode=\"before\")\n@classmethod\ndef ensure_list(cls, v):\n    if isinstance(v, str):\n        return [v]  # \"John\" \u2192 [\"John\"]\n    return v\n</code></pre>"},{"location":"usage/examples/id-card/#4-address-parsing","title":"4. Address Parsing","text":"<pre><code># Validator parses address string\n@field_validator(\"lives_at\", mode=\"before\")\n@classmethod\ndef parse_address(cls, v):\n    if isinstance(v, str):\n        # \"123 Main St, NYC, USA\" \u2192 Address object\n        parts = v.split(\",\")\n        return {\"street_address\": parts[0], ...}\n    return v\n</code></pre>"},{"location":"usage/examples/id-card/#visualization","title":"Visualization","text":"<pre><code># Interactive visualization\nuv run docling-graph inspect outputs/id_card/\n</code></pre> <p>Features: - View extracted personal information - See address relationships - Verify dates are parsed correctly</p>"},{"location":"usage/examples/id-card/#customization","title":"Customization","text":""},{"location":"usage/examples/id-card/#add-more-fields","title":"Add More Fields","text":"<pre><code>class IDCard(BaseModel):\n    document_number: str\n    issuing_country: str | None\n    issue_date: date | None\n    expiry_date: date | None\n\n    # Add document type\n    document_type: str | None = Field(\n        None,\n        description=\"Type of ID document\",\n        examples=[\"Passport\", \"Driver License\", \"National ID\"]\n    )\n\n    # Add nationality\n    nationality: str | None = Field(\n        None,\n        description=\"Holder's nationality\",\n        examples=[\"American\", \"French\", \"British\"]\n    )\n\n    holder: Person = edge(label=\"BELONGS_TO\")\n</code></pre>"},{"location":"usage/examples/id-card/#add-validation","title":"Add Validation","text":"<pre><code>from pydantic import field_validator\nfrom datetime import date\n\nclass IDCard(BaseModel):\n    issue_date: date | None\n    expiry_date: date | None\n\n    @field_validator(\"expiry_date\")\n    @classmethod\n    def validate_expiry(cls, v, info):\n        \"\"\"Ensure expiry date is after issue date.\"\"\"\n        issue = info.data.get(\"issue_date\")\n        if issue and v and v &lt;= issue:\n            raise ValueError(\"Expiry date must be after issue date\")\n        return v\n</code></pre>"},{"location":"usage/examples/id-card/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/id-card/#issue-dates-not-parsed","title":"Issue: Dates Not Parsed","text":"<p>Problem: Date fields are None or incorrect</p> <p>Solution: <pre><code># Make dates optional and add examples\ndate_of_birth: date | None = Field(\n    None,\n    description=\"Date of birth. Parse formats like DD/MM/YYYY, MM-DD-YYYY, YYYY-MM-DD\",\n    examples=[\"1990-05-15\", \"05/15/1990\", \"15-05-1990\"]\n)\n</code></pre></p>"},{"location":"usage/examples/id-card/#issue-name-parsing","title":"Issue: Name Parsing","text":"<p>Problem: Full name extracted as single string</p> <p>Solution: <pre><code># Add validator to split names\n@field_validator(\"given_names\", mode=\"before\")\n@classmethod\ndef split_names(cls, v):\n    if isinstance(v, str):\n        # \"John Paul\" \u2192 [\"John\", \"Paul\"]\n        return v.split()\n    return v\n</code></pre></p>"},{"location":"usage/examples/id-card/#issue-address-not-structured","title":"Issue: Address Not Structured","text":"<p>Problem: Address extracted as single string</p> <p>Solution: <pre><code># Use validator to parse\n@field_validator(\"lives_at\", mode=\"before\")\n@classmethod\ndef parse_address(cls, v):\n    if isinstance(v, str):\n        # Extract postal code\n        postal_match = re.search(r'\\b(\\d{5})\\b', v)\n        postal = postal_match.group(1) if postal_match else None\n\n        return {\n            \"street_address\": v.split(\",\")[0] if \",\" in v else v,\n            \"postal_code\": postal\n        }\n    return v\n</code></pre></p>"},{"location":"usage/examples/id-card/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/id-card/#1-use-vlm-for-images","title":"1. Use VLM for Images","text":"<pre><code># \u2705 Good - VLM for image documents\nuv run docling-graph convert id_card.jpg \\\n    --backend vlm\n\n# \u274c Avoid - LLM for images (slower, less accurate)\nuv run docling-graph convert id_card.jpg \\\n    --backend llm\n</code></pre>"},{"location":"usage/examples/id-card/#2-make-fields-optional","title":"2. Make Fields Optional","text":"<pre><code># \u2705 Good - Optional fields for incomplete data\nclass Person(BaseModel):\n    given_names: List[str] | None = Field(default=None)\n    last_name: str | None = Field(default=None)\n    date_of_birth: date | None = Field(default=None)\n\n# \u274c Avoid - Required fields that might be missing\nclass Person(BaseModel):\n    given_names: List[str]  # Fails if not found\n    last_name: str\n</code></pre>"},{"location":"usage/examples/id-card/#3-provide-date-format-examples","title":"3. Provide Date Format Examples","text":"<pre><code># \u2705 Good - Multiple format examples\ndate_of_birth: date | None = Field(\n    None,\n    description=\"Date of birth in various formats\",\n    examples=[\"1990-05-15\", \"05/15/1990\", \"15-05-1990\"]\n)\n</code></pre>"},{"location":"usage/examples/id-card/#next-steps","title":"Next Steps","text":"<ol> <li>Insurance Policy \u2192 - Financial documents</li> <li>Validation Guide \u2192 - Advanced validators</li> <li>VLM Backend \u2192 - Vision models</li> </ol>"},{"location":"usage/examples/id-card/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/examples/id-card/#process-id-card","title":"Process ID Card","text":"<pre><code># VLM (recommended)\nuv run docling-graph convert id_card.jpg \\\n    -t \"id_card_template.IDCard\" \\\n    --backend vlm\n\n# LLM (alternative)\nuv run docling-graph convert id_card.pdf \\\n    -t \"id_card_template.IDCard\" \\\n    --backend llm\n</code></pre>"},{"location":"usage/examples/id-card/#view-results","title":"View Results","text":"<pre><code>uv run docling-graph inspect outputs/id_card/\ncat outputs/id_card/nodes.csv\n</code></pre>"},{"location":"usage/examples/id-card/#template-location","title":"Template Location","text":"<pre><code>docs/examples/templates/id_card.py\n</code></pre>"},{"location":"usage/examples/insurance-policy/","title":"Insurance Policy Extraction","text":""},{"location":"usage/examples/insurance-policy/#overview","title":"Overview","text":"<p>Extract structured information from insurance policy documents including coverage details, terms, and relationships.</p> <p>What You'll Learn: - Complex nested structures - Multiple entity relationships - Coverage modeling - Term extraction - Financial data handling</p> <p>Document Type: Insurance Policy (PDF)  Time: 20 minutes Backend: LLM (recommended)</p>"},{"location":"usage/examples/insurance-policy/#prerequisites","title":"Prerequisites","text":"<pre><code># Install with all features\nuv sync --extra all\n\n# For remote API (recommended for complex documents)\nexport MISTRAL_API_KEY=\"your_key_here\"\n</code></pre>"},{"location":"usage/examples/insurance-policy/#template-definition","title":"Template Definition","text":""},{"location":"usage/examples/insurance-policy/#complete-template","title":"Complete Template","text":"<p>File: <code>insurance_template.py</code></p> <pre><code>\"\"\"\nInsurance policy extraction template.\nDemonstrates complex relationships and nested structures.\n\"\"\"\n\nfrom datetime import date\nfrom decimal import Decimal\nfrom typing import List\nfrom pydantic import BaseModel, ConfigDict, Field\n\ndef edge(label: str, **kwargs):\n    \"\"\"Helper for graph edges.\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- Components (is_entity=False) ---\n\nclass Address(BaseModel):\n    \"\"\"Physical address.\"\"\"\n\n    model_config = ConfigDict(is_entity=False)\n\n    street: str | None = Field(None, description=\"Street address\")\n    city: str | None = Field(None, description=\"City\")\n    state: str | None = Field(None, description=\"State or province\")\n    postal_code: str | None = Field(None, description=\"Postal code\")\n    country: str | None = Field(None, description=\"Country\")\n\nclass MonetaryAmount(BaseModel):\n    \"\"\"Money value with currency.\"\"\"\n\n    model_config = ConfigDict(is_entity=False)\n\n    amount: Decimal = Field(..., description=\"Numeric amount\")\n    currency: str = Field(default=\"USD\", description=\"Currency code\")\n\nclass DateRange(BaseModel):\n    \"\"\"Date range for coverage periods.\"\"\"\n\n    model_config = ConfigDict(is_entity=False)\n\n    start_date: date = Field(..., description=\"Start date\")\n    end_date: date = Field(..., description=\"End date\")\n\n# --- Entities ---\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"full_name\", \"date_of_birth\"])\n\n    full_name: str = Field(..., description=\"Full legal name\")\n    date_of_birth: date | None = Field(None, description=\"Date of birth\")\n    email: str | None = Field(None, description=\"Email address\")\n    phone: str | None = Field(None, description=\"Phone number\")\n\n    # Relationship\n    address: Address | None = edge(\n        label=\"LIVES_AT\",\n        description=\"Residential address\"\n    )\n\nclass Organization(BaseModel):\n    \"\"\"Insurance company or provider.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(..., description=\"Organization name\")\n    registration_number: str | None = Field(None, description=\"Business registration\")\n    phone: str | None = Field(None, description=\"Contact phone\")\n    email: str | None = Field(None, description=\"Contact email\")\n    website: str | None = Field(None, description=\"Website URL\")\n\n    # Relationship\n    headquarters: Address | None = edge(\n        label=\"LOCATED_AT\",\n        description=\"Main office address\"\n    )\n\nclass Coverage(BaseModel):\n    \"\"\"Insurance coverage details.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"coverage_type\", \"policy_number\"])\n\n    coverage_type: str = Field(\n        ...,\n        description=\"Type of coverage\",\n        examples=[\"Liability\", \"Collision\", \"Comprehensive\", \"Medical\"]\n    )\n\n    policy_number: str = Field(..., description=\"Associated policy number\")\n\n    coverage_limit: MonetaryAmount | None = Field(\n        None,\n        description=\"Maximum coverage amount\"\n    )\n\n    deductible: MonetaryAmount | None = Field(\n        None,\n        description=\"Deductible amount\"\n    )\n\n    premium: MonetaryAmount | None = Field(\n        None,\n        description=\"Premium cost\"\n    )\n\n    description: str | None = Field(\n        None,\n        description=\"Coverage description\"\n    )\n\nclass PolicyTerm(BaseModel):\n    \"\"\"Policy term or condition.\"\"\"\n\n    model_config = ConfigDict(is_entity=True)\n\n    term_type: str = Field(\n        ...,\n        description=\"Type of term\",\n        examples=[\"Exclusion\", \"Condition\", \"Limitation\", \"Requirement\"]\n    )\n\n    description: str = Field(..., description=\"Term description\")\n\n    applies_to: str | None = Field(\n        None,\n        description=\"What this term applies to\"\n    )\n\n# --- Root Entity: InsurancePolicy ---\n\nclass InsurancePolicy(BaseModel):\n    \"\"\"Complete insurance policy document.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"policy_number\"])\n\n    policy_number: str = Field(\n        ...,\n        description=\"Unique policy identifier\",\n        examples=[\"POL-2024-001234\", \"AUTO-12345\"]\n    )\n\n    policy_type: str = Field(\n        ...,\n        description=\"Type of insurance policy\",\n        examples=[\"Auto\", \"Home\", \"Life\", \"Health\", \"Business\"]\n    )\n\n    status: str | None = Field(\n        None,\n        description=\"Policy status\",\n        examples=[\"Active\", \"Pending\", \"Expired\", \"Cancelled\"]\n    )\n\n    effective_period: DateRange = Field(\n        ...,\n        description=\"Policy effective dates\"\n    )\n\n    total_premium: MonetaryAmount | None = Field(\n        None,\n        description=\"Total policy premium\"\n    )\n\n    payment_frequency: str | None = Field(\n        None,\n        description=\"Payment schedule\",\n        examples=[\"Monthly\", \"Quarterly\", \"Annually\"]\n    )\n\n    # Relationships\n    policyholder: Person = edge(\n        label=\"HELD_BY\",\n        description=\"Primary policyholder\"\n    )\n\n    insurer: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Insurance company\"\n    )\n\n    coverages: List[Coverage] = edge(\n        label=\"INCLUDES_COVERAGE\",\n        description=\"Coverage items\"\n    )\n\n    beneficiaries: List[Person] | None = edge(\n        label=\"BENEFITS\",\n        description=\"Policy beneficiaries\",\n        default=None\n    )\n\n    terms: List[PolicyTerm] | None = edge(\n        label=\"HAS_TERM\",\n        description=\"Policy terms and conditions\",\n        default=None\n    )\n</code></pre>"},{"location":"usage/examples/insurance-policy/#processing","title":"Processing","text":""},{"location":"usage/examples/insurance-policy/#using-cli","title":"Using CLI","text":"<pre><code># Process with remote LLM (best for complex documents)\nuv run docling-graph convert insurance_policy.pdf \\\n    --template \"insurance_template.InsurancePolicy\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider mistral \\\n    --model mistral-small-latest \\\n    --processing-mode many-to-one \\\n    --output-dir \"outputs/insurance\"\n</code></pre>"},{"location":"usage/examples/insurance-policy/#using-python-api","title":"Using Python API","text":"<pre><code>\"\"\"Process insurance policy.\"\"\"\n\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"insurance_policy.pdf\",\n    template=\"insurance_template.InsurancePolicy\",\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\",\n    model_override=\"mistral-small-latest\",\n    provider_override=\"mistral\",\n    output_dir=\"outputs/insurance\"\n)\n\nprint(\"Processing insurance policy...\")\nconfig.run()\nprint(\"\u2713 Complete!\")\n</code></pre>"},{"location":"usage/examples/insurance-policy/#expected-results","title":"Expected Results","text":""},{"location":"usage/examples/insurance-policy/#graph-structure","title":"Graph Structure","text":"<pre><code>InsurancePolicy (POL-2024-001234)\n\u251c\u2500\u2500 HELD_BY \u2192 Person (John Smith)\n\u2502   \u2514\u2500\u2500 LIVES_AT \u2192 Address (123 Main St)\n\u251c\u2500\u2500 ISSUED_BY \u2192 Organization (ABC Insurance)\n\u2502   \u2514\u2500\u2500 LOCATED_AT \u2192 Address (456 Corp Plaza)\n\u251c\u2500\u2500 INCLUDES_COVERAGE \u2192 Coverage (Liability)\n\u251c\u2500\u2500 INCLUDES_COVERAGE \u2192 Coverage (Collision)\n\u251c\u2500\u2500 INCLUDES_COVERAGE \u2192 Coverage (Comprehensive)\n\u251c\u2500\u2500 BENEFITS \u2192 Person (Jane Smith)\n\u2514\u2500\u2500 HAS_TERM \u2192 PolicyTerm (Exclusion)\n</code></pre>"},{"location":"usage/examples/insurance-policy/#nodes-csv","title":"Nodes CSV","text":"<pre><code>id,label,type,policy_number,policy_type,status\npolicy_1,POL-2024-001234,InsurancePolicy,POL-2024-001234,Auto,Active\nperson_1,John Smith,Person,,,\nperson_2,Jane Smith,Person,,,\norg_1,ABC Insurance,Organization,,,\ncov_1,Liability,Coverage,,,\ncov_2,Collision,Coverage,,,\nterm_1,Exclusion,PolicyTerm,,,\n</code></pre>"},{"location":"usage/examples/insurance-policy/#edges-csv","title":"Edges CSV","text":"<pre><code>source,target,type\npolicy_1,person_1,HELD_BY\npolicy_1,org_1,ISSUED_BY\npolicy_1,cov_1,INCLUDES_COVERAGE\npolicy_1,cov_2,INCLUDES_COVERAGE\npolicy_1,person_2,BENEFITS\npolicy_1,term_1,HAS_TERM\nperson_1,addr_1,LIVES_AT\norg_1,addr_2,LOCATED_AT\n</code></pre>"},{"location":"usage/examples/insurance-policy/#key-features","title":"Key Features","text":""},{"location":"usage/examples/insurance-policy/#1-complex-nested-structures","title":"1. Complex Nested Structures","text":"<pre><code># Policy contains multiple coverages\ncoverages: List[Coverage] = edge(\n    label=\"INCLUDES_COVERAGE\",\n    description=\"Coverage items\"\n)\n\n# Each coverage has its own details\nclass Coverage(BaseModel):\n    coverage_type: str\n    coverage_limit: MonetaryAmount\n    deductible: MonetaryAmount\n</code></pre>"},{"location":"usage/examples/insurance-policy/#2-financial-data-handling","title":"2. Financial Data Handling","text":"<pre><code># Use Decimal for precise amounts\nclass MonetaryAmount(BaseModel):\n    amount: Decimal  # Not float!\n    currency: str = \"USD\"\n\n# In policy\ntotal_premium: MonetaryAmount = Field(\n    ...,\n    description=\"Total premium with currency\"\n)\n</code></pre>"},{"location":"usage/examples/insurance-policy/#3-date-ranges","title":"3. Date Ranges","text":"<pre><code># Structured date range\nclass DateRange(BaseModel):\n    start_date: date\n    end_date: date\n\n# In policy\neffective_period: DateRange = Field(\n    ...,\n    description=\"Coverage period\"\n)\n</code></pre>"},{"location":"usage/examples/insurance-policy/#4-multiple-relationships","title":"4. Multiple Relationships","text":"<pre><code># One-to-one\npolicyholder: Person = edge(label=\"HELD_BY\")\n\n# One-to-many\ncoverages: List[Coverage] = edge(label=\"INCLUDES_COVERAGE\")\nbeneficiaries: List[Person] = edge(label=\"BENEFITS\")\n</code></pre>"},{"location":"usage/examples/insurance-policy/#visualization","title":"Visualization","text":"<pre><code># Interactive visualization\nuv run docling-graph inspect outputs/insurance/\n</code></pre> <p>Features: - View policy structure - Explore coverage relationships - See beneficiary connections - Review terms and conditions</p>"},{"location":"usage/examples/insurance-policy/#customization","title":"Customization","text":""},{"location":"usage/examples/insurance-policy/#add-vehicle-information","title":"Add Vehicle Information","text":"<pre><code>class Vehicle(BaseModel):\n    \"\"\"Vehicle covered by policy.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"vin\"])\n\n    vin: str = Field(..., description=\"Vehicle identification number\")\n    make: str | None = Field(None, description=\"Manufacturer\")\n    model: str | None = Field(None, description=\"Model name\")\n    year: int | None = Field(None, description=\"Model year\")\n\nclass InsurancePolicy(BaseModel):\n    # ... existing fields ...\n\n    # Add vehicle relationship\n    insured_vehicles: List[Vehicle] | None = edge(\n        label=\"COVERS_VEHICLE\",\n        description=\"Vehicles covered by this policy\",\n        default=None\n    )\n</code></pre>"},{"location":"usage/examples/insurance-policy/#add-claim-history","title":"Add Claim History","text":"<pre><code>class Claim(BaseModel):\n    \"\"\"Insurance claim.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"claim_number\"])\n\n    claim_number: str = Field(..., description=\"Claim ID\")\n    claim_date: date = Field(..., description=\"Date filed\")\n    claim_amount: MonetaryAmount = Field(..., description=\"Claim amount\")\n    status: str = Field(..., description=\"Claim status\")\n    description: str | None = Field(None, description=\"Claim details\")\n\nclass InsurancePolicy(BaseModel):\n    # ... existing fields ...\n\n    # Add claims relationship\n    claims: List[Claim] | None = edge(\n        label=\"HAS_CLAIM\",\n        description=\"Claims filed under this policy\",\n        default=None\n    )\n</code></pre>"},{"location":"usage/examples/insurance-policy/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/insurance-policy/#issue-coverage-not-extracted","title":"Issue: Coverage Not Extracted","text":"<p>Problem: Coverage list is empty</p> <p>Solution: <pre><code># Make coverages optional and add clear examples\ncoverages: List[Coverage] | None = edge(\n    label=\"INCLUDES_COVERAGE\",\n    description=\"List of coverage types. Extract ALL coverages mentioned: Liability, Collision, Comprehensive, Medical, etc.\",\n    examples=[\n        [\n            {\"coverage_type\": \"Liability\", \"coverage_limit\": {\"amount\": 100000, \"currency\": \"USD\"}},\n            {\"coverage_type\": \"Collision\", \"deductible\": {\"amount\": 500, \"currency\": \"USD\"}}\n        ]\n    ],\n    default=None\n)\n</code></pre></p>"},{"location":"usage/examples/insurance-policy/#issue-amounts-not-parsed","title":"Issue: Amounts Not Parsed","text":"<p>Problem: MonetaryAmount fields are None</p> <p>Solution: <pre><code># Add validator to parse currency strings\nfrom pydantic import field_validator\nimport re\n\nclass MonetaryAmount(BaseModel):\n    amount: Decimal\n    currency: str = \"USD\"\n\n    @field_validator(\"amount\", mode=\"before\")\n    @classmethod\n    def parse_amount(cls, v):\n        if isinstance(v, str):\n            # Remove currency symbols and commas\n            v = re.sub(r'[$,]', '', v)\n            return Decimal(v)\n        return v\n</code></pre></p>"},{"location":"usage/examples/insurance-policy/#issue-dates-not-recognized","title":"Issue: Dates Not Recognized","text":"<p>Problem: Date fields are None</p> <p>Solution: <pre><code># Add multiple date format examples\neffective_period: DateRange = Field(\n    ...,\n    description=\"Policy effective dates. Parse formats like MM/DD/YYYY, YYYY-MM-DD, Month DD, YYYY\",\n    examples=[\n        {\"start_date\": \"2024-01-01\", \"end_date\": \"2025-01-01\"},\n        {\"start_date\": \"01/01/2024\", \"end_date\": \"01/01/2025\"}\n    ]\n)\n</code></pre></p>"},{"location":"usage/examples/insurance-policy/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/insurance-policy/#1-use-remote-api-for-complex-documents","title":"1. Use Remote API for Complex Documents","text":"<pre><code># \u2705 Good - Remote API for multi-page policies\nuv run docling-graph convert policy.pdf \\\n    --backend llm \\\n    --inference remote\n\n# \u26a0\ufe0f Caution - Local models may struggle with complexity\nuv run docling-graph convert policy.pdf \\\n    --backend llm \\\n    --inference local\n</code></pre>"},{"location":"usage/examples/insurance-policy/#2-use-decimal-for-money","title":"2. Use Decimal for Money","text":"<pre><code># \u2705 Good - Decimal for financial precision\nfrom decimal import Decimal\n\nclass MonetaryAmount(BaseModel):\n    amount: Decimal  # Exact precision\n\n# \u274c Avoid - Float for money (rounding errors)\nclass MonetaryAmount(BaseModel):\n    amount: float  # 0.1 + 0.2 = 0.30000000000000004\n</code></pre>"},{"location":"usage/examples/insurance-policy/#3-make-lists-optional","title":"3. Make Lists Optional","text":"<pre><code># \u2705 Good - Optional lists with defaults\nbeneficiaries: List[Person] | None = edge(\n    label=\"BENEFITS\",\n    default=None\n)\n\n# \u274c Avoid - Required lists (fails if empty)\nbeneficiaries: List[Person] = edge(label=\"BENEFITS\")\n</code></pre>"},{"location":"usage/examples/insurance-policy/#4-provide-clear-examples","title":"4. Provide Clear Examples","text":"<pre><code># \u2705 Good - Detailed examples\ncoverage_type: str = Field(\n    ...,\n    description=\"Type of coverage\",\n    examples=[\n        \"Bodily Injury Liability\",\n        \"Property Damage Liability\",\n        \"Collision\",\n        \"Comprehensive\",\n        \"Medical Payments\",\n        \"Uninsured Motorist\"\n    ]\n)\n</code></pre>"},{"location":"usage/examples/insurance-policy/#advanced-multi-document-processing","title":"Advanced: Multi-Document Processing","text":"<p>Process multiple policies:</p> <pre><code># Process all policies in directory\nfor policy in policies/*.pdf; do\n    uv run docling-graph convert \"$policy\" \\\n        -t \"insurance_template.InsurancePolicy\" \\\n        --backend llm \\\n        --inference remote \\\n        --output-dir \"outputs/$(basename \"$policy\" .pdf)\"\ndone\n</code></pre> <p>Or use Python:</p> <pre><code>\"\"\"Process multiple policies.\"\"\"\n\nfrom pathlib import Path\nfrom docling_graph import PipelineConfig\n\npolicies_dir = Path(\"policies\")\noutput_base = Path(\"outputs\")\n\nfor policy_file in policies_dir.glob(\"*.pdf\"):\n    print(f\"Processing {policy_file.name}...\")\n\n    config = PipelineConfig(\n        source=str(policy_file),\n        template=\"insurance_template.InsurancePolicy\",\n        backend=\"llm\",\n        inference=\"remote\",\n        output_dir=str(output_base / policy_file.stem)\n    )\n\n    config.run()\n    print(f\"\u2713 {policy_file.name} complete!\")\n</code></pre>"},{"location":"usage/examples/insurance-policy/#next-steps","title":"Next Steps","text":"<ol> <li>Examples Index - See all examples</li> <li>Graph Analysis \u2192 - Analyze extracted data</li> <li>Neo4j Integration \u2192 - Load into database</li> </ol>"},{"location":"usage/examples/insurance-policy/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/examples/insurance-policy/#process-policy","title":"Process Policy","text":"<pre><code># Remote API (recommended)\nuv run docling-graph convert policy.pdf \\\n    -t \"insurance_template.InsurancePolicy\" \\\n    --backend llm \\\n    --inference remote\n\n# Local (alternative)\nuv run docling-graph convert policy.pdf \\\n    -t \"insurance_template.InsurancePolicy\" \\\n    --backend llm \\\n    --inference local\n</code></pre>"},{"location":"usage/examples/insurance-policy/#view-results","title":"View Results","text":"<pre><code>uv run docling-graph inspect outputs/insurance/\ncat outputs/insurance/nodes.csv\ncat outputs/insurance/edges.csv\n</code></pre>"},{"location":"usage/examples/insurance-policy/#template-location","title":"Template Location","text":"<pre><code>docs/examples/templates/insurance.py\n</code></pre>"},{"location":"usage/examples/invoice-extraction/","title":"Invoice Extraction","text":""},{"location":"usage/examples/invoice-extraction/#overview","title":"Overview","text":"<p>Extract complete structured data from invoices including issuer, client, line items, and financial details.</p> <p>What You'll Learn: - Creating entity and component models - Defining graph relationships with <code>edge()</code> - Handling nested structures - Address and line item extraction - Graph visualization</p> <p>Document Type: Invoice (PDF/JPG) Time: 15 minutes Backend: VLM (recommended) or LLM</p>"},{"location":"usage/examples/invoice-extraction/#prerequisites","title":"Prerequisites","text":"<pre><code># Install with all features\nuv sync --extra all\n\n# Verify installation\nuv run docling-graph --version\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#template-definition","title":"Template Definition","text":""},{"location":"usage/examples/invoice-extraction/#complete-template","title":"Complete Template","text":"<p>File: <code>invoice_template.py</code></p> <pre><code>\"\"\"\nComplete invoice extraction template.\nDemonstrates entities, components, and relationships.\n\"\"\"\n\nfrom typing import List\nfrom pydantic import BaseModel, ConfigDict, Field\n\n# Edge helper\ndef edge(label: str, **kwargs):\n    \"\"\"Helper to create graph edges.\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- Components (is_entity=False) ---\n\nclass Address(BaseModel):\n    \"\"\"Physical address component.\"\"\"\n\n    model_config = ConfigDict(is_entity=False)\n\n    street: str = Field(\n        description=\"Street name and number\",\n        examples=[\"123 Main St\", \"456 Oak Avenue\"]\n    )\n\n    city: str = Field(\n        description=\"City name\",\n        examples=[\"New York\", \"San Francisco\"]\n    )\n\n    postal_code: str = Field(\n        description=\"Postal or ZIP code\",\n        examples=[\"10001\", \"94102\"]\n    )\n\n    country: str | None = Field(\n        default=None,\n        description=\"Country name or code\",\n        examples=[\"USA\", \"United States\"]\n    )\n\nclass LineItem(BaseModel):\n    \"\"\"Individual line item in invoice.\"\"\"\n\n    model_config = ConfigDict(is_entity=False)\n\n    description: str = Field(\n        description=\"Product or service description\",\n        examples=[\"Web Development Services\", \"Consulting Hours\"]\n    )\n\n    quantity: float = Field(\n        description=\"Quantity of items\",\n        examples=[1.0, 10.0, 100.0]\n    )\n\n    unit: str | None = Field(\n        default=None,\n        description=\"Unit of measurement\",\n        examples=[\"hours\", \"items\", \"pcs\"]\n    )\n\n    unit_price: float = Field(\n        description=\"Price per unit\",\n        examples=[50.00, 100.00, 25.50]\n    )\n\n    total: float = Field(\n        description=\"Total price (quantity \u00d7 unit_price)\",\n        examples=[500.00, 1000.00, 2550.00]\n    )\n\n# --- Entities (is_entity=True, default) ---\n\nclass Organization(BaseModel):\n    \"\"\"Organization entity (issuer).\"\"\"\n\n    name: str = Field(\n        description=\"Legal organization name\",\n        examples=[\"Acme Corporation\", \"ABC Services Inc\"]\n    )\n\n    phone: str | None = Field(\n        default=None,\n        description=\"Contact phone number\",\n        examples=[\"+1-555-0100\", \"(555) 123-4567\"]\n    )\n\n    email: str | None = Field(\n        default=None,\n        description=\"Contact email\",\n        examples=[\"billing@acme.com\", \"info@abc.com\"]\n    )\n\n    website: str | None = Field(\n        default=None,\n        description=\"Company website\",\n        examples=[\"www.acme.com\", \"https://abc.com\"]\n    )\n\n    # Relationship to address\n    located_at: Address = edge(label=\"LOCATED_AT\")\n\nclass Client(BaseModel):\n    \"\"\"Client entity (recipient).\"\"\"\n\n    name: str = Field(\n        description=\"Client name (person or organization)\",\n        examples=[\"John Doe\", \"XYZ Company\"]\n    )\n\n    phone: str | None = Field(\n        default=None,\n        description=\"Client phone number\",\n        examples=[\"+1-555-0200\"]\n    )\n\n    email: str | None = Field(\n        default=None,\n        description=\"Client email\",\n        examples=[\"john@example.com\"]\n    )\n\n    # Relationship to address\n    lives_at: Address = edge(label=\"LIVES_AT\")\n\n# --- Root Entity ---\n\nclass Invoice(BaseModel):\n    \"\"\"Root invoice entity.\"\"\"\n\n    invoice_number: str = Field(\n        description=\"Unique invoice identifier\",\n        examples=[\"INV-001\", \"2024-001\"]\n    )\n\n    date: str = Field(\n        description=\"Invoice date (any format)\",\n        examples=[\"2024-01-15\", \"January 15, 2024\"]\n    )\n\n    currency: str = Field(\n        description=\"Currency code\",\n        examples=[\"USD\", \"EUR\", \"GBP\"]\n    )\n\n    subtotal: float = Field(\n        description=\"Amount before tax\",\n        examples=[1000.00, 5000.00]\n    )\n\n    vat_rate: float | str | None = Field(\n        default=None,\n        description=\"VAT/tax rate percentage\",\n        examples=[\"7.5\", 10.0, \"8.5%\"]\n    )\n\n    vat_amount: float = Field(\n        description=\"Total tax amount\",\n        examples=[75.00, 500.00]\n    )\n\n    total: float = Field(\n        description=\"Final total amount\",\n        examples=[1075.00, 5500.00]\n    )\n\n    # Relationships\n    issued_by: Organization = edge(label=\"ISSUED_BY\")\n    sent_to: Client = edge(label=\"SENT_TO\")\n    contains_items: List[LineItem] = edge(label=\"CONTAINS_ITEM\")\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#processing","title":"Processing","text":""},{"location":"usage/examples/invoice-extraction/#using-cli","title":"Using CLI","text":"<pre><code># Process invoice with VLM (recommended for images)\nuv run docling-graph convert invoice.jpg \\\n    --template \"invoice_template.Invoice\" \\\n    --backend vlm \\\n    --processing-mode one-to-one \\\n    --output-dir \"outputs/invoice\"\n\n# Process PDF with LLM\nuv run docling-graph convert invoice.pdf \\\n    --template \"invoice_template.Invoice\" \\\n    --backend llm \\\n    --inference remote \\\n    --output-dir \"outputs/invoice\"\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#using-python-api","title":"Using Python API","text":"<p>File: <code>process_invoice.py</code></p> <pre><code>\"\"\"Process invoice using Python API.\"\"\"\n\nimport os\nfrom docling_graph import PipelineConfig\n\n# Set API key if using remote\nos.environ[\"MISTRAL_API_KEY\"] = \"your-key\"\n\n# Configure pipeline\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"invoice_template.Invoice\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-small-latest\",\n    output_dir=\"outputs/invoice\"\n)\n\n# Run extraction\nprint(\"Processing invoice...\")\nconfig.run()\nprint(\"\u2713 Complete! Check outputs/invoice/\")\n</code></pre> <p>Run it:</p> <pre><code>uv run python process_invoice.py\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#expected-results","title":"Expected Results","text":""},{"location":"usage/examples/invoice-extraction/#graph-structure","title":"Graph Structure","text":"<pre><code>Invoice (INV-001)\n\u251c\u2500\u2500 ISSUED_BY \u2192 Organization (Acme Corp)\n\u2502   \u2514\u2500\u2500 LOCATED_AT \u2192 Address (123 Main St, NYC)\n\u251c\u2500\u2500 SENT_TO \u2192 Client (John Doe)\n\u2502   \u2514\u2500\u2500 LIVES_AT \u2192 Address (456 Oak Ave, SF)\n\u2514\u2500\u2500 CONTAINS_ITEM \u2192 LineItem (Web Development)\n    \u2514\u2500\u2500 CONTAINS_ITEM \u2192 LineItem (Consulting)\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#nodes-csv","title":"Nodes CSV","text":"<p>outputs/invoice/nodes.csv: <pre><code>id,label,type,invoice_number,date,total,currency\ninvoice_1,INV-001,Invoice,INV-001,2024-01-15,1075.00,USD\norg_1,Acme Corp,Organization,,,\nclient_1,John Doe,Client,,,\naddr_1,123 Main St,Address,,,\naddr_2,456 Oak Ave,Address,,,\nitem_1,Web Development,LineItem,,,\nitem_2,Consulting,LineItem,,,\n</code></pre></p>"},{"location":"usage/examples/invoice-extraction/#edges-csv","title":"Edges CSV","text":"<p>outputs/invoice/edges.csv: <pre><code>source,target,type\ninvoice_1,org_1,ISSUED_BY\ninvoice_1,client_1,SENT_TO\ninvoice_1,item_1,CONTAINS_ITEM\ninvoice_1,item_2,CONTAINS_ITEM\norg_1,addr_1,LOCATED_AT\nclient_1,addr_2,LIVES_AT\n</code></pre></p>"},{"location":"usage/examples/invoice-extraction/#statistics","title":"Statistics","text":"<p>outputs/invoice/graph_stats.json: <pre><code>{\n  \"node_count\": 7,\n  \"edge_count\": 6,\n  \"density\": 0.143,\n  \"avg_degree\": 1.714,\n  \"node_types\": {\n    \"Invoice\": 1,\n    \"Organization\": 1,\n    \"Client\": 1,\n    \"Address\": 2,\n    \"LineItem\": 2\n  },\n  \"edge_types\": {\n    \"ISSUED_BY\": 1,\n    \"SENT_TO\": 1,\n    \"CONTAINS_ITEM\": 2,\n    \"LOCATED_AT\": 1,\n    \"LIVES_AT\": 1\n  }\n}\n</code></pre></p>"},{"location":"usage/examples/invoice-extraction/#visualization","title":"Visualization","text":""},{"location":"usage/examples/invoice-extraction/#interactive-html","title":"Interactive HTML","text":"<pre><code># Open visualization\nuv run docling-graph inspect outputs/invoice/\n</code></pre> <p>Features: - Click nodes to see properties - Hover over edges to see relationships - Zoom and pan - Search nodes - Filter by type</p>"},{"location":"usage/examples/invoice-extraction/#neo4j-import","title":"Neo4j Import","text":"<pre><code># Export as Cypher\nuv run docling-graph convert invoice.pdf \\\n    --template \"invoice_template.Invoice\" \\\n    --export-format cypher \\\n    --output-dir \"outputs/neo4j\"\n\n# Import to Neo4j\ncat outputs/neo4j/graph.cypher | cypher-shell -u neo4j -p password\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#template-breakdown","title":"Template Breakdown","text":""},{"location":"usage/examples/invoice-extraction/#1-components-vs-entities","title":"1. Components vs Entities","text":"<pre><code># Component (embedded, no separate node)\nclass Address(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    street: str\n    city: str\n\n# Entity (separate node in graph)\nclass Organization(BaseModel):\n    # is_entity=True by default\n    name: str\n    located_at: Address  # Creates edge to Address\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#2-edge-definitions","title":"2. Edge Definitions","text":"<pre><code>def edge(label: str, **kwargs):\n    \"\"\"Creates graph relationship.\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\nclass Invoice(BaseModel):\n    # Creates ISSUED_BY edge from Invoice to Organization\n    issued_by: Organization = edge(label=\"ISSUED_BY\")\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#3-optional-fields","title":"3. Optional Fields","text":"<pre><code># Required field\nname: str = Field(description=\"Required name\")\n\n# Optional field\nphone: str | None = Field(\n    default=None,\n    description=\"Optional phone\"\n)\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#4-lists","title":"4. Lists","text":"<pre><code># List of line items\ncontains_items: List[LineItem] = edge(label=\"CONTAINS_ITEM\")\n\n# Creates multiple edges:\n# Invoice --CONTAINS_ITEM--&gt; LineItem1\n# Invoice --CONTAINS_ITEM--&gt; LineItem2\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#customization","title":"Customization","text":""},{"location":"usage/examples/invoice-extraction/#add-more-fields","title":"Add More Fields","text":"<pre><code>class Invoice(BaseModel):\n    # Existing fields...\n\n    # Add payment terms\n    payment_terms: str | None = Field(\n        default=None,\n        description=\"Payment terms\",\n        examples=[\"Net 30\", \"Due on receipt\"]\n    )\n\n    # Add due date\n    due_date: str | None = Field(\n        default=None,\n        description=\"Payment due date\",\n        examples=[\"2024-02-15\"]\n    )\n\n    # Add notes\n    notes: str | None = Field(\n        default=None,\n        description=\"Additional notes or comments\"\n    )\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#add-validation","title":"Add Validation","text":"<pre><code>from pydantic import field_validator\n\nclass Invoice(BaseModel):\n    subtotal: float\n    vat_amount: float\n    total: float\n\n    @field_validator('total')\n    @classmethod\n    def validate_total(cls, v, info):\n        \"\"\"Ensure total = subtotal + vat_amount.\"\"\"\n        subtotal = info.data.get('subtotal', 0)\n        vat = info.data.get('vat_amount', 0)\n        expected = subtotal + vat\n\n        if abs(v - expected) &gt; 0.01:  # Allow small rounding\n            raise ValueError(\n                f\"Total {v} doesn't match subtotal + VAT ({expected})\"\n            )\n        return v\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/invoice-extraction/#issue-missing-line-items","title":"Issue: Missing Line Items","text":"<p>Problem: Line items not extracted</p> <p>Solution: <pre><code># Make line items optional\ncontains_items: List[LineItem] = edge(\n    label=\"CONTAINS_ITEM\",\n    default_factory=list  # Empty list if none found\n)\n</code></pre></p>"},{"location":"usage/examples/invoice-extraction/#issue-address-not-parsed","title":"Issue: Address Not Parsed","text":"<p>Problem: Address fields empty</p> <p>Solution: <pre><code># Make address fields optional\nclass Address(BaseModel):\n    street: str | None = Field(default=None, ...)\n    city: str | None = Field(default=None, ...)\n    postal_code: str | None = Field(default=None, ...)\n</code></pre></p>"},{"location":"usage/examples/invoice-extraction/#issue-wrong-currency","title":"Issue: Wrong Currency","text":"<p>Problem: Currency extracted incorrectly</p> <p>Solution: <pre><code># Add examples and validation\ncurrency: str = Field(\n    description=\"Three-letter currency code (ISO 4217)\",\n    examples=[\"USD\", \"EUR\", \"GBP\", \"CHF\"],\n    pattern=\"^[A-Z]{3}$\"  # Enforce 3 uppercase letters\n)\n</code></pre></p>"},{"location":"usage/examples/invoice-extraction/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/invoice-extraction/#1-clear-descriptions","title":"1. Clear Descriptions","text":"<pre><code># \u2705 Good - Specific and clear\ninvoice_number: str = Field(\n    description=\"The unique invoice identifier, typically alphanumeric\",\n    examples=[\"INV-001\", \"2024-001\", \"ABC123\"]\n)\n\n# \u274c Avoid - Vague\ninvoice_number: str = Field(description=\"Invoice number\")\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#2-concrete-examples","title":"2. Concrete Examples","text":"<pre><code># \u2705 Good - Real examples\ntotal: float = Field(\n    description=\"Total amount to be paid\",\n    examples=[1234.56, 999.99, 5000.00]\n)\n\n# \u274c Avoid - Abstract examples\ntotal: float = Field(\n    description=\"Total amount\",\n    examples=[\"amount\", \"total\"]\n)\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#3-appropriate-optionality","title":"3. Appropriate Optionality","text":"<pre><code># \u2705 Good - Core fields required, details optional\nclass Invoice(BaseModel):\n    invoice_number: str  # Required\n    total: float  # Required\n    notes: str | None = Field(default=None)  # Optional\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#next-steps","title":"Next Steps","text":"<ol> <li>Research Paper \u2192 - Complex scientific documents</li> <li>ID Card \u2192 - Vision-based extraction</li> <li>Schema Definition \u2192 - Advanced templates</li> </ol>"},{"location":"usage/examples/invoice-extraction/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/examples/invoice-extraction/#run-extraction","title":"Run Extraction","text":"<pre><code># VLM (images)\nuv run docling-graph convert invoice.jpg \\\n    -t \"invoice_template.Invoice\" \\\n    --backend vlm\n\n# LLM (PDFs)\nuv run docling-graph convert invoice.pdf \\\n    -t \"invoice_template.Invoice\" \\\n    --backend llm\n</code></pre>"},{"location":"usage/examples/invoice-extraction/#view-results","title":"View Results","text":"<pre><code># Visualize\nuv run docling-graph inspect outputs/invoice/\n\n# View data\ncat outputs/invoice/nodes.csv\ncat outputs/invoice/edges.csv\n</code></pre>"},{"location":"usage/examples/markdown-input/","title":"Markdown Input Example","text":""},{"location":"usage/examples/markdown-input/#overview","title":"Overview","text":"<p>This example demonstrates how to process Markdown documents directly, extracting structured data from formatted text without requiring OCR or visual processing.</p> <p>What You'll Learn: - Processing Markdown files - Text-only extraction workflow - LLM backend requirements - Structured text parsing</p> <p>Time: 10 minutes</p>"},{"location":"usage/examples/markdown-input/#use-case-documentation-analysis","title":"Use Case: Documentation Analysis","text":"<p>Extract structured information from project documentation, including sections, code examples, and metadata.</p>"},{"location":"usage/examples/markdown-input/#document-source","title":"Document Source","text":"<p>File: <code>README.md</code> or <code>DOCUMENTATION.md</code></p> <p>Type: Markdown</p> <p>Content: Project documentation with sections, code blocks, and structured information.</p>"},{"location":"usage/examples/markdown-input/#template-definition","title":"Template Definition","text":"<p>We'll create a template for documentation that captures sections, code examples, and metadata.</p> <pre><code>from pydantic import BaseModel, Field\nfrom docling_graph.utils import edge\n\nclass CodeExample(BaseModel):\n    \"\"\"Code example component.\"\"\"\n    model_config = {'is_entity': False}\n\n    language: str = Field(description=\"Programming language\")\n    code: str = Field(description=\"Code snippet\")\n    description: str = Field(description=\"What the code does\")\n\nclass Section(BaseModel):\n    \"\"\"Documentation section entity.\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['title']\n    }\n\n    title: str = Field(description=\"Section title\")\n    content: str = Field(description=\"Section content\")\n    subsections: list[str] = Field(\n        default_factory=list,\n        description=\"Subsection titles\"\n    )\n\nclass Documentation(BaseModel):\n    \"\"\"Complete documentation structure.\"\"\"\n    model_config = {'is_entity': True}\n\n    title: str = Field(description=\"Document title\")\n    description: str = Field(description=\"Project description\")\n    version: str | None = Field(\n        default=None,\n        description=\"Documentation version\"\n    )\n    sections: list[Section] = edge(\n        \"HAS_SECTION\",\n        description=\"Documentation sections\"\n    )\n    code_examples: list[CodeExample] = Field(\n        default_factory=list,\n        description=\"Code examples\"\n    )\n    requirements: list[str] = Field(\n        default_factory=list,\n        description=\"Project requirements\"\n    )\n</code></pre> <p>Save as: <code>templates/documentation.py</code></p>"},{"location":"usage/examples/markdown-input/#processing-with-cli","title":"Processing with CLI","text":""},{"location":"usage/examples/markdown-input/#basic-markdown-processing","title":"Basic Markdown Processing","text":"<pre><code># Process README.md\nuv run docling-graph convert README.md \\\n    --template \"templates.documentation.Documentation\" \\\n    --backend llm \\\n    --inference remote\n</code></pre> <p>Important: Markdown files require LLM backend (VLM doesn't support text-only inputs).</p>"},{"location":"usage/examples/markdown-input/#with-local-llm","title":"With Local LLM","text":"<pre><code># Use local Ollama\nuv run docling-graph convert DOCUMENTATION.md \\\n    --template \"templates.documentation.Documentation\" \\\n    --backend llm \\\n    --inference local \\\n    --provider ollama \\\n    --model llama3.1:8b\n</code></pre>"},{"location":"usage/examples/markdown-input/#with-chunking","title":"With Chunking","text":"<pre><code># Process large markdown with chunking\nuv run docling-graph convert LARGE_DOC.md \\\n    --template \"templates.documentation.Documentation\" \\\n    --backend llm \\\n    --inference remote \\\n    --use-chunking \\\n    --llm-consolidation\n</code></pre>"},{"location":"usage/examples/markdown-input/#processing-with-python-api","title":"Processing with Python API","text":""},{"location":"usage/examples/markdown-input/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import PipelineConfig\nfrom templates.documentation import Documentation\n\n# Configure pipeline for Markdown input\nconfig = PipelineConfig(\n    source=\"README.md\",\n    template=Documentation,\n    backend=\"llm\",  # Required for text inputs\n    inference=\"remote\",\n    processing_mode=\"many-to-one\",\n    output_dir=\"outputs/docs\"\n)\n\n# Run pipeline\nconfig.run()\n</code></pre>"},{"location":"usage/examples/markdown-input/#processing-multiple-markdown-files","title":"Processing Multiple Markdown Files","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\nfrom templates.documentation import Documentation\n\n# Process all markdown files in a directory\ndocs_dir = Path(\"docs\")\nmarkdown_files = docs_dir.glob(\"**/*.md\")\n\nfor md_file in markdown_files:\n    print(f\"Processing: {md_file}\")\n\n    config = PipelineConfig(\n        source=str(md_file),\n        template=Documentation,\n        backend=\"llm\",\n        inference=\"remote\",\n        processing_mode=\"many-to-one\",\n        output_dir=f\"outputs/{md_file.stem}\"\n    )\n\n    try:\n        config.run()\n        print(f\"\u2713 Completed: {md_file}\")\n    except Exception as e:\n        print(f\"\u2717 Failed: {md_file} - {e}\")\n</code></pre>"},{"location":"usage/examples/markdown-input/#with-custom-provider","title":"With Custom Provider","text":"<pre><code>from docling_graph import PipelineConfig\nfrom templates.documentation import Documentation\n\n# Use specific LLM provider\nconfig = PipelineConfig(\n    source=\"API_DOCS.md\",\n    template=Documentation,\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",\n    use_chunking=True,\n    output_dir=\"outputs/api_docs\"\n)\n\nconfig.run()\n</code></pre>"},{"location":"usage/examples/markdown-input/#expected-output","title":"Expected Output","text":""},{"location":"usage/examples/markdown-input/#graph-structure","title":"Graph Structure","text":"<pre><code>Documentation (root node)\n\u251c\u2500\u2500 HAS_SECTION \u2192 Section (Installation)\n\u2502   \u251c\u2500\u2500 title: \"Installation\"\n\u2502   \u251c\u2500\u2500 content: \"...\"\n\u2502   \u2514\u2500\u2500 subsections: [\"Requirements\", \"Setup\"]\n\u251c\u2500\u2500 HAS_SECTION \u2192 Section (Usage)\n\u2502   \u251c\u2500\u2500 title: \"Usage\"\n\u2502   \u2514\u2500\u2500 content: \"...\"\n\u251c\u2500\u2500 code_examples (list)\n\u2502   \u251c\u2500\u2500 CodeExample 1: Python\n\u2502   \u2514\u2500\u2500 CodeExample 2: Bash\n\u2514\u2500\u2500 requirements: [\"Python 3.10+\", \"uv\"]\n</code></pre>"},{"location":"usage/examples/markdown-input/#csv-export","title":"CSV Export","text":"<p>nodes.csv: <pre><code>node_id,node_type,title,description,version\ndoc_1,Documentation,\"Project Name\",\"Description...\",\"1.0.0\"\n\nnode_id,node_type,title,content\nsection_installation,Section,\"Installation\",\"Installation instructions...\"\nsection_usage,Section,\"Usage\",\"Usage guide...\"\n</code></pre></p> <p>edges.csv: <pre><code>source_id,target_id,edge_type\ndoc_1,section_installation,HAS_SECTION\ndoc_1,section_usage,HAS_SECTION\n</code></pre></p>"},{"location":"usage/examples/markdown-input/#markdown-processing-features","title":"Markdown Processing Features","text":""},{"location":"usage/examples/markdown-input/#what-gets-processed","title":"What Gets Processed","text":"<p>The pipeline extracts: - Headers \u2192 Section titles - Paragraphs \u2192 Content - Code blocks \u2192 Code examples - Lists \u2192 Requirements, features - Links \u2192 References - Tables \u2192 Structured data</p>"},{"location":"usage/examples/markdown-input/#markdown-preservation","title":"Markdown Preservation","text":"<p>The original Markdown formatting is preserved in the extracted content, allowing you to: - Maintain code block syntax - Preserve link references - Keep list structures - Retain emphasis and formatting</p>"},{"location":"usage/examples/markdown-input/#text-only-pipeline","title":"Text-Only Pipeline","text":"<p>Markdown files skip: \u274c OCR (no visual processing needed) \u274c Page segmentation (single text stream) \u2705 Direct LLM extraction \u2705 Semantic chunking (if enabled)</p>"},{"location":"usage/examples/markdown-input/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/markdown-input/#issue-vlm-backend-error","title":"Issue: VLM Backend Error","text":"<p>Error: <pre><code>ExtractionError: VLM backend does not support text-only inputs\n</code></pre></p> <p>Solution: <pre><code># Always use LLM backend for Markdown\nuv run docling-graph convert README.md \\\n    --template \"templates.documentation.Documentation\" \\\n    --backend llm  # Required\n</code></pre></p>"},{"location":"usage/examples/markdown-input/#issue-empty-file","title":"Issue: Empty File","text":"<p>Error: <pre><code>ValidationError: Text input is empty\n</code></pre></p> <p>Solution: <pre><code># Ensure file has content\ncat README.md  # Check file content\nfile README.md  # Verify file type\n\n# If file is empty, add content first\necho \"# Documentation\" &gt; README.md\n</code></pre></p>"},{"location":"usage/examples/markdown-input/#issue-encoding-problems","title":"Issue: Encoding Problems","text":"<p>Error: <pre><code>ValidationError: Failed to read text file: encoding error\n</code></pre></p> <p>Solution: <pre><code># Convert file to UTF-8 first\nwith open(\"README.md\", \"r\", encoding=\"latin-1\") as f:\n    content = f.read()\n\nwith open(\"README_utf8.md\", \"w\", encoding=\"utf-8\") as f:\n    f.write(content)\n\n# Then process\nconfig = PipelineConfig(source=\"README_utf8.md\", ...)\n</code></pre></p>"},{"location":"usage/examples/markdown-input/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/markdown-input/#1-use-descriptive-section-headers","title":"1. Use Descriptive Section Headers","text":"<pre><code>\u2705 Good - Clear hierarchy\n# Installation Guide\n## Requirements\n## Setup Steps\n\n\u274c Bad - Unclear structure\n# Stuff\n## Things\n</code></pre>"},{"location":"usage/examples/markdown-input/#2-include-code-language-tags","title":"2. Include Code Language Tags","text":"<pre><code>\u2705 Good - Language specified\n```python\ndef hello():\n    print(\"Hello\")\n</code></pre> <p>\u274c Bad - No language <pre><code>def hello():\n    print(\"Hello\")\n</code></pre> <pre><code>### 3. Structure Content Logically\n\n```markdown\n\u2705 Good - Logical flow\n# Overview\n# Installation\n# Usage\n# Examples\n# Troubleshooting\n\n\u274c Bad - Random order\n# Examples\n# Overview\n# Troubleshooting\n# Installation\n</code></pre></p>"},{"location":"usage/examples/markdown-input/#4-use-consistent-formatting","title":"4. Use Consistent Formatting","text":"<pre><code>\u2705 Good - Consistent style\n- Item 1\n- Item 2\n- Item 3\n\n\u274c Bad - Mixed styles\n- Item 1\n* Item 2\n+ Item 3\n</code></pre>"},{"location":"usage/examples/markdown-input/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/examples/markdown-input/#processing-markdown-from-string","title":"Processing Markdown from String","text":"<pre><code>from docling_graph import PipelineConfig, run_pipeline\nfrom templates.documentation import Documentation\n\n# Markdown content as string\nmarkdown_content = \"\"\"\n# My Project\n\n## Overview\nThis is a sample project.\n\n## Features\n- Feature 1\n- Feature 2\n\"\"\"\n\n# Process directly (API mode only)\nconfig = PipelineConfig(\n    source=markdown_content,\n    template=Documentation,\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\"\n)\n\nrun_pipeline(config, mode=\"api\")  # mode=\"api\" required for string input\n</code></pre>"},{"location":"usage/examples/markdown-input/#combining-multiple-markdown-files","title":"Combining Multiple Markdown Files","text":"<pre><code>from pathlib import Path\n\n# Combine multiple markdown files\nmd_files = [\"intro.md\", \"guide.md\", \"reference.md\"]\ncombined_content = \"\\n\\n---\\n\\n\".join(\n    Path(f).read_text() for f in md_files\n)\n\n# Save combined file\nPath(\"combined.md\").write_text(combined_content)\n\n# Process combined file\nconfig = PipelineConfig(\n    source=\"combined.md\",\n    template=Documentation,\n    backend=\"llm\",\n    inference=\"remote\"\n)\nconfig.run()\n</code></pre>"},{"location":"usage/examples/markdown-input/#extracting-specific-sections","title":"Extracting Specific Sections","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass QuickStart(BaseModel):\n    \"\"\"Extract only quickstart section.\"\"\"\n    model_config = {'is_entity': True}\n\n    installation: str = Field(description=\"Installation instructions\")\n    basic_usage: str = Field(description=\"Basic usage example\")\n    next_steps: list[str] = Field(description=\"Next steps\")\n\n# Process with focused template\nconfig = PipelineConfig(\n    source=\"README.md\",\n    template=QuickStart,\n    backend=\"llm\",\n    inference=\"remote\"\n)\n</code></pre>"},{"location":"usage/examples/markdown-input/#comparison-markdown-vs-pdf","title":"Comparison: Markdown vs PDF","text":"Feature Markdown PDF OCR Required \u274c No \u2705 Yes Processing Speed \u26a1 Fast \ud83d\udc22 Slower Backend Support LLM only LLM + VLM Structure Preservation \u2705 Excellent \u26a0\ufe0f Variable Code Blocks \u2705 Native \u26a0\ufe0f Extracted Best For Documentation, Notes Scanned docs, Forms"},{"location":"usage/examples/markdown-input/#next-steps","title":"Next Steps","text":"<ul> <li>DoclingDocument Input \u2192 - Use pre-processed documents</li> <li>Input Formats Guide - Complete input format reference</li> <li>LLM Backend Configuration - Configure LLM settings</li> </ul>"},{"location":"usage/examples/research-paper/","title":"Research Paper Extraction","text":""},{"location":"usage/examples/research-paper/#overview","title":"Overview","text":"<p>Extract complex research data from scientific papers including experiments, measurements, materials, and results.</p> <p>What You'll Learn: - Complex ontology design - Enum normalization - Custom validators - Measurement parsing - Multi-page consolidation</p> <p>Document Type: Research Paper (PDF) Time: 30 minutes Backend: LLM with chunking</p>"},{"location":"usage/examples/research-paper/#prerequisites","title":"Prerequisites","text":"<pre><code># Install with remote API support\nuv sync --extra remote\n\n# Set API key\nexport MISTRAL_API_KEY=\"your-key\"\n</code></pre>"},{"location":"usage/examples/research-paper/#template-overview","title":"Template Overview","text":"<p>The research paper template (<code>rheology_research.py</code>) includes:</p> <ul> <li>Measurements - Flexible value/unit pairs</li> <li>Materials - Granular material properties</li> <li>Geometry - Experimental setup</li> <li>Vibration - Vibration parameters</li> <li>Simulation - DEM simulation details</li> <li>Results - Rheological measurements</li> <li>Experiments - Complete experiment instances</li> <li>Research - Root document model</li> </ul>"},{"location":"usage/examples/research-paper/#key-components","title":"Key Components","text":"<pre><code># 1. Measurement Model\nclass Measurement(BaseModel):\n    \"\"\"Flexible measurement with value and unit.\"\"\"\n    name: str\n    numeric_value: float | None = None\n    text_value: str | None = None\n    unit: str | None = None\n\n# 2. Enum Types\nclass GeometryType(str, Enum):\n    VANE_RHEOMETER = \"Vane Rheometer\"\n    DOUBLE_PLATE = \"Double Plate\"\n    CYLINDRICAL_CONTAINER = \"Cylindrical Container\"\n\n# 3. Experiment Entity\nclass Experiment(BaseModel):\n    experiment_id: str\n    objective: str\n    granular_material: GranularMaterial = edge(\"USES_MATERIAL\")\n    vibration_conditions: VibrationConditions = edge(\"HAS_VIBRATION\")\n    rheological_results: List[RheologicalResult] = edge(\"HAS_RESULT\")\n\n# 4. Root Model\nclass Research(BaseModel):\n    title: str\n    authors: List[str]\n    experiments: List[Experiment] = edge(\"HAS_EXPERIMENT\")\n</code></pre>"},{"location":"usage/examples/research-paper/#processing","title":"Processing","text":""},{"location":"usage/examples/research-paper/#using-cli","title":"Using CLI","text":"<pre><code># Process research paper with chunking\nuv run docling-graph convert research.pdf \\\n    --template \"docs.examples.templates.rheology_research.Research\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider mistral \\\n    --model mistral-large-latest \\\n    --processing-mode many-to-one \\\n    --use-chunking \\\n    --llm-consolidation \\\n    --docling-pipeline vision \\\n    --output-dir \"outputs/research\"\n</code></pre>"},{"location":"usage/examples/research-paper/#using-python-api","title":"Using Python API","text":"<pre><code>\"\"\"Process research paper.\"\"\"\n\nimport os\nfrom docling_graph import PipelineConfig\n\nos.environ[\"MISTRAL_API_KEY\"] = \"your-key\"\n\nconfig = PipelineConfig(\n    source=\"research.pdf\",\n    template=\"docs.examples.templates.rheology_research.Research\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    llm_consolidation=True,\n    docling_config=\"vision\",  # Better for complex layouts\n    output_dir=\"outputs/research\"\n)\n\nprint(\"Processing research paper (may take several minutes)...\")\nconfig.run()\nprint(\"\u2713 Complete!\")\n</code></pre>"},{"location":"usage/examples/research-paper/#expected-results","title":"Expected Results","text":""},{"location":"usage/examples/research-paper/#graph-structure","title":"Graph Structure","text":"<pre><code>Research (Title)\n\u251c\u2500\u2500 HAS_EXPERIMENT \u2192 Experiment 1\n\u2502   \u251c\u2500\u2500 USES_MATERIAL \u2192 GranularMaterial\n\u2502   \u2502   \u2514\u2500\u2500 properties: [Measurement, Measurement]\n\u2502   \u251c\u2500\u2500 HAS_GEOMETRY \u2192 SystemGeometry\n\u2502   \u2502   \u2514\u2500\u2500 dimensions: [Measurement, Measurement]\n\u2502   \u251c\u2500\u2500 HAS_VIBRATION \u2192 VibrationConditions\n\u2502   \u2502   \u251c\u2500\u2500 amplitude: Measurement\n\u2502   \u2502   \u251c\u2500\u2500 frequency: Measurement\n\u2502   \u2502   \u2514\u2500\u2500 confining_pressure: Measurement\n\u2502   \u251c\u2500\u2500 HAS_SIMULATION \u2192 SimulationSetup\n\u2502   \u2502   \u2514\u2500\u2500 parameters: [Measurement, Measurement]\n\u2502   \u2514\u2500\u2500 HAS_RESULT \u2192 RheologicalResult\n\u2502       \u2514\u2500\u2500 measurement: Measurement\n\u2514\u2500\u2500 HAS_EXPERIMENT \u2192 Experiment 2\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"usage/examples/research-paper/#statistics","title":"Statistics","text":"<pre><code>{\n  \"node_count\": 45,\n  \"edge_count\": 38,\n  \"density\": 0.019,\n  \"node_types\": {\n    \"Research\": 1,\n    \"Experiment\": 3,\n    \"GranularMaterial\": 3,\n    \"SystemGeometry\": 3,\n    \"VibrationConditions\": 3,\n    \"RheologicalResult\": 12,\n    \"Measurement\": 20\n  }\n}\n</code></pre>"},{"location":"usage/examples/research-paper/#key-features","title":"Key Features","text":""},{"location":"usage/examples/research-paper/#1-enum-normalization","title":"1. Enum Normalization","text":"<pre><code>class GeometryType(str, Enum):\n    VANE_RHEOMETER = \"Vane Rheometer\"\n    CYLINDRICAL_CONTAINER = \"Cylindrical Container\"\n\n# Validator accepts multiple formats\n@field_validator(\"geometry_type\", mode=\"before\")\n@classmethod\ndef normalize_enum(cls, v):\n    # Accepts: \"Vane Rheometer\", \"vane_rheometer\", \"VANE_RHEOMETER\"\n    return _normalize_enum(GeometryType, v)\n</code></pre>"},{"location":"usage/examples/research-paper/#2-measurement-parsing","title":"2. Measurement Parsing","text":"<pre><code># Parses strings like \"1.6 mPa.s\", \"2 mm\", \"80-90 \u00b0C\"\ndef _parse_measurement_string(s: str):\n    # Single value: \"1.6 mPa.s\" \u2192 {numeric_value: 1.6, unit: \"mPa.s\"}\n    # Range: \"80-90 \u00b0C\" \u2192 {numeric_value_min: 80, numeric_value_max: 90, unit: \"\u00b0C\"}\n    ...\n</code></pre>"},{"location":"usage/examples/research-paper/#3-flexible-measurements","title":"3. Flexible Measurements","text":"<pre><code>class Measurement(BaseModel):\n    name: str\n    numeric_value: float | None = None  # Single value\n    numeric_value_min: float | None = None  # Range min\n    numeric_value_max: float | None = None  # Range max\n    text_value: str | None = None  # Qualitative\n    unit: str | None = None\n</code></pre>"},{"location":"usage/examples/research-paper/#4-nested-relationships","title":"4. Nested Relationships","text":"<pre><code>class Experiment(BaseModel):\n    # Direct edges\n    granular_material: GranularMaterial = edge(\"USES_MATERIAL\")\n\n    # Nested properties (not separate nodes)\n    key_findings: List[str] = Field(default_factory=list)\n</code></pre>"},{"location":"usage/examples/research-paper/#configuration-tips","title":"Configuration Tips","text":""},{"location":"usage/examples/research-paper/#for-long-documents","title":"For Long Documents","text":"<pre><code># Enable chunking and consolidation\nuv run docling-graph convert research.pdf \\\n    --template \"templates.Research\" \\\n    --use-chunking \\\n    --llm-consolidation \\\n    --processing-mode many-to-one\n</code></pre>"},{"location":"usage/examples/research-paper/#for-complex-layouts","title":"For Complex Layouts","text":"<pre><code># Use vision pipeline for better table/figure handling\nuv run docling-graph convert research.pdf \\\n    --template \"templates.Research\" \\\n    --docling-pipeline vision\n</code></pre>"},{"location":"usage/examples/research-paper/#for-cost-optimization","title":"For Cost Optimization","text":"<pre><code># Use smaller model without consolidation\nuv run docling-graph convert research.pdf \\\n    --template \"templates.Research\" \\\n    --model mistral-small-latest \\\n    --no-llm-consolidation\n</code></pre>"},{"location":"usage/examples/research-paper/#customization","title":"Customization","text":""},{"location":"usage/examples/research-paper/#simplify-for-your-domain","title":"Simplify for Your Domain","text":"<pre><code>\"\"\"Simplified research template.\"\"\"\n\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\ndef edge(label: str, **kwargs):\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\nclass Measurement(BaseModel):\n    \"\"\"Simple measurement.\"\"\"\n    name: str\n    value: str  # Keep as string for simplicity\n    unit: str | None = None\n\nclass Experiment(BaseModel):\n    \"\"\"Simplified experiment.\"\"\"\n    title: str\n    objective: str\n    methods: str\n    results: str\n    measurements: List[Measurement] = Field(default_factory=list)\n\nclass Research(BaseModel):\n    \"\"\"Simplified research paper.\"\"\"\n    title: str\n    authors: List[str]\n    abstract: str\n    experiments: List[Experiment] = edge(\"HAS_EXPERIMENT\")\n</code></pre>"},{"location":"usage/examples/research-paper/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/research-paper/#issue-extraction-takes-too-long","title":"Issue: Extraction Takes Too Long","text":"<p>Solution: <pre><code># Disable consolidation for faster processing\nuv run docling-graph convert research.pdf \\\n    --template \"templates.Research\" \\\n    --no-llm-consolidation\n\n# Or use smaller model\n--model mistral-small-latest\n</code></pre></p>"},{"location":"usage/examples/research-paper/#issue-missing-measurements","title":"Issue: Missing Measurements","text":"<p>Solution: <pre><code># Make measurements optional\nmeasurements: List[Measurement] = Field(\n    default_factory=list,\n    description=\"List of measurements (optional)\"\n)\n</code></pre></p>"},{"location":"usage/examples/research-paper/#issue-enum-validation-errors","title":"Issue: Enum Validation Errors","text":"<p>Solution: <pre><code># Add OTHER option to enums\nclass GeometryType(str, Enum):\n    VANE_RHEOMETER = \"Vane Rheometer\"\n    OTHER = \"Other\"  # Fallback\n\n# Or make enum optional\ngeometry_type: GeometryType | None = Field(default=None)\n</code></pre></p>"},{"location":"usage/examples/research-paper/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/research-paper/#1-start-simple-add-complexity","title":"1. Start Simple, Add Complexity","text":"<pre><code># Phase 1: Basic structure\nclass Research(BaseModel):\n    title: str\n    authors: List[str]\n    abstract: str\n\n# Phase 2: Add experiments\nclass Research(BaseModel):\n    title: str\n    authors: List[str]\n    abstract: str\n    experiments: List[Experiment]\n\n# Phase 3: Add measurements, validations, etc.\n</code></pre>"},{"location":"usage/examples/research-paper/#2-use-appropriate-chunking","title":"2. Use Appropriate Chunking","text":"<pre><code># For papers &gt; 10 pages\nconfig = PipelineConfig(\n    source=\"long_paper.pdf\",\n    template=\"templates.Research\",\n    use_chunking=True,  # Essential\n    llm_consolidation=True  # Better accuracy\n)\n</code></pre>"},{"location":"usage/examples/research-paper/#3-provide-clear-examples","title":"3. Provide Clear Examples","text":"<pre><code># \u2705 Good - Domain-specific examples\nviscosity: Measurement = Field(\n    description=\"Effective viscosity measurement\",\n    examples=[\n        {\"name\": \"Effective Viscosity\", \"numeric_value\": 1.6, \"unit\": \"mPa.s\"}\n    ]\n)\n</code></pre>"},{"location":"usage/examples/research-paper/#next-steps","title":"Next Steps","text":"<ol> <li>ID Card \u2192 - Vision-based extraction</li> <li>Advanced Patterns \u2192 - Complex templates</li> <li>Performance Tuning \u2192 - Optimization</li> </ol>"},{"location":"usage/examples/research-paper/#quick-reference","title":"Quick Reference","text":""},{"location":"usage/examples/research-paper/#process-research-paper","title":"Process Research Paper","text":"<pre><code>uv run docling-graph convert research.pdf \\\n    -t \"docs.examples.templates.rheology_research.Research\" \\\n    --backend llm \\\n    --inference remote \\\n    --use-chunking \\\n    --llm-consolidation\n</code></pre>"},{"location":"usage/examples/research-paper/#view-results","title":"View Results","text":"<pre><code>uv run docling-graph inspect outputs/research/\ncat outputs/research/graph_stats.json\n</code></pre>"},{"location":"usage/examples/research-paper/#template-location","title":"Template Location","text":"<pre><code>docs/examples/templates/rheology_research.py\n</code></pre>"},{"location":"usage/examples/url-input/","title":"URL Input Example","text":""},{"location":"usage/examples/url-input/#overview","title":"Overview","text":"<p>This example demonstrates how to process documents directly from URLs, showcasing Docling Graph's ability to download and extract data from remote documents without manual file management.</p> <p>What You'll Learn: - Processing documents from URLs - Automatic content type detection - URL-based workflow integration - Remote document extraction</p> <p>Time: 10 minutes</p>"},{"location":"usage/examples/url-input/#use-case-research-paper-analysis","title":"Use Case: Research Paper Analysis","text":"<p>Extract structured information from a scientific paper hosted on arXiv, including authors, abstract, methodology, and key findings.</p>"},{"location":"usage/examples/url-input/#document-source","title":"Document Source","text":"<p>URL: <code>https://arxiv.org/pdf/2207.02720</code></p> <p>Type: PDF (Research Paper on Rheology)</p> <p>Content: Scientific paper with complex structure including authors, abstract, methodology, results, and references.</p>"},{"location":"usage/examples/url-input/#template-definition","title":"Template Definition","text":"<p>We'll use a research paper template that captures the essential structure of scientific documents.</p> <pre><code>from pydantic import BaseModel, Field\nfrom docling_graph.utils import edge\n\nclass Author(BaseModel):\n    \"\"\"Author entity.\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['name']\n    }\n\n    name: str = Field(description=\"Author's full name\")\n    affiliation: str | None = Field(\n        default=None,\n        description=\"Author's institutional affiliation\"\n    )\n\nclass Methodology(BaseModel):\n    \"\"\"Research methodology component.\"\"\"\n    model_config = {'is_entity': False}\n\n    approach: str = Field(description=\"Research approach or method used\")\n    materials: list[str] = Field(\n        default_factory=list,\n        description=\"Materials or tools used\"\n    )\n    procedure: str = Field(description=\"Experimental or analytical procedure\")\n\nclass Finding(BaseModel):\n    \"\"\"Key research finding.\"\"\"\n    model_config = {'is_entity': False}\n\n    description: str = Field(description=\"Description of the finding\")\n    significance: str = Field(description=\"Significance or implication\")\n\nclass Research(BaseModel):\n    \"\"\"Complete research paper structure.\"\"\"\n    model_config = {'is_entity': True}\n\n    title: str = Field(description=\"Paper title\")\n    abstract: str = Field(description=\"Paper abstract\")\n    authors: list[Author] = edge(\n        \"AUTHORED_BY\",\n        description=\"Paper authors\"\n    )\n    methodology: Methodology = Field(description=\"Research methodology\")\n    key_findings: list[Finding] = Field(\n        default_factory=list,\n        description=\"Key research findings\"\n    )\n    conclusion: str = Field(description=\"Paper conclusion\")\n</code></pre> <p>Save as: <code>templates/research.py</code></p>"},{"location":"usage/examples/url-input/#processing-with-cli","title":"Processing with CLI","text":""},{"location":"usage/examples/url-input/#basic-url-processing","title":"Basic URL Processing","text":"<pre><code># Process research paper from URL\nuv run docling-graph convert \"https://arxiv.org/pdf/2207.02720\" \\\n    --template \"templates.research.Research\" \\\n    --processing-mode \"many-to-one\" \\\n    --backend llm \\\n    --inference remote\n</code></pre>"},{"location":"usage/examples/url-input/#with-custom-output","title":"With Custom Output","text":"<pre><code># Process with custom output directory\nuv run docling-graph convert \"https://arxiv.org/pdf/2207.02720\" \\\n    --template \"templates.research.Research\" \\\n    --processing-mode \"many-to-one\" \\\n    --output-dir \"outputs/research_paper\" \\\n    --export-format json\n</code></pre>"},{"location":"usage/examples/url-input/#with-specific-model","title":"With Specific Model","text":"<pre><code># Use specific LLM model\nuv run docling-graph convert \"https://arxiv.org/pdf/2207.02720\" \\\n    --template \"templates.research.Research\" \\\n    --processing-mode \"many-to-one\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider openai \\\n    --model gpt-4-turbo\n</code></pre>"},{"location":"usage/examples/url-input/#processing-with-python-api","title":"Processing with Python API","text":""},{"location":"usage/examples/url-input/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import PipelineConfig\nfrom templates.research import Research\n\n# Configure pipeline for URL input\nconfig = PipelineConfig(\n    source=\"https://arxiv.org/pdf/2207.02720\",\n    template=Research,\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\",\n    output_dir=\"outputs/research\"\n)\n\n# Run pipeline\nconfig.run()\n</code></pre>"},{"location":"usage/examples/url-input/#with-custom-settings","title":"With Custom Settings","text":"<pre><code>from docling_graph import PipelineConfig\nfrom templates.research import Research\n\n# Advanced configuration\nconfig = PipelineConfig(\n    source=\"https://arxiv.org/pdf/2207.02720\",\n    template=Research,\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n    use_chunking=True,\n    llm_consolidation=True,\n    output_dir=\"outputs/research\",\n    export_format=\"json\"\n)\n\n# Run pipeline\nconfig.run()\n</code></pre>"},{"location":"usage/examples/url-input/#error-handling","title":"Error Handling","text":"<pre><code>from docling_graph import PipelineConfig\nfrom docling_graph.exceptions import ValidationError, ExtractionError\nfrom templates.research import Research\n\ntry:\n    config = PipelineConfig(\n        source=\"https://arxiv.org/pdf/2207.02720\",\n        template=Research,\n        backend=\"llm\",\n        inference=\"remote\",\n        processing_mode=\"many-to-one\"\n    )\n    config.run()\n\nexcept ValidationError as e:\n    print(f\"URL validation failed: {e.message}\")\n    if e.details:\n        print(f\"Details: {e.details}\")\n\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n    # Handle extraction errors (e.g., retry with different model)\n</code></pre>"},{"location":"usage/examples/url-input/#expected-output","title":"Expected Output","text":""},{"location":"usage/examples/url-input/#graph-structure","title":"Graph Structure","text":"<pre><code>Research (root node)\n\u251c\u2500\u2500 AUTHORED_BY \u2192 Author (John Doe)\n\u251c\u2500\u2500 AUTHORED_BY \u2192 Author (Jane Smith)\n\u251c\u2500\u2500 methodology (embedded)\n\u2502   \u251c\u2500\u2500 approach: \"Experimental rheology\"\n\u2502   \u251c\u2500\u2500 materials: [\"Polymer samples\", \"Rheometer\"]\n\u2502   \u2514\u2500\u2500 procedure: \"...\"\n\u251c\u2500\u2500 key_findings (list)\n\u2502   \u251c\u2500\u2500 Finding 1: \"...\"\n\u2502   \u2514\u2500\u2500 Finding 2: \"...\"\n\u2514\u2500\u2500 conclusion: \"...\"\n</code></pre>"},{"location":"usage/examples/url-input/#csv-export","title":"CSV Export","text":"<p>nodes.csv: <pre><code>node_id,node_type,title,abstract,conclusion\nresearch_1,Research,\"Paper Title\",\"Abstract text...\",\"Conclusion text...\"\n\nnode_id,node_type,name,affiliation\nauthor_john_doe,Author,\"John Doe\",\"University X\"\nauthor_jane_smith,Author,\"Jane Smith\",\"Institute Y\"\n</code></pre></p> <p>edges.csv: <pre><code>source_id,target_id,edge_type\nresearch_1,author_john_doe,AUTHORED_BY\nresearch_1,author_jane_smith,AUTHORED_BY\n</code></pre></p>"},{"location":"usage/examples/url-input/#json-export","title":"JSON Export","text":"<pre><code>{\n  \"nodes\": [\n    {\n      \"id\": \"research_1\",\n      \"type\": \"Research\",\n      \"properties\": {\n        \"title\": \"Paper Title\",\n        \"abstract\": \"Abstract text...\",\n        \"conclusion\": \"Conclusion text...\"\n      }\n    },\n    {\n      \"id\": \"author_john_doe\",\n      \"type\": \"Author\",\n      \"properties\": {\n        \"name\": \"John Doe\",\n        \"affiliation\": \"University X\"\n      }\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"research_1\",\n      \"target\": \"author_john_doe\",\n      \"type\": \"AUTHORED_BY\"\n    }\n  ]\n}\n</code></pre>"},{"location":"usage/examples/url-input/#url-processing-features","title":"URL Processing Features","text":""},{"location":"usage/examples/url-input/#automatic-download","title":"Automatic Download","text":"<p>The pipeline automatically: 1. Downloads the PDF from the URL 2. Saves to temporary location 3. Detects content type (PDF) 4. Routes to appropriate processing pipeline 5. Cleans up temporary files</p>"},{"location":"usage/examples/url-input/#content-type-detection","title":"Content Type Detection","text":"<p>Supported URL content types: - PDF documents \u2192 Full document pipeline - Images (PNG, JPG) \u2192 Full document pipeline - Text files \u2192 Text-only pipeline (LLM backend required) - Markdown files \u2192 Text-only pipeline (LLM backend required)</p>"},{"location":"usage/examples/url-input/#configuration-options","title":"Configuration Options","text":"<pre><code>from docling_graph.core.input.handlers import URLInputHandler\n\n# Custom URL handler settings\nhandler = URLInputHandler(\n    timeout=60,      # Download timeout in seconds\n    max_size_mb=100  # Maximum file size in MB\n)\n</code></pre>"},{"location":"usage/examples/url-input/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/url-input/#issue-url-download-timeout","title":"Issue: URL Download Timeout","text":"<p>Error: <pre><code>ValidationError: URL download timeout after 30 seconds\n</code></pre></p> <p>Solution: <pre><code># Increase timeout for large files\nfrom docling_graph.core.input.handlers import URLInputHandler\n\nhandler = URLInputHandler(timeout=120)  # 2 minutes\n</code></pre></p>"},{"location":"usage/examples/url-input/#issue-file-too-large","title":"Issue: File Too Large","text":"<p>Error: <pre><code>ValidationError: File size (150MB) exceeds maximum size (100MB)\n</code></pre></p> <p>Solution: <pre><code># Increase size limit or download manually\nhandler = URLInputHandler(max_size_mb=200)\n\n# Or download manually first\nimport requests\nresponse = requests.get(url)\nwith open(\"document.pdf\", \"wb\") as f:\n    f.write(response.content)\n\n# Then process local file\nconfig = PipelineConfig(source=\"document.pdf\", ...)\n</code></pre></p>"},{"location":"usage/examples/url-input/#issue-unsupported-url-scheme","title":"Issue: Unsupported URL Scheme","text":"<p>Error: <pre><code>ValidationError: URL must use http or https scheme\n</code></pre></p> <p>Solution: <pre><code># Only HTTP/HTTPS URLs are supported\n# For FTP or other protocols, download manually first\nwget ftp://example.com/file.pdf\nuv run docling-graph convert file.pdf --template \"...\"\n</code></pre></p>"},{"location":"usage/examples/url-input/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/url-input/#1-use-https-when-available","title":"1. Use HTTPS When Available","text":"<pre><code># \u2705 Good - Secure connection\nsource = \"https://arxiv.org/pdf/2207.02720\"\n\n# \u26a0\ufe0f Avoid - Insecure connection\nsource = \"http://example.com/document.pdf\"\n</code></pre>"},{"location":"usage/examples/url-input/#2-handle-network-errors","title":"2. Handle Network Errors","text":"<pre><code>from docling_graph.exceptions import ValidationError\n\ntry:\n    config.run()\nexcept ValidationError as e:\n    if \"timeout\" in str(e).lower():\n        print(\"Network timeout - retrying with longer timeout\")\n        # Retry logic\n    elif \"failed to download\" in str(e).lower():\n        print(\"Download failed - check URL and network connection\")\n</code></pre>"},{"location":"usage/examples/url-input/#3-verify-url-before-processing","title":"3. Verify URL Before Processing","text":"<pre><code>import requests\n\ndef verify_url(url: str) -&gt; bool:\n    \"\"\"Verify URL is accessible before processing.\"\"\"\n    try:\n        response = requests.head(url, timeout=10)\n        return response.status_code == 200\n    except:\n        return False\n\nif verify_url(url):\n    config = PipelineConfig(source=url, ...)\n    config.run()\nelse:\n    print(f\"URL not accessible: {url}\")\n</code></pre>"},{"location":"usage/examples/url-input/#4-cache-downloaded-files","title":"4. Cache Downloaded Files","text":"<pre><code>from pathlib import Path\nimport hashlib\n\ndef get_cache_path(url: str) -&gt; Path:\n    \"\"\"Generate cache path for URL.\"\"\"\n    url_hash = hashlib.md5(url.encode()).hexdigest()\n    return Path(f\"cache/{url_hash}.pdf\")\n\ncache_path = get_cache_path(url)\nif cache_path.exists():\n    # Use cached file\n    config = PipelineConfig(source=str(cache_path), ...)\nelse:\n    # Download from URL\n    config = PipelineConfig(source=url, ...)\n</code></pre>"},{"location":"usage/examples/url-input/#next-steps","title":"Next Steps","text":"<ul> <li>Markdown Input \u2192 - Process markdown documents</li> <li>DoclingDocument Input \u2192 - Use pre-processed documents</li> <li>Input Formats Guide - Complete input format reference</li> </ul>"}]}