{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Docling Graph Documentation","text":""},{"location":"#what-is-docling-graph","title":"What is Docling Graph?","text":"<p>Docling-Graph turns documents into validated Pydantic objects, then builds a directed knowledge graph with explicit semantic relationships.</p> <p>This transformation enables high-precision use cases in chemistry, finance, and legal domains, where AI must capture exact entity connections (compounds and reactions, instruments and dependencies, properties and measurements) rather than rely on approximate text embeddings.</p> <p>This toolkit supports two extraction paths: local VLM extraction via Docling, and LLM-based extraction using either local runtimes (vLLM, Ollama, LM Studio) or API providers (Mistral, OpenAI, Gemini, IBM WatsonX), all orchestrated through a flexible, config-driven pipeline.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\u270d\ud83c\udffb Multi-Format Input: Ingest PDFs, images, URLs, raw text, Markdown and more.</li> <li>\ud83e\udde0 Flexible Extraction: VLM or LLM-based (vLLM, Ollama, Mistral, Gemini, WatsonX, etc.)</li> <li>\ud83d\udd28 Smart Graphs: Convert Pydantic models to NetworkX graphs with stable node IDs</li> <li>\ud83d\udce6 Multiple Export: CSV (Neo4j-compatible), Cypher scripts, JSON, Markdown</li> <li>\ud83d\udcca Rich Visualizations: Interactive HTML and detailed Markdown reports</li> <li>\u2699\ufe0f Type-Safe Configuration: Pydantic-based validation</li> </ul>"},{"location":"#quick-navigation","title":"Quick Navigation","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li> <p>Installation \u2192</p> <p>Set up your environment with uv package manager</p> </li> <li> <p>Quick Start \u2192</p> <p>Run your first extraction in 5 minutes</p> </li> <li> <p>Architecture \u2192</p> <p>Understand the pipeline stages and components</p> </li> <li> <p>Key Concepts \u2192</p> <p>Learn how documents flow through the system</p> </li> </ul>"},{"location":"#core-documentation","title":"Core Documentation","text":"<ul> <li> <p>Introduction</p> <p>Overview, architecture, and core concepts</p> </li> <li> <p>Fundamentals</p> <p>Installation, schema definition, pipeline configuration, extraction, and more</p> </li> <li> <p>Usage</p> <p>CLI reference, Python API, examples, and advanced topics</p> </li> <li> <p>Reference</p> <p>Detailed API documentation</p> </li> <li> <p>Community</p> <p>Contributing and development guide</p> </li> </ul>"},{"location":"#resources","title":"Resources","text":""},{"location":"#documentation","title":"Documentation","text":"<ul> <li>GitHub Repository - Source code and issues</li> <li>PyPI Package - Install via pip/uv</li> <li>Contributing Guidelines - How to contribute</li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>GitHub Issues - Report bugs and request features</li> <li>GitHub Discussions - Ask questions and share ideas</li> </ul>"},{"location":"#related-projects","title":"Related Projects","text":"<ul> <li>Docling - Document processing engine</li> <li>Pydantic - Data validation library</li> <li>NetworkX - Graph library</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ol> <li>Install Docling Graph \u2192</li> <li>Follow the Quick Start \u2192</li> <li>Create Your First Template \u2192</li> <li>Explore Examples \u2192</li> </ol>"},{"location":"#need-help","title":"Need Help?","text":"<ul> <li>Installation Issues: See Installation Guide</li> <li>Template Questions: See Schema Definition</li> <li>Configuration Help: See Pipeline Configuration</li> <li>Error Messages: See Error Handling</li> </ul>"},{"location":"assets/flowcharts/architecture/","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% Transparent Subgraph Style\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5 5,color:#969696\n\n    %% 2. Define Nodes &amp; Subgraphs\n    A@{ shape: terminal, label: \"Source Input\" }\n    n2@{ shape: terminal, label: \"Config\" }\n    n3@{ shape: terminal, label: \"Pydantic Template\" }\n    n4@{ shape: procs, label: \"Docling Graph Pipeline\" }\n    n35@{ shape: lin-proc, label: \"Input Validator\" }\n\n    %% HANDLERS\n    n37@{ shape: tag-proc, label: \"Image &amp; PDF Handler\" }\n    n39@{ shape: tag-proc, label: \"DoclingDoc Loader\" }\n    n40@{ shape: tag-proc, label: \"MD &amp; Text Handler\" }\n\n    %% Defined first to prioritize placement\n    n6@{ shape: procs, label: \"Docling Pipeline\" }\n    n25@{ shape: lin-proc, label: \"Extract\" } \n    n7@{ shape: lin-proc, label: \"OCR Engine\" }\n    n8@{ shape: lin-proc, label: \"Vision\" }\n\n    n9@{ shape: procs, label: \"Extraction Factory\" }\n    n16@{ shape: terminal, label: \"Prompt\" }\n    n13@{ shape: procs, label: \"Extraction Backend\" }\n    n14@{ shape: lin-proc, label: \"LLM Inference\" }\n    n15@{ shape: lin-proc, label: \"VLM Inference\" }\n    n17@{ shape: terminal, label: \"Extracted Content\" }\n    n10@{ shape: procs, label: \"Consolidation Factory\" }\n    n11@{ shape: lin-proc, label: \"One To One\" }\n    n12@{ shape: lin-proc, label: \"Many To One\" }\n    n18@{ shape: tag-proc, label: \"Smart Template Merger\" }\n    n20@{ shape: terminal, label: \"Populated Pydantic Model(s)\" }\n\n    %% ENTRY POINT\n    n21@{ shape: tag-proc, label: \"Graph Converter\" }\n\n    %% INTERNAL STEPS\n    n21a@{ shape: lin-proc, label: \"Node Generation\" }\n    n21b@{ shape: lin-proc, label: \"Edge Resolution\" }\n    n21c@{ shape: lin-proc, label: \"Integrity Check\" }\n\n    n22@{ shape: terminal, label: \"NetworkX Graph\" }\n    n23@{ shape: tag-proc, label: \"Exporter\" }\n    n29@{ shape: terminal, label: \"CSV\" }\n    n30@{ shape: terminal, label: \"Cypher\" }\n    n31@{ shape: terminal, label: \"JSON\" }\n    n34@{ shape: tag-proc, label: \"Batch Loader\" }\n    n33@{ shape: db, label: \"Knowledge Base\" }\n    n24@{ shape: tag-proc, label: \"Visualizer\" }\n    n28@{ shape: terminal, label: \"Images\" }\n    n27@{ shape: terminal, label: \"HTML\" }\n    n26@{ shape: terminal, label: \"Markdown\" }\n\n    %% 3. Define Connections\n    A &amp; n2 &amp; n3 --&gt; n4\n\n    n4 --&gt; n35\n\n    %% Validator Routing\n    n35 --&gt; n37 &amp; n39 &amp; n40\n\n    %% HANDLER CONNECTIONS\n    n37 --&gt; n6\n    n39 --&gt; n9\n    n40 --&gt; n9\n\n    %% Processing\n    n6 --&gt; n25 &amp; n7 &amp; n8\n    n7 &amp; n8 --&gt; n9\n\n    %% Extraction\n    n9 --&gt; n16\n    n16 --&gt; n13\n    n13 --&gt; n14 &amp; n15\n    n14 &amp; n15 --&gt; n17\n    n17 --&gt; n10\n\n    %% Strategy\n    n10 --&gt; n11 &amp; n12\n    n12 --&gt; n18\n    n11 &amp; n18 &amp; n25 --&gt; n20\n\n    %% Graph (Updated Flow)\n    n20 --&gt; n21\n    n21 --&gt; n21a\n    n21 --&gt; n21b\n    n21 --&gt; n21c\n    n21a --&gt; n22\n    n21b --&gt; n22\n    n21c --&gt; n22\n    n22 --&gt; n23 &amp; n24\n\n    %% Export\n    n23 --&gt; n29 &amp; n30 &amp; n31 &amp; n33\n    n29 &amp; n30 &amp; n31 --&gt; n34\n    n34 --&gt; n33\n\n    %% Visuals\n    n24 --&gt; n28 &amp; n27 &amp; n26\n\n    %% 4. Apply Classes\n    class A,n3 input\n    class n2,n16 config\n    class n4,n6,n9,n10 data\n    class n35,n7,n8,n25,n13,n14,n15,n11,n12,n33 process\n    class n21a,n21b,n21c process\n    class n37,n39,n40,n18,n21,n23,n34,n24 operator\n    class n17,n20,n22,n29,n30,n31,n28,n27,n26 output\n    class S1,S2,S3,S4,S5 subgraph_style</code></pre>"},{"location":"assets/flowcharts/chunk_batcher/","title":"Chunk batcher","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"10 Chunks\" }\n\n    B@{ shape: procs, label: \"Greedy Packing\" }\n    C@{ shape: doc, label: \"5 Candidate Batches\" }\n\n    D@{ shape: lin-proc, label: \"Merge Undersized\" }\n    E@{ shape: doc, label: \"3 Final Batches\" }\n\n    F@{ shape: tag-proc, label: \"3 API Calls\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,D process\n    class C,E data\n    class F output</code></pre>"},{"location":"assets/flowcharts/config_flow/","title":"Config flow","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% Subgraph Styling (Transparent with dashed border for visibility)\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5,color:#969696\n\n    %% 2. Define Nodes &amp; Subgraphs\n    A@{ shape: procs, label: \"PipelineConfig\" }\n\n    subgraph Backends [\"Backend Configuration\"]\n        B@{ shape: lin-proc, label: \"Backend Selection\" }\n        F@{ shape: tag-proc, label: \"LLM Backend\" }\n        G@{ shape: tag-proc, label: \"VLM Backend\" }\n    end\n\n    subgraph Models [\"Inference Settings\"]\n        C@{ shape: lin-proc, label: \"Model Selection\" }\n        H@{ shape: tag-proc, label: \"Local Inference\" }\n        I@{ shape: tag-proc, label: \"Remote Inference\" }\n    end\n\n    subgraph Strategy [\"Processing Mode\"]\n        D@{ shape: lin-proc, label: \"Processing Mode\" }\n        J@{ shape: tag-proc, label: \"One-to-One\" }\n        K@{ shape: tag-proc, label: \"Many-to-One\" }\n    end\n\n    subgraph Exports [\"Output Settings\"]\n        E@{ shape: lin-proc, label: \"Export Settings\" }\n        L@{ shape: tag-proc, label: \"CSV Export\" }\n        M@{ shape: tag-proc, label: \"Cypher Export\" }\n    end\n\n    %% 3. Define Connections\n    A --&gt; B &amp; C &amp; D &amp; E\n\n    B --&gt; F &amp; G\n    C --&gt; H &amp; I\n    D --&gt; J &amp; K\n    E --&gt; L &amp; M\n\n    %% 4. Apply Classes\n    class A config\n    class B,C,D,E process\n    class F,G,H,I,J,K operator\n    class L,M output\n    class Backends,Models,Strategy,Exports subgraph_style</code></pre>"},{"location":"assets/flowcharts/conversion_process/","title":"Conversion process","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Pydantic Models\" }\n\n    B@{ shape: lin-proc, label: \"Pre-register Models\" }\n    C@{ shape: procs, label: \"Create Nodes\" }\n    D@{ shape: procs, label: \"Create Edges\" }\n\n    E@{ shape: tag-proc, label: \"Auto Cleanup\" }\n    F@{ shape: tag-proc, label: \"Validate Graph\" }\n    G@{ shape: tag-proc, label: \"Calculate Stats\" }\n\n    H@{ shape: doc, label: \"NetworkX Graph\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n    F --&gt; G\n    G --&gt; H\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D process\n    class E,F,G operator\n    class H output</code></pre>"},{"location":"assets/flowcharts/delta_extraction/","title":"Delta extraction","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5 5,color:#969696\n\n    %% 2. Define Nodes\n    n1@{ shape: terminal, label: \"Source Chunks\" }\n    n2@{ shape: terminal, label: \"Delta Template Config\" }\n\n    n3@{ shape: procs, label: \"Batch Planning\" }\n    n3a@{ shape: lin-proc, label: \"Greedy Token Packing\" }\n\n    n4@{ shape: tag-proc, label: \"Per-batch LLM\" }\n    n5@{ shape: db, label: \"Raw DeltaGraph\" }\n\n    n6@{ shape: lin-proc, label: \"IR Normalization\" }\n    n7@{ shape: procs, label: \"Graph Merge &amp; Deduplication\" }\n\n    n8@{ shape: tag-proc, label: \"Resolvers (Optional)\" }\n    n9@{ shape: tag-proc, label: \"Identity Filter (Optional)\" }\n\n    n10@{ shape: procs, label: \"Projection\" }\n    n11@{ shape: lin-proc, label: \"Quality Gate Check\" }\n\n    n12@{ shape: tag-proc, label: \"Direct Extraction Fallback\" }\n    n13@{ shape: terminal, label: \"Final Result\" }\n\n    %% 3. Define Connections\n    n1 &amp; n2 --&gt; n3\n    n3 --&gt; n3a\n    n3a --&gt; n4\n    n4 --&gt; n5\n    n5 --&gt; n6\n    n6 --&gt; n7\n\n    %% Sequence of Logic\n    n7 --&gt; n8\n    n8 --&gt; n9\n    n9 --&gt; n10\n    n10 --&gt; n11\n\n    %% Branching Logic\n    n11 -- \"Pass\" --&gt; n13\n    n11 -- \"Fail\" --&gt; n12\n    n12 --&gt; n13\n\n    %% 4. Apply Classes\n    class n1 input\n    class n2 config\n    class n5 data\n    class n3,n7,n10,n11 process\n    class n3a,n6 process\n    class n4,n8,n9,n12 operator\n    class n13 output</code></pre>"},{"location":"assets/flowcharts/doc_chunker/","title":"Doc chunker","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Full Document\" }\n\n    B@{ shape: procs, label: \"Docling&lt;br/&gt;Segmentation\" }\n    C@{ shape: lin-proc, label: \"Semantic&lt;br/&gt;Boundaries\" }\n    D@{ shape: tag-proc, label: \"Token-Aware&lt;br/&gt;Splitting\" }\n\n    E(\"Chunks with&lt;br/&gt;Context\")\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B,C process\n    class D operator\n    class E output</code></pre>"},{"location":"assets/flowcharts/exporters/","title":"Exporters","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5,color:#969696\n\n    %% 2. Define Nodes &amp; Subgraphs\n    A@{ shape: terminal, label: \"NetworkX Graph\" }\n\n    subgraph subGraph0[\"Export Modules\"]\n        B@{ shape: tag-proc, label: \"CSV Exporter\" }\n        C@{ shape: tag-proc, label: \"Cypher Exporter\" }\n        D@{ shape: tag-proc, label: \"JSON Exporter\" }\n        E@{ shape: tag-proc, label: \"Docling Exporter\" }\n    end\n\n    %% Output Files\n    F@{ shape: doc, label: \"nodes.csv\" }\n    n1@{ shape: doc, label: \"edges.csv\" }\n    G@{ shape: doc, label: \"graph.cypher\" }\n    H@{ shape: doc, label: \"graph.json\" }\n    I@{ shape: doc, label: \"docling.json\" }\n    n2@{ shape: doc, label: \"document.md\" }\n\n    %% 3. Define Connections\n    A --&gt; B &amp; C &amp; D &amp; E\n\n    B --&gt; F &amp; n1\n    C --&gt; G\n    D --&gt; H\n    E --&gt; I &amp; n2\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D,E operator\n    class F,n1,G,H,I,n2 output\n    class subGraph0 subgraph_style</code></pre>"},{"location":"assets/flowcharts/extension_points/","title":"Extension points","text":"<p>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%% flowchart TB     %% 1. Define Classes     classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1     classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037     classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20     classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100     classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0     classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A     classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238</p> <pre><code>%% 2. Define Nodes\nA@{ shape: terminal, label: \"Input Source\" }\n\nB@{ shape: lin-proc, label: \"Custom Stage 1\" }\nC@{ shape: procs, label: \"Docling Conversion\" }\nD@{ shape: tag-proc, label: \"Custom Backend\" }\nE@{ shape: procs, label: \"Extraction\" }\nF@{ shape: lin-proc, label: \"Custom Stage 2\" }\nG@{ shape: procs, label: \"Graph Conversion\" }\nH@{ shape: tag-proc, label: \"Custom Exporter\" }\n\nI@{ shape: doc, label: \"Output\" }\n\n%% 3. Define Connections\nA --&gt; B\nB --&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; F\nF --&gt; G\nG --&gt; H\nH --&gt; I\n\n%% 4. Apply Classes\nclass A input\nclass B,F config\nclass C,E,G process\nclass D,H operator\nclass I output\n</code></pre> <p>```</p>"},{"location":"assets/flowcharts/extraction_flow/","title":"Extraction flow","text":"<p>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%% flowchart TD     %% 1. Define Classes     classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1     classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037     classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20     classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100     classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0     classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A     classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238</p> <pre><code>%% 2. Define Nodes\nStart@{ shape: terminal, label: \"Input Source\" }\n\nNormalize@{ shape: procs, label: \"Input Normalization\" }\nCheckInput{\"Input Type\"}\n\nConvert@{ shape: procs, label: \"Document Conversion&lt;br/&gt;PDF/Image\" }\nTextProc@{ shape: lin-proc, label: \"Text Processing&lt;br/&gt;Text/Markdown\" }\nLoadDoc@{ shape: lin-proc, label: \"Load DoclingDocument&lt;br/&gt;Skip to Graph\" }\n\nCheckMode{\"Process. Mode\"}\nCheckChunk{\"Chunking?\"}\n\nPageExtract@{ shape: lin-proc, label: \"Page-by-Page Extraction\" }\nFullDoc@{ shape: lin-proc, label: \"Full Document Extraction\" }\n\nChunk@{ shape: tag-proc, label: \"Structure-Aware Chunking\" }\nBatch@{ shape: tag-proc, label: \"Batch Chunks\" }\n\nExtract@{ shape: procs, label: \"Extract from Batches\" }\n\nCheckMerge{\"Multiple Models?\"}\n\nMerge@{ shape: lin-proc, label: \"Programmatic Merge\" }\nSingle@{ shape: doc, label: \"Single Model\" }\n\nCheckConsol{\"Consolidation?\"}\nConsol@{ shape: procs, label: \"LLM Consolidation\" }\n\nFinal@{ shape: doc, label: \"Final Model\" }\nGraph@{ shape: db, label: \"Knowledge Graph\" }\n\n%% 3. Define Connections\nStart --&gt; Normalize\nNormalize --&gt; CheckInput\n\nCheckInput -- \"PDF/Image\" --&gt; Convert\nCheckInput -- \"Text/Markdown\" --&gt; TextProc\nCheckInput -- \"DoclingDocument\" --&gt; LoadDoc\n\nConvert --&gt; CheckMode\nTextProc --&gt; CheckMode\n\nLoadDoc --&gt; Graph\n\nCheckMode -- Many-to-One --&gt; CheckChunk\nCheckMode -- One-to-One --&gt; PageExtract\n\nCheckChunk -- Yes --&gt; Chunk\nCheckChunk -- No --&gt; FullDoc\n\nChunk --&gt; Batch\nBatch --&gt; Extract\n\nFullDoc --&gt; Extract\nPageExtract --&gt; Extract\n\nExtract --&gt; CheckMerge\nCheckMerge -- Yes --&gt; Merge\nCheckMerge -- No --&gt; Single\n\nMerge --&gt; CheckConsol\nCheckConsol -- Yes --&gt; Consol\nCheckConsol -- No --&gt; Final\n\nConsol --&gt; Final\nSingle --&gt; Final\nFinal --&gt; Graph\n\n%% 4. Apply Classes\nclass Start input\nclass Normalize,Convert,Extract,Consol process\nclass TextProc,LoadDoc,PageExtract,FullDoc,Merge process\nclass Chunk,Batch operator\nclass CheckInput,CheckMode,CheckChunk,CheckMerge,CheckConsol decision\nclass Single data\nclass Final,Graph output\n</code></pre> <p>```</p>"},{"location":"assets/flowcharts/four_stage_pipeline/","title":"Four stage pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Input Source\" }\n\n    A1@{ shape: tag-proc, label: \"Input Normalization\" }\n    B@{ shape: procs, label: \"Conversion\" }\n    C@{ shape: tag-proc, label: \"Chunking\" }\n    D@{ shape: procs, label: \"Extraction\" }\n    E@{ shape: lin-proc, label: \"Merging\" }\n\n    F@{ shape: db, label: \"Knowledge Graph\" }\n\n    %% 3. Define Connections\n    A --&gt; A1\n    A1 --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class A1,C operator\n    class B,D,E process\n    class F output</code></pre>"},{"location":"assets/flowcharts/graph_converter/","title":"Graph converter","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Pydantic Models\" }\n\n    B@{ shape: lin-proc, label: \"Node ID&lt;br/&gt;Generation\" }\n    C@{ shape: lin-proc, label: \"Node&lt;br/&gt;Creation\" }\n    D@{ shape: lin-proc, label: \"Edge&lt;br/&gt;Creation\" }\n    E@{ shape: tag-proc, label: \"Graph&lt;br/&gt;Validation\" }\n\n    F(\"NetworkX&lt;br/&gt;DiGraph\")\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D process\n    class E operator\n    class F output</code></pre>"},{"location":"assets/flowcharts/graph_pipeline/","title":"Graph pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Pydantic Models\" }\n\n    B@{ shape: procs, label: \"Graph Conversion\" }\n    C@{ shape: doc, label: \"NetworkX Graph\" }\n\n    D@{ shape: tag-proc, label: \"Export\" }\n    F@{ shape: tag-proc, label: \"Visualization\" }\n\n    E1@{ shape: doc, label: \"CSV Files\" }\n    E2@{ shape: doc, label: \"Cypher Script\" }\n    E3@{ shape: doc, label: \"JSON\" }\n\n    G@{ shape: doc, label: \"Interactive HTML\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n\n    C --&gt; D\n    C --&gt; F\n\n    D --&gt; E1\n    D --&gt; E2\n    D --&gt; E3\n\n    F --&gt; G\n\n    %% 4. Apply Classes\n    class A input\n    class B process\n    class C data\n    class D,F operator\n    class E1,E2,E3,G output</code></pre>"},{"location":"assets/flowcharts/input_normalization/","title":"Input normalization","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    Start@{ shape: terminal, label: \"Input Source\" }\n    Detect@{ shape: procs, label: \"Input Type Detection\" }\n\n    %% Validators\n    ValPDF@{ shape: lin-proc, label: \"Validate PDF\" }\n    ValImg@{ shape: lin-proc, label: \"Validate Image\" }\n    ValText@{ shape: lin-proc, label: \"Validate Text\" }\n    ValMD@{ shape: lin-proc, label: \"Validate MD\" }\n    ValDoc@{ shape: lin-proc, label: \"Validate Docling\" }\n\n    %% URL Specifics\n    ValURL@{ shape: lin-proc, label: \"Validate &amp; Download URL\" }\n    CheckDL{\"Type?\"}\n\n    %% Handlers\n    HandVisual@{ shape: tag-proc, label: \"Visual Handler\" }\n    HandText@{ shape: tag-proc, label: \"Text Handler\" }\n    HandDoc@{ shape: tag-proc, label: \"Object Handler\" }\n\n    %% Outcomes\n    SetFlags@{ shape: procs, label: \"Set Processing Flags\" }\n    Output@{ shape: doc, label: \"Normalized Context\" }\n\n    %% 3. Define Connections\n    Start --&gt; Detect\n\n    %% Input Detection Routing\n    Detect -- PDF --&gt; ValPDF\n    Detect -- Image --&gt; ValImg\n    Detect -- Text --&gt; ValText\n    Detect -- MD --&gt; ValMD\n    Detect -- Docling --&gt; ValDoc\n    Detect -- URL --&gt; ValURL\n\n    %% URL Routing (Feeds back into validators)\n    ValURL --&gt; CheckDL\n    CheckDL -- PDF --&gt; ValPDF\n    CheckDL -- Image --&gt; ValImg\n    CheckDL -- Text --&gt; ValText\n    CheckDL -- MD --&gt; ValMD\n\n    %% Validation to Handlers (The \"Happy Path\")\n    ValPDF &amp; ValImg --&gt; HandVisual\n    ValText &amp; ValMD --&gt; HandText\n    ValDoc --&gt; HandDoc\n\n    %% Converge Handlers to Output\n    HandVisual &amp; HandText &amp; HandDoc --&gt; SetFlags --&gt; Output\n\n    %% 4. Apply Classes\n    class Start input\n    class Detect,SetFlags process\n    class ValPDF,ValImg,ValText,ValMD,ValURL,ValDoc process\n    class HandVisual,HandText,HandDoc operator\n    class CheckDL decision\n    class Output output</code></pre>"},{"location":"assets/flowcharts/llm_backend/","title":"Llm backend","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: procs, label: \"Docling Conversion\" }\n    C@{ shape: doc, label: \"Markdown Text\" }\n    D@{ shape: tag-proc, label: \"Chunking Optional\" }\n    E@{ shape: procs, label: \"LLM Extraction\" }\n\n    F@{ shape: doc, label: \"Structured Data\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,E process\n    class C data\n    class D operator\n    class F output</code></pre>"},{"location":"assets/flowcharts/llm_clients/","title":"Llm clients","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% Custom Subgraph Style (Transparent with dashed border)\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5,color:#969696\n\n    %% 2. Define Nodes\n    A@{ shape: procs, label: \"LLMClientProtocol\" }\n    B@{ shape: lin-proc, label: \"LiteLLMClient\" }\n\n    H@{ shape: tag-proc, label: \"ResponseHandler JSON Parsing\" }\n    I(\"ProviderConfig (tokenizer, merge_threshold)\")\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; H\n    B --&gt; I\n\n    %% 4. Apply Classes\n    class A,B process\n    class H operator\n    class I config</code></pre>"},{"location":"assets/flowcharts/llm_consolidation/","title":"Llm consolidation","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Raw Models\" }\n\n    B@{ shape: lin-proc, label: \"Programmatic Merge\" }\n    C@{ shape: doc, label: \"Draft Model\" }\n\n    D@{ shape: procs, label: \"LLM Consolidation\" }\n    E@{ shape: doc, label: \"Final Model\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n\n    A --&gt; D\n    C --&gt; D\n\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A,C data\n    class B,D process\n    class E output</code></pre>"},{"location":"assets/flowcharts/many_to_one_mode/","title":"Many to one mode","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: doc, label: \"All Pages\" }\n    C@{ shape: tag-proc, label: \"Chunking\" }\n    D@{ shape: procs, label: \"Extract Chunks\" }\n    E@{ shape: lin-proc, label: \"Merge Results\" }\n\n    F@{ shape: procs, label: \"Single Model\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B data\n    class C operator\n    class D,E process\n    class F output</code></pre>"},{"location":"assets/flowcharts/model_decision_tree/","title":"Model decision tree","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"New Model\" }\n\n    B{\"Should this be&lt;br/&gt;tracked individually?\"}\n    C{\"Does it have a&lt;br/&gt;natural unique ID?\"}\n    F{\"Can you create&lt;br/&gt;a composite ID?\"}\n    G{\"Is it a value&lt;br/&gt;that's shared?\"}\n\n    %% Outcomes\n    D@{ shape: tag-proc, label: \"Component&lt;br/&gt;is_entity=False\" }\n    E@{ shape: procs, label: \"Entity&lt;br/&gt;graph_id_fields\" }\n    H@{ shape: lin-proc, label: \"Consider redesigning&lt;br/&gt;or use content-based ID\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B -- Yes --&gt; C\n    B -- No --&gt; D\n\n    C -- Yes --&gt; E\n    C -- No --&gt; F\n\n    F -- Yes --&gt; E\n    F -- No --&gt; G\n\n    G -- Yes --&gt; D\n    G -- No --&gt; H\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,F,G decision\n    class E output\n    class D data\n    class H config</code></pre>"},{"location":"assets/flowcharts/ocr_pipeline/","title":"Ocr pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Image / PDF Document\" }\n\n    B@{ shape: procs, label: \"OCR Engine\" }\n    C@{ shape: lin-proc, label: \"Text Extraction\" }\n    D@{ shape: lin-proc, label: \"Layout Analysis\" }\n\n    E@{ shape: doc, label: \"Markdown\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D process\n    class E output</code></pre>"},{"location":"assets/flowcharts/one_to_one_mode/","title":"One to one mode","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: doc, label: \"Page 1\" }\n    C@{ shape: doc, label: \"Page 2\" }\n    D@{ shape: doc, label: \"Page 3\" }\n\n    E@{ shape: tag-proc, label: \"Extract 1\" }\n    F@{ shape: tag-proc, label: \"Extract 2\" }\n    G@{ shape: tag-proc, label: \"Extract 3\" }\n\n    H@{ shape: procs, label: \"Model 1\" }\n    I@{ shape: procs, label: \"Model 2\" }\n    J@{ shape: procs, label: \"Model 3\" }\n\n    %% 3. Define Connections\n    A --&gt; B &amp; C &amp; D\n\n    B --&gt; E\n    C --&gt; F\n    D --&gt; G\n\n    E --&gt; H\n    F --&gt; I\n    G --&gt; J\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D data\n    class E,F,G operator\n    class H,I,J output</code></pre>"},{"location":"assets/flowcharts/pipeline_flow/","title":"Pipeline flow","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Input Source\" }\n    A1@{ shape: procs, label: \"1. Input Normalization&lt;br/&gt;Type Detection &amp; Validation\" }\n\n    A2{\"Input Type\"}\n\n    %% Ingestion Paths\n    B@{ shape: procs, label: \"2a. Docling Conversion&lt;br/&gt;Generates Images &amp; Markdown\" }\n    B2@{ shape: lin-proc, label: \"2b. Text Processing&lt;br/&gt;Direct to Markdown\" }\n    B3@{ shape: lin-proc, label: \"2c. Load DoclingDocument&lt;br/&gt;Pre-parsed Content\" }\n\n    %% Strategy Decision\n    C{\"3. Backend\"}\n\n    %% Extraction Paths\n    D@{ shape: lin-proc, label: \"4a. VLM Extraction&lt;br/&gt;Page-by-Page (Images)\" }\n    E@{ shape: lin-proc, label: \"4b. Markdown Prep&lt;br/&gt;Merge Text Content\" }\n\n    %% Chunking Logic (LLM Path)\n    F{\"5. Chunking\"}\n    G@{ shape: tag-proc, label: \"6a. Hybrid Chunking&lt;br/&gt;Semantic + Token-Aware\" }\n    H@{ shape: tag-proc, label: \"6b. Full Document&lt;br/&gt;Context Window Permitting\" }\n\n    I@{ shape: procs, label: \"7. Batch Extraction&lt;br/&gt;LLM Inference\" }\n\n    %% Convergence &amp; Validation\n    J@{ shape: tag-proc, label: \"8. Pydantic Validation&lt;br/&gt;Per-Chunk/Page Check\" }\n\n    K{\"9. Consolidation\"}\n\n    L@{ shape: lin-proc, label: \"10a. Smart Merge&lt;br/&gt;Programmatic/Reduce\" }\n    M@{ shape: lin-proc, label: \"10b. LLM Consolidation&lt;br/&gt;Refinement Loop\" }\n\n    %% Graph &amp; Export\n    N@{ shape: procs, label: \"11. Graph Conversion&lt;br/&gt;Pydantic \u2192 NetworkX\" }\n    O@{ shape: tag-proc, label: \"12. Node ID Generation&lt;br/&gt;Stable Hashing\" }\n\n    P@{ shape: tag-proc, label: \"13. Export&lt;br/&gt;CSV/Cypher/JSON\" }\n    Q@{ shape: tag-proc, label: \"14. Visualization&lt;br/&gt;HTML + Reports\" }\n\n    %% 3. Define Connections\n    A --&gt; A1\n    A1 --&gt; A2\n\n    %% Routing Inputs\n    A2 -- \"PDF/Image\" --&gt; B\n    A2 -- \"Text/MD\" --&gt; B2\n    A2 -- \"DoclingDoc\" --&gt; B3\n\n    %% Routing to Backend Strategy\n    B --&gt; C\n    B2 &amp; B3 --&gt; E\n\n    %% Backend Decisions\n    C -- VLM --&gt; D\n    C -- LLM --&gt; E\n\n    %% LLM Path: Markdown -&gt; Chunking -&gt; Extraction\n    E --&gt; F\n    F -- Yes --&gt; G\n    F -- No --&gt; H\n\n    G --&gt; I\n    H --&gt; I\n\n    %% VLM Path: Direct to Validation (Skips Chunking)\n    D --&gt; J\n\n    %% LLM Path: Join Validation\n    I --&gt; J\n\n    %% Consolidation\n    J --&gt; K\n    K -- \"Rule-Based\" --&gt; L\n    K -- \"AI-Based\" --&gt; M\n\n    %% Final Stages\n    L --&gt; N\n    M --&gt; N\n\n    N --&gt; O\n    O --&gt; P\n    P --&gt; Q\n\n    %% 4. Apply Classes\n    class A input\n    class A1,B,I,N process\n    class B2,B3,D,E,L,M process\n    class A2,C,F,K decision\n    class G,H,J,O operator\n    class P,Q output</code></pre>"},{"location":"assets/flowcharts/pipeline_stages/","title":"Pipeline stages","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A(\"1. Install\")\n\n    B@{ shape: lin-proc, label: \"2. Define Schema\" }\n    C@{ shape: lin-proc, label: \"3. Configure Pipeline\" }\n\n    D@{ shape: procs, label: \"4. Extract Data\" }\n    E@{ shape: procs, label: \"5. Build Graph\" }\n\n    F@{ shape: tag-proc, label: \"6. Export &amp; Visualize\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,C config\n    class D,E process\n    class F output</code></pre>"},{"location":"assets/flowcharts/processing_mode_tree/","title":"Processing mode tree","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A(\"Start\")\n\n    B{\"Are pages&lt;br/&gt;independent?\"}\n    D{\"Single entity&lt;br/&gt;across pages?\"}\n    F{\"Need page-level&lt;br/&gt;tracking?\"}\n\n    C@{ shape: tag-proc, label: \"One-to-One\" }\n    E@{ shape: tag-proc, label: \"Many-to-One\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n\n    B -- Yes --&gt; C\n    B -- No --&gt; D\n\n    D -- Yes --&gt; E\n    D -- No --&gt; F\n\n    F -- Yes --&gt; C\n    F -- No --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B,D,F decision\n    class C,E output</code></pre>"},{"location":"assets/flowcharts/programmatic_merge/","title":"Programmatic merge","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Model 1\" }\n    B@{ shape: terminal, label: \"Model 2\" }\n    C@{ shape: terminal, label: \"Model 3\" }\n\n    D@{ shape: lin-proc, label: \"Deep Merge\" }\n    E@{ shape: tag-proc, label: \"Deduplicate\" }\n    F@{ shape: tag-proc, label: \"Validate\" }\n\n    G@{ shape: doc, label: \"Final Model\" }\n\n    %% 3. Define Connections\n    A &amp; B &amp; C --&gt; D\n\n    D --&gt; E\n    E --&gt; F\n    F --&gt; G\n\n    %% 4. Apply Classes\n    class A,B,C data\n    class D process\n    class E,F operator\n    class G output</code></pre>"},{"location":"assets/flowcharts/staged_extraction/","title":"Staged extraction","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk',\n  'themeVariables': {'loopTextColor': '#ADADAD', 'signalColor': '#ADADAD', 'signalTextColor': '#ADADAD', 'actorBkg': '#CCCCCC', 'actorBorder': '#ADADAD'}\n}}%%\nsequenceDiagram\n  participant Doc as Document\n  participant Catalog as Catalog\n  participant LLM as LLM\n  participant Orch as Orchestrator\n  participant Fill as Fill_Pass\n  participant Merge as Merge\n\n  Doc-&gt;&gt;Catalog: Template\n  Catalog-&gt;&gt;Orch: Node specs (path, id_fields, parent rules)\n  loop Sequential ID shards\n    Orch-&gt;&gt;LLM: ID pass shard (paths + doc)\n    LLM-&gt;&gt;Orch: nodes(path, ids, parent)\n  end\n  Orch-&gt;&gt;Orch: Validate and dedupe skeleton\n  Orch-&gt;&gt;Fill: Build per-path batches (bottom-up)\n  loop Fill calls (parallel with parallel_workers)\n    Fill-&gt;&gt;LLM: Fill(path, descriptors, schema, doc)\n    LLM-&gt;&gt;Fill: Filled objects\n  end\n  Fill-&gt;&gt;Merge: path_filled + descriptors\n  Merge-&gt;&gt;Merge: Attach by path+ids and parent path+ids</code></pre>"},{"location":"assets/flowcharts/vision_pipeline/","title":"Vision pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Images / PDF Document\" }\n\n    B@{ shape: doc, label: \"Page Images\" }\n    C@{ shape: procs, label: \"VLM Processing\" }\n    D@{ shape: lin-proc, label: \"Visual Understanding\" }\n\n    E@{ shape: doc, label: \"Structured Output\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B data\n    class C,D process\n    class E output</code></pre>"},{"location":"assets/flowcharts/vlm_backend/","title":"Vlm backend","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    InputPDF@{ shape: terminal, label: \"PDF Document\" }\n    InputImg@{ shape: terminal, label: \"Images\" }\n\n    Convert@{ shape: procs, label: \"PDF to Image&lt;br&gt;Conversion\" }\n    PageImgs@{ shape: doc, label: \"Page Images\" }\n\n    VLM@{ shape: procs, label: \"VLM Processing\" }\n    Understand@{ shape: lin-proc, label: \"Visual Understanding\" }\n    Extract@{ shape: tag-proc, label: \"Direct Extraction\" }\n\n    Output@{ shape: doc, label: \"Pydantic Models\" }\n\n    %% 3. Define Connections\n    %% Path A: PDF requires conversion\n    InputPDF --&gt; Convert\n    Convert --&gt; PageImgs\n    PageImgs --&gt; VLM\n\n    %% Path B: Direct Image Input (Merges here)\n    InputImg --&gt; VLM\n\n    %% Shared Processing Chain\n    VLM --&gt; Understand\n    Understand --&gt; Extract\n    Extract --&gt; Output\n\n    %% 4. Apply Classes\n    class InputPDF,InputImg input\n    class Convert,VLM,Understand process\n    class PageImgs data\n    class Extract operator\n    class Output output</code></pre>"},{"location":"community/","title":"Development Guide","text":""},{"location":"community/#overview","title":"Overview","text":"<p>Guide for contributing to docling-graph development.</p> <p>What's Included: - Contributing guidelines - Development setup - Code standards - Testing requirements - GitHub workflow - Release process</p>"},{"location":"community/#quick-start","title":"Quick Start","text":""},{"location":"community/#1-fork-and-clone","title":"1. Fork and Clone","text":"<pre><code># Fork on GitHub, then clone\ngit clone https://github.com/YOUR_USERNAME/docling-graph.git\ncd docling-graph\n</code></pre>"},{"location":"community/#2-setup-development-environment","title":"2. Setup Development Environment","text":"<pre><code># Install with all dependencies\nuv sync --extra dev\n\n# Verify installation\nuv run python -c \"import docling_graph; print(docling_graph.__version__)\"\n</code></pre>"},{"location":"community/#3-create-branch","title":"3. Create Branch","text":"<pre><code># Create feature branch\ngit checkout -b feature/my-feature\n\n# Or bug fix branch\ngit checkout -b fix/issue-123\n</code></pre>"},{"location":"community/#4-make-changes","title":"4. Make Changes","text":"<pre><code># Edit code\n# Add tests\n# Update documentation\n</code></pre>"},{"location":"community/#5-run-tests","title":"5. Run Tests","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run with coverage\nuv run pytest --cov=docling_graph --cov-report=html\n</code></pre>"},{"location":"community/#6-submit-pull-request","title":"6. Submit Pull Request","text":"<pre><code># Commit changes\ngit add .\ngit commit -s -m \"feat: add new feature\"\n\n# Push to your fork\ngit push origin feature/my-feature\n\n# Create PR on GitHub\n</code></pre>"},{"location":"community/#development-topics","title":"Development Topics","text":""},{"location":"community/#contributing","title":"\ud83d\udcdd Contributing","text":"<p>Contributing Guidelines Official contribution guidelines for the project.</p> <ul> <li>Code of conduct</li> <li>Contribution workflow</li> <li>Issue reporting</li> <li>Pull request process</li> <li>Legal requirements (DCO)</li> </ul>"},{"location":"community/#github-workflow","title":"\ud83d\udd27 GitHub Workflow","text":"<p>GitHub Workflow Working with GitHub and CI/CD.</p> <ul> <li>Branch strategy</li> <li>Commit conventions</li> <li>CI/CD pipeline</li> <li>Automated testing</li> <li>Code quality checks</li> </ul>"},{"location":"community/#release-process","title":"\ud83d\ude80 Release Process","text":"<p>Release Process How releases are managed.</p> <ul> <li>Version numbering</li> <li>Release checklist</li> <li>Changelog management</li> <li>Publishing process</li> <li>Documentation updates</li> </ul>"},{"location":"community/#development-setup","title":"Development Setup","text":""},{"location":"community/#system-requirements","title":"System Requirements","text":"<ul> <li>Python 3.10+</li> <li>Git</li> <li>uv package manager</li> <li>(Optional) GPU with CUDA for local inference</li> </ul>"},{"location":"community/#install-development-dependencies","title":"Install Development Dependencies","text":"<pre><code># Full development setup\nuv sync --extra dev\n\n# This installs:\n# - Core dependencies\n# - Local inference (vLLM, transformers)\n# - Remote API clients\n# - Development tools (pytest, ruff, mypy)\n# - Documentation tools (mkdocs)\n</code></pre>"},{"location":"community/#verify-setup","title":"Verify Setup","text":"<pre><code># Check Python version\npython --version  # Should be 3.10+\n\n# Check uv\nuv --version\n\n# Run tests\nuv run pytest\n\n# Check code quality\nuv run ruff check .\nuv run mypy docling_graph\n</code></pre>"},{"location":"community/#code-standards","title":"Code Standards","text":""},{"location":"community/#style-guide","title":"Style Guide","text":"<p>We follow PEP 8 with some modifications:</p> <ul> <li>Line length: 100 characters</li> <li>Use type hints for all functions</li> <li>Docstrings for all public APIs</li> <li>Format with <code>ruff format</code></li> </ul>"},{"location":"community/#type-checking","title":"Type Checking","text":"<p>All code must pass mypy:</p> <pre><code>uv run mypy docling_graph\n</code></pre>"},{"location":"community/#linting","title":"Linting","text":"<p>Code must pass ruff checks:</p> <pre><code># Check code\nuv run ruff check .\n\n# Auto-fix issues\nuv run ruff check --fix .\n\n# Format code\nuv run ruff format .\n</code></pre>"},{"location":"community/#testing-requirements","title":"Testing Requirements","text":""},{"location":"community/#test-coverage","title":"Test Coverage","text":"<ul> <li>Minimum 80% code coverage</li> <li>All new features must have tests</li> <li>Bug fixes must include regression tests</li> </ul>"},{"location":"community/#running-tests","title":"Running Tests","text":"<pre><code># All tests\nuv run pytest\n\n# Specific test file\nuv run pytest tests/unit/test_config.py\n\n# Specific test\nuv run pytest tests/unit/test_config.py::test_pipeline_config\n\n# With coverage\nuv run pytest --cov=docling_graph --cov-report=html\n\n# Fast tests only (skip slow)\nuv run pytest -m \"not slow\"\n</code></pre>"},{"location":"community/#writing-tests","title":"Writing Tests","text":"<pre><code>\"\"\"Test example.\"\"\"\n\nimport pytest\nfrom docling_graph import PipelineConfig\n\ndef test_pipeline_config_creation():\n    \"\"\"Test PipelineConfig can be created.\"\"\"\n    config = PipelineConfig(\n        source=\"test.pdf\",\n        template=\"templates.Test\"\n    )\n    assert config.source == \"test.pdf\"\n    assert config.backend == \"llm\"  # Default\n\ndef test_pipeline_config_validation():\n    \"\"\"Test PipelineConfig validates inputs.\"\"\"\n    with pytest.raises(ValueError):\n        PipelineConfig(\n            source=\"test.pdf\",\n            template=\"templates.Test\",\n            backend=\"invalid\"  # Should fail\n        )\n</code></pre>"},{"location":"community/#documentation","title":"Documentation","text":""},{"location":"community/#building-documentation","title":"Building Documentation","text":"<pre><code># Install mkdocs\nuv add --dev mkdocs mkdocs-material\n\n# Serve locally\nuv run mkdocs serve\n\n# Build static site\nuv run mkdocs build\n</code></pre>"},{"location":"community/#documentation-standards","title":"Documentation Standards","text":"<ul> <li>All public APIs must be documented</li> <li>Include code examples</li> <li>Use clear, concise language</li> <li>Cross-reference related docs</li> <li>Keep examples up to date</li> </ul>"},{"location":"community/#project-structure","title":"Project Structure","text":"<pre><code>docling-graph/\n\u251c\u2500\u2500 docling_graph/           # Source code\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 pipeline.py\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u251c\u2500\u2500 protocols.py\n\u2502   \u251c\u2500\u2500 exceptions.py\n\u2502   \u251c\u2500\u2500 core/               # Core modules\n\u2502   \u251c\u2500\u2500 llm_clients/        # LLM integrations\n\u2502   \u251c\u2500\u2500 pipeline/           # Pipeline orchestration\n\u2502   \u2514\u2500\u2500 cli/                # CLI commands\n\u2502\n\u251c\u2500\u2500 tests/                  # Test suite\n\u2502   \u251c\u2500\u2500 unit/              # Unit tests\n\u2502   \u251c\u2500\u2500 integration/       # Integration tests\n\u2502   \u251c\u2500\u2500 fixtures/          # Test fixtures\n\u2502   \u2514\u2500\u2500 mocks/             # Mock objects\n\u2502\n\u251c\u2500\u2500 docs/                   # Documentation\n\u2502   \u251c\u2500\u2500 01-introduction/\n\u2502   \u251c\u2500\u2500 installation/\n\u2502   \u2514\u2500\u2500 ...\n\u2502\n\u251c\u2500\u2500 examples/               # Example code\n\u2502   \u251c\u2500\u2500 scripts/\n\u2502   \u2514\u2500\u2500 templates/\n\u2502\n\u251c\u2500\u2500 .github/               # GitHub configuration\n\u2502\n\u251c\u2500\u2500 pyproject.toml         # Project configuration\n\u251c\u2500\u2500 README.md              # Project README\n\u251c\u2500\u2500 CHANGELOG.md           # Version history\n\u2514\u2500\u2500 LICENSE                # License file\n</code></pre>"},{"location":"community/#common-tasks","title":"Common Tasks","text":""},{"location":"community/#add-new-feature","title":"Add New Feature","text":"<ol> <li>Create issue describing feature</li> <li>Create feature branch</li> <li>Implement feature with tests</li> <li>Update documentation</li> <li>Submit pull request</li> </ol>"},{"location":"community/#fix-bug","title":"Fix Bug","text":"<ol> <li>Create issue describing bug</li> <li>Create fix branch</li> <li>Write failing test</li> <li>Fix bug</li> <li>Verify test passes</li> <li>Submit pull request</li> </ol>"},{"location":"community/#update-documentation","title":"Update Documentation","text":"<ol> <li>Edit markdown files in <code>docs/</code></li> <li>Test locally with <code>mkdocs serve</code></li> <li>Submit pull request</li> </ol>"},{"location":"community/#add-new-llm-client","title":"Add New LLM Client","text":"<ol> <li>Implement <code>LLMClientProtocol</code></li> <li>Add to <code>llm_clients/</code></li> <li>Add tests</li> <li>Update documentation</li> <li>Submit pull request</li> </ol>"},{"location":"community/#getting-help","title":"Getting Help","text":""},{"location":"community/#resources","title":"Resources","text":"<ul> <li>GitHub Issues - Report bugs, request features</li> <li>GitHub Discussions - Ask questions</li> <li>GitHub Repository - Source code and issues</li> </ul>"},{"location":"community/#communication","title":"Communication","text":"<ul> <li>Be respectful and constructive</li> <li>Provide clear, detailed information</li> <li>Include code examples when relevant</li> <li>Follow up on feedback</li> </ul>"},{"location":"community/#next-steps","title":"Next Steps","text":"<ol> <li>GitHub Workflow \u2192 - Understand the workflow</li> <li>Release Process \u2192 - Learn about releases</li> <li>GitHub Workflow \u2192 - Development workflow</li> </ol>"},{"location":"community/github-workflow/","title":"GitHub Workflow","text":""},{"location":"community/github-workflow/#overview","title":"Overview","text":"<p>Guide to working with GitHub for docling-graph development.</p>"},{"location":"community/github-workflow/#branch-strategy","title":"Branch Strategy","text":""},{"location":"community/github-workflow/#main-branches","title":"Main Branches","text":"Branch Purpose Protected <code>main</code> Stable releases \u2705 Yes <code>develop</code> Development integration \u2705 Yes"},{"location":"community/github-workflow/#feature-branches","title":"Feature Branches","text":"<p>Create from <code>develop</code>:</p> <pre><code># Feature\ngit checkout -b feature/add-custom-backend\n\n# Bug fix\ngit checkout -b fix/extraction-error\n\n# Documentation\ngit checkout -b docs/update-api-reference\n</code></pre>"},{"location":"community/github-workflow/#branch-naming","title":"Branch Naming","text":"Type Pattern Example Feature <code>feature/&lt;description&gt;</code> <code>feature/add-vlm-support</code> Bug Fix <code>fix/&lt;description&gt;</code> <code>fix/config-validation</code> Documentation <code>docs/&lt;description&gt;</code> <code>docs/update-examples</code> Refactor <code>refactor/&lt;description&gt;</code> <code>refactor/pipeline-stages</code>"},{"location":"community/github-workflow/#workflow-steps","title":"Workflow Steps","text":""},{"location":"community/github-workflow/#1-create-issue","title":"1. Create Issue","text":"<p>Before starting work:</p> <pre><code>**Title**: Add custom backend support\n\n**Description**:\nAllow users to create custom extraction backends by implementing protocols.\n\n**Acceptance Criteria**:\n- [ ] Protocol defined\n- [ ] Example implementation\n- [ ] Tests added\n- [ ] Documentation updated\n</code></pre>"},{"location":"community/github-workflow/#2-create-branch","title":"2. Create Branch","text":"<pre><code># From develop\ngit checkout develop\ngit pull origin develop\n\n# Create feature branch\ngit checkout -b feature/custom-backends\n</code></pre>"},{"location":"community/github-workflow/#3-develop","title":"3. Develop","text":"<pre><code># Make changes\nvim docling_graph/protocols.py\n\n# Add tests\nvim tests/unit/test_protocols.py\n\n# Test locally\nuv run pytest\nuv run ruff check .\nuv run mypy docling_graph\n</code></pre>"},{"location":"community/github-workflow/#4-commit","title":"4. Commit","text":"<pre><code># Stage changes\ngit add .\n\n# Commit with conventional message\ngit commit -m \"feat(protocols): add custom backend protocol\n\n- Define ExtractionBackendProtocol\n- Add example implementation\n- Include comprehensive tests\"\n</code></pre>"},{"location":"community/github-workflow/#5-push","title":"5. Push","text":"<pre><code># Push to your fork\ngit push origin feature/custom-backends\n</code></pre>"},{"location":"community/github-workflow/#6-create-pull-request","title":"6. Create Pull Request","text":"<p>On GitHub:</p> <ol> <li>Click \"New Pull Request\"</li> <li>Select <code>develop</code> as base branch</li> <li>Fill in PR template</li> <li>Link related issue</li> <li>Request review</li> </ol>"},{"location":"community/github-workflow/#pull-request-template","title":"Pull Request Template","text":"<pre><code>## Description\nBrief description of changes\n\nFixes #123\n\n## Type of Change\n- [ ] Bug fix (non-breaking change fixing an issue)\n- [ ] New feature (non-breaking change adding functionality)\n- [ ] Breaking change (fix or feature causing existing functionality to change)\n- [ ] Documentation update\n\n## How Has This Been Tested?\nDescribe the tests you ran:\n- [ ] Unit tests\n- [ ] Integration tests\n- [ ] Manual testing\n\n## Checklist\n- [ ] My code follows the style guidelines\n- [ ] I have performed a self-review\n- [ ] I have commented my code where needed\n- [ ] I have updated the documentation\n- [ ] My changes generate no new warnings\n- [ ] I have added tests that prove my fix/feature works\n- [ ] New and existing unit tests pass locally\n- [ ] I have updated CHANGELOG.md\n\n## Screenshots (if applicable)\nAdd screenshots to help explain your changes\n</code></pre>"},{"location":"community/github-workflow/#cicd-pipeline","title":"CI/CD Pipeline","text":""},{"location":"community/github-workflow/#automated-checks","title":"Automated Checks","text":"<p>On every push and PR:</p> <pre><code># .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Install uv\n        run: curl -LsSf https://astral.sh/uv/install.sh | sh\n\n      - name: Install dependencies\n        run: uv sync --extra dev\n\n      - name: Run tests\n        run: uv run pytest --cov --cov-report=xml\n\n      - name: Lint\n        run: uv run ruff check .\n\n      - name: Type check\n        run: uv run mypy docling_graph\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n</code></pre>"},{"location":"community/github-workflow/#status-checks","title":"Status Checks","text":"<p>Required checks before merge: \u2705 Tests pass \u2705 Code coverage \u2265 80% \u2705 Linting passes \u2705 Type checking passes \u2705 Documentation builds</p>"},{"location":"community/github-workflow/#code-review-process","title":"Code Review Process","text":""},{"location":"community/github-workflow/#for-contributors","title":"For Contributors","text":"<p>After submitting PR:</p> <ol> <li>Wait for automated checks</li> <li>Address any failures</li> <li>Respond to reviewer feedback</li> <li>Make requested changes</li> <li>Re-request review</li> </ol> <p>Responding to feedback:</p> <pre><code>&gt; Can you add a test for the error case?\n\nGood point! Added test in commit abc123.\n\n&gt; This could be simplified\n\nRefactored in commit def456. Let me know if this is clearer.\n</code></pre>"},{"location":"community/github-workflow/#for-reviewers","title":"For Reviewers","text":"<p>Review checklist:</p> <ul> <li> Code follows style guide</li> <li> Tests are comprehensive</li> <li> Documentation is updated</li> <li> No breaking changes (or properly documented)</li> <li> Performance considerations addressed</li> <li> Security implications considered</li> </ul> <p>Providing feedback:</p> <pre><code># \u2705 Good feedback\nThe logic here is correct, but could be simplified:\n\n\\`\\`\\`python\n# Instead of:\nif condition:\n    return True\nelse:\n    return False\n\n# Consider:\nreturn condition\n\\`\\`\\`\n\n# \u274c Avoid\nThis is wrong. Fix it.\n</code></pre>"},{"location":"community/github-workflow/#merge-strategy","title":"Merge Strategy","text":""},{"location":"community/github-workflow/#squash-and-merge","title":"Squash and Merge","text":"<p>We use squash merging:</p> <pre><code># Multiple commits:\nfeat: add feature part 1\nfeat: add feature part 2\nfix: typo\ndocs: update\n\n# Become single commit:\nfeat: add custom backend support (#123)\n</code></pre>"},{"location":"community/github-workflow/#merge-requirements","title":"Merge Requirements","text":"<p>Before merging: \u2705 All checks pass \u2705 At least one approval \u2705 No unresolved conversations \u2705 Branch is up to date</p>"},{"location":"community/github-workflow/#issue-management","title":"Issue Management","text":""},{"location":"community/github-workflow/#labels","title":"Labels","text":"Label Purpose <code>bug</code> Something isn't working <code>enhancement</code> New feature or request <code>documentation</code> Documentation improvements <code>good first issue</code> Good for newcomers <code>help wanted</code> Extra attention needed <code>question</code> Further information requested"},{"location":"community/github-workflow/#issue-templates","title":"Issue Templates","text":"<p>Bug Report:</p> <pre><code>**Describe the bug**\nA clear description of the bug.\n\n**To Reproduce**\nSteps to reproduce the behavior.\n\n**Expected behavior**\nWhat you expected to happen.\n\n**Environment**\n- OS: [e.g., Ubuntu 22.04]\n- Python: [e.g., 3.10.12]\n- docling-graph: [e.g., v1.2.0]\n</code></pre> <p>Feature Request:</p> <pre><code>**Is your feature request related to a problem?**\nA clear description of the problem.\n\n**Describe the solution you'd like**\nA clear description of what you want to happen.\n\n**Describe alternatives you've considered**\nAlternative solutions or features you've considered.\n</code></pre>"},{"location":"community/github-workflow/#release-workflow","title":"Release Workflow","text":""},{"location":"community/github-workflow/#version-bumping","title":"Version Bumping","text":"<pre><code># Update version in pyproject.toml\n# Update CHANGELOG.md\n# Commit changes\ngit commit -m \"chore: bump version to 0.4.0\"\n\n# Tag release\ngit tag -a v0.4.0 -m \"Release v0.4.0\"\n\n# Push\ngit push origin main --tags\n</code></pre>"},{"location":"community/github-workflow/#automated-release","title":"Automated Release","text":"<p>GitHub Actions automatically:</p> <ol> <li>Runs tests</li> <li>Builds package</li> <li>Publishes to PyPI</li> <li>Creates GitHub release</li> <li>Updates documentation</li> </ol>"},{"location":"community/github-workflow/#semantic-release-cd-workflow","title":"Semantic Release (CD workflow)","text":"<p>Releases are driven by the Semantic Release workflow (push to <code>main</code> or Actions \u2192 Run workflow). It uses a GitHub App so the release job can push to protected <code>main</code>.</p> <p>Maintainer setup:</p> <ol> <li>GitHub App \u2013 Create or reuse an app with repo contents permission. In the repo (or org): set variable <code>CI_APP_ID</code> and secret <code>CI_PRIVATE_KEY</code> (app private key PEM). In branch protection for <code>main</code>, allow that app to bypass \u201cRequire a pull request\u201d.</li> <li>Environment \u2013 Ensure the auto-release environment exists (Settings \u2192 Environments). You can add protection or required reviewers there.</li> <li>Manual-only \u2013 To run releases only from the UI, remove the <code>push: branches: [main]</code> trigger from <code>.github/workflows/semantic-release.yml</code>.</li> </ol>"},{"location":"community/github-workflow/#best-practices","title":"Best Practices","text":""},{"location":"community/github-workflow/#commit-messages","title":"Commit Messages","text":"<pre><code># \u2705 Good\nfeat(extractors): add support for custom chunking\n\nAllows users to provide custom chunking strategies\nvia the ChunkerProtocol interface.\n\nCloses #123\n\n# \u274c Avoid\nupdate code\nfix stuff\nwip\n</code></pre>"},{"location":"community/github-workflow/#pr-size","title":"PR Size","text":"<ul> <li>Keep PRs focused and small</li> <li>One feature/fix per PR</li> <li>Split large changes into multiple PRs</li> </ul>"},{"location":"community/github-workflow/#communication","title":"Communication","text":"<ul> <li>Be responsive to feedback</li> <li>Ask questions if unclear</li> <li>Update PR description if scope changes</li> <li>Close stale PRs</li> </ul>"},{"location":"community/github-workflow/#troubleshooting","title":"Troubleshooting","text":""},{"location":"community/github-workflow/#ci-failures","title":"CI Failures","text":"<p>Tests fail:</p> <pre><code># Run tests locally\nuv run pytest -v\n\n# Check specific failure\nuv run pytest tests/unit/test_config.py::test_validation -v\n</code></pre> <p>Linting fails:</p> <pre><code># Check issues\nuv run ruff check .\n\n# Auto-fix\nuv run ruff check --fix .\n</code></pre> <p>Type checking fails:</p> <pre><code># Check types\nuv run mypy docling_graph\n\n# Check specific file\nuv run mypy docling_graph/config.py\n</code></pre>"},{"location":"community/github-workflow/#merge-conflicts","title":"Merge Conflicts","text":"<pre><code># Update your branch\ngit checkout feature/my-feature\ngit fetch origin\ngit rebase origin/develop\n\n# Resolve conflicts\n# Edit conflicted files\ngit add .\ngit rebase --continue\n\n# Force push\ngit push origin feature/my-feature --force\n</code></pre>"},{"location":"community/github-workflow/#next-steps","title":"Next Steps","text":"<ol> <li>Release Process \u2192 - Learn about releases</li> <li>Development Guide - Back to overview</li> <li>Testing Guide - Testing practices</li> </ol>"},{"location":"community/release-process/","title":"Release Process","text":""},{"location":"community/release-process/#overview","title":"Overview","text":"<p>Guide to the docling-graph release process.</p>"},{"location":"community/release-process/#version-numbering","title":"Version Numbering","text":"<p>We follow Semantic Versioning:</p> <pre><code>MAJOR.MINOR.PATCH\n\nExample: 1.0.0\n</code></pre>"},{"location":"community/release-process/#version-components","title":"Version Components","text":"Component When to Increment MAJOR Breaking changes (manual only) MINOR New features (backward compatible) PATCH Bug fixes (backward compatible)"},{"location":"community/release-process/#examples","title":"Examples","text":"<pre><code>1.0.0 \u2192 1.0.1  # Bug fix\n1.0.1 \u2192 1.1.0  # New feature\n1.1.0 \u2192 2.0.0  # Breaking change (manual tag required)\n</code></pre>"},{"location":"community/release-process/#automated-vs-manual-releases","title":"Automated vs Manual Releases","text":""},{"location":"community/release-process/#automated-releases-semantic-release","title":"Automated Releases (Semantic Release)","text":"<p>Our CI/CD automatically handles routine releases:</p> Commit Type Version Bump Example <code>feat:</code> Minor (1.0.0 \u2192 1.1.0) <code>feat: add CSV export</code> <code>refactor:</code> Patch (1.0.0 \u2192 1.0.1) <code>refactor: improve parser</code> <code>fix:</code> Patch (1.0.0 \u2192 1.0.1) <code>fix: handle null values</code> <code>perf:</code> Patch (1.0.0 \u2192 1.0.1) <code>perf: optimize graph build</code> <p>Breaking changes and releases</p> <p>BREAKING CHANGE commits trigger minor releases (not major). This lets you accumulate breaking changes and ship them together later as a planned major version.</p>"},{"location":"community/release-process/#manual-releases-git-tags","title":"Manual Releases (Git Tags)","text":"<p>Major version bumps require manual Git tags:</p> <ul> <li>Major releases (1.x.x \u2192 2.0.0): Manual Git tags only</li> <li>Requires deliberate decision and planning</li> <li>Includes migration guides and announcements</li> <li>Prevents accidental major bumps from commit messages</li> </ul>"},{"location":"community/release-process/#why-manual-major-releases","title":"Why Manual Major Releases?","text":"<p>Following industry best practices:</p> <ol> <li>Strategic Milestones: Major versions signal significant changes requiring coordination</li> <li>Communication: Need time for announcements, migration guides, and user preparation</li> <li>Prevent Accidents: Developers can't accidentally trigger major bumps with commit messages</li> <li>Stability Perception: Controlled major releases signal project maturity</li> <li>Accumulate Changes: Collect multiple breaking changes for a single coordinated release</li> </ol>"},{"location":"community/release-process/#release-types","title":"Release Types","text":""},{"location":"community/release-process/#patch-release-v120-031","title":"Patch Release (v1.2.0 \u2192 0.3.1)","text":"<p>When: - Bug fixes - Documentation updates - Performance improvements (no API changes)</p> <p>Example: <pre><code># Fix extraction error\ngit commit -m \"fix(extractors): handle empty markdown\"\n\n# Release\ngit tag v0.3.1\n</code></pre></p>"},{"location":"community/release-process/#minor-release-v120-040","title":"Minor Release (v1.2.0 \u2192 0.4.0)","text":"<p>When: - New features - New backends/exporters - Deprecations (with warnings)</p> <p>Example: <pre><code># Add new feature\ngit commit -m \"feat(exporters): add GraphML exporter\"\n\n# Release\ngit tag v0.4.0\n</code></pre></p>"},{"location":"community/release-process/#major-release-1xx-200-manual-only","title":"Major Release (1.x.x \u2192 2.0.0) - Manual Only","text":"<p>When: - Breaking API changes - Removed deprecated features - Major architectural refactoring - Multiple accumulated breaking changes</p> <p>Important: Major releases require manual Git tags and cannot be triggered by commits.</p> <p>Process:</p> <ol> <li>Prepare breaking changes on a release branch</li> <li>Update version manually in <code>pyproject.toml</code> and <code>__init__.py</code></li> <li>Create comprehensive CHANGELOG with migration guide</li> <li>Merge to main via PR</li> <li>Create and push Git tag:</li> </ol> <pre><code>git checkout main\ngit pull origin main\n\n# Create annotated tag with detailed message\ngit tag -a v2.0.0 -m \"Major release v2.0.0\n\nBreaking changes:\n- Changed run_pipeline signature to require PipelineConfig\n- Removed deprecated old_function() (use new_function instead)\n- Refactored graph converter API\n\nSee CHANGELOG.md for full details and migration guide.\"\n\n# Push tag to trigger release workflow\ngit push origin v2.0.0\n</code></pre> <p>Semantic-release major bumps</p> <p>Even if you use BREAKING CHANGE: in commits, semantic-release will only bump to the next minor version. Major bumps require manual tags.</p>"},{"location":"community/release-process/#creating-a-major-release-detailed-guide","title":"Creating a Major Release (Detailed Guide)","text":"<p>Major releases are strategic milestones that require careful planning and execution. Follow this comprehensive guide:</p>"},{"location":"community/release-process/#prerequisites","title":"Prerequisites","text":"<p>Before starting a major release:</p> <ul> <li> All breaking changes are documented</li> <li> Migration guide is prepared</li> <li> Deprecation warnings were in place in previous versions</li> <li> Team consensus on timing and scope</li> <li> Communication plan is ready (announcements, blog posts, etc.)</li> <li> All tests pass with breaking changes</li> <li> Documentation is updated for new APIs</li> </ul>"},{"location":"community/release-process/#step-by-step-process","title":"Step-by-Step Process","text":""},{"location":"community/release-process/#1-create-release-branch","title":"1. Create Release Branch","text":"<pre><code># Start from main\ngit checkout main\ngit pull origin main\n\n# Create release branch\ngit checkout -b release/2.0.0\n</code></pre>"},{"location":"community/release-process/#2-implement-breaking-changes","title":"2. Implement Breaking Changes","text":"<p>Make all necessary breaking changes on this branch:</p> <pre><code># Make changes\nvim docling_graph/pipeline.py\n\n# Commit with clear messages\ngit commit -m \"feat!: change run_pipeline signature\n\nBREAKING CHANGE: run_pipeline now requires PipelineConfig object\ninstead of individual parameters. This provides better type safety\nand makes the API more maintainable.\n\nMigration:\n  Before: run_pipeline(source, template, backend='llm')\n  After:  config = PipelineConfig(source=source, template=template)\n          run_pipeline(config)\"\n</code></pre>"},{"location":"community/release-process/#3-update-version-numbers-manually","title":"3. Update Version Numbers Manually","text":"<p>pyproject.toml: <pre><code>[project]\nname = \"docling-graph\"\nversion = \"2.0.0\"  # Update to new major version\n</code></pre></p> <p>docling_graph/init.py: <pre><code>__version__ = \"2.0.0\"  # Update to new major version\n</code></pre></p>"},{"location":"community/release-process/#4-create-comprehensive-changelog","title":"4. Create Comprehensive CHANGELOG","text":"<p>CHANGELOG.md: <pre><code># Changelog\n\n## [2.0.0] - 2024-XX-XX\n\n### BREAKING CHANGES\n\n#### Changed run_pipeline API\n\n**Before:**\n\\`\\`\\`python\nfrom docling_graph import run_pipeline\n\nresult = run_pipeline(\n    source=\"document.pdf\",\n    template=MyTemplate,\n    backend=\"llm\"\n)\n\\`\\`\\`\n\n**After:**\n\\`\\`\\`python\nfrom docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=MyTemplate,\n    backend=\"llm\"\n)\nresult = run_pipeline(config)\n\\`\\`\\`\n\n**Migration:** Update all `run_pipeline` calls to use `PipelineConfig`.\n\n#### Removed deprecated functions\n\n- Removed `old_function()` (deprecated in v1.5.0)\n  - **Migration:** Use `new_function()` instead\n\n### Added\n- New graph validation features\n- Enhanced error messages\n\n### Fixed\n- Various bug fixes\n</code></pre></p>"},{"location":"community/release-process/#5-update-documentation","title":"5. Update Documentation","text":"<p>Update all documentation to reflect breaking changes:</p> <pre><code># Update examples\nvim docs/introduction/quickstart.md\n\n# Update API documentation\nvim docs/api/run-pipeline.md\n\n# Create migration guide\nvim docs/12-development/migration-v2.md\n</code></pre>"},{"location":"community/release-process/#6-commit-version-updates","title":"6. Commit Version Updates","text":"<pre><code>git add pyproject.toml docling_graph/__init__.py CHANGELOG.md docs/\ngit commit -m \"chore: prepare version 2.0.0 release\"\n</code></pre>"},{"location":"community/release-process/#7-final-testing","title":"7. Final Testing","text":"<pre><code># Run full test suite\nuv run pytest\n\n# Check code quality\nuv run ruff check .\nuv run mypy docling_graph\n\n# Build and test package\nuv build\nuv run pip install dist/docling_graph-2.0.0-*.whl\n</code></pre>"},{"location":"community/release-process/#8-create-pull-request","title":"8. Create Pull Request","text":"<pre><code># Push release branch\ngit push origin release/2.0.0\n\n# Create PR to main\n# Title: \"Release v2.0.0\"\n# Description: Include summary of breaking changes\n# Get team approval\n</code></pre>"},{"location":"community/release-process/#9-merge-to-main","title":"9. Merge to Main","text":"<p>After PR approval: <pre><code># Merge PR (via GitHub UI or command line)\n# DO NOT create a tag yet - this is done manually next\n</code></pre></p>"},{"location":"community/release-process/#10-create-and-push-git-tag","title":"10. Create and Push Git Tag","text":"<p>This is the critical step that triggers the major release:</p> <pre><code># Checkout and update main\ngit checkout main\ngit pull origin main\n\n# Create annotated tag with comprehensive message\ngit tag -a v2.0.0 -m \"Major release v2.0.0\n\nBreaking changes:\n- Changed run_pipeline API to use PipelineConfig\n- Removed old_function() (use new_function instead)\n- Refactored graph converter for better performance\n\nNew features:\n- Enhanced graph validation\n- Improved error messages\n\nSee CHANGELOG.md for complete details and migration guide.\nSee docs/12-development/migration-v2.md for migration instructions.\"\n\n# Push tag to trigger release workflow\ngit push origin v2.0.0\n</code></pre>"},{"location":"community/release-process/#11-monitor-release","title":"11. Monitor Release","text":"<p>Watch the GitHub Actions workflow: - Build completes successfully - Tests pass - Package published to PyPI - GitHub release created</p>"},{"location":"community/release-process/#12-post-release-tasks","title":"12. Post-Release Tasks","text":"<pre><code># Verify PyPI release\npip install docling-graph==2.0.0\n\n# Update documentation site\n# Publish announcement\n# Monitor for issues\n</code></pre>"},{"location":"community/release-process/#communication-checklist","title":"Communication Checklist","text":"<ul> <li> GitHub release notes published</li> <li> Migration guide available</li> <li> Announcement in GitHub Discussions</li> <li> Update README badges if needed</li> <li> Social media announcement (if applicable)</li> <li> Email to major users (if applicable)</li> </ul>"},{"location":"community/release-process/#rollback-plan","title":"Rollback Plan","text":"<p>If critical issues are discovered:</p> <ol> <li>Quick fix: Release v2.0.1 hotfix</li> <li>Major issues: Yank v2.0.0 from PyPI, recommend v1.x.x</li> </ol>"},{"location":"community/release-process/#release-checklist","title":"Release Checklist","text":""},{"location":"community/release-process/#pre-release","title":"Pre-Release","text":"<ul> <li> All tests pass</li> <li> Documentation is updated</li> <li> CHANGELOG.md is updated</li> <li> Version bumped in <code>pyproject.toml</code></li> <li> No open critical bugs</li> <li> Breaking changes documented</li> </ul>"},{"location":"community/release-process/#release","title":"Release","text":"<ul> <li> Create release branch</li> <li> Final testing</li> <li> Tag release</li> <li> Push to GitHub</li> <li> Automated build and publish</li> <li> Verify PyPI upload</li> </ul>"},{"location":"community/release-process/#post-release","title":"Post-Release","text":"<ul> <li> Create GitHub release notes</li> <li> Announce release</li> <li> Update documentation site</li> <li> Close milestone</li> <li> Merge back to develop</li> </ul>"},{"location":"community/release-process/#step-by-step-process_1","title":"Step-by-Step Process","text":""},{"location":"community/release-process/#1-prepare-release","title":"1. Prepare Release","text":"<pre><code># Checkout develop\ngit checkout develop\ngit pull origin develop\n\n# Create release branch\ngit checkout -b release/0.4.0\n</code></pre>"},{"location":"community/release-process/#2-update-version","title":"2. Update Version","text":"<p>pyproject.toml:</p> <pre><code>[project]\nname = \"docling-graph\"\nversion = \"0.4.0\"  # Update version\n</code></pre> <p>docling_graph/__init__.py:</p> <pre><code>__version__ = \"0.4.0\"  # Update version\n</code></pre>"},{"location":"community/release-process/#3-update-changelog","title":"3. Update CHANGELOG","text":"<p>CHANGELOG.md:</p> <pre><code># Changelog\n\n## [0.4.0] - 2024-01-22\n\n### Added\n- GraphML exporter for graph visualization tools\n- Support for custom chunking strategies\n- New examples for insurance policy extraction\n\n### Changed\n- Improved error messages in extraction pipeline\n- Updated documentation structure\n\n### Fixed\n- Fixed VLM backend memory leak\n- Corrected date parsing in templates\n\n### Deprecated\n- Old configuration format (use PipelineConfig)\n\n## [v1.2.0] - 2024-01-15\n...\n</code></pre>"},{"location":"community/release-process/#4-commit-changes","title":"4. Commit Changes","text":"<pre><code>git add pyproject.toml docling_graph/__init__.py CHANGELOG.md\ngit commit -m \"chore: bump version to 0.4.0\"\n</code></pre>"},{"location":"community/release-process/#5-final-testing","title":"5. Final Testing","text":"<pre><code># Run full test suite\nuv run pytest\n\n# Check code quality\nuv run ruff check .\nuv run mypy docling_graph\n\n# Build documentation\nuv run mkdocs build\n\n# Test package build\nuv build\n</code></pre>"},{"location":"community/release-process/#6-merge-to-main","title":"6. Merge to Main","text":"<pre><code># Push release branch\ngit push origin release/0.4.0\n\n# Create PR to main\n# Get approval\n# Merge PR\n</code></pre>"},{"location":"community/release-process/#7-tag-release","title":"7. Tag Release","text":"<pre><code># Checkout main\ngit checkout main\ngit pull origin main\n\n# Create tag\ngit tag -a v0.4.0 -m \"Release v0.4.0\n\n- Add GraphML exporter\n- Support custom chunking\n- Improve error messages\n- Fix VLM memory leak\"\n\n# Push tag\ngit push origin v0.4.0\n</code></pre>"},{"location":"community/release-process/#8-automated-build","title":"8. Automated Build","text":"<p>GitHub Actions automatically:</p> <pre><code># .github/workflows/release.yml\nname: Release\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Install uv\n        run: curl -LsSf https://astral.sh/uv/install.sh | sh\n\n      - name: Build package\n        run: uv build\n\n      - name: Publish to PyPI\n        run: uv publish\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_TOKEN }}\n\n      - name: Create GitHub Release\n        uses: actions/create-release@v1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          body_path: CHANGELOG.md\n</code></pre>"},{"location":"community/release-process/#9-verify-release","title":"9. Verify Release","text":"<pre><code># Check PyPI\npip install docling-graph==0.4.0\n\n# Verify version\npython -c \"import docling_graph; print(docling_graph.__version__)\"\n</code></pre>"},{"location":"community/release-process/#10-create-release-notes","title":"10. Create Release Notes","text":"<p>On GitHub:</p> <ol> <li>Go to Releases</li> <li>Click \"Draft a new release\"</li> <li>Select tag v0.4.0</li> <li>Title: \"Release 0.4.0\"</li> <li>Description from CHANGELOG</li> <li>Publish release</li> </ol>"},{"location":"community/release-process/#11-announce-release","title":"11. Announce Release","text":"<ul> <li>GitHub Discussions</li> <li>Project README</li> <li>Social media (if applicable)</li> </ul>"},{"location":"community/release-process/#12-merge-back","title":"12. Merge Back","text":"<pre><code># Merge main back to develop\ngit checkout develop\ngit merge main\ngit push origin develop\n</code></pre>"},{"location":"community/release-process/#changelog-format","title":"CHANGELOG Format","text":"<p>Follow Keep a Changelog:</p> <pre><code># Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/),\nand this project adheres to [Semantic Versioning](https://semver.org/).\n\n## [Unreleased]\n\n### Added\n- New features in development\n\n### Changed\n- Changes to existing features\n\n### Deprecated\n- Features to be removed\n\n### Removed\n- Removed features\n\n### Fixed\n- Bug fixes\n\n### Security\n- Security fixes\n\n## [0.4.0] - 2024-01-22\n\n### Added\n- GraphML exporter (#123)\n- Custom chunking support (#124)\n\n### Fixed\n- VLM memory leak (#125)\n\n## [v1.2.0] - 2024-01-15\n...\n</code></pre>"},{"location":"community/release-process/#breaking-changes","title":"Breaking Changes","text":""},{"location":"community/release-process/#documentation","title":"Documentation","text":"<p>Document breaking changes clearly:</p> <pre><code>## [1.0.0] - 2024-02-01\n\n### BREAKING CHANGES\n\n#### run_pipeline signature changed\n\n**Before:**\n\\`\\`\\`python\nrun_pipeline(source, template, backend=\"llm\")\n\\`\\`\\`\n\n**After:**\n\\`\\`\\`python\nconfig = PipelineConfig(source=source, template=template)\nrun_pipeline(config)\n\\`\\`\\`\n\n**Migration:**\nUpdate all calls to use PipelineConfig.\n\n#### Removed deprecated features\n\n- Removed `old_function()` (deprecated in 0.8.0)\n- Use `new_function()` instead\n</code></pre>"},{"location":"community/release-process/#deprecation-period","title":"Deprecation Period","text":"<ol> <li>Version N: Add deprecation warning</li> <li>Version N+1: Keep with warning</li> <li>Version N+2: Remove feature</li> </ol> <p>Example:</p> <pre><code># Version 0.8.0 - Add warning\ndef old_function():\n    warnings.warn(\n        \"old_function is deprecated, use new_function\",\n        DeprecationWarning,\n        stacklevel=2\n    )\n    return new_function()\n\n# Version 0.9.0 - Keep warning\n\n# Version 1.0.0 - Remove\n# old_function() removed\n</code></pre>"},{"location":"community/release-process/#hotfix-process","title":"Hotfix Process","text":"<p>For critical bugs in production:</p>"},{"location":"community/release-process/#1-create-hotfix-branch","title":"1. Create Hotfix Branch","text":"<pre><code># From main\ngit checkout main\ngit checkout -b hotfix/0.3.1\n</code></pre>"},{"location":"community/release-process/#2-fix-bug","title":"2. Fix Bug","text":"<pre><code># Fix the bug\nvim docling_graph/module.py\n\n# Add test\nvim tests/unit/test_module.py\n\n# Commit\ngit commit -m \"fix: critical extraction bug\"\n</code></pre>"},{"location":"community/release-process/#3-update-version","title":"3. Update Version","text":"<pre><code># Bump patch version\n# Update CHANGELOG\n\ngit commit -m \"chore: bump version to 0.3.1\"\n</code></pre>"},{"location":"community/release-process/#4-release","title":"4. Release","text":"<pre><code># Merge to main\ngit checkout main\ngit merge hotfix/0.3.1\n\n# Tag\ngit tag v0.3.1\n\n# Push\ngit push origin main --tags\n\n# Merge back to develop\ngit checkout develop\ngit merge hotfix/0.3.1\ngit push origin develop\n</code></pre>"},{"location":"community/release-process/#release-schedule","title":"Release Schedule","text":""},{"location":"community/release-process/#regular-releases","title":"Regular Releases","text":"<ul> <li>Minor releases: Monthly (if features ready)</li> <li>Patch releases: As needed (bug fixes)</li> <li>Major releases: When breaking changes accumulated</li> </ul>"},{"location":"community/release-process/#release-windows","title":"Release Windows","text":"<ul> <li>Avoid releases on Fridays</li> <li>Avoid holiday periods</li> <li>Allow time for testing</li> </ul>"},{"location":"community/release-process/#rollback-procedure","title":"Rollback Procedure","text":"<p>If a release has critical issues:</p>"},{"location":"community/release-process/#1-identify-issue","title":"1. Identify Issue","text":"<pre><code># Check reports\n# Verify bug\n# Assess severity\n</code></pre>"},{"location":"community/release-process/#2-quick-fix-or-rollback","title":"2. Quick Fix or Rollback","text":"<p>Option A: Quick hotfix</p> <pre><code># If fix is simple\ngit checkout -b hotfix/0.4.1\n# Fix bug\n# Release 0.4.1\n</code></pre> <p>Option B: Rollback</p> <pre><code># If fix is complex\n# Yank from PyPI (if possible)\n# Announce rollback\n# Recommend previous version\n</code></pre>"},{"location":"community/release-process/#3-communicate","title":"3. Communicate","text":"<ul> <li>Update GitHub release</li> <li>Post in Discussions</li> <li>Update documentation</li> </ul>"},{"location":"community/release-process/#post-release-tasks","title":"Post-Release Tasks","text":""},{"location":"community/release-process/#documentation_1","title":"Documentation","text":"<ul> <li> Update docs site</li> <li> Update examples</li> <li> Update tutorials</li> </ul>"},{"location":"community/release-process/#communication","title":"Communication","text":"<ul> <li> Announce on GitHub</li> <li> Update README badges</li> <li> Social media posts</li> </ul>"},{"location":"community/release-process/#monitoring","title":"Monitoring","text":"<ul> <li> Watch for issues</li> <li> Monitor PyPI downloads</li> <li> Check user feedback</li> </ul>"},{"location":"community/release-process/#tools","title":"Tools","text":""},{"location":"community/release-process/#version-management","title":"Version Management","text":"<pre><code># Check current version\ngrep version pyproject.toml\n\n# Update version\nsed -i 's/version = \"v1.2.0\"/version = \"0.4.0\"/' pyproject.toml\n</code></pre>"},{"location":"community/release-process/#build-and-publish","title":"Build and Publish","text":"<pre><code># Build package\nuv build\n\n# Check package\nuv run twine check dist/*\n\n# Publish to TestPyPI (testing)\nuv publish --repository testpypi\n\n# Publish to PyPI (production)\nuv publish\n</code></pre>"},{"location":"community/release-process/#next-steps","title":"Next Steps","text":"<ol> <li>Development Guide - Back to overview</li> <li>GitHub Workflow - Development workflow</li> <li>Testing Guide - Testing practices</li> </ol>"},{"location":"examples/","title":"Docling Graph Examples","text":"<p>Example scripts and Pydantic templates for docling-graph. Run scripts from the project root with <code>uv run python docs/examples/scripts/...</code>.</p>"},{"location":"examples/#project-structure","title":"Project Structure","text":"Path Description <code>docs/examples/scripts/</code> Python example scripts (01\u201313) <code>docs/examples/templates/</code> Pydantic templates (e.g. <code>billing_document.py</code>, <code>rheology_research.py</code>)"},{"location":"examples/#example-scripts-0113","title":"Example Scripts (01\u201313)","text":""},{"location":"examples/#getting-started","title":"Getting Started","text":"<ol> <li><code>01_quickstart_vlm_image.py</code> \u2014 VLM extraction from an invoice image</li> <li><code>02_quickstart_llm_pdf.py</code> \u2014 LLM extraction from a multi-page PDF (e.g. rheology)</li> <li><code>03_url_processing.py</code> \u2014 Process documents from URLs (e.g. arXiv)</li> </ol>"},{"location":"examples/#core-features","title":"Core Features","text":"<ol> <li><code>04_input_formats.py</code> \u2014 Text, Markdown, and DoclingDocument inputs</li> <li><code>05_processing_modes.py</code> \u2014 One-to-one vs many-to-one modes</li> <li><code>06_export_formats.py</code> \u2014 CSV, Cypher, and JSON exports</li> <li><code>07_local_inference.py</code> \u2014 Local inference with Ollama</li> </ol>"},{"location":"examples/#optimization-providers","title":"Optimization &amp; Providers","text":"<ol> <li><code>08_chunking_consolidation.py</code> \u2014 Chunking and merge behavior</li> <li><code>09_batch_processing.py</code> \u2014 Batch processing with error handling</li> <li><code>10_provider_configs.py</code> \u2014 OpenAI, Mistral, Gemini, WatsonX</li> <li><code>11_staged_extraction.py</code> \u2014 Staged extraction (ID pass \u2192 fill pass \u2192 merge) for complex templates</li> <li><code>12_custom_llm_client.py</code> \u2014 Custom LLM client (bring your own URL) with full pipeline</li> <li><code>13_delta_extraction.py</code> \u2014 Delta extraction (chunk \u2192 batch \u2192 graph IR \u2192 merge \u2192 projection) for long documents</li> </ol> <p>For CLI usage, see CLI Reference and convert command.</p>"},{"location":"examples/#quick-start","title":"Quick Start","text":"<pre><code># From project root: VLM from image\nuv run python docs/examples/scripts/01_quickstart_vlm_image.py\n\n# Or use the CLI\nuv run docling-graph convert \"https://upload.wikimedia.org/wikipedia/commons/9/9f/Swiss_QR-Bill_example.jpg\" \\\n    --template \"docs.examples.templates.billing_document.BillingDocument\" \\\n    --backend \"vlm\"\n</code></pre>"},{"location":"examples/#learning-path","title":"Learning Path","text":"<ol> <li>Run 01 for a minimal VLM run, then 02 for LLM extraction.</li> <li>Use 03\u201307 for input formats, processing modes, exports, and local inference.</li> <li>Use 08\u201310 for chunking, batch runs, and multiple providers.</li> </ol>"},{"location":"fundamentals/","title":"Fundamentals","text":"<p>Master the core concepts and essential setup for Docling Graph.</p>"},{"location":"fundamentals/#topics","title":"Topics","text":"<ol> <li>Installation - Environment setup and dependencies</li> <li>Schema Definition - Create Pydantic templates</li> <li>Pipeline Configuration - Configure backends and modes</li> <li>Extraction Process - Document conversion and extraction</li> <li>Graph Management - Export and visualize graphs</li> </ol> <p>Start here: Installation Guide</p>"},{"location":"fundamentals/extraction-process/","title":"The Extraction Process","text":""},{"location":"fundamentals/extraction-process/#overview","title":"Overview","text":"<p>The Extraction Process is the core of Docling Graph, transforming raw documents into structured knowledge graphs through a multi-stage pipeline. This section explains each stage in detail.</p> <p>What you'll learn: - How documents are converted to structured format - Intelligent chunking strategies - Extraction backends (LLM vs VLM) - Model merging and consolidation - Pipeline orchestration</p>"},{"location":"fundamentals/extraction-process/#the-four-stage-pipeline","title":"The Four-Stage Pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Input Source\" }\n\n    A1@{ shape: tag-proc, label: \"Input Normalization\" }\n    B@{ shape: procs, label: \"Conversion\" }\n    C@{ shape: tag-proc, label: \"Chunking\" }\n    D@{ shape: procs, label: \"Extraction\" }\n    E@{ shape: lin-proc, label: \"Merging\" }\n\n    F@{ shape: db, label: \"Knowledge Graph\" }\n\n    %% 3. Define Connections\n    A --&gt; A1\n    A1 --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class A1,C operator\n    class B,D,E process\n    class F output</code></pre>"},{"location":"fundamentals/extraction-process/#stage-1-document-conversion","title":"Stage 1: Document Conversion","text":"<p>Purpose: Convert PDF/images to structured Docling format</p> <p>Process: - OCR or Vision pipeline - Layout analysis - Table extraction - Text extraction</p> <p>Output: DoclingDocument with structure</p> <p>Learn more: Document Conversion \u2192</p>"},{"location":"fundamentals/extraction-process/#stage-2-chunking","title":"Stage 2: Chunking","text":"<p>Purpose: Split document into optimal chunks for LLM processing</p> <p>Process: - Structure-aware splitting - Token counting - Semantic boundaries - Context preservation</p> <p>Output: List of contextualized chunks</p> <p>Learn more: Chunking Strategies \u2192</p>"},{"location":"fundamentals/extraction-process/#stage-3-extraction","title":"Stage 3: Extraction","text":"<p>Purpose: Extract structured data using LLM/VLM</p> <p>Process: - Backend selection (LLM/VLM) - Batch processing - Schema validation - Error handling</p> <p>Output: List of Pydantic models</p> <p>Learn more: Extraction Backends \u2192</p>"},{"location":"fundamentals/extraction-process/#stage-4-merging","title":"Stage 4: Merging","text":"<p>Purpose: Consolidate multiple extractions into single model</p> <p>Process: - Programmatic merging - LLM consolidation (optional) - Conflict resolution - Validation</p> <p>Output: Single consolidated model</p> <p>Learn more: Model Merging \u2192</p>"},{"location":"fundamentals/extraction-process/#processing-modes","title":"Processing Modes","text":""},{"location":"fundamentals/extraction-process/#many-to-one-default","title":"Many-to-One (Default)","text":"<p>Best for: Most documents</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"many-to-one\"  # Default\n)\n</code></pre> <p>Process: 1. Convert entire document 2. Chunk intelligently 3. Extract from each chunk 4. Merge into single model</p> <p>Output: 1 consolidated model</p>"},{"location":"fundamentals/extraction-process/#one-to-one","title":"One-to-One","text":"<p>Best for: Multi-page forms, page-specific data</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"one-to-one\"\n)\n</code></pre> <p>Process: 1. Convert entire document 2. Extract from each page 3. Return separate models</p> <p>Output: N models (one per page)</p>"},{"location":"fundamentals/extraction-process/#backend-comparison","title":"Backend Comparison","text":"Feature LLM Backend VLM Backend Input Markdown text Images/PDFs Accuracy High for text High for visuals Speed Fast Slower Cost Low (local) Medium Best For Text documents Complex layouts"},{"location":"fundamentals/extraction-process/#extraction-contracts-llm-many-to-one","title":"Extraction contracts (LLM + many-to-one)","text":"<p>For LLM many-to-one extraction you can choose:</p> <ul> <li>direct (default): Single-pass extraction then programmatic merge.</li> <li>staged: Catalog \u2192 ID pass \u2192 fill pass \u2192 merge; better for complex nested templates. See Staged Extraction.</li> <li>delta: Chunk \u2192 token-bounded batches \u2192 flat graph IR \u2192 normalize \u2192 merge \u2192 projection; for long documents and graph-first extraction. Supports optional resolvers and configurable quality gates. Use <code>docling-graph init</code> and select delta to configure resolvers and quality interactively. See Delta Extraction.</li> </ul>"},{"location":"fundamentals/extraction-process/#pipeline-stages-in-code","title":"Pipeline Stages in Code","text":""},{"location":"fundamentals/extraction-process/#stage-overview","title":"Stage Overview","text":"<pre><code>from docling_graph.pipeline.stages import (\n    TemplateLoadingStage,    # Load Pydantic template\n    ExtractionStage,         # Extract data\n    DoclingExportStage,      # Export Docling outputs\n    GraphConversionStage,    # Convert to graph\n    ExportStage,             # Export graph\n    VisualizationStage       # Generate visualizations\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/#orchestration","title":"Orchestration","text":"<pre><code>from docling_graph.pipeline.orchestrator import PipelineOrchestrator\n\norchestrator = PipelineOrchestrator(config)\ncontext = orchestrator.run()\n\n# Access results\nprint(f\"Extracted {len(context.extracted_models)} models\")\nprint(f\"Graph has {context.graph_metadata.node_count} nodes\")\n</code></pre>"},{"location":"fundamentals/extraction-process/#extraction-flow","title":"Extraction Flow","text":""},{"location":"fundamentals/extraction-process/#complete-flow-diagram","title":"Complete Flow Diagram","text":"<p>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%% flowchart TD     %% 1. Define Classes     classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1     classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037     classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20     classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100     classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0     classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A     classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238</p> <pre><code>%% 2. Define Nodes\nStart@{ shape: terminal, label: \"Input Source\" }\n\nNormalize@{ shape: procs, label: \"Input Normalization\" }\nCheckInput{\"Input Type\"}\n\nConvert@{ shape: procs, label: \"Document Conversion&lt;br/&gt;PDF/Image\" }\nTextProc@{ shape: lin-proc, label: \"Text Processing&lt;br/&gt;Text/Markdown\" }\nLoadDoc@{ shape: lin-proc, label: \"Load DoclingDocument&lt;br/&gt;Skip to Graph\" }\n\nCheckMode{\"Process. Mode\"}\nCheckChunk{\"Chunking?\"}\n\nPageExtract@{ shape: lin-proc, label: \"Page-by-Page Extraction\" }\nFullDoc@{ shape: lin-proc, label: \"Full Document Extraction\" }\n\nChunk@{ shape: tag-proc, label: \"Structure-Aware Chunking\" }\nBatch@{ shape: tag-proc, label: \"Batch Chunks\" }\n\nExtract@{ shape: procs, label: \"Extract from Batches\" }\n\nCheckMerge{\"Multiple Models?\"}\n\nMerge@{ shape: lin-proc, label: \"Programmatic Merge\" }\nSingle@{ shape: doc, label: \"Single Model\" }\n\nCheckConsol{\"Consolidation?\"}\nConsol@{ shape: procs, label: \"LLM Consolidation\" }\n\nFinal@{ shape: doc, label: \"Final Model\" }\nGraph@{ shape: db, label: \"Knowledge Graph\" }\n\n%% 3. Define Connections\nStart --&gt; Normalize\nNormalize --&gt; CheckInput\n\nCheckInput -- \"PDF/Image\" --&gt; Convert\nCheckInput -- \"Text/Markdown\" --&gt; TextProc\nCheckInput -- \"DoclingDocument\" --&gt; LoadDoc\n\nConvert --&gt; CheckMode\nTextProc --&gt; CheckMode\n\nLoadDoc --&gt; Graph\n\nCheckMode -- Many-to-One --&gt; CheckChunk\nCheckMode -- One-to-One --&gt; PageExtract\n\nCheckChunk -- Yes --&gt; Chunk\nCheckChunk -- No --&gt; FullDoc\n\nChunk --&gt; Batch\nBatch --&gt; Extract\n\nFullDoc --&gt; Extract\nPageExtract --&gt; Extract\n\nExtract --&gt; CheckMerge\nCheckMerge -- Yes --&gt; Merge\nCheckMerge -- No --&gt; Single\n\nMerge --&gt; CheckConsol\nCheckConsol -- Yes --&gt; Consol\nCheckConsol -- No --&gt; Final\n\nConsol --&gt; Final\nSingle --&gt; Final\nFinal --&gt; Graph\n\n%% 4. Apply Classes\nclass Start input\nclass Normalize,Convert,Extract,Consol process\nclass TextProc,LoadDoc,PageExtract,FullDoc,Merge process\nclass Chunk,Batch operator\nclass CheckInput,CheckMode,CheckChunk,CheckMerge,CheckConsol decision\nclass Single data\nclass Final,Graph output\n</code></pre> <p>```</p>"},{"location":"fundamentals/extraction-process/#key-concepts","title":"Key Concepts","text":""},{"location":"fundamentals/extraction-process/#1-document-conversion","title":"1. Document Conversion","text":"<p>Transform raw documents into structured format:  <code>python from docling_graph.core.extractors import DocumentProcessor  processor = DocumentProcessor(docling_config=\"ocr\") document = processor.convert_to_docling_doc(\"document.pdf\")</code></p> <p>Learn more: Document Conversion \u2192</p>"},{"location":"fundamentals/extraction-process/#2-chunking","title":"2. Chunking","text":"<p>Split documents intelligently:</p> <pre><code>from docling_graph.core.extractors import DocumentChunker\n\nchunker = DocumentChunker(\n    tokenizer_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n    chunk_max_tokens=512\n)\nchunks = chunker.chunk_document(document)\n</code></pre> <p>Learn more: Chunking Strategies \u2192</p>"},{"location":"fundamentals/extraction-process/#3-extraction","title":"3. Extraction","text":"<p>Extract structured data:</p> <pre><code>from docling_graph.core.extractors import ExtractorFactory\n\nextractor = ExtractorFactory.create_extractor(\n    processing_mode=\"many-to-one\",\n    backend_name=\"llm\",\n    extraction_contract=\"direct\",  # or \"staged\" / \"delta\" for complex or chunk-based extraction\n    llm_client=client,\n)\nmodels, doc = extractor.extract(source, template)\n</code></pre> <p>Learn more: Extraction Backends \u2192</p>"},{"location":"fundamentals/extraction-process/#4-merging","title":"4. Merging","text":"<p>Consolidate multiple models:</p> <pre><code>from docling_graph.core.utils import merge_pydantic_models\n\nmerged = merge_pydantic_models(models, template)\n</code></pre> <p>Learn more: Model Merging \u2192</p>"},{"location":"fundamentals/extraction-process/#performance-optimization","title":"Performance Optimization","text":""},{"location":"fundamentals/extraction-process/#chunking-vs-no-chunking","title":"Chunking vs No Chunking","text":"Approach Speed Accuracy Memory Best For Chunking Fast High Low Large docs No Chunking Slow Medium High Small docs"},{"location":"fundamentals/extraction-process/#batch-processing","title":"Batch Processing","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    use_chunking=True,\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/#error-handling","title":"Error Handling","text":""},{"location":"fundamentals/extraction-process/#extraction-errors","title":"Extraction Errors","text":"<pre><code>from docling_graph.exceptions import ExtractionError\n\ntry:\n    run_pipeline(config)\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n    print(f\"Details: {e.details}\")\n</code></pre>"},{"location":"fundamentals/extraction-process/#pipeline-errors","title":"Pipeline Errors","text":"<pre><code>from docling_graph.exceptions import PipelineError\n\ntry:\n    run_pipeline(config)\nexcept PipelineError as e:\n    print(f\"Pipeline failed at stage: {e.details['stage']}\")\n</code></pre>"},{"location":"fundamentals/extraction-process/#section-contents","title":"Section Contents","text":""},{"location":"fundamentals/extraction-process/#1-document-conversion_1","title":"1. Document Conversion","text":"<p>Learn how documents are converted to structured format using Docling pipelines.</p> <p>Topics: - OCR vs Vision pipelines - Layout analysis - Table extraction - Multi-language support</p>"},{"location":"fundamentals/extraction-process/#2-chunking-strategies","title":"2. Chunking Strategies","text":"<p>Understand intelligent document chunking for optimal LLM processing.</p> <p>Topics: - Structure-aware chunking - Token management - Semantic boundaries - Provider-specific optimization</p>"},{"location":"fundamentals/extraction-process/#3-extraction-backends","title":"3. Extraction Backends","text":"<p>Deep dive into LLM and VLM extraction backends.</p> <p>Topics: - LLM backend (text-based) - VLM backend (vision-based) - Backend selection - Extraction contracts (direct, staged, delta)</p>"},{"location":"fundamentals/extraction-process/#4-staged-extraction","title":"4. Staged Extraction","text":"<p>Multi-pass extraction for complex nested templates (ID pass \u2192 fill pass \u2192 merge).</p> <p>Topics: - When to use staged - Tuning (presets, parallel_workers, fill cap, id shard size)</p>"},{"location":"fundamentals/extraction-process/#5-delta-extraction","title":"5. Delta Extraction","text":"<p>Chunk-based graph extraction: token-bounded batches \u2192 flat graph IR \u2192 normalize \u2192 merge \u2192 projection.</p> <p>Topics: - When to use delta - Batch planning, IR normalizer, resolvers, quality gate - Configuration (llm_batch_token_size, parallel_workers, delta_* options)</p>"},{"location":"fundamentals/extraction-process/#6-model-merging","title":"6. Model Merging","text":"<p>Learn how multiple extractions are consolidated into single models.</p> <p>Topics: - Programmatic merging - LLM consolidation - Conflict resolution - Validation strategies</p>"},{"location":"fundamentals/extraction-process/#7-batch-processing","title":"7. Batch Processing","text":"<p>Optimize extraction with intelligent batching.</p> <p>Topics: - Chunk batching - Context window management - Adaptive batch sizing - Performance tuning</p>"},{"location":"fundamentals/extraction-process/#8-pipeline-orchestration","title":"8. Pipeline Orchestration","text":"<p>Understand how pipeline stages are coordinated through the extraction process.</p> <p>Topics: - Stage execution - Context management - Error handling - Resource cleanup</p>"},{"location":"fundamentals/extraction-process/#quick-examples","title":"Quick Examples","text":""},{"location":"fundamentals/extraction-process/#basic-extraction","title":"\ud83d\udccd Basic Extraction","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"local\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/#high-accuracy-extraction","title":"\ud83d\udccd High-Accuracy Extraction","text":"<pre><code>config = PipelineConfig(\n    source=\"complex_document.pdf\",\n    template=\"templates.ScholarlyRheologyPaper\",\n    backend=\"vlm\",              # Vision backend\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\"     # Vision pipeline\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/#optimized-for-large-documents","title":"\ud83d\udccd Optimized for Large Documents","text":"<pre><code>config = PipelineConfig(\n    source=\"large_document.pdf\",\n    template=\"templates.Contract\",\n    backend=\"llm\",\n    use_chunking=True,\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/#choose-the-right-backend","title":"\ud83d\udc4d Choose the Right Backend","text":"<pre><code># \u2705 Good - Match backend to document type\nif document_has_complex_layout:\n    backend = \"vlm\"\nelse:\n    backend = \"llm\"\n</code></pre>"},{"location":"fundamentals/extraction-process/#enable-chunking-for-large-documents","title":"\ud83d\udc4d Enable Chunking for Large Documents","text":"<pre><code># \u2705 Good - Use chunking for efficiency\nconfig = PipelineConfig(\n    source=\"large_doc.pdf\",\n    template=\"templates.BillingDocument\",\n    use_chunking=True  # Recommended\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/#extraction-returns-empty-results","title":"\ud83d\udc1b Extraction Returns Empty Results","text":"<p>Solution: <pre><code># Check document conversion\nprocessor = DocumentProcessor()\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\nmarkdown = processor.extract_full_markdown(document)\n\nif not markdown.strip():\n    print(\"Document conversion failed\")\n</code></pre></p>"},{"location":"fundamentals/extraction-process/#out-of-memory","title":"\ud83d\udc1b Out of Memory","text":"<p>Solution: <pre><code># Enable chunking and reduce batch size\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    use_chunking=True,\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/#slow-extraction","title":"\ud83d\udc1b Slow Extraction","text":"<p>Solution: <pre><code># Use local backend for faster inference\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"local\"\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/#next-steps","title":"Next Steps","text":"<p>Ready to dive deeper? Start with:</p> <ol> <li>Document Conversion \u2192 - Learn about Docling pipelines</li> <li>Chunking Strategies \u2192 - Optimize document splitting</li> <li>Extraction Backends \u2192 - Choose the right backend</li> </ol>"},{"location":"fundamentals/extraction-process/batch-processing/","title":"Batch Processing","text":""},{"location":"fundamentals/extraction-process/batch-processing/#overview","title":"Overview","text":"<p>Batch processing optimizes extraction by grouping multiple chunks into single LLM calls, reducing API overhead while maximizing context window utilization.</p> <p>In this guide: - Why batching matters - Adaptive batching algorithm - Context window optimization - Performance tuning - Best practices</p>"},{"location":"fundamentals/extraction-process/batch-processing/#why-batching-matters","title":"Why Batching Matters","text":""},{"location":"fundamentals/extraction-process/batch-processing/#the-api-call-problem","title":"The API Call Problem","text":"<p>Without batching:</p> <pre><code># 10 chunks = 10 API calls\nfor chunk in chunks:  # 10 iterations\n    model = llm.extract(chunk)  # 10 API calls\n    models.append(model)\n\n# Cost: 10 \u00d7 API_COST\n# Time: 10 \u00d7 LATENCY\n</code></pre> <p>With batching:</p> <pre><code># 10 chunks = 3 batches = 3 API calls\nbatches = batcher.batch_chunks(chunks)  # Group into 3 batches\nfor batch in batches:  # 3 iterations\n    model = llm.extract(batch.combined_text)  # 3 API calls\n    models.append(model)\n\n# Cost: 3 \u00d7 API_COST (70% savings)\n# Time: 3 \u00d7 LATENCY (70% faster)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#chunkbatcher","title":"ChunkBatcher","text":""},{"location":"fundamentals/extraction-process/batch-processing/#what-is-chunkbatcher","title":"What is ChunkBatcher?","text":"<p>ChunkBatcher intelligently groups chunks to fit within context windows, minimizing API calls while preserving semantic boundaries.</p>"},{"location":"fundamentals/extraction-process/batch-processing/#architecture","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"10 Chunks\" }\n\n    B@{ shape: procs, label: \"Greedy Packing\" }\n    C@{ shape: doc, label: \"5 Candidate Batches\" }\n\n    D@{ shape: lin-proc, label: \"Merge Undersized\" }\n    E@{ shape: doc, label: \"3 Final Batches\" }\n\n    F@{ shape: tag-proc, label: \"3 API Calls\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,D process\n    class C,E data\n    class F output</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#basic-usage","title":"Basic Usage","text":""},{"location":"fundamentals/extraction-process/batch-processing/#initialize-batcher","title":"Initialize Batcher","text":"<pre><code>from docling_graph.core.extractors import ChunkBatcher\n\n# Create batcher with context constraints\nbatcher = ChunkBatcher(\n    context_limit=8000,          # Total context window\n    system_prompt_tokens=500,    # System prompt overhead\n    response_buffer_tokens=500,  # Response space\n    merge_threshold=0.95         # Merge if &lt;95% utilized (default)\n)\n\n# Available for content: 8000 - 500 - 500 = 7000 tokens\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#batch-chunks","title":"Batch Chunks","text":"<pre><code># Batch your chunks\nbatches = batcher.batch_chunks(chunks)\n\nprint(f\"Reduced {len(chunks)} chunks to {len(batches)} batches\")\n\n# Process batches\nfor batch in batches:\n    print(f\"Batch {batch.batch_id}: {batch.chunk_count} chunks\")\n    print(f\"  Tokens: {batch.total_tokens}\")\n    print(f\"  Utilization: {batch.total_tokens / 7000 * 100:.1f}%\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#batching-algorithm","title":"Batching Algorithm","text":""},{"location":"fundamentals/extraction-process/batch-processing/#phase-1-greedy-packing","title":"Phase 1: Greedy Packing","text":"<p>Strategy: Pack chunks sequentially until context limit reached</p> <pre><code>current_batch = []\ncurrent_tokens = 0\n\nfor chunk in chunks:\n    chunk_tokens = estimate_tokens(chunk) + OVERHEAD\n\n    if current_tokens + chunk_tokens &gt; available_tokens:\n        # Start new batch\n        batches.append(current_batch)\n        current_batch = [chunk]\n        current_tokens = chunk_tokens\n    else:\n        # Add to current batch\n        current_batch.append(chunk)\n        current_tokens += chunk_tokens\n</code></pre> <p>Result: Candidate batches that fit context window</p>"},{"location":"fundamentals/extraction-process/batch-processing/#phase-2-merge-undersized","title":"Phase 2: Merge Undersized","text":"<p>Strategy: Combine small batches to improve utilization</p> <pre><code>threshold = available_tokens * merge_threshold  # e.g., 95% (default)\n\nfor batch in batches:\n    if batch.total_tokens &lt; threshold:\n        # Try to merge with next batch\n        if can_merge_with_next(batch):\n            merge_batches(batch, next_batch)\n</code></pre> <p>Result: Optimized batches with high utilization</p>"},{"location":"fundamentals/extraction-process/batch-processing/#chunkbatch-object","title":"ChunkBatch Object","text":""},{"location":"fundamentals/extraction-process/batch-processing/#structure","title":"Structure","text":"<pre><code>@dataclass\nclass ChunkBatch:\n    batch_id: int              # Batch sequence number\n    chunks: List[str]          # Chunk texts\n    total_tokens: int          # Estimated tokens\n    chunk_indices: List[int]   # Original indices\n\n    @property\n    def chunk_count(self) -&gt; int:\n        return len(self.chunks)\n\n    @property\n    def combined_text(self) -&gt; str:\n        # Chunks with separators\n        return \"\\n\\n---CHUNK BOUNDARY---\\n\\n\".join(chunks)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#usage","title":"Usage","text":"<pre><code>batch = batches[0]\n\nprint(f\"Batch ID: {batch.batch_id}\")\nprint(f\"Chunks: {batch.chunk_count}\")\nprint(f\"Tokens: {batch.total_tokens}\")\nprint(f\"Indices: {batch.chunk_indices}\")\n\n# Get combined text for LLM\ncombined = batch.combined_text\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#token-estimation","title":"Token Estimation","text":""},{"location":"fundamentals/extraction-process/batch-processing/#estimation-methods","title":"Estimation Methods","text":""},{"location":"fundamentals/extraction-process/batch-processing/#1-heuristic-default","title":"1. Heuristic (Default)","text":"<pre><code># Fast but approximate\ntokens = len(text) // 4  # ~4 chars per token\n</code></pre> <p>Pros: Fast, no dependencies Cons: Approximate (\u00b120% error)</p>"},{"location":"fundamentals/extraction-process/batch-processing/#2-custom-tokenizer","title":"2. Custom Tokenizer","text":"<pre><code>from transformers import AutoTokenizer\n\n# Accurate token counting\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n\ndef count_tokens(text: str) -&gt; int:\n    return len(tokenizer.encode(text))\n\n# Use with batcher\nbatches = batcher.batch_chunks(chunks, tokenizer_fn=count_tokens)\n</code></pre> <p>Pros: Accurate Cons: Slower, requires tokenizer</p>"},{"location":"fundamentals/extraction-process/batch-processing/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"fundamentals/extraction-process/batch-processing/#context-limit","title":"Context Limit","text":"<p>Definition: Total context window size</p> <pre><code>batcher = ChunkBatcher(\n    context_limit=8000  # Mistral: 32K, GPT-4: 128K, Llama: 8K\n)\n</code></pre> <p>How to choose: - Use model's actual context limit - Be conservative (leave buffer) - Account for prompt overhead</p>"},{"location":"fundamentals/extraction-process/batch-processing/#system-prompt-tokens","title":"System Prompt Tokens","text":"<p>Definition: Tokens used by system prompt</p> <pre><code>batcher = ChunkBatcher(\n    context_limit=8000,\n    system_prompt_tokens=500  # Typical: 300-700\n)\n</code></pre> <p>Includes: - Extraction instructions - Schema definition - Example format</p>"},{"location":"fundamentals/extraction-process/batch-processing/#response-buffer-tokens","title":"Response Buffer Tokens","text":"<p>Definition: Space reserved for LLM response</p> <pre><code>batcher = ChunkBatcher(\n    context_limit=8000,\n    response_buffer_tokens=500  # Typical: 500-1000\n)\n</code></pre> <p>Depends on: - Schema complexity - Expected output size - Safety margin</p>"},{"location":"fundamentals/extraction-process/batch-processing/#merge-threshold","title":"Merge Threshold","text":"<p>Definition: Minimum utilization before merging (default: 95%)</p> <pre><code>batcher = ChunkBatcher(\n    context_limit=8000,\n    merge_threshold=0.95  # Merge if &lt;95% utilized (default)\n)\n</code></pre> <p>Effects: - Higher (0.95-0.98): More batches, better fit, less merging - Lower (0.80-0.90): Fewer batches, more aggressive merging</p> <p>Default: 95% for all providers. This ensures efficient batching while maintaining good chunk boundaries.</p>"},{"location":"fundamentals/extraction-process/batch-processing/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/extraction-process/batch-processing/#basic-batching","title":"\ud83d\udccd Basic Batching","text":"<pre><code>from docling_graph.core.extractors import ChunkBatcher, DocumentChunker, DocumentProcessor\n\n# Convert and chunk document\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"large_document.pdf\")\n\nchunker = DocumentChunker(provider=\"mistral\")\nchunks = chunker.chunk_document(document)\n\nprint(f\"Created {len(chunks)} chunks\")\n\n# Batch chunks\nbatcher = ChunkBatcher(\n    context_limit=32000,  # Mistral Large\n    system_prompt_tokens=500,\n    response_buffer_tokens=500,\n    merge_threshold=0.95  # Default: 95%\n)\n\nbatches = batcher.batch_chunks(chunks)\n\nprint(f\"Reduced to {len(batches)} batches\")\nprint(f\"API call reduction: {(1 - len(batches)/len(chunks)) * 100:.0f}%\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#with-custom-tokenizer","title":"\ud83d\udccd With Custom Tokenizer","text":"<pre><code>from docling_graph.core.extractors import ChunkBatcher\nfrom transformers import AutoTokenizer\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n\ndef count_tokens(text: str) -&gt; int:\n    return len(tokenizer.encode(text))\n\n# Batch with accurate token counting\nbatcher = ChunkBatcher(context_limit=8000)\nbatches = batcher.batch_chunks(chunks, tokenizer_fn=count_tokens)\n\nprint(f\"Accurate batching: {len(batches)} batches\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#integration-with-extraction","title":"\ud83d\udccd Integration with Extraction","text":"<pre><code>from docling_graph.core.extractors.backends import LlmBackend\nfrom docling_graph.llm_clients import get_client\nfrom docling_graph.llm_clients.config import resolve_effective_model_config\n\n# Initialize backend\neffective = resolve_effective_model_config(\"mistral\", \"mistral-large-latest\")\nclient = get_client(\"mistral\")(model_config=effective)\nbackend = LlmBackend(llm_client=client)\n\n# Batch chunks\nbatcher = ChunkBatcher(context_limit=32000)\nbatches = batcher.batch_chunks(chunks)\n\n# Extract from batches\nmodels = []\nfor batch in batches:\n    print(f\"Processing batch {batch.batch_id} ({batch.chunk_count} chunks)\")\n\n    model = backend.extract_from_markdown(\n        markdown=batch.combined_text,\n        template=InvoiceTemplate,\n        context=f\"batch {batch.batch_id}\",\n        is_partial=True\n    )\n\n    if model:\n        models.append(model)\n\nprint(f\"Extracted {len(models)} models from {len(batches)} batches\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#automatic-batching-in-pipeline","title":"\ud83d\udccd Automatic Batching in Pipeline","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Batching happens automatically\nconfig = PipelineConfig(\n    source=\"large_document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\",\n    use_chunking=True  # Enables automatic batching\n)\n\nrun_pipeline(config)\n\n# ChunkBatcher is used internally to optimize API calls\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#performance-optimization","title":"Performance Optimization","text":""},{"location":"fundamentals/extraction-process/batch-processing/#batch-size-vs-api-calls","title":"Batch Size vs API Calls","text":"Chunks No Batching With Batching Reduction 10 10 calls 3 calls 70% 20 20 calls 5 calls 75% 50 50 calls 12 calls 76% 100 100 calls 23 calls 77%"},{"location":"fundamentals/extraction-process/batch-processing/#cost-savings","title":"Cost Savings","text":"<pre><code># Example: Mistral Large API\nAPI_COST_PER_CALL = $0.002  # Input tokens\n\n# Without batching: 50 chunks\ncost_without = 50 * API_COST_PER_CALL = $0.10\n\n# With batching: 12 batches\ncost_with = 12 * API_COST_PER_CALL = $0.024\n\n# Savings: 76%\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#context-utilization","title":"Context Utilization","text":""},{"location":"fundamentals/extraction-process/batch-processing/#measuring-utilization","title":"Measuring Utilization","text":"<pre><code>batches = batcher.batch_chunks(chunks)\n\nfor batch in batches:\n    utilization = batch.total_tokens / batcher.available_tokens * 100\n    print(f\"Batch {batch.batch_id}: {utilization:.1f}% utilized\")\n\n# Average utilization\navg_util = sum(b.total_tokens for b in batches) / (len(batches) * batcher.available_tokens) * 100\nprint(f\"Average utilization: {avg_util:.1f}%\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#optimization-tips","title":"Optimization Tips","text":"<pre><code># \u2705 Good - High utilization (90-95%)\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    merge_threshold=0.95  # Default: merge if &lt;95% utilized\n)\n\n# \u274c Bad - Low utilization (&lt;70%)\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    merge_threshold=0.5  # Too aggressive merging\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/batch-processing/#match-context-limit-to-model","title":"\ud83d\udc4d Match Context Limit to Model","text":"<pre><code># \u2705 Good - Use actual model limits\nif model == \"mistral-large\":\n    context_limit = 32000\nelif model == \"gpt-4-turbo\":\n    context_limit = 128000\nelif model == \"llama3.1:8b\":\n    context_limit = 8000\n\nbatcher = ChunkBatcher(context_limit=context_limit)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#leave-adequate-buffer","title":"\ud83d\udc4d Leave Adequate Buffer","text":"<pre><code># \u2705 Good - Conservative buffers\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    system_prompt_tokens=500,  # Adequate\n    response_buffer_tokens=500  # Safe margin\n)\n\n# \u274c Bad - Insufficient buffer\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    system_prompt_tokens=100,  # Too small\n    response_buffer_tokens=100  # Risky\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#use-merge-threshold-wisely","title":"\ud83d\udc4d Use Merge Threshold Wisely","text":"<pre><code># \u2705 Good - Default balance (recommended)\nbatcher = ChunkBatcher(\n    merge_threshold=0.95  # Default: 95% - good balance\n)\n\n# For many small chunks (more aggressive merging)\nbatcher = ChunkBatcher(\n    merge_threshold=0.85  # More aggressive merging\n)\n\n# For few large chunks (less merging)\nbatcher = ChunkBatcher(\n    merge_threshold=0.98  # Minimal merging, better fit\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#monitor-batch-statistics","title":"\ud83d\udc4d Monitor Batch Statistics","text":"<pre><code># \u2705 Good - Check batching effectiveness\nbatches = batcher.batch_chunks(chunks)\n\nreduction = (1 - len(batches) / len(chunks)) * 100\nprint(f\"API call reduction: {reduction:.0f}%\")\n\nif reduction &lt; 50:\n    print(\"Warning: Low batching efficiency\")\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/batch-processing/#too-many-batches","title":"\ud83d\udc1b Too Many Batches","text":"<p>Batching not reducing API calls enough</p> <p>Solution: <pre><code># Lower merge threshold for more aggressive merging\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    merge_threshold=0.85  # More aggressive (default is 0.95)\n)\n\n# Or increase context limit if model supports it\nbatcher = ChunkBatcher(\n    context_limit=16000  # Use larger context\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/batch-processing/#batches-too-large","title":"\ud83d\udc1b Batches Too Large","text":"<p>Batches exceeding context limit</p> <p>Solution: <pre><code># Increase buffer sizes\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    system_prompt_tokens=700,  # More buffer (was 500)\n    response_buffer_tokens=700  # More buffer (was 500)\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/batch-processing/#low-utilization","title":"\ud83d\udc1b Low Utilization","text":"<p>Batches not filling context window</p> <p>Solution: <pre><code># Increase merge threshold (closer to default 0.95)\nbatcher = ChunkBatcher(\n    context_limit=8000,\n    merge_threshold=0.98  # Less merging, better fit (default is 0.95)\n)\n\n# Or use smaller chunks\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=3000  # Smaller chunks\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/batch-processing/#advanced-techniques","title":"Advanced Techniques","text":""},{"location":"fundamentals/extraction-process/batch-processing/#custom-batch-processing","title":"Custom Batch Processing","text":"<pre><code>from docling_graph.core.extractors import ChunkBatcher\n\ndef process_with_retry(batches, backend, template):\n    \"\"\"Process batches with retry logic.\"\"\"\n    models = []\n\n    for batch in batches:\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                model = backend.extract_from_markdown(\n                    markdown=batch.combined_text,\n                    template=template,\n                    context=f\"batch {batch.batch_id}\",\n                    is_partial=True\n                )\n\n                if model:\n                    models.append(model)\n                    break\n\n            except Exception as e:\n                if attempt == max_retries - 1:\n                    print(f\"Failed batch {batch.batch_id} after {max_retries} attempts\")\n                else:\n                    print(f\"Retry {attempt + 1} for batch {batch.batch_id}\")\n\n    return models\n</code></pre>"},{"location":"fundamentals/extraction-process/batch-processing/#next-steps","title":"Next Steps","text":"<p>Now that you understand batch processing:</p> <ol> <li>Graph Management \u2192 - Work with knowledge graphs</li> <li>Export Formats \u2192 - Export graphs</li> <li>Visualization \u2192 - Visualize graphs</li> </ol>"},{"location":"fundamentals/extraction-process/chunking-strategies/","title":"Chunking Strategies","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#overview","title":"Overview","text":"<p>Chunking is the process of intelligently splitting documents into optimal pieces for LLM processing. Docling Graph uses structure-aware chunking that preserves document semantics, tables, and hierarchies.</p> <p>In this guide: - Why chunking matters - Structure-aware vs naive chunking - Real tokenizer integration - Token management with safety margins - Schema-aware chunking - Provider-specific optimization - Performance tuning</p> <p>New: Real Tokenizer Integration</p> <p>Docling Graph now uses real tokenizers for accurate token counting instead of character-based heuristics. This prevents context window overflows and enables more efficient chunk packing with a 20% safety margin.</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#why-chunking-matters","title":"Why Chunking Matters","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#the-context-window-problem","title":"The Context Window Problem","text":"<p>LLMs have limited context windows:</p> Provider Model Context Limit OpenAI GPT-4 Turbo 128K tokens Mistral Mistral Large 32K tokens Ollama Llama 3.1 8B 8K tokens IBM Granite 4.0 8K tokens <p>Problem: Most documents exceed these limits.</p> <p>Solution: Intelligent chunking.</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#chunking-approaches","title":"Chunking Approaches","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#naive-chunking","title":"\u274c Naive Chunking","text":"<pre><code># \u274c Bad - Breaks tables and structure\ndef naive_chunk(text, max_chars=1000):\n    return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]\n</code></pre> <p>Problems: - Breaks tables mid-row - Splits lists - Ignores semantic boundaries - Loses context</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#structure-aware-chunking","title":"\u2705 Structure-Aware Chunking","text":"<pre><code># \u2705 Good - Preserves structure\nfrom docling_graph.core.extractors import DocumentChunker\n\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096\n)\n\nchunks = chunker.chunk_document(document)\n</code></pre> <p>Benefits: - Preserves tables - Keeps lists intact - Respects sections - Maintains context</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#documentchunker","title":"DocumentChunker","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#basic-usage","title":"Basic Usage","text":"<pre><code>import json\n\nfrom docling_graph.core.extractors import DocumentChunker, DocumentProcessor\nfrom my_templates import ContractTemplate\n\n# Initialize processor\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n\n# Initialize chunker\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096\n)\n\n# Chunk document\nchunks = chunker.chunk_document(document)\n\nprint(f\"Created {len(chunks)} chunks\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#configuration-options","title":"Configuration Options","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#by-provider","title":"By Provider","text":"<pre><code># Automatic configuration for provider\nchunker = DocumentChunker(\n    provider=\"mistral\",  # Auto-configures for Mistral\n    merge_peers=True\n)\n</code></pre> <p>Supported providers: - <code>mistral</code> - Mistral AI models - <code>openai</code> - OpenAI models - <code>ollama</code> - Ollama local models - <code>watsonx</code> - IBM watsonx models - <code>google</code> - Google Gemini models</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#custom-tokenizer","title":"Custom Tokenizer","text":"<pre><code># Use specific tokenizer\nchunker = DocumentChunker(\n    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n    max_tokens=4096,\n    merge_peers=True\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#custom-max-tokens","title":"Custom Max Tokens","text":"<pre><code># Override max tokens\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=8000,  # Custom limit\n    merge_peers=True\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#structure-preservation","title":"Structure Preservation","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#what-gets-preserved","title":"What Gets Preserved?","text":"<p>The HybridChunker preserves:</p> <ol> <li>Tables - Never split across chunks</li> <li>Lists - Kept intact</li> <li>Sections - With headers</li> <li>Hierarchies - Parent-child relationships</li> <li>Semantic boundaries - Natural breaks</li> </ol>"},{"location":"fundamentals/extraction-process/chunking-strategies/#example-table-preservation","title":"Example: Table Preservation","text":"<p>Input document: <pre><code># Sales Report\n\n| Product | Q1 | Q2 | Q3 | Q4 |\n|---------|----|----|----|----|\n| A       | 10 | 15 | 20 | 25 |\n| B       | 5  | 10 | 15 | 20 |\n</code></pre></p> <p>Chunking result: <pre><code># \u2705 Table stays together in one chunk\nchunks = [\n    \"# Sales Report\\n\\n| Product | Q1 | Q2 | Q3 | Q4 |\\n...\"\n]\n</code></pre></p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#context-enrichment","title":"Context Enrichment","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#what-is-context-enrichment","title":"What is Context Enrichment?","text":"<p>Chunks are contextualized with metadata: - Section headers - Parent sections - Document structure - Page numbers</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#example","title":"Example","text":"<p>Original text: <pre><code>Product A costs $50.\n</code></pre></p> <p>Contextualized chunk: <pre><code># BillingDocument INV-001\n## Line Items\n### Product Details\n\nProduct A costs $50.\n</code></pre></p> <p>Why it matters: LLM understands context better.</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#real-tokenizer-integration","title":"Real Tokenizer Integration","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#accurate-token-counting","title":"Accurate Token Counting","text":"<p>Docling Graph uses real tokenizers instead of character-based heuristics:</p> <pre><code>from docling_graph.core.extractors import DocumentChunker\n\n# \u2705 Good - Real tokenizer (accurate)\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096\n)\n# Uses Mistral's actual tokenizer for precise counting\n\n# \u274c Old approach - Character heuristic (inaccurate)\n# estimated_tokens = len(text) / 4  # Rough approximation\n</code></pre> <p>Benefits:</p> Feature Character Heuristic Real Tokenizer Accuracy ~70% 95%+ Context Overflows Occasional Rare Chunk Efficiency 60-70% 80-90% Provider-Specific No Yes"},{"location":"fundamentals/extraction-process/chunking-strategies/#how-it-works","title":"How It Works","text":"<pre><code># Behind the scenes:\n# 1. Load provider-specific tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n\n# 2. Count tokens accurately\ntokens = tokenizer.encode(text)\ntoken_count = len(tokens)\n\n# 3. Apply safety margin (20%)\nsafe_limit = int(max_tokens * 0.8)\n\n# 4. Chunk based on actual token count\nif token_count &gt; safe_limit:\n    # Split into multiple chunks\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#safety-margins","title":"Safety Margins","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#why-safety-margins","title":"Why Safety Margins?","text":"<p>Even with real tokenizers, we apply a 20% safety margin:</p> <pre><code># Example: Model with 8192 token context\nmax_tokens = 8192\n\n# Effective limit with 20% safety margin\nsafe_limit = int(max_tokens * 0.8)  # 6553 tokens\n\n# Why?\n# - Schema takes tokens (~500-2000)\n# - System prompts take tokens (~200-500)\n# - Response buffer needed (~500-1000)\n# - Edge cases and variations\n</code></pre> <p>Safety Margin Breakdown:</p> Component Token Usage Example (8K context) Document chunk 80% 6553 tokens Schema 10-15% 819-1228 tokens System prompt 3-5% 245-409 tokens Response buffer 5-10% 409-819 tokens"},{"location":"fundamentals/extraction-process/chunking-strategies/#configuring-safety-margins","title":"Configuring Safety Margins","text":"<pre><code># Default: 20% safety margin (recommended)\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096  # Effective: ~3276 tokens per chunk\n)\n\n# For aggressive batching (not recommended):\n# Modify ChunkBatcher.batch_chunks merge_threshold\n# But this increases risk of context overflows\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#token-management","title":"Token Management","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#token-counting-with-statistics","title":"Token Counting with Statistics","text":"<pre><code># Get detailed token statistics\nchunks, stats = chunker.chunk_document_with_stats(document)\n\nprint(f\"Total chunks: {stats['total_chunks']}\")\nprint(f\"Average tokens: {stats['avg_tokens']:.0f}\")\nprint(f\"Max tokens: {stats['max_tokens_in_chunk']}\")\nprint(f\"Total tokens: {stats['total_tokens']}\")\nprint(f\"Safety margin: {(1 - stats['max_tokens_in_chunk']/max_tokens)*100:.1f}%\")\n</code></pre> <p>Output: <pre><code>Total chunks: 5\nAverage tokens: 3200\nMax tokens: 3950\nTotal tokens: 16000\nSafety margin: 3.5%\n</code></pre></p> <p>Monitor Safety Margins</p> <p>If <code>max_tokens_in_chunk</code> is &gt; 95% of <code>max_tokens</code>, consider:</p> <ul> <li>Reducing <code>max_tokens</code> parameter</li> <li>Increasing schema efficiency</li> <li>Splitting large tables</li> </ul>"},{"location":"fundamentals/extraction-process/chunking-strategies/#schema-aware-chunking","title":"Schema-Aware Chunking","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#dynamic-adjustment-based-on-schema","title":"Dynamic Adjustment Based on Schema","text":"<p>Chunk size automatically adjusts based on schema complexity:</p> <pre><code>import json\n\nfrom my_templates import ComplexTemplate\n\n# Schema-aware chunking\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    schema_json=json.dumps(ComplexTemplate.model_json_schema())\n)\n\n# Behind the scenes:\n# 1. Build prompt skeleton with schema JSON and empty content\n# 2. Count exact tokens for system + user prompt\n# 3. max_tokens = context_limit - static_overhead - reserved_output - safety_margin\n# 4. Chunk with the adjusted limit\nchunks = chunker.chunk_document(document)\n</code></pre> <p>Schema Size Impact:</p> <p>Chunk size is computed from exact prompt token counts, so larger schemas reduce available content tokens deterministically without heuristic ratios.</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#update-schema-configuration","title":"Update Schema Configuration","text":"<pre><code># Update schema JSON after initialization\nchunker = DocumentChunker(provider=\"mistral\")\n\n# Later, update for different template\nfrom my_templates import LargeTemplate\n\nimport json\n\nchunker.update_schema_config(\n    schema_json=json.dumps(LargeTemplate.model_json_schema())\n)\n\n# Chunker now uses adjusted limits\nchunks = chunker.chunk_document(document)\n</code></pre> <p>Schema Optimization</p> <p>To maximize chunk size:</p> <ul> <li>Keep schemas focused and minimal</li> <li>Use field descriptions sparingly</li> <li>Avoid deeply nested structures</li> <li>Consider splitting large schemas</li> </ul>"},{"location":"fundamentals/extraction-process/chunking-strategies/#merge-peers-option","title":"Merge Peers Option","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#what-is-merge-peers","title":"What is Merge Peers?","text":"<p>Merge peers combines sibling sections when they fit together:</p> <pre><code># Enable merge peers (default)\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    merge_peers=True  # Combine related sections\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#example_1","title":"Example","text":"<p>Without merge_peers: <pre><code>chunks = [\n    \"## Section 1\\nContent 1\",\n    \"## Section 2\\nContent 2\",\n    \"## Section 3\\nContent 3\"\n]\n</code></pre></p> <p>With merge_peers: <pre><code>chunks = [\n    \"## Section 1\\nContent 1\\n\\n## Section 2\\nContent 2\",\n    \"## Section 3\\nContent 3\"\n]\n</code></pre></p> <p>Benefit: Fewer chunks, better context.</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#integration-with-pipeline","title":"Integration with Pipeline","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#automatic-chunking","title":"Automatic Chunking","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    use_chunking=True  # Automatic chunking (default)\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#disable-chunking","title":"Disable Chunking","text":"<pre><code>config = PipelineConfig(\n    source=\"small_document.pdf\",\n    template=\"templates.BillingDocument\",\n    use_chunking=False  # Process full document\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#basic-chunking","title":"\ud83d\udccd Basic Chunking","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker, DocumentProcessor\n\n# Convert document\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n\n# Chunk with Mistral settings\nchunker = DocumentChunker(provider=\"mistral\")\nchunks = chunker.chunk_document(document)\n\nprint(f\"Created {len(chunks)} chunks\")\nfor i, chunk in enumerate(chunks, 1):\n    print(f\"Chunk {i}: {len(chunk)} characters\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#with-statistics","title":"\ud83d\udccd With Statistics","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker, DocumentProcessor\n\n# Convert and chunk\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"large_document.pdf\")\n\n# Get detailed statistics\nchunker = DocumentChunker(provider=\"openai\", max_tokens=8000)\nchunks, stats = chunker.chunk_document_with_stats(document)\n\nprint(f\"Chunking Statistics:\")\nprint(f\"  Total chunks: {stats['total_chunks']}\")\nprint(f\"  Average tokens: {stats['avg_tokens']:.0f}\")\nprint(f\"  Max tokens: {stats['max_tokens_in_chunk']}\")\nprint(f\"  Total tokens: {stats['total_tokens']}\")\n\n# Check if any chunk exceeds limit\nif stats['max_tokens_in_chunk'] &gt; 8000:\n    print(\"Warning: Some chunks exceed token limit!\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#custom-configuration","title":"\ud83d\udccd Custom Configuration","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker, DocumentProcessor\n\n# Custom chunker for specific use case\nchunker = DocumentChunker(\n    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n    max_tokens=6000,  # Conservative limit\n    merge_peers=True,\n    schema_json=json.dumps(ContractTemplate.model_json_schema()),\n)\n\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"contract.pdf\")\n\nchunks = chunker.chunk_document(document)\nprint(f\"Created {len(chunks)} optimized chunks\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#fallback-text-chunking","title":"\ud83d\udccd Fallback Text Chunking","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker\n\n# For raw text (when DoclingDocument unavailable)\nchunker = DocumentChunker(provider=\"mistral\")\n\nraw_text = \"\"\"\nLong text content that needs to be chunked...\n\"\"\"\n\nchunks = chunker.chunk_text_fallback(raw_text)\nprint(f\"Created {len(chunks)} text chunks\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#provider-specific-optimization","title":"Provider-Specific Optimization","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#mistral-ai","title":"Mistral AI","text":"<pre><code>chunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096  # Optimized for Mistral Large\n)\n</code></pre> <p>Context limit: 32K tokens Recommended chunk size: 4096 tokens (with 20% safety margin) Effective chunk size: ~3276 tokens Tokenizer: Mistral-7B-Instruct-v0.2 (real tokenizer)</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#openai","title":"OpenAI","text":"<pre><code>chunker = DocumentChunker(\n    provider=\"openai\",\n    max_tokens=8000  # Optimized for GPT-4\n)\n</code></pre> <p>Context limit: 128K tokens Recommended chunk size: 8000 tokens (with 20% safety margin) Effective chunk size: ~6400 tokens Tokenizer: tiktoken (GPT-4) (real tokenizer)</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#ollama-local","title":"Ollama (Local)","text":"<pre><code>chunker = DocumentChunker(\n    provider=\"ollama\",\n    max_tokens=3500  # Conservative for 8K context\n)\n</code></pre> <p>Context limit: 8K tokens (typical) Recommended chunk size: 3500 tokens (with 20% safety margin) Effective chunk size: ~2800 tokens Tokenizer: Model-specific (real tokenizer when available)</p> <p>Ollama Tokenizer Fallback</p> <p>If model-specific tokenizer is unavailable, falls back to character heuristic with extra safety margin (75% instead of 80%).</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#ibm-watsonx","title":"IBM watsonx","text":"<pre><code>chunker = DocumentChunker(\n    provider=\"watsonx\",\n    max_tokens=3500  # Optimized for Granite\n)\n</code></pre> <p>Context limit: 8K tokens Recommended chunk size: 3500 tokens (with 20% safety margin) Effective chunk size: ~2800 tokens Tokenizer: Granite-specific (real tokenizer)</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#google-gemini","title":"Google Gemini","text":"<pre><code>chunker = DocumentChunker(\n    provider=\"google\",\n    max_tokens=6000  # Optimized for Gemini\n)\n</code></pre> <p>Context limit: 32K-128K tokens (model-dependent) Recommended chunk size: 6000 tokens (with 20% safety margin) Effective chunk size: ~4800 tokens Tokenizer: Gemini-specific (real tokenizer)</p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#performance-tuning","title":"Performance Tuning","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#chunk-size-vs-accuracy","title":"Chunk Size vs Accuracy","text":"Chunk Size Accuracy Speed Memory Small (2K) Lower Fast Low Medium (4K) Good Medium Medium Large (8K) Best Slow High"},{"location":"fundamentals/extraction-process/chunking-strategies/#recommendations","title":"Recommendations","text":"<pre><code># \u2705 Good - Balance accuracy and speed\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096  # Sweet spot\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#chunks-too-large","title":"\ud83d\udc1b Chunks Too Large","text":"<p>Solution: <pre><code># Reduce max_tokens\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=3000  # Smaller chunks\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#too-many-chunks","title":"\ud83d\udc1b Too Many Chunks","text":"<p>Solution: <pre><code># Increase max_tokens and enable merge_peers\nchunker = DocumentChunker(\n    provider=\"openai\",\n    max_tokens=8000,  # Larger chunks\n    merge_peers=True  # Combine sections\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#tables-split-across-chunks","title":"\ud83d\udc1b Tables Split Across Chunks","text":"<p>Solution: <pre><code># This shouldn't happen with HybridChunker\n# If it does, increase max_tokens\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=6000  # Larger to fit tables\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#out-of-memory","title":"\ud83d\udc1b Out of Memory","text":"<p>Solution: <pre><code># Use smaller chunks\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=2000,  # Smaller chunks\n    merge_peers=False  # Don't combine\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/chunking-strategies/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#match-provider","title":"\ud83d\udc4d Match Provider","text":"<pre><code># \u2705 Good - Match chunker to LLM provider\nif using_mistral:\n    chunker = DocumentChunker(provider=\"mistral\")\nelif using_openai:\n    chunker = DocumentChunker(provider=\"openai\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#enable-merge-peers","title":"\ud83d\udc4d Enable Merge Peers","text":"<pre><code># \u2705 Good - Better context\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    merge_peers=True  # Recommended\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#monitor-statistics","title":"\ud83d\udc4d Monitor Statistics","text":"<pre><code># \u2705 Good - Check chunk distribution\nchunks, stats = chunker.chunk_document_with_stats(document)\n\nif stats['max_tokens_in_chunk'] &gt; max_tokens * 0.95:\n    print(\"Warning: Chunks near limit\")\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#adjust-for-schema-complexity","title":"\ud83d\udc4d Adjust for Schema Complexity","text":"<pre><code># \u2705 Good - Account for schema JSON\nimport json\n\nschema_json = json.dumps(template.model_json_schema())\n\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    schema_json=schema_json  # Dynamic adjustment\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#advanced-features","title":"Advanced Features","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#custom-tokenizer_1","title":"Custom Tokenizer","text":"<pre><code>from transformers import AutoTokenizer\nfrom docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n\n# Load custom tokenizer\nhf_tokenizer = AutoTokenizer.from_pretrained(\"custom/model\")\ncustom_tokenizer = HuggingFaceTokenizer(\n    tokenizer=hf_tokenizer,\n    max_tokens=4096\n)\n\n# Use with HybridChunker\nfrom docling.chunking import HybridChunker\n\nchunker = HybridChunker(\n    tokenizer=custom_tokenizer,\n    merge_peers=True\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#recommended-chunk-size-calculation","title":"Recommended Chunk Size Calculation","text":"<pre><code>from docling_graph.core.extractors import DocumentChunker\n\n# Calculate recommended size\nrecommended = DocumentChunker.calculate_recommended_max_tokens(\n    context_limit=32000,  # Mistral Large\n    system_prompt_tokens=500,\n    response_buffer_tokens=500\n)\n\nprint(f\"Recommended max_tokens: {recommended}\")\n# Output: Recommended max_tokens: 24800\n</code></pre>"},{"location":"fundamentals/extraction-process/chunking-strategies/#performance-impact","title":"Performance Impact","text":""},{"location":"fundamentals/extraction-process/chunking-strategies/#real-tokenizer-vs-heuristic","title":"Real Tokenizer vs Heuristic","text":"<p>Benchmark Results (100-page document):</p> Method Chunks Created Context Overflows Processing Time API Calls Character Heuristic 45 3 (6.7%) 180s 48 (3 retries) Real Tokenizer 38 0 (0%) 152s 38 (no retries) <p>Improvements:</p> <ul> <li>\u2705 15% fewer chunks (better packing)</li> <li>\u2705 Zero context overflows (vs 6.7%)</li> <li>\u2705 15% faster processing (no retries)</li> <li>\u2705 21% fewer API calls (no retries)</li> </ul>"},{"location":"fundamentals/extraction-process/chunking-strategies/#safety-margin-impact","title":"Safety Margin Impact","text":"Safety Margin Chunk Efficiency Context Overflows Recommended For 10% 90% Occasional Aggressive batching 20% (default) 80% Rare General use 30% 70% Very rare Complex schemas"},{"location":"fundamentals/extraction-process/chunking-strategies/#next-steps","title":"Next Steps","text":"<p>Now that you understand chunking:</p> <ol> <li>Staged Extraction \u2192 - Multi-pass extraction for complex templates</li> <li>Extraction Backends \u2192 - Learn about LLM and VLM backends</li> <li>Batch Processing \u2192 - Optimize chunk processing</li> <li>Model Merging \u2192 - Consolidate chunk extractions</li> <li>Performance Tuning \u2192 - Advanced optimization</li> </ol>"},{"location":"fundamentals/extraction-process/delta-extraction/","title":"Delta Extraction","text":""},{"location":"fundamentals/extraction-process/delta-extraction/#overview","title":"Overview","text":"<p>Delta extraction is an LLM extraction contract for many-to-one processing that turns document chunks into a flat graph IR (nodes and relationships), then normalizes, merges, and projects the result into your Pydantic template. It is designed for long documents and chunk-based workflows.</p> <p>Set <code>extraction_contract=\"delta\"</code> in your config or use <code>--extraction-contract delta</code> on the CLI. Chunking must be enabled (<code>use_chunking=True</code>, which is the default for many-to-one).</p> <p>When to use:</p> <ul> <li>Long documents where you want token-bounded batching (multiple chunks per LLM call, then merge by identity).</li> <li>You prefer a graph-first representation: entities as nodes with <code>path</code>, <code>ids</code>, and <code>parent</code>, then projected to the template.</li> <li>You want optional post-merge resolvers (fuzzy/semantic) to merge near-duplicate entities.</li> </ul> <p>When to use direct (default) or staged:</p> <ul> <li>Direct: Flat or simple templates; single-pass extraction and programmatic merge.</li> <li>Staged: Complex nested templates; ID pass \u2192 fill pass \u2192 merge (no chunk batching).</li> </ul>"},{"location":"fundamentals/extraction-process/delta-extraction/#how-it-works","title":"How It Works","text":"<p>Delta extraction runs these steps:</p> <pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5 5,color:#969696\n\n    %% 2. Define Nodes\n    n1@{ shape: terminal, label: \"Source Chunks\" }\n    n2@{ shape: terminal, label: \"Delta Template Config\" }\n\n    n3@{ shape: procs, label: \"Batch Planning\" }\n    n3a@{ shape: lin-proc, label: \"Greedy Token Packing\" }\n\n    n4@{ shape: tag-proc, label: \"Per-batch LLM\" }\n    n5@{ shape: db, label: \"Raw DeltaGraph\" }\n\n    n6@{ shape: lin-proc, label: \"IR Normalization\" }\n    n7@{ shape: procs, label: \"Graph Merge &amp; Deduplication\" }\n\n    n8@{ shape: tag-proc, label: \"Resolvers (Optional)\" }\n    n9@{ shape: tag-proc, label: \"Identity Filter (Optional)\" }\n\n    n10@{ shape: procs, label: \"Projection\" }\n    n11@{ shape: lin-proc, label: \"Quality Gate Check\" }\n\n    n12@{ shape: tag-proc, label: \"Direct Extraction Fallback\" }\n    n13@{ shape: terminal, label: \"Final Result\" }\n\n    %% 3. Define Connections\n    n1 &amp; n2 --&gt; n3\n    n3 --&gt; n3a\n    n3a --&gt; n4\n    n4 --&gt; n5\n    n5 --&gt; n6\n    n6 --&gt; n7\n\n    %% Sequence of Logic\n    n7 --&gt; n8\n    n8 --&gt; n9\n    n9 --&gt; n10\n    n10 --&gt; n11\n\n    %% Branching Logic\n    n11 -- \"Pass\" --&gt; n13\n    n11 -- \"Fail\" --&gt; n12\n    n12 --&gt; n13\n\n    %% 4. Apply Classes\n    class n1 input\n    class n2 config\n    class n5 data\n    class n3,n7,n10,n11 process\n    class n3a,n6 process\n    class n4,n8,n9,n12 operator\n    class n13 output</code></pre> <ol> <li> <p>Chunking \u2014 Done outside delta (document processor or strategy). Produces chunks and optional chunk metadata (e.g. token counts, page numbers).</p> </li> <li> <p>Batch planning \u2014 Chunks are packed into token-bounded batches (<code>llm_batch_token_size</code>). Each batch is sent in one LLM call.</p> </li> <li> <p>Per-batch LLM \u2014 For each batch, the LLM receives the batch document plus a path catalog and semantic guide from your template. It returns a DeltaGraph: <code>nodes</code> (path, ids, parent, properties) and optional <code>relationships</code>. Output is validated with retries on failure.</p> </li> <li> <p>IR normalization \u2014 Batch results are normalized: paths canonicalized to catalog paths, IDs normalized and optionally inferred from path indices, parent references repaired, nested properties stripped, provenance attached. Unknown paths can be dropped if <code>delta_normalizer_validate_paths</code> is true.</p> </li> <li> <p>Graph merge \u2014 Normalized graphs are merged with deduplication by (path, identity). Node properties are merged (e.g. prefer longer string on conflict). Relationships are deduplicated by edge and endpoints.</p> </li> <li> <p>Resolvers (optional) \u2014 If <code>delta_resolvers_enabled</code> is true, a post-merge pass can merge near-duplicate nodes by fuzzy or semantic similarity (<code>delta_resolvers_mode</code>: <code>fuzzy</code>, <code>semantic</code>, or <code>chain</code>).</p> </li> <li> <p>Identity filter (optional) \u2014 If <code>delta_identity_filter_enabled</code> is true, entity nodes whose identity looks like a section/chapter title are dropped. With <code>delta_identity_filter_strict</code> true, only identities in the schema allowlist are kept.</p> </li> <li> <p>Projection \u2014 The merged graph is projected into a template-shaped root dict: nodes are attached to parents via (path, ids). When a parent is missing (e.g. dropped by the identity filter), a best-effort attachment to the first available parent of the same path is attempted so more nodes stay in the tree.</p> </li> <li> <p>Quality gate \u2014 The gate uses attached node count (nodes that made it into the root tree), not raw graph size. If <code>attached_node_count</code> is below <code>delta_quality_min_instances</code> (default 20) or parent lookup misses exceed the allowed tolerance, the gate fails. On fail, delta returns <code>None</code> and the many-to-one strategy falls back to direct extraction (full-document, single LLM call), which usually yields a richer graph for sparse delta runs.</p> </li> </ol>"},{"location":"fundamentals/extraction-process/delta-extraction/#schema-requirements","title":"Schema Requirements","text":"<p>Delta uses a catalog derived from your Pydantic template (same idea as staged):</p> <ul> <li>Paths \u2014 Root <code>\"\"</code>, then nested paths like <code>line_items[]</code>, <code>line_items[].item</code>. The LLM must use only these catalog paths.</li> <li>Identity \u2014 Entities with <code>graph_id_fields</code> get stable keys for dedup and parent linkage; list items often use a field like <code>line_number</code> or <code>index</code>.</li> <li>Flat properties \u2014 Node and relationship properties must be flat (scalars or lists of scalars). Nested objects are stripped by the normalizer.</li> <li>Root required fields \u2014 Required root-level fields (e.g. <code>reference_document</code>, <code>title</code>) should be documented in the template so the LLM can fill them; the catalog hints the root path to include required root-level fields when present in the document.</li> </ul> <p>For identity and linkage best practices, see Schema design for staged extraction (same concepts apply to delta).</p>"},{"location":"fundamentals/extraction-process/delta-extraction/#configuration-and-options","title":"Configuration and options","text":"<p>All options can be set in Python via <code>PipelineConfig</code> or a config dict passed to <code>run_pipeline()</code>. CLI flags (when available) override config-file defaults.</p>"},{"location":"fundamentals/extraction-process/delta-extraction/#batching-and-parallelism","title":"Batching and parallelism","text":"Python (<code>PipelineConfig</code> / config dict) CLI flag Default Description <code>extraction_contract</code> <code>--extraction-contract</code> <code>\"direct\"</code> Set to <code>\"delta\"</code> to enable delta extraction. <code>use_chunking</code> <code>--use-chunking</code> / <code>--no-use-chunking</code> <code>True</code> Must be enabled for delta (chunk \u2192 batch flow). <code>llm_batch_token_size</code> <code>--llm-batch-token-size</code> <code>1024</code> Max input tokens per LLM batch; a new call is started when a batch would exceed this. <code>parallel_workers</code> <code>--parallel-workers</code> <code>1</code> (or preset) Number of parallel workers for delta batch LLM calls. <code>staged_pass_retries</code> <code>--staged-retries</code> <code>1</code> Retries per batch when the LLM returns invalid JSON (used as <code>max_pass_retries</code> for delta)."},{"location":"fundamentals/extraction-process/delta-extraction/#quality-gate","title":"Quality gate","text":"<p>The gate uses attached node count (nodes successfully attached into the root tree during projection). If the gate fails, delta returns <code>None</code> and the strategy falls back to direct extraction.</p> Python (config dict) Default Description <code>delta_quality_require_root</code> <code>True</code> Require at least one root instance (<code>path=\"\"</code>). <code>delta_quality_min_instances</code> <code>20</code> Minimum attached nodes; below this, gate fails and direct extraction is used. <code>delta_quality_max_parent_lookup_miss</code> <code>4</code> Max allowed parent lookup misses before fail. Use <code>-1</code> to disable this check (e.g. for deep or id-sparse schemas). <code>delta_quality_adaptive_parent_lookup</code> <code>True</code> When root exists, allow higher effective miss tolerance (e.g. up to half of instances, cap 300). <code>delta_quality_require_relationships</code> <code>False</code> Require at least one relationship in the graph."},{"location":"fundamentals/extraction-process/delta-extraction/#identity-filter","title":"Identity filter","text":"Python (config dict) Default Description <code>delta_identity_filter_enabled</code> <code>True</code> Drop entity nodes whose identity looks like a section/chapter title. <code>delta_identity_filter_strict</code> <code>False</code> If true, drop any entity whose identity is not in the schema allowlist (for paths with <code>identity_example_values</code>). If false, only section-title heuristic is applied. <p>Other gate options (e.g. <code>delta_quality_require_structural_attachments</code>, <code>quality_max_unknown_path_drops</code>, <code>quality_max_id_mismatch</code>, <code>quality_max_nested_property_drops</code>) are documented in the config reference. Quality gate and identity filter options are not CLI flags; set them in a config file or config dict.</p>"},{"location":"fundamentals/extraction-process/delta-extraction/#ir-normalizer","title":"IR normalizer","text":"Python (config dict) CLI flag Default Description <code>delta_normalizer_validate_paths</code> <code>--delta-normalizer-validate-paths</code> / <code>--no-delta-normalizer-validate-paths</code> <code>True</code> Drop or repair nodes with unknown catalog paths. <code>delta_normalizer_canonicalize_ids</code> <code>--delta-normalizer-canonicalize-ids</code> / <code>--no-delta-normalizer-canonicalize-ids</code> <code>True</code> Canonicalize ID values before merge. <code>delta_normalizer_strip_nested_properties</code> <code>--delta-normalizer-strip-nested-properties</code> / <code>--no-delta-normalizer-strip-nested-properties</code> <code>True</code> Drop nested dict/list-of-dict properties from nodes and relationships. <code>delta_normalizer_attach_provenance</code> (config only) <code>True</code> Attach batch/chunk provenance to normalized nodes and relationships."},{"location":"fundamentals/extraction-process/delta-extraction/#resolvers-post-merge-dedup","title":"Resolvers (post-merge dedup)","text":"<p>Optional pass to merge near-duplicate entities after the graph merge.</p> Python (config dict) CLI flag Default Description <code>delta_resolvers_enabled</code> <code>--delta-resolvers-enabled</code> / <code>--no-delta-resolvers-enabled</code> <code>True</code> Enable the resolver pass. <code>delta_resolvers_mode</code> <code>--delta-resolvers-mode</code> <code>\"semantic\"</code> One of <code>off</code>, <code>fuzzy</code>, <code>semantic</code>, <code>chain</code>. <code>delta_resolver_fuzzy_threshold</code> <code>--delta-resolver-fuzzy-threshold</code> <code>0.9</code> Similarity threshold for fuzzy matching. <code>delta_resolver_semantic_threshold</code> <code>--delta-resolver-semantic-threshold</code> <code>0.92</code> Similarity threshold for semantic matching. <code>delta_resolver_properties</code> (config only) <code>None</code> List of property names used for matching; default uses catalog fallback fields. <code>delta_resolver_paths</code> (config only) <code>None</code> Restrict resolver to these catalog paths; empty means all."},{"location":"fundamentals/extraction-process/delta-extraction/#gleaning-direct-and-delta","title":"Gleaning (direct and delta)","text":"<p>Optional second-pass extraction (\"what did you miss?\") to improve recall. Applies to direct and delta contracts only (not staged). Enabled by default.</p> Python (<code>PipelineConfig</code> / config dict) CLI flag Default Description <code>gleaning_enabled</code> <code>--gleaning-enabled</code> / <code>--no-gleaning-enabled</code> <code>True</code> Run one extra extraction pass and merge additional entities/relations. <code>gleaning_max_passes</code> <code>--gleaning-max-passes</code> <code>1</code> Max number of gleaning passes when gleaning is enabled."},{"location":"fundamentals/extraction-process/delta-extraction/#usage","title":"Usage","text":""},{"location":"fundamentals/extraction-process/delta-extraction/#python-api","title":"Python API","text":"<p>Pass options via <code>PipelineConfig</code> or a dict to <code>run_pipeline()</code>:</p> <pre><code>from docling_graph import PipelineConfig, run_pipeline\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    processing_mode=\"many-to-one\",\n    extraction_contract=\"delta\",\n    use_chunking=True,\n    # Batching and parallelism\n    llm_batch_token_size=2048,\n    parallel_workers=2,\n    staged_pass_retries=1,\n    # Quality gate (optional overrides)\n    delta_quality_require_root=True,\n    delta_quality_min_instances=1,\n    delta_quality_max_parent_lookup_miss=4,\n    delta_quality_adaptive_parent_lookup=True,\n    # IR normalizer\n    delta_normalizer_validate_paths=True,\n    delta_normalizer_canonicalize_ids=True,\n    delta_normalizer_strip_nested_properties=True,\n    delta_normalizer_attach_provenance=True,\n    # Resolvers (optional)\n    delta_resolvers_enabled=True,\n    delta_resolvers_mode=\"semantic\",\n    delta_resolver_fuzzy_threshold=0.9,\n    delta_resolver_semantic_threshold=0.92,\n    # Gleaning (optional second-pass recall; also applies to direct)\n    gleaning_enabled=True,\n    gleaning_max_passes=1,\n)\ncontext = run_pipeline(config)\n</code></pre> <p>The options <code>delta_quality_require_relationships</code> and <code>delta_quality_require_structural_attachments</code> are not fields on <code>PipelineConfig</code>; set them in a config file (e.g. <code>defaults</code> in your YAML) or in a config dict: <code>run_pipeline({..., \"delta_quality_require_relationships\": False})</code>.</p>"},{"location":"fundamentals/extraction-process/delta-extraction/#cli","title":"CLI","text":"<p>All delta-related flags (when using <code>--extraction-contract delta</code>):</p> <pre><code># Required for delta\nuv run docling-graph convert document.pdf \\\n  --template \"templates.BillingDocument\" \\\n  --extraction-contract delta\n\n# Batching and parallelism\nuv run docling-graph convert document.pdf \\\n  --template \"templates.BillingDocument\" \\\n  --extraction-contract delta \\\n  --use-chunking \\\n  --llm-batch-token-size 2048 \\\n  --parallel-workers 2 \\\n  --staged-retries 1\n\n# IR normalizer (toggles)\nuv run docling-graph convert document.pdf \\\n  --extraction-contract delta \\\n  --template \"templates.BillingDocument\" \\\n  --delta-normalizer-validate-paths \\\n  --delta-normalizer-canonicalize-ids \\\n  --no-delta-normalizer-strip-nested-properties\n\n# Resolvers\nuv run docling-graph convert document.pdf \\\n  --extraction-contract delta \\\n  --template \"templates.BillingDocument\" \\\n  --delta-resolvers-enabled \\\n  --delta-resolvers-mode fuzzy \\\n  --delta-resolver-fuzzy-threshold 0.9 \\\n  --delta-resolver-semantic-threshold 0.92\n</code></pre> <p>Quality gate and resolver list options (<code>delta_resolver_properties</code>, <code>delta_resolver_paths</code>, <code>delta_quality_*</code>, <code>quality_max_*</code>) are not CLI flags; use a config file (e.g. <code>defaults</code> in <code>config_template.yaml</code> or your project config) to set them.</p>"},{"location":"fundamentals/extraction-process/delta-extraction/#trace-and-debugging","title":"Trace and debugging","text":"<p>When delta runs, the pipeline emits a trace (e.g. via <code>trace_data</code> or debug artifacts) containing:</p> <ul> <li><code>contract: \"delta\"</code></li> <li><code>chunk_count</code>, <code>batch_count</code>, <code>batch_timings</code>, <code>batch_errors</code></li> <li><code>path_counts</code>, <code>normalizer_stats</code>, <code>merge_stats</code>, <code>resolver</code> (if enabled)</li> <li><code>quality_gate</code>: <code>{ ok, reasons }</code></li> <li><code>diagnostics</code>: e.g. top missing-id paths, unknown path examples, parent lookup miss examples</li> </ul> <p>With <code>debug=True</code>, artifacts like <code>delta_trace.json</code>, <code>delta_merged_graph.json</code>, and <code>delta_merged_output.json</code> can be written to the debug directory.</p>"},{"location":"fundamentals/extraction-process/delta-extraction/#related","title":"Related","text":"<ul> <li>Staged Extraction \u2014 Multi-pass ID \u2192 fill \u2192 merge (no chunk batching)</li> <li>Extraction Backends \u2014 LLM vs VLM and extraction contracts</li> <li>Configuration reference \u2014 Full config API</li> <li>convert command \u2014 CLI flags for delta</li> </ul>"},{"location":"fundamentals/extraction-process/document-conversion/","title":"Document Conversion","text":""},{"location":"fundamentals/extraction-process/document-conversion/#overview","title":"Overview","text":"<p>Document Conversion is the first stage of the extraction pipeline, transforming raw PDFs and images into structured DoclingDocument format. This stage uses the Docling library to perform OCR, layout analysis, and content extraction.</p> <p>In this guide: - OCR vs Vision pipelines - Layout analysis - Table extraction - Multi-language support - Performance optimization</p>"},{"location":"fundamentals/extraction-process/document-conversion/#docling-pipelines","title":"Docling Pipelines","text":""},{"location":"fundamentals/extraction-process/document-conversion/#quick-comparison","title":"Quick Comparison","text":"Pipeline Best For Speed Accuracy GPU Required OCR Standard documents Fast High No Vision Complex layouts Slower Very High Recommended"},{"location":"fundamentals/extraction-process/document-conversion/#ocr-pipeline-default","title":"OCR Pipeline (Default)","text":""},{"location":"fundamentals/extraction-process/document-conversion/#what-is-ocr-pipeline","title":"What is OCR Pipeline?","text":"<p>The OCR (Optical Character Recognition) pipeline is the default and most accurate for standard documents. It uses traditional OCR engines combined with layout analysis.</p>"},{"location":"fundamentals/extraction-process/document-conversion/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"ocr\"  # Default\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#features","title":"Features","text":"<p>\u2705 Strengths: - Fast processing - High accuracy for text - Excellent table extraction - Multi-language support - No GPU required</p> <p>\u274c Limitations: - May struggle with complex layouts - Less effective for handwriting - Requires clear text</p>"},{"location":"fundamentals/extraction-process/document-conversion/#when-to-use-ocr","title":"When to Use OCR","text":"<p>Use OCR pipeline for: - Standard business documents - Invoices and forms - Reports and contracts - Documents with clear text - Batch processing (faster)</p>"},{"location":"fundamentals/extraction-process/document-conversion/#vision-pipeline","title":"Vision Pipeline","text":""},{"location":"fundamentals/extraction-process/document-conversion/#what-is-vision-pipeline","title":"What is Vision Pipeline?","text":"<p>The Vision pipeline uses Vision-Language Models (VLMs) to understand document layout and content visually, similar to how humans read documents.</p>"},{"location":"fundamentals/extraction-process/document-conversion/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"vision\"  # Vision pipeline\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#features_1","title":"Features","text":"<p>\u2705 Strengths: - Excellent for complex layouts - Handles handwriting better - Understands visual context - Better for images - Robust to noise</p> <p>\u274c Limitations: - Slower processing - Requires more memory - GPU recommended - Higher resource usage</p>"},{"location":"fundamentals/extraction-process/document-conversion/#when-to-use-vision","title":"When to Use Vision","text":"<p>Use Vision pipeline for: - Complex layouts (magazines, brochures) - Handwritten documents - Low-quality scans - Documents with images - Visual-heavy content</p>"},{"location":"fundamentals/extraction-process/document-conversion/#document-processor","title":"Document Processor","text":""},{"location":"fundamentals/extraction-process/document-conversion/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph.core.extractors import DocumentProcessor\n\n# Initialize with OCR pipeline\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\n# Convert document\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n\nprint(f\"Converted {document.num_pages()} pages\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#with-vision-pipeline","title":"With Vision Pipeline","text":"<pre><code># Initialize with Vision pipeline\nprocessor = DocumentProcessor(docling_config=\"vision\")\n\n# Convert document\ndocument = processor.convert_to_docling_doc(\"complex_document.pdf\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#doclingdocument-structure","title":"DoclingDocument Structure","text":""},{"location":"fundamentals/extraction-process/document-conversion/#what-is-doclingdocument","title":"What is DoclingDocument?","text":"<p>A DoclingDocument is a structured representation of your document containing: - Page information - Layout elements - Text content - Tables - Images - Metadata</p>"},{"location":"fundamentals/extraction-process/document-conversion/#accessing-document-data","title":"Accessing Document Data","text":"<pre><code># Get number of pages\nnum_pages = document.num_pages()\n\n# Get page keys\npage_keys = sorted(document.pages.keys())\n\n# Access specific page\npage = document.pages[page_keys[0]]\n\n# Get document metadata\nmetadata = document.metadata\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#markdown-extraction","title":"Markdown Extraction","text":""},{"location":"fundamentals/extraction-process/document-conversion/#full-document-markdown","title":"Full Document Markdown","text":"<pre><code># Extract complete document as markdown\nfull_markdown = processor.extract_full_markdown(document)\n\nprint(f\"Document length: {len(full_markdown)} characters\")\n</code></pre> <p>Output example: <pre><code># Invoice\n\n**Invoice Number:** INV-001\n**Date:** 2024-01-15\n\n## Items\n\n| Description | Quantity | Price |\n|-------------|----------|-------|\n| Product A   | 2        | $50   |\n| Product B   | 1        | $100  |\n\n**Total:** $200\n</code></pre></p>"},{"location":"fundamentals/extraction-process/document-conversion/#per-page-markdown","title":"Per-Page Markdown","text":"<pre><code># Extract markdown for each page\npage_markdowns = processor.extract_page_markdowns(document)\n\nfor i, page_md in enumerate(page_markdowns, 1):\n    print(f\"Page {i}: {len(page_md)} characters\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#layout-analysis","title":"Layout Analysis","text":""},{"location":"fundamentals/extraction-process/document-conversion/#what-is-layout-analysis","title":"What is Layout Analysis?","text":"<p>Layout analysis identifies document structure: - Headers and footers - Sections and paragraphs - Tables and lists - Images and figures - Captions and footnotes</p>"},{"location":"fundamentals/extraction-process/document-conversion/#accessing-layout-information","title":"Accessing Layout Information","text":"<pre><code># Get document structure\nfor page_no, page in document.pages.items():\n    print(f\"Page {page_no}:\")\n\n    # Access layout elements\n    for element in page.elements:\n        print(f\"  - {element.type}: {element.text[:50]}\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#table-extraction","title":"Table Extraction","text":""},{"location":"fundamentals/extraction-process/document-conversion/#automatic-table-detection","title":"Automatic Table Detection","text":"<p>The OCR pipeline automatically detects and extracts tables:</p> <pre><code># Tables are preserved in markdown\nmarkdown = processor.extract_full_markdown(document)\n\n# Tables appear as markdown tables\n# | Column 1 | Column 2 |\n# |----------|----------|\n# | Value 1  | Value 2  |\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#table-structure","title":"Table Structure","text":"<p>Tables are extracted with: - Column headers - Row data - Cell alignment - Merged cells (when possible)</p>"},{"location":"fundamentals/extraction-process/document-conversion/#multi-language-support","title":"Multi-Language Support","text":""},{"location":"fundamentals/extraction-process/document-conversion/#supported-languages","title":"Supported Languages","text":"<p>The OCR pipeline supports multiple languages:</p> <pre><code>from docling_graph.core.extractors import DocumentProcessor\n\n# Default: English and French\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\n# Document will be processed with both languages\ndocument = processor.convert_to_docling_doc(\"multilingual.pdf\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#language-configuration","title":"Language Configuration","text":"<p>Currently configured for: - English (en) - French (fr)</p> <p>Language configuration</p> <p>Language configuration is set in the DocumentProcessor initialization and can be extended by modifying the source code.</p>"},{"location":"fundamentals/extraction-process/document-conversion/#performance-optimization","title":"Performance Optimization","text":""},{"location":"fundamentals/extraction-process/document-conversion/#ocr-pipeline-optimization","title":"OCR Pipeline Optimization","text":"<pre><code>from docling.datamodel.accelerator_options import AcceleratorDevice\n\n# The OCR pipeline is pre-configured with:\n# - 4 threads for parallel processing\n# - Auto device selection (GPU if available)\n# - Optimized table structure matching\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#vision-pipeline-optimization","title":"Vision Pipeline Optimization","text":"<pre><code># Vision pipeline automatically uses:\n# - GPU acceleration (if available)\n# - Optimized batch processing\n# - Memory-efficient processing\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/extraction-process/document-conversion/#basic-ocr-conversion","title":"\ud83d\udccd Basic OCR Conversion","text":"<pre><code>from docling_graph.core.extractors import DocumentProcessor\n\n# Initialize processor\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\n# Convert document\ndocument = processor.convert_to_docling_doc(\"invoice.pdf\")\n\n# Extract markdown\nmarkdown = processor.extract_full_markdown(document)\n\nprint(f\"Converted {document.num_pages()} pages\")\nprint(f\"Markdown length: {len(markdown)} characters\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#vision-pipeline-for-complex-layout","title":"\ud83d\udccd Vision Pipeline for Complex Layout","text":"<pre><code>from docling_graph.core.extractors import DocumentProcessor\n\n# Initialize with vision pipeline\nprocessor = DocumentProcessor(docling_config=\"vision\")\n\n# Convert complex document\ndocument = processor.convert_to_docling_doc(\"magazine.pdf\")\n\n# Extract per-page markdown\npages = processor.extract_page_markdowns(document)\n\nfor i, page in enumerate(pages, 1):\n    print(f\"Page {i}: {len(page)} characters\")\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#batch-processing","title":"\ud83d\udccd Batch Processing","text":"<pre><code>from docling_graph.core.extractors import DocumentProcessor\nfrom pathlib import Path\n\n# Initialize processor once\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\n# Process multiple documents\nfor pdf_file in Path(\"documents\").glob(\"*.pdf\"):\n    print(f\"Processing {pdf_file.name}\")\n\n    document = processor.convert_to_docling_doc(str(pdf_file))\n    markdown = processor.extract_full_markdown(document)\n\n    # Save markdown\n    output_file = pdf_file.with_suffix(\".md\")\n    output_file.write_text(markdown)\n\n# Cleanup resources\nprocessor.cleanup()\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#integration-with-pipeline","title":"Integration with Pipeline","text":""},{"location":"fundamentals/extraction-process/document-conversion/#automatic-conversion","title":"Automatic Conversion","text":"<p>When using PipelineConfig, conversion happens automatically:</p> <pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"ocr\"  # Conversion happens automatically\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#manual-conversion","title":"Manual Conversion","text":"<p>For more control, use DocumentProcessor directly:</p> <pre><code>from docling_graph.core.extractors import DocumentProcessor\n\n# Manual conversion\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n\n# Now use document for extraction\n# ... extraction code ...\n\n# Cleanup\nprocessor.cleanup()\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#export-options","title":"Export Options","text":""},{"location":"fundamentals/extraction-process/document-conversion/#export-docling-json","title":"Export Docling JSON","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_docling_json=True  # Export DoclingDocument as JSON\n)\n</code></pre> <p>Output: <code>outputs/document.json</code></p>"},{"location":"fundamentals/extraction-process/document-conversion/#export-markdown","title":"Export Markdown","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_markdown=True  # Export as markdown\n)\n</code></pre> <p>Output: <code>outputs/document.md</code></p>"},{"location":"fundamentals/extraction-process/document-conversion/#export-per-page-markdown","title":"Export Per-Page Markdown","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_per_page_markdown=True  # Export each page\n)\n</code></pre> <p>Output: <code>outputs/pages/page_001.md</code>, <code>page_002.md</code>, etc.</p>"},{"location":"fundamentals/extraction-process/document-conversion/#advanced-features","title":"Advanced Features","text":""},{"location":"fundamentals/extraction-process/document-conversion/#custom-pipeline-options","title":"Custom Pipeline Options","text":"<p>For advanced use cases, you can customize the pipeline:</p> <pre><code>from docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.datamodel.accelerator_options import AcceleratorOptions, AcceleratorDevice\n\n# Create custom options\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.do_table_structure = True\npipeline_options.ocr_options.lang = [\"en\", \"de\", \"fr\"]  # Multiple languages\n\n# Set accelerator options\npipeline_options.accelerator_options = AcceleratorOptions(\n    num_threads=8,  # More threads\n    device=AcceleratorDevice.CUDA  # Force GPU\n)\n\n# Note: This requires modifying DocumentProcessor source code\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/document-conversion/#conversion-fails","title":"\ud83d\udc1b Conversion Fails","text":"<p>Solution: <pre><code>try:\n    document = processor.convert_to_docling_doc(\"document.pdf\")\nexcept Exception as e:\n    print(f\"Conversion failed: {e}\")\n    # Check if file exists\n    # Check if file is valid PDF\n    # Try with different pipeline\n</code></pre></p>"},{"location":"fundamentals/extraction-process/document-conversion/#poor-ocr-quality","title":"\ud83d\udc1b Poor OCR Quality","text":"<p>Solution: <pre><code># Try Vision pipeline instead\nprocessor = DocumentProcessor(docling_config=\"vision\")\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\n</code></pre></p>"},{"location":"fundamentals/extraction-process/document-conversion/#slow-conversion","title":"\ud83d\udc1b Slow Conversion","text":"<p>Solution: <pre><code># Use OCR pipeline (faster)\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\n# Or process in batches\n# ... batch processing code ...\n</code></pre></p>"},{"location":"fundamentals/extraction-process/document-conversion/#out-of-memory","title":"\ud83d\udc1b Out of Memory","text":"<p>Solution: <pre><code># Process pages individually\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ndocument = processor.convert_to_docling_doc(\"large_doc.pdf\")\n\n# Extract per-page to reduce memory\npages = processor.extract_page_markdowns(document)\n\n# Process each page separately\nfor page in pages:\n    # ... process page ...\n    pass\n\n# Cleanup\nprocessor.cleanup()\n</code></pre></p>"},{"location":"fundamentals/extraction-process/document-conversion/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/document-conversion/#choose-the-right-pipeline","title":"\ud83d\udc4d Choose the Right Pipeline","text":"<pre><code># \u2705 Good - Match pipeline to document type\nif document_is_standard:\n    docling_config = \"ocr\"  # Faster\nelse:\n    docling_config = \"vision\"  # More accurate\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#cleanup-resources","title":"\ud83d\udc4d Cleanup Resources","text":"<pre><code># \u2705 Good - Always cleanup\nprocessor = DocumentProcessor(docling_config=\"ocr\")\ntry:\n    document = processor.convert_to_docling_doc(\"document.pdf\")\n    # ... process document ...\nfinally:\n    processor.cleanup()\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#reuse-processor-for-batch-processing","title":"\ud83d\udc4d Reuse Processor for Batch Processing","text":"<pre><code># \u2705 Good - Reuse processor\nprocessor = DocumentProcessor(docling_config=\"ocr\")\n\nfor pdf_file in pdf_files:\n    document = processor.convert_to_docling_doc(pdf_file)\n    # ... process ...\n\nprocessor.cleanup()\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#export-for-debugging","title":"\ud83d\udc4d Export for Debugging","text":"<pre><code># \u2705 Good - Export markdown for inspection\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_markdown=True,  # Check conversion quality\n    export_per_page_markdown=True  # Debug per page\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/document-conversion/#next-steps","title":"Next Steps","text":"<p>Now that you understand document conversion:</p> <ol> <li>Chunking Strategies \u2192 - Learn intelligent document splitting</li> <li>Extraction Backends \u2192 - Choose LLM or VLM backend</li> <li>Model Merging \u2192 - Consolidate extractions</li> </ol>"},{"location":"fundamentals/extraction-process/extraction-backends/","title":"Extraction Backends","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#overview","title":"Overview","text":"<p>Extraction backends are the engines that extract structured data from documents. Docling Graph supports two types: LLM backends (text-based) and VLM backends (vision-based).</p> <p>In this guide: - LLM vs VLM comparison - Backend selection criteria - Configuration and usage - Extraction contracts (direct, staged, delta) - Performance optimization - Error handling</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#backend-types","title":"Backend Types","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#quick-comparison","title":"Quick Comparison","text":"Feature LLM Backend VLM Backend Input Markdown text Images/PDFs directly Processing Text-based Vision-based Accuracy High for text High for visuals Speed Fast Slower Cost Low (local) / Medium (API) Medium GPU Optional Recommended Best For Standard documents Complex layouts"},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend","title":"LLM Backend","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#what-is-llm-backend","title":"What is LLM Backend?","text":"<p>The LLM (Language Model) backend processes documents as text, using markdown extracted from PDFs. It supports both local and remote models.</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#architecture","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: procs, label: \"Docling Conversion\" }\n    C@{ shape: doc, label: \"Markdown Text\" }\n    D@{ shape: tag-proc, label: \"Chunking Optional\" }\n    E@{ shape: procs, label: \"LLM Extraction\" }\n\n    F@{ shape: doc, label: \"Structured Data\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,E process\n    class C data\n    class D operator\n    class F output</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",           # LLM backend\n    inference=\"local\",       # or \"remote\"\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\"\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#extraction-contracts-llm-backend","title":"Extraction contracts (LLM backend)","text":"<p>For many-to-one extraction with the LLM backend you can choose:</p> <ul> <li>direct (default): Single-pass extraction; chunks are extracted and merged programmatically.</li> <li>staged: Multi-pass extraction (catalog \u2192 ID pass \u2192 fill pass \u2192 merge), better for complex nested templates and weaker models. See Staged Extraction.</li> <li>delta: Chunk \u2192 token-bounded batches \u2192 flat graph IR (nodes/relationships) \u2192 normalize \u2192 merge \u2192 projection; for long documents and graph-first extraction. Requires chunking. See Delta Extraction.</li> </ul>"},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend-features","title":"LLM Backend Features","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#strengths","title":"\u2705 Strengths","text":"<ol> <li>Fast Processing</li> <li>Quick text extraction</li> <li>Efficient chunking</li> <li> <p>Parallel processing</p> </li> <li> <p>Cost Effective</p> </li> <li>Local models are free</li> <li>Remote APIs are affordable</li> <li> <p>No GPU required (local)</p> </li> <li> <p>Flexible</p> </li> <li>Multiple providers</li> <li>Easy to switch models</li> <li> <p>API or local</p> </li> <li> <p>Accurate for Text</p> </li> <li>Excellent for standard documents</li> <li>Good table understanding</li> <li>Strong reasoning</li> </ol>"},{"location":"fundamentals/extraction-process/extraction-backends/#limitations","title":"\u274c Limitations","text":"<ol> <li>Text-Only</li> <li>No visual understanding</li> <li>Relies on OCR quality</li> <li> <p>May miss layout cues</p> </li> <li> <p>Context Limits</p> </li> <li>Requires chunking for large docs</li> <li>May lose cross-page context</li> <li>Needs merging</li> </ol>"},{"location":"fundamentals/extraction-process/extraction-backends/#supported-providers","title":"Supported Providers","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#local-providers","title":"Local Providers","text":"<p>Ollama: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\"\n)\n</code></pre></p> <p>vLLM: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"vllm\",\n    model_override=\"ibm-granite/granite-4.0-1b\"\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#remote-providers","title":"Remote Providers","text":"<p>Mistral AI: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\"\n)\n</code></pre></p> <p>OpenAI: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\"\n)\n</code></pre></p> <p>Google Gemini: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"gemini\",\n    model_override=\"gemini-2.5-flash\"\n)\n</code></pre></p> <p>IBM watsonx: <pre><code>config = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"watsonx\",\n    model_override=\"ibm/granite-13b-chat-v2\"\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend-usage","title":"LLM Backend Usage","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#basic-extraction","title":"Basic Extraction","text":"<pre><code>from docling_graph.core.extractors.backends import LlmBackend\nfrom docling_graph.llm_clients import get_client\nfrom docling_graph.llm_clients.config import resolve_effective_model_config\n\n# Initialize client\neffective = resolve_effective_model_config(\"ollama\", \"llama3.1:8b\")\nclient = get_client(\"ollama\")(model_config=effective)\n\n# Create backend\nbackend = LlmBackend(llm_client=client)\n\n# Extract from markdown\nmodel = backend.extract_from_markdown(\n    markdown=\"# BillingDocument\\n\\nInvoice Number: INV-001\\nTotal: $1000\",\n    template=InvoiceTemplate,\n    context=\"full document\",\n    is_partial=False\n)\n\nprint(model)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#with-consolidation","title":"With Consolidation","text":"<pre><code># Extract from multiple chunks\nmodels = []\nfor chunk in chunks:\n    model = backend.extract_from_markdown(\n        markdown=chunk,\n        template=InvoiceTemplate,\n        context=f\"chunk {i}\",\n        is_partial=True\n    )\n    if model:\n        models.append(model)\n\n# Consolidate with LLM\nfrom docling_graph.core.utils import merge_pydantic_models\n\nprogrammatic_merge = merge_pydantic_models(models, InvoiceTemplate)\n\nfinal_model = backend.consolidate_from_pydantic_models(\n    raw_models=models,\n    programmatic_model=programmatic_merge,\n    template=InvoiceTemplate\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-backend","title":"VLM Backend","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#what-is-vlm-backend","title":"What is VLM Backend?","text":"<p>The VLM (Vision-Language Model) backend processes documents visually, understanding layout, images, and text together like a human would.</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#architecture_1","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    InputPDF@{ shape: terminal, label: \"PDF Document\" }\n    InputImg@{ shape: terminal, label: \"Images\" }\n\n    Convert@{ shape: procs, label: \"PDF to Image&lt;br&gt;Conversion\" }\n    PageImgs@{ shape: doc, label: \"Page Images\" }\n\n    VLM@{ shape: procs, label: \"VLM Processing\" }\n    Understand@{ shape: lin-proc, label: \"Visual Understanding\" }\n    Extract@{ shape: tag-proc, label: \"Direct Extraction\" }\n\n    Output@{ shape: doc, label: \"Pydantic Models\" }\n\n    %% 3. Define Connections\n    %% Path A: PDF requires conversion\n    InputPDF --&gt; Convert\n    Convert --&gt; PageImgs\n    PageImgs --&gt; VLM\n\n    %% Path B: Direct Image Input (Merges here)\n    InputImg --&gt; VLM\n\n    %% Shared Processing Chain\n    VLM --&gt; Understand\n    Understand --&gt; Extract\n    Extract --&gt; Output\n\n    %% 4. Apply Classes\n    class InputPDF,InputImg input\n    class Convert,VLM,Understand process\n    class PageImgs data\n    class Extract operator\n    class Output output</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\",                      # VLM backend\n    inference=\"local\",                  # Only local supported\n    model_override=\"numind/NuExtract-2.0-8B\"\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-backend-features","title":"VLM Backend Features","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#strengths_1","title":"\u2705 Strengths","text":"<ol> <li>Visual Understanding</li> <li>Sees layout and structure</li> <li>Understands images</li> <li> <p>Handles complex formats</p> </li> <li> <p>No Chunking Needed</p> </li> <li>Processes pages directly</li> <li>No context window limits</li> <li> <p>Simpler pipeline</p> </li> <li> <p>Robust to OCR Issues</p> </li> <li>Doesn't rely on OCR</li> <li>Handles poor quality</li> <li> <p>Better for handwriting</p> </li> <li> <p>Layout Aware</p> </li> <li>Understands visual hierarchy</li> <li>Recognizes forms</li> <li>Detects tables visually</li> </ol>"},{"location":"fundamentals/extraction-process/extraction-backends/#limitations_1","title":"\u274c Limitations","text":"<ol> <li>Slower</li> <li>More computation</li> <li>GPU recommended</li> <li> <p>Longer processing time</p> </li> <li> <p>Local Only</p> </li> <li>No remote API support</li> <li>Requires local GPU</li> <li> <p>Higher resource usage</p> </li> <li> <p>Model Size</p> </li> <li>Large models (2B-8B params)</li> <li>More memory needed</li> <li>Longer startup time</li> </ol>"},{"location":"fundamentals/extraction-process/extraction-backends/#supported-models","title":"Supported Models","text":"<p>NuExtract 2.0 (Recommended): <pre><code># 2B model (faster, less accurate)\nmodel_override=\"numind/NuExtract-2.0-2B\"\n\n# 8B model (slower, more accurate)\nmodel_override=\"numind/NuExtract-2.0-8B\"\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-backend-usage","title":"VLM Backend Usage","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#basic-extraction_1","title":"Basic Extraction","text":"<pre><code>from docling_graph.core.extractors.backends import VlmBackend\n\n# Initialize backend\nbackend = VlmBackend(model_name=\"numind/NuExtract-2.0-8B\")\n\n# Extract from document\nmodels = backend.extract_from_document(\n    source=\"document.pdf\",\n    template=InvoiceTemplate\n)\n\nprint(f\"Extracted {len(models)} models\")\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#with-pipeline","title":"With Pipeline","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"complex_form.pdf\",\n    template=\"templates.ApplicationForm\",\n    backend=\"vlm\",\n    inference=\"local\",\n    processing_mode=\"one-to-one\"  # One model per page\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#backend-selection","title":"Backend Selection","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend-criteria","title":"LLM Backend Criteria","text":"<ul> <li>Document is text-heavy  </li> <li>Need fast processing  </li> <li>Want to use remote APIs  </li> <li>Processing many documents  </li> <li>Standard layout  </li> <li>Good OCR quality  </li> </ul>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-backend-criteria","title":"VLM Backend Criteria","text":"<ul> <li>Complex visual layout  </li> <li>Poor OCR quality  </li> <li>Handwritten content  </li> <li>Image-heavy documents  </li> <li>Form-based extraction  </li> <li>Have GPU available  </li> </ul>"},{"location":"fundamentals/extraction-process/extraction-backends/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend-local","title":"\ud83d\udccd LLM Backend (Local)","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.BillingDocument\",\n\n    # LLM backend with Ollama\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n\n    # Optimized settings\n    use_chunking=True,\n    processing_mode=\"many-to-one\",\n\n    output_dir=\"outputs/llm_local\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend-remote","title":"\ud83d\udccd LLM Backend (Remote)","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nimport os\n\n# Set API key\nos.environ[\"MISTRAL_API_KEY\"] = \"your_api_key\"\n\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"templates.Contract\",\n\n    # LLM backend with Mistral API\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n\n    # High accuracy settings\n    use_chunking=True,\n    processing_mode=\"many-to-one\",\n\n    output_dir=\"outputs/llm_remote\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-backend_1","title":"\ud83d\udccd VLM Backend","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"complex_form.pdf\",\n    template=\"templates.ApplicationForm\",\n\n    # VLM backend\n    backend=\"vlm\",\n    inference=\"local\",\n    model_override=\"numind/NuExtract-2.0-8B\",\n\n    # VLM settings\n    processing_mode=\"one-to-one\",  # One model per page\n    docling_config=\"vision\",       # Vision pipeline\n    use_chunking=False,            # VLM doesn't need chunking\n\n    output_dir=\"outputs/vlm\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#hybrid-approach","title":"\ud83d\udccd Hybrid Approach","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\ndef process_document(doc_path: str, doc_type: str):\n    \"\"\"Process document with appropriate backend.\"\"\"\n\n    if doc_type == \"form\":\n        # Use VLM for forms\n        backend = \"vlm\"\n        inference = \"local\"\n        processing_mode = \"one-to-one\"\n    else:\n        # Use LLM for standard docs\n        backend = \"llm\"\n        inference = \"remote\"\n        processing_mode = \"many-to-one\"\n\n    config = PipelineConfig(\n        source=doc_path,\n        template=f\"templates.{doc_type.capitalize()}\",\n        backend=backend,\n        inference=inference,\n        processing_mode=processing_mode\n    )\n\n    run_pipeline(config)\n\n# Process different document types\nprocess_document(\"invoice.pdf\", \"invoice\")  # LLM\nprocess_document(\"form.pdf\", \"form\")        # VLM\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#error-handling","title":"Error Handling","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#llm-backend-errors","title":"LLM Backend Errors","text":"<pre><code>from docling_graph.exceptions import ExtractionError\n\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.BillingDocument\",\n        backend=\"llm\",\n        inference=\"remote\"\n    )\n    run_pipeline(config)\n\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n    print(f\"Details: {e.details}\")\n\n    # Fallback to local\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.BillingDocument\",\n        backend=\"llm\",\n        inference=\"local\"\n    )\n    run_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-backend-errors","title":"VLM Backend Errors","text":"<pre><code>from docling_graph.exceptions import ExtractionError\n\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.BillingDocument\",\n        backend=\"vlm\"\n    )\n    run_pipeline(config)\n\nexcept ExtractionError as e:\n    print(f\"VLM extraction failed: {e.message}\")\n\n    # Fallback to LLM\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.BillingDocument\",\n        backend=\"llm\",\n        inference=\"local\"\n    )\n    run_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#match-backend-to-document-type","title":"\ud83d\udc4d Match Backend to Document Type","text":"<pre><code># \u2705 Good - Choose based on document\nif document_is_form:\n    backend = \"vlm\"\nelif document_is_standard:\n    backend = \"llm\"\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#use-local-for-development","title":"\ud83d\udc4d Use Local for Development","text":"<pre><code># \u2705 Good - Fast iteration\nconfig = PipelineConfig(\n    source=\"test.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"local\"  # Fast for testing\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#use-remote-for-production","title":"\ud83d\udc4d Use Remote for Production","text":"<pre><code># \u2705 Good - Reliable and scalable\nconfig = PipelineConfig(\n    source=\"production.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\"  # Reliable\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/extraction-backends/#cleanup-resources","title":"\ud83d\udc4d Cleanup Resources","text":"<pre><code># \u2705 Good - Always cleanup\nfrom docling_graph.core.extractors.backends import VlmBackend\n\nbackend = VlmBackend(model_name=\"numind/NuExtract-2.0-8B\")\ntry:\n    models = backend.extract_from_document(source, template)\nfinally:\n    backend.cleanup()  # Free GPU memory\n</code></pre> <p>Enhanced GPU Cleanup</p> <p>VLM backend now includes enhanced GPU memory management:</p> <ul> <li>Model-to-CPU Transfer: Moves model to CPU before deletion</li> <li>CUDA Cache Clearing: Explicitly clears GPU cache</li> <li>Memory Tracking: Logs memory usage before/after cleanup</li> <li>Multi-GPU Support: Handles multiple GPU devices</li> </ul> <p>This ensures GPU memory is properly released, especially important for long-running processes.</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#use-real-tokenizers","title":"\ud83d\udc4d Use Real Tokenizers","text":"<pre><code># \u2705 Good - Accurate token counting\nfrom docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n    use_chunking=True  # Uses real tokenizer with 20% safety margin\n)\n</code></pre> <p>Benefits: - Prevents context window overflows - More efficient chunk packing - Better resource utilization</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#llm-returns-empty-results","title":"\ud83d\udc1b LLM Returns Empty Results","text":"<p>Solution: <pre><code># Check markdown extraction\nfrom docling_graph.core.extractors import DocumentProcessor\n\nprocessor = DocumentProcessor()\ndocument = processor.convert_to_docling_doc(\"document.pdf\")\nmarkdown = processor.extract_full_markdown(document)\n\nif not markdown.strip():\n    print(\"Markdown extraction failed\")\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#vlm-out-of-memory","title":"\ud83d\udc1b VLM Out of Memory","text":"<p>Solution: <pre><code># Use smaller model\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\",\n    model_override=\"numind/NuExtract-2.0-2B\"  # Smaller model\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#slow-vlm-processing","title":"\ud83d\udc1b Slow VLM Processing","text":"<p>Solution: <pre><code># Switch to LLM for speed\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",  # Faster\n    inference=\"local\"\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/extraction-backends/#advanced-features","title":"Advanced Features","text":""},{"location":"fundamentals/extraction-process/extraction-backends/#provider-specific-batching","title":"Provider-Specific Batching","text":"<p>Different LLM providers have different optimal batching strategies:</p> <pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# OpenAI - Uses default 95% threshold\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",\n    use_chunking=True  # Automatically uses 95% threshold (default)\n)\n\n# Anthropic - Uses default 95% threshold\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"anthropic\",\n    model_override=\"claude-3-opus\",\n    use_chunking=True  # Automatically uses 95% threshold (default)\n)\n\n# Ollama - Uses default 95% threshold\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n    use_chunking=True  # Automatically uses 95% threshold (default)\n)\n</code></pre> <p>Why Different Thresholds? - OpenAI/Google: Robust to near-limit contexts \u2192 aggressive batching - Anthropic: More conservative \u2192 moderate batching - Ollama/Local: Variable performance \u2192 conservative batching</p>"},{"location":"fundamentals/extraction-process/extraction-backends/#next-steps","title":"Next Steps","text":"<p>Now that you understand extraction backends:</p> <ol> <li>Staged Extraction \u2192 - Multi-pass extraction for complex templates</li> <li>Delta Extraction \u2192 - Chunk-based graph extraction for long documents</li> <li>Model Merging \u2192 - Learn how to consolidate extractions</li> <li>Batch Processing \u2192 - Optimize chunk processing</li> <li>Performance Tuning \u2192 - Advanced optimization</li> </ol>"},{"location":"fundamentals/extraction-process/model-merging/","title":"Model Merging","text":""},{"location":"fundamentals/extraction-process/model-merging/#overview","title":"Overview","text":"<p>Model merging is the process of consolidating multiple Pydantic model instances into a single unified model. This is essential when extracting from multiple chunks or pages.</p> <p>In this guide: - Why merging is needed - Programmatic vs LLM merging - Optional LLM consolidation - Zero data loss strategies - Deduplication strategies - Conflict resolution - Best practices</p>"},{"location":"fundamentals/extraction-process/model-merging/#why-merging-matters","title":"Why Merging Matters","text":""},{"location":"fundamentals/extraction-process/model-merging/#the-multi-extraction-problem","title":"The Multi-Extraction Problem","text":"<p>When processing large documents:</p> <pre><code># Document split into 3 chunks\nchunk_1 = \"Invoice INV-001, Issued by: Acme Corp\"\nchunk_2 = \"Line items: Product A ($50), Product B ($100)\"\nchunk_3 = \"Total: $150, Due date: 2024-01-31\"\n\n# Each chunk produces a partial model\nmodel_1 = BillingDocument(document_no=\"INV-001\", issued_by=Organization(name=\"Acme Corp\"))\nmodel_2 = BillingDocument(line_items=[LineItem(...), LineItem(...)])\nmodel_3 = BillingDocument(total=150, due_date=\"2024-01-31\")\n\n# Need to merge into one complete model\nfinal_model = merge(model_1, model_2, model_3)\n</code></pre> <p>Without merging: Incomplete, fragmented data With merging: Complete, unified model</p>"},{"location":"fundamentals/extraction-process/model-merging/#merging-strategies","title":"Merging Strategies","text":""},{"location":"fundamentals/extraction-process/model-merging/#quick-comparison","title":"Quick Comparison","text":"Strategy Speed Accuracy Cost Use Case Programmatic \u26a1 Fast \ud83d\udfe1 Good Free Default, simple merging LLM consolidation \ud83d\udc22 Slower \ud83d\udfe2 Better $ API cost High accuracy needs <p>Zero Data Loss</p> <p>All merging strategies now implement zero data loss - if merging fails, the system returns partial models instead of empty results.</p>"},{"location":"fundamentals/extraction-process/model-merging/#programmatic-merging","title":"Programmatic Merging","text":""},{"location":"fundamentals/extraction-process/model-merging/#what-is-programmatic-merging","title":"What is Programmatic Merging?","text":"<p>Programmatic merging uses rule-based algorithms to combine models without LLM calls. It's fast, free, and works well for most cases.</p>"},{"location":"fundamentals/extraction-process/model-merging/#how-it-works","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Model 1\" }\n    B@{ shape: terminal, label: \"Model 2\" }\n    C@{ shape: terminal, label: \"Model 3\" }\n\n    D@{ shape: lin-proc, label: \"Deep Merge\" }\n    E@{ shape: tag-proc, label: \"Deduplicate\" }\n    F@{ shape: tag-proc, label: \"Validate\" }\n\n    G@{ shape: doc, label: \"Final Model\" }\n\n    %% 3. Define Connections\n    A &amp; B &amp; C --&gt; D\n\n    D --&gt; E\n    E --&gt; F\n    F --&gt; G\n\n    %% 4. Apply Classes\n    class A,B,C data\n    class D process\n    class E,F operator\n    class G output</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph.core.utils import merge_pydantic_models\n\n# Multiple partial models\nmodels = [\n    BillingDocument(document_no=\"INV-001\", issued_by=Organization(name=\"Acme\")),\n    BillingDocument(line_items=[LineItem(description=\"Product A\", total=50)]),\n    BillingDocument(total=150, due_date=\"2024-01-31\")\n]\n\n# Merge programmatically\nmerged = merge_pydantic_models(models, Invoice)\n\nprint(merged)\n# BillingDocument(\n#     document_no=\"INV-001\",\n#     issued_by=Organization(name=\"Acme\"),\n#     line_items=[LineItem(description=\"Product A\", total=50)],\n#     total=150,\n#     due_date=\"2024-01-31\"\n# )\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#merge-rules","title":"Merge Rules","text":""},{"location":"fundamentals/extraction-process/model-merging/#1-field-overwriting","title":"1. Field Overwriting","text":"<p>Rule: Non-empty values overwrite empty ones</p> <pre><code># Model 1\nBillingDocument(document_no=\"INV-001\", total=None)\n\n# Model 2\nBillingDocument(document_no=None, total=150)\n\n# Merged\nBillingDocument(document_no=\"INV-001\", total=150)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#2-list-concatenation","title":"2. List Concatenation","text":"<p>Rule: Lists are concatenated and deduplicated</p> <pre><code># Model 1\nBillingDocument(line_items=[LineItem(description=\"Product A\")])\n\n# Model 2\nBillingDocument(line_items=[LineItem(description=\"Product B\")])\n\n# Merged\nBillingDocument(line_items=[\n    LineItem(description=\"Product A\"),\n    LineItem(description=\"Product B\")\n])\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#3-nested-object-merging","title":"3. Nested Object Merging","text":"<p>Rule: Nested objects are recursively merged</p> <pre><code># Model 1\nBillingDocument(issued_by=Organization(name=\"Acme\"))\n\n# Model 2\nBillingDocument(issued_by=Organization(address=Address(city=\"Paris\")))\n\n# Merged\nBillingDocument(issued_by=Organization(\n    name=\"Acme\",\n    address=Address(city=\"Paris\")\n))\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#4-entity-deduplication","title":"4. Entity Deduplication","text":"<p>Rule: Duplicate entities are detected and removed</p> <pre><code># Model 1\nBillingDocument(line_items=[LineItem(description=\"Product A\", total=50)])\n\n# Model 2 (duplicate)\nBillingDocument(line_items=[LineItem(description=\"Product A\", total=50)])\n\n# Merged (deduplicated)\nBillingDocument(line_items=[LineItem(description=\"Product A\", total=50)])\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#deduplication-algorithm","title":"Deduplication Algorithm","text":""},{"location":"fundamentals/extraction-process/model-merging/#content-based-hashing","title":"Content-Based Hashing","text":"<p>Entities are deduplicated using content hashing:</p> <pre><code>def entity_hash(entity: dict) -&gt; str:\n    \"\"\"Compute content hash for entity.\"\"\"\n    # Use stable fields (exclude id, __class__)\n    stable_fields = {\n        k: v for k, v in entity.items() \n        if k not in {\"id\", \"__class__\"} and v is not None\n    }\n\n    # Create stable JSON representation\n    content = json.dumps(stable_fields, sort_keys=True)\n\n    # Hash content\n    return hashlib.blake2b(content.encode()).hexdigest()[:16]\n</code></pre> <p>Example: <pre><code># These are considered duplicates\nentity_1 = {\"name\": \"Acme Corp\", \"city\": \"Paris\"}\nentity_2 = {\"name\": \"Acme Corp\", \"city\": \"Paris\"}\n\n# These are different\nentity_3 = {\"name\": \"Acme Corp\", \"city\": \"London\"}\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#llm-consolidation","title":"LLM Consolidation","text":""},{"location":"fundamentals/extraction-process/model-merging/#what-is-llm-consolidation","title":"What is LLM Consolidation?","text":"<p>LLM consolidation uses an LLM to intelligently merge models, resolving conflicts and improving accuracy. The backend merges chunk results programmatically first, then optionally runs an LLM consolidation step.</p>"},{"location":"fundamentals/extraction-process/model-merging/#when-to-use","title":"When to Use","text":"<p>\u2705 Use LLM consolidation when: - High accuracy is needed - Complex conflict resolution required - Budget allows extra API calls</p> <p>\u274c Don't use LLM consolidation when: - Speed is priority - Cost is primary concern - Simple merging sufficient - Processing high volume (&gt;1000 docs)</p>"},{"location":"fundamentals/extraction-process/model-merging/#how-it-works_1","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: procs, label: \"Docling Conversion\" }\n    C@{ shape: doc, label: \"Markdown Text\" }\n    D@{ shape: tag-proc, label: \"Chunking Optional\" }\n    E@{ shape: procs, label: \"LLM Extraction\" }\n\n    F@{ shape: doc, label: \"Structured Data\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,E process\n    class C data\n    class D operator\n    class F output</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\",\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#llm-consolidation-process","title":"LLM Consolidation Process","text":""},{"location":"fundamentals/extraction-process/model-merging/#step-1-programmatic-merge","title":"Step 1: Programmatic Merge","text":"<pre><code># First, merge programmatically\nprogrammatic_model = merge_pydantic_models(raw_models, template)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#step-2-llm-review","title":"Step 2: LLM Review","text":"<pre><code># Then, LLM reviews and improves\nfinal_model = backend.consolidate_from_pydantic_models(\n    raw_models=raw_models,\n    programmatic_model=programmatic_model,\n    template=template\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#step-3-validation","title":"Step 3: Validation","text":"<pre><code># LLM output is validated against schema\nvalidated_model = template.model_validate(llm_output)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#llm-consolidation-prompt","title":"LLM Consolidation Prompt","text":"<p>The LLM receives:</p> <ol> <li>Schema: Pydantic model structure</li> <li>Raw models: All partial extractions</li> <li>Draft model: Programmatic merge result</li> </ol> <p>Task: Create the best possible consolidated model</p>"},{"location":"fundamentals/extraction-process/model-merging/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/extraction-process/model-merging/#basic-programmatic-merge","title":"\ud83d\udccd Basic Programmatic Merge","text":"<pre><code>from docling_graph.core.utils import merge_pydantic_models\nfrom templates.billing_document import BillingDocument, Organization, LineItem\n\n# Partial models from chunks\nmodels = [\n    BillingDocument(\n        document_no=\"INV-001\",\n        issued_by=Organization(name=\"Acme Corp\")\n    ),\n    BillingDocument(\n        line_items=[\n            LineItem(description=\"Product A\", quantity=2, unit_price=50, total=100),\n            LineItem(description=\"Product B\", quantity=1, unit_price=150, total=150)\n        ]\n    ),\n    BillingDocument(\n        subtotal=250,\n        tax=25,\n        total=275,\n        due_date=\"2024-01-31\"\n    )\n]\n\n# Merge\nmerged = merge_pydantic_models(models, Invoice)\n\nprint(f\"Invoice: {merged.document_no}\")\nprint(f\"Issued by: {merged.issued_by.name}\")\nprint(f\"Line items: {len(merged.line_items)}\")\nprint(f\"Total: ${merged.total}\")\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#with-llm-consolidation","title":"\ud83d\udccd With LLM Consolidation","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"templates.Contract\",\n\n    # Enable LLM consolidation\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n\n    # Chunking settings\n    use_chunking=True,\n    processing_mode=\"many-to-one\",\n\n    output_dir=\"outputs/consolidated\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#manual-consolidation","title":"\ud83d\udccd Manual Consolidation","text":"<pre><code>from docling_graph.core.extractors.backends import LlmBackend\nfrom docling_graph.core.utils import merge_pydantic_models\nfrom docling_graph.llm_clients import get_client\nfrom docling_graph.llm_clients.config import resolve_effective_model_config\n\n# Extract from chunks\nmodels = []\nfor chunk in chunks:\n    model = backend.extract_from_markdown(chunk, template, is_partial=True)\n    if model:\n        models.append(model)\n\n# Programmatic merge\nprogrammatic = merge_pydantic_models(models, template)\n\n# LLM consolidation\neffective = resolve_effective_model_config(\"mistral\", \"mistral-large-latest\")\nclient = get_client(\"mistral\")(model_config=effective)\nbackend = LlmBackend(llm_client=client)\n\nfinal = backend.consolidate_from_pydantic_models(\n    raw_models=models,\n    programmatic_model=programmatic,\n    template=template\n)\n\nprint(f\"Consolidated {len(models)} models into 1\")\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#handling-merge-failures","title":"\ud83d\udccd Handling Merge Failures","text":"<pre><code>from docling_graph.core.utils import merge_pydantic_models\n\ntry:\n    merged = merge_pydantic_models(models, template)\n    print(\"\u2705 Merge successful\")\n\nexcept Exception as e:\n    print(f\"\u274c Merge failed: {e}\")\n\n    # Fallback: use first model\n    merged = models[0] if models else template()\n    print(\"Using first model as fallback\")\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#zero-data-loss","title":"Zero Data Loss","text":""},{"location":"fundamentals/extraction-process/model-merging/#what-is-zero-data-loss","title":"What is Zero Data Loss?","text":"<p>Zero data loss ensures that extraction failures never result in completely empty results. Instead, the system returns partial models with whatever data was successfully extracted.</p>"},{"location":"fundamentals/extraction-process/model-merging/#how-it-works_2","title":"How It Works","text":""},{"location":"fundamentals/extraction-process/model-merging/#before-old-behavior","title":"Before (Old Behavior)","text":"<pre><code># If merging failed\ntry:\n    merged = merge_pydantic_models(models, template)\nexcept Exception:\n    return []  # \u274c All data lost!\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#after-zero-data-loss","title":"After (Zero Data Loss)","text":"<pre><code># If merging fails, return partial models\ntry:\n    merged = merge_pydantic_models(models, template)\n    return [merged]\nexcept Exception:\n    # \u2705 Return partial models instead of empty list\n    return models if models else [template()]\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#benefits","title":"Benefits","text":"<p>Data Preservation: <pre><code># Even if consolidation fails, you get partial data\nmodels = [\n    BillingDocument(document_no=\"INV-001\"),  # From chunk 1\n    BillingDocument(line_items=[...]),          # From chunk 2\n    BillingDocument(total=150)                  # From chunk 3\n]\n\n# If merge fails, you still have all 3 partial models\n# Better than nothing!\n</code></pre></p> <p>Graceful Degradation: <pre><code># System continues processing even with errors\nfor document in documents:\n    try:\n        result = process_document(document)\n        # May return merged model or partial models\n        print(f\"Extracted {len(result)} model(s)\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n        # But still got partial data\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#configuration_1","title":"Configuration","text":"<p>Zero data loss is automatic - no configuration needed:</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"many-to-one\"\n    # Zero data loss is always enabled\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#handling-partial-results","title":"\ud83d\udccd Handling Partial Results","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"many-to-one\"\n)\n\nresults = run_pipeline(config)\n\n# Check if we got merged or partial models\nif len(results) == 1:\n    print(\"\u2705 Successfully merged into single model\")\n    merged = results[0]\nelse:\n    print(f\"\u26a0 Got {len(results)} partial models\")\n    # Still useful! Can manually merge or use as-is\n    for i, model in enumerate(results, 1):\n        print(f\"  Model {i}: {model.document_no or 'N/A'}\")\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#conflict-resolution","title":"Conflict Resolution","text":""},{"location":"fundamentals/extraction-process/model-merging/#common-conflicts","title":"Common Conflicts","text":""},{"location":"fundamentals/extraction-process/model-merging/#1-duplicate-entities","title":"1. Duplicate Entities","text":"<p>Problem: Same entity appears multiple times</p> <pre><code># Chunk 1\nOrganization(name=\"Acme Corp\", city=\"Paris\")\n\n# Chunk 2\nOrganization(name=\"Acme Corp\", city=\"Paris\")\n\n# Solution: Deduplicated automatically\nOrganization(name=\"Acme Corp\", city=\"Paris\")  # Only one\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#2-conflicting-values","title":"2. Conflicting Values","text":"<p>Problem: Different values for same field</p> <pre><code># Chunk 1\nBillingDocument(total=150)\n\n# Chunk 2\nBillingDocument(total=275)\n\n# Programmatic: Last value wins\nBillingDocument(total=275)\n\n# LLM: Intelligent resolution\nBillingDocument(total=275)  # LLM chooses correct value\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#3-partial-information","title":"3. Partial Information","text":"<p>Problem: Information spread across chunks</p> <pre><code># Chunk 1\nOrganization(name=\"Acme Corp\")\n\n# Chunk 2\nOrganization(address=Address(city=\"Paris\"))\n\n# Solution: Merged recursively\nOrganization(\n    name=\"Acme Corp\",\n    address=Address(city=\"Paris\")\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#performance-comparison","title":"Performance Comparison","text":""},{"location":"fundamentals/extraction-process/model-merging/#speed-benchmark","title":"Speed Benchmark","text":"Strategy Models Time Throughput Programmatic 5 0.01s 500 merges/s LLM Consolidation 5 3s 0.3 merges/s Programmatic 20 0.05s 400 merges/s LLM Consolidation 20 8s 0.1 merges/s"},{"location":"fundamentals/extraction-process/model-merging/#accuracy-comparison","title":"Accuracy Comparison","text":"Document Type Programmatic LLM Consolidation Improvement Simple invoice 95% 96% +1% Complex contract 88% 94% +6% Multi-page form 90% 95% +5% Rheology research 85% 92% +7%"},{"location":"fundamentals/extraction-process/model-merging/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/extraction-process/model-merging/#use-programmatic-by-default","title":"\ud83d\udc4d Use Programmatic by Default","text":"<pre><code># \u2705 Good - Fast and free\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#enable-standard-llm-for-high-accuracy","title":"\ud83d\udc4d Enable Standard LLM for High Accuracy","text":"<pre><code># \u2705 Good - Better accuracy for important documents\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"templates.Contract\",\n    backend=\"llm\",\n    inference=\"local\",\n    model_override=\"llama3.1:8b\",  # STANDARD tier\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#use-llm-consolidation-for-critical-documents","title":"\ud83d\udc4d Use LLM Consolidation for Critical Documents","text":"<pre><code># \u2705 Good - Higher accuracy for critical data (uses extra LLM call)\nconfig = PipelineConfig(\n    source=\"legal_contract.pdf\",\n    template=\"templates.LegalContract\",\n    backend=\"llm\",\n    inference=\"remote\",\n)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#validate-merged-results","title":"\ud83d\udc4d Validate Merged Results","text":"<pre><code># \u2705 Good - Always validate\nmerged = merge_pydantic_models(models, template)\n\n# Check completeness\nif not merged.document_no:\n    print(\"Warning: Missing invoice number\")\n\nif not merged.line_items:\n    print(\"Warning: No line items\")\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#handle-empty-model-lists","title":"\ud83d\udc4d Handle Empty Model Lists","text":"<pre><code># \u2705 Good - Handle edge cases\nif not models:\n    print(\"No models to merge\")\n    merged = template()  # Empty model\nelse:\n    merged = merge_pydantic_models(models, template)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/extraction-process/model-merging/#duplicate-entities","title":"\ud83d\udc1b Duplicate Entities","text":"<p>Solution: <pre><code># Deduplication is automatic\n# If duplicates persist, check entity fields\n\n# Ensure entities have stable identifiers\nclass Organization(BaseModel):\n    name: str  # Used for deduplication\n    address: Address | None = None\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#lost-information","title":"\ud83d\udc1b Lost Information","text":"<p>Solution: <pre><code># Check if fields are being overwritten\n# Use LLM consolidation for better merging\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#merge-validation-fails","title":"\ud83d\udc1b Merge Validation Fails","text":"<p>Solution: <pre><code># Check merged data structure\ntry:\n    merged = merge_pydantic_models(models, template)\nexcept ValidationError as e:\n    print(f\"Validation errors: {e.errors()}\")\n\n    # Inspect raw merged data\n    dicts = [m.model_dump() for m in models]\n    print(f\"Raw data: {dicts}\")\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#slow-consolidation","title":"\ud83d\udc1b Slow Consolidation","text":"<p>Solution: <pre><code># Disable LLM consolidation for speed\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n)\n</code></pre></p>"},{"location":"fundamentals/extraction-process/model-merging/#advanced-techniques","title":"Advanced Techniques","text":""},{"location":"fundamentals/extraction-process/model-merging/#custom-merge-logic","title":"Custom Merge Logic","text":"<p>For special cases, implement custom merging:</p> <pre><code>from docling_graph.core.utils import merge_pydantic_models\n\ndef custom_merge(models, template):\n    \"\"\"Custom merge with special rules.\"\"\"\n\n    # Start with programmatic merge\n    base = merge_pydantic_models(models, template)\n\n    # Apply custom logic\n    if base.total is None and base.line_items:\n        # Calculate total from line items\n        base.total = sum(item.total for item in base.line_items)\n\n    return base\n\n# Use custom merge\nmerged = custom_merge(models, Invoice)\n</code></pre>"},{"location":"fundamentals/extraction-process/model-merging/#performance-comparison_1","title":"Performance Comparison","text":""},{"location":"fundamentals/extraction-process/model-merging/#consolidation-strategy-comparison","title":"Consolidation Strategy Comparison","text":"Strategy Time Tokens Accuracy Cost (100 docs) Best For Programmatic 0.01s 0 90% $0 Default, high volume LLM consolidation 3s 1500 95% $15 Important documents"},{"location":"fundamentals/extraction-process/model-merging/#next-steps","title":"Next Steps","text":"<p>Now that you understand model merging:</p> <ol> <li>Staged Extraction \u2192 - Multi-pass extraction for complex templates</li> <li>Batch Processing \u2192 - Optimize chunk processing</li> <li>Extraction Backends \u2192 - Understand backends</li> <li>Performance Tuning \u2192 - Optimize consolidation</li> <li>Graph Management \u2192 - Work with knowledge graphs</li> </ol>"},{"location":"fundamentals/extraction-process/staged-extraction/","title":"Staged Extraction - EXPERIMENTAL","text":""},{"location":"fundamentals/extraction-process/staged-extraction/#overview","title":"Overview","text":"<p>Staged extraction is a multi-pass extraction mode for the LLM backend when using many-to-one processing. It is useful for complex nested templates and for models that benefit from smaller, focused tasks.</p> <p>Set <code>extraction_contract=\"staged\"</code> in your config or use <code>--extraction-contract staged</code> on the CLI. Staged currently uses legacy prompt-schema mode only (no API-level structured output) to avoid provider-specific failures; the global <code>structured_output</code> setting does not apply to staged.</p> <p>Experimental feature - Not production-ready</p> <p>Staged extraction is still in an experimental phase.</p> <p>Expect ongoing quality improvements, but also be aware that clean breaks may happen and backward compatibility is not guaranteed yet.</p> <p>When to use:</p> <ul> <li>Nested Pydantic templates with lists and sub-objects (e.g. offers with included guarantees)</li> <li>You want stable identity-first extraction (IDs from the document, then fill)</li> <li>Direct single-pass extraction struggles with consistency</li> </ul> <p>When to use direct (default):</p> <ul> <li>Flat or simple templates</li> <li>You prefer a single extraction pass and programmatic merge</li> </ul>"},{"location":"fundamentals/extraction-process/staged-extraction/#how-it-works","title":"How It Works","text":"<p>Staged extraction runs three conceptual phases:</p> <ol> <li> <p>Catalog \u2014 Built from your Pydantic template. Derives all extractable node types and paths (e.g. root, <code>offres[]</code>, <code>offres[].garanties_incluses[]</code>) and their <code>graph_id_fields</code> and parent rules.</p> </li> <li> <p>ID pass \u2014 The LLM discovers node instances per path with only the identifiers (from <code>graph_id_fields</code>) and parent linkage. Output is a skeleton: path, ids, parent. No full content yet. By default only paths that have identity fields are sent (reducing prompt size and truncation). ID pass can be auto-sharded when the catalog is large (root and top-level paths first); shards run in parallel when <code>parallel_workers</code> &gt; 1.</p> </li> <li> <p>Fill pass \u2014 For each path, the LLM fills full schema content for the skeleton instances. Paths are processed in bottom-up order (leaf paths first). Fill calls can run in parallel. Each path gets a projected schema (no nested child paths in the same call), so root and children stay consistent. Results are merged into the root model by parent linkage.</p> </li> <li> <p>Quality gate \u2014 After merge, a quick check runs (e.g. root instance present, minimum instances). If it fails, the pipeline can fall back to direct extraction so you still get a result; the trace will indicate why (e.g. <code>fallback_reason: \"quality_gate_failed\"</code>).</p> </li> </ol> <p>List paths and many-to-many \u2014 For paths that are lists under another list (e.g. <code>offres[].garanties_incluses[]</code>), the same child entity can belong to multiple parents. The pipeline keeps one descriptor per (parent, child) pair in the ID pass and merge, and fills each unique child once in the fill pass, then reuses that filled object for every parent. That preserves many-to-many relationships in the graph (e.g. one guarantee linked to several offers) without duplicate fill calls.</p> <p></p>"},{"location":"fundamentals/extraction-process/staged-extraction/#schema-requirements","title":"Schema requirements","text":"<p>Staged extraction succeeds when the ID pass can discover node instances (root and nested entities) and the quality gate passes. Your Pydantic template should be designed with that in mind:</p> <ul> <li>Root model must have <code>graph_id_fields</code> so at least one root instance can be discovered.</li> <li>Entities that should appear in the ID pass must have <code>graph_id_fields</code>; use required, short, extractable fields and add schema examples.</li> <li>Components (<code>is_entity=False</code>) are not identity paths by default; use <code>edge()</code> with <code>edge_label</code> when they must appear in the catalog.</li> <li>Keep nesting depth and catalog size reasonable to avoid truncation and excessive sharding.</li> </ul> <p>For a domain-agnostic checklist, identity best practices, and troubleshooting (e.g. mapping <code>missing_root_instance</code> or <code>insufficient_id_instances</code> to schema fixes), see Schema design for staged extraction.</p>"},{"location":"fundamentals/extraction-process/staged-extraction/#staged-friendly-template-guidelines","title":"Staged-friendly template guidelines","text":"<p>Templates with many nested entities (e.g. <code>list[Exclusion]</code> with <code>Exclusion</code> containing <code>list[Bien]</code>) produce a large catalog and more ID-pass shards. That can lead to slower runs, more truncation, and retries. To keep the ID pass fast and reliable:</p> <ul> <li>Prefer <code>list[str]</code> (or other shallow types) for high-cardinality nested concepts when you only need labels or short values (e.g. exclusion titles, bien names). The catalog does not create node paths for <code>list[str]</code>, so you get fewer paths and smaller ID responses.</li> <li>Reserve nested Pydantic entities (<code>list[SomeModel]</code>) for when you need full structure and identity in the graph (e.g. deduplication by id, edges to other entities).</li> </ul> <p>Example: the MRH insurance template has a full variant (<code>docs/examples/templates/cgv_mrh.py</code>) with <code>Garantie.exclusions_specifiques: list[Exclusion]</code> and <code>Exclusion.biens_exclus: list[Bien]</code>, which yields many catalog paths. The staged-optimized variant (<code>docs/examples/templates/cgv_mrh_staged.py</code>) uses <code>exclusions_specifiques: list[str]</code> and <code>biens_couverts: list[str]</code> on <code>Garantie</code>/<code>Option</code>, reducing catalog size and ID pass time while still filling the root structure. Use the staged variant when you want faster extraction and do not need full entity nodes for every exclusion or bien.</p>"},{"location":"fundamentals/extraction-process/staged-extraction/#configuration-and-options","title":"Configuration and options","text":"<p>All options can be set in Python via <code>PipelineConfig</code> or a config dict passed to <code>run_pipeline()</code>. CLI flags (when available) override config-file defaults.</p>"},{"location":"fundamentals/extraction-process/staged-extraction/#preset-and-overrides","title":"Preset and overrides","text":"<p>The preset (<code>standard</code> or <code>advanced</code>) sets default values for retries, workers, fill cap, and ID shard size. Overrides apply when provided.</p> Python (<code>PipelineConfig</code> / config dict) CLI flag Default Description <code>extraction_contract</code> <code>--extraction-contract</code> <code>\"direct\"</code> Set to <code>\"staged\"</code> to enable staged extraction. <code>staged_tuning_preset</code> <code>--staged-tuning</code> <code>\"standard\"</code> Preset: <code>\"standard\"</code> or <code>\"advanced\"</code> (advanced = larger ID shards, larger fill batches). <code>staged_pass_retries</code> <code>--staged-retries</code> preset (<code>standard</code>: 2) Retries per staged pass when the LLM returns invalid JSON. <code>parallel_workers</code> <code>--parallel-workers</code> preset (<code>standard</code>: 1) Parallel workers for the fill pass and for the ID pass shards; also used for delta. <code>staged_nodes_fill_cap</code> <code>--staged-nodes-fill-cap</code> preset (<code>standard</code>: 5) Max node instances per LLM call in the fill pass. <code>staged_id_shard_size</code> <code>--staged-id-shard-size</code> preset (<code>standard</code>: 0) Paths per ID-pass call; <code>0</code> = no sharding or auto-shard when catalog is large."},{"location":"fundamentals/extraction-process/staged-extraction/#id-pass","title":"ID pass","text":"Python (config dict) CLI flag Default Description <code>staged_id_identity_only</code> (config only) <code>True</code> Use only paths with identity fields in the ID pass (smaller prompts). <code>staged_id_compact_prompt</code> (config only) <code>True</code> Use compact ID prompt and omit full schema in user message. <code>staged_id_auto_shard_threshold</code> (config only) <code>10</code> If catalog paths exceed this and shard size is 0, auto-enable sharding. <code>staged_id_shard_min_size</code> (config only) <code>2</code> Minimum paths per shard when auto-sharding. <code>staged_id_max_tokens</code> <code>--staged-id-max-tokens</code> <code>16384</code> Max tokens for ID pass responses; avoids truncation on large catalogs. Set to <code>None</code> to use client default. <code>staged_fill_max_tokens</code> <code>--staged-fill-max-tokens</code> <code>None</code> Max tokens for fill pass responses; <code>None</code> = client default."},{"location":"fundamentals/extraction-process/staged-extraction/#quality-gate","title":"Quality gate","text":"<p>When the quality gate fails (e.g. no root instance, too few instances), the pipeline returns direct extraction instead of the staged result. Check the trace for <code>quality_gate</code> and <code>fallback_reason</code>.</p> Python (config dict) Default Description <code>staged_quality_require_root</code> <code>True</code> Require at least one root instance; if not met, gate fails. <code>staged_quality_min_instances</code> <code>1</code> Minimum total skeleton instances for gate. <code>staged_quality_max_parent_lookup_miss</code> <code>0</code> Max allowed parent lookup misses before gate fails. <p>Quality gate options are not CLI flags; set them in a config file or config dict.</p>"},{"location":"fundamentals/extraction-process/staged-extraction/#usage","title":"Usage","text":""},{"location":"fundamentals/extraction-process/staged-extraction/#python-api","title":"Python API","text":"<p>Pass options via <code>PipelineConfig</code> or a dict to <code>run_pipeline()</code>:</p> <pre><code>from docling_graph import PipelineConfig, run_pipeline\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyNestedTemplate\",\n    backend=\"llm\",\n    processing_mode=\"many-to-one\",\n    extraction_contract=\"staged\",\n    staged_tuning_preset=\"standard\",  # or \"advanced\"\n    # Optional overrides (preset defaults applied when not set):\n    # staged_pass_retries=2,\n    # parallel_workers=2,\n    # staged_nodes_fill_cap=5,\n    # staged_id_shard_size=0,\n    # staged_id_max_tokens=16384,  # default; set None for client default\n    # staged_fill_max_tokens=None,\n    # staged_quality_require_root=True,\n    # staged_quality_min_instances=1,\n    # staged_quality_max_parent_lookup_miss=0,\n)\ncontext = run_pipeline(config)\n</code></pre>"},{"location":"fundamentals/extraction-process/staged-extraction/#cli","title":"CLI","text":"<p>Staged-related flags (when using <code>--extraction-contract staged</code>):</p> <pre><code># Enable staged\nuv run docling-graph convert document.pdf \\\n  --template \"templates.MyNestedTemplate\" \\\n  --processing-mode many-to-one \\\n  --extraction-contract staged\n\n# Preset and overrides\nuv run docling-graph convert document.pdf \\\n  --template \"templates.MyNestedTemplate\" \\\n  --extraction-contract staged \\\n  --staged-tuning standard \\\n  --staged-retries 2 \\\n  --parallel-workers 2 \\\n  --staged-nodes-fill-cap 5 \\\n  --staged-id-shard-size 0\n\n# Token limits (e.g. to avoid truncation)\nuv run docling-graph convert document.pdf \\\n  --template \"templates.MyNestedTemplate\" \\\n  --extraction-contract staged \\\n  --staged-id-max-tokens 8192 \\\n  --staged-fill-max-tokens 8192\n</code></pre> <p>Options such as <code>staged_id_identity_only</code>, <code>staged_id_compact_prompt</code>, <code>staged_id_auto_shard_threshold</code>, and <code>staged_quality_*</code> have no CLI flags; set them in a config file or in a config dict when using the Python API.</p> <p>See Configuration reference and convert command for the full list.</p> <p>When to adjust:</p> <ul> <li>Structured output: Staged uses legacy prompt-schema mode only (no API structured output); the global <code>structured_output</code> setting does not apply to staged.</li> <li>Truncation or invalid ID output: Default <code>staged_id_max_tokens=16384</code> reduces ID-pass truncation; increase or set <code>staged_fill_max_tokens</code> if fill responses are cut off.</li> <li>Slow ID pass or \u201cResponse Truncated\u201d: For large catalogs or long documents, the ID pass can hit the response token limit, causing truncation, validation errors, retries, and shard splits\u2014and much longer runtimes. Set <code>staged_id_max_tokens</code> explicitly (e.g. <code>16384</code> or <code>32768</code>) via CLI <code>--staged-id-max-tokens</code> or config so ID responses are less likely to truncate; this reduces retries and speeds up the ID pass.</li> <li>Staged fallback to direct: If the trace shows <code>fallback_reason: \"quality_gate_failed\"</code>, check <code>quality_gate.reasons</code> (e.g. missing root instance). Relax <code>staged_quality_require_root</code> or <code>staged_quality_min_instances</code> only if your template legitimately has no root or very few instances.</li> <li>Large catalogs: Defaults use identity-only paths and auto-sharding; tune <code>staged_id_auto_shard_threshold</code> or <code>staged_id_shard_size</code> via config if the ID pass is still too heavy. For very large catalogs, also increase <code>staged_id_max_tokens</code> to avoid truncation and extra retries.</li> </ul>"},{"location":"fundamentals/extraction-process/staged-extraction/#next-steps","title":"Next Steps","text":"<ul> <li>Schema design for staged extraction \u2014 Identity fields, linkage, and schema checklist for staged mode</li> <li>Extraction Backends \u2014 LLM vs VLM and extraction contracts</li> <li>Model Merging \u2014 How chunk results are merged</li> <li>Configuration reference \u2014 Full config and staged fields</li> </ul>"},{"location":"fundamentals/graph-management/","title":"Knowledge Graph Management","text":""},{"location":"fundamentals/graph-management/#overview","title":"Overview","text":"<p>Knowledge Graph Management covers converting extracted Pydantic models into graph structures, exporting to various formats, and visualizing the results.</p> <p>What you'll learn: - Graph conversion from Pydantic models - Export formats (CSV, Cypher, JSON) - Visualization techniques - Graph analysis and statistics - Neo4j integration</p>"},{"location":"fundamentals/graph-management/#the-graph-pipeline","title":"The Graph Pipeline","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Pydantic Models\" }\n\n    B@{ shape: procs, label: \"Graph Conversion\" }\n    C@{ shape: doc, label: \"NetworkX Graph\" }\n\n    D@{ shape: tag-proc, label: \"Export\" }\n    F@{ shape: tag-proc, label: \"Visualization\" }\n\n    E1@{ shape: doc, label: \"CSV Files\" }\n    E2@{ shape: doc, label: \"Cypher Script\" }\n    E3@{ shape: doc, label: \"JSON\" }\n\n    G@{ shape: doc, label: \"Interactive HTML\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n\n    C --&gt; D\n    C --&gt; F\n\n    D --&gt; E1\n    D --&gt; E2\n    D --&gt; E3\n\n    F --&gt; G\n\n    %% 4. Apply Classes\n    class A input\n    class B process\n    class C data\n    class D,F operator\n    class E1,E2,E3,G output</code></pre>"},{"location":"fundamentals/graph-management/#key-concepts","title":"Key Concepts","text":""},{"location":"fundamentals/graph-management/#1-graph-conversion","title":"1. Graph Conversion","text":"<p>Transform Pydantic models into graph structure:</p> <pre><code>from docling_graph.core.converters import GraphConverter\n\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\nprint(f\"Nodes: {metadata.node_count}\")\nprint(f\"Edges: {metadata.edge_count}\")\n</code></pre> <p>Learn more: Graph Conversion \u2192</p>"},{"location":"fundamentals/graph-management/#2-export-formats","title":"2. Export Formats","text":"<p>Export graphs in multiple formats:</p> <pre><code>from docling_graph.core.exporters import CSVExporter, CypherExporter\n\n# CSV export\nCSVExporter().export(graph, output_dir)\n\n# Cypher export\nCypherExporter().export(graph, output_file)\n</code></pre> <p>Learn more: Export Formats \u2192</p>"},{"location":"fundamentals/graph-management/#3-visualization","title":"3. Visualization","text":"<p>Generate interactive visualizations:</p> <pre><code>from docling_graph.core.visualizers import InteractiveVisualizer\n\nvisualizer = InteractiveVisualizer()\nvisualizer.save_cytoscape_graph(graph, \"graph.html\")\n</code></pre> <p>Learn more: Visualization \u2192</p>"},{"location":"fundamentals/graph-management/#4-neo4j-integration","title":"4. Neo4j Integration","text":"<p>Import graphs into Neo4j:</p> <pre><code># Import Cypher script\ncat graph.cypher | cypher-shell -u neo4j -p password\n</code></pre> <p>Learn more: Neo4j Integration \u2192</p>"},{"location":"fundamentals/graph-management/#quick-start","title":"Quick Start","text":""},{"location":"fundamentals/graph-management/#complete-pipeline","title":"Complete Pipeline","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Run complete pipeline\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"local\",\n    export_format=\"csv\",  # or \"cypher\"\n    output_dir=\"outputs\"\n)\n\nrun_pipeline(config)\n\n# Outputs:\n# - outputs/nodes.csv\n# - outputs/edges.csv\n# - outputs/graph_stats.json\n# - outputs/visualization.html\n</code></pre>"},{"location":"fundamentals/graph-management/#graph-structure","title":"Graph Structure","text":""},{"location":"fundamentals/graph-management/#nodes","title":"Nodes","text":"<p>Nodes represent entities from your Pydantic models:</p> <pre><code># Node structure\n{\n    \"id\": \"invoice_001\",\n    \"label\": \"BillingDocument\",\n    \"type\": \"entity\",\n    \"document_no\": \"INV-001\",\n    \"total\": 1000\n}\n</code></pre>"},{"location":"fundamentals/graph-management/#edges","title":"Edges","text":"<p>Edges represent relationships between entities:</p> <pre><code># Edge structure\n{\n    \"source\": \"invoice_001\",\n    \"target\": \"org_acme\",\n    \"label\": \"ISSUED_BY\"\n}\n</code></pre>"},{"location":"fundamentals/graph-management/#export-formats-comparison","title":"Export Formats Comparison","text":"Format Best For File Type Use Case CSV Analysis, spreadsheets <code>.csv</code> Data analysis, Excel Cypher Neo4j import <code>.cypher</code> Graph database JSON APIs, processing <code>.json</code> Programmatic access"},{"location":"fundamentals/graph-management/#section-contents","title":"Section Contents","text":""},{"location":"fundamentals/graph-management/#1-graph-conversion_1","title":"1. Graph Conversion","text":"<p>Learn how Pydantic models are converted to NetworkX graphs.</p> <p>Topics: - Node creation - Edge generation - Node ID registry - Graph validation - Automatic cleanup</p>"},{"location":"fundamentals/graph-management/#2-export-formats_1","title":"2. Export Formats","text":"<p>Understand different export formats and when to use them.</p> <p>Topics: - CSV export (nodes and edges) - Cypher export (Neo4j) - JSON export (programmatic) - Format selection</p>"},{"location":"fundamentals/graph-management/#3-visualization_1","title":"3. Visualization","text":"<p>Generate interactive visualizations of your knowledge graphs.</p> <p>Topics: - Interactive HTML graphs - Markdown reports - Graph statistics - Customization options</p>"},{"location":"fundamentals/graph-management/#4-neo4j-integration_1","title":"4. Neo4j Integration","text":"<p>Import and query graphs in Neo4j database.</p> <p>Topics: - Cypher import - Neo4j setup - Query examples - Best practices</p>"},{"location":"fundamentals/graph-management/#5-graph-analysis","title":"5. Graph Analysis","text":"<p>Analyze graph structure and statistics.</p> <p>Topics: - Node and edge counts - Graph metrics - Connectivity analysis - Quality checks</p>"},{"location":"fundamentals/graph-management/#6-advanced-topics","title":"6. Advanced Topics","text":"<p>Advanced graph management techniques covered in other sections.</p> <p>See also: - Custom Exporters - Performance Tuning - Graph Analysis</p>"},{"location":"fundamentals/graph-management/#common-workflows","title":"Common Workflows","text":""},{"location":"fundamentals/graph-management/#workflow-1-csv-analysis","title":"Workflow 1: CSV Analysis","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Extract and export to CSV\nconfig = PipelineConfig(\n    source=\"invoices.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"csv\",\n    output_dir=\"analysis\"\n)\n\nrun_pipeline(config)\n\n# Analyze in Python\nimport pandas as pd\n\nnodes = pd.read_csv(\"analysis/nodes.csv\")\nedges = pd.read_csv(\"analysis/edges.csv\")\n\nprint(f\"Total invoices: {len(nodes[nodes['label'] == 'BillingDocument'])}\")\n</code></pre>"},{"location":"fundamentals/graph-management/#workflow-2-neo4j-import","title":"Workflow 2: Neo4j Import","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Extract and export to Cypher\nconfig = PipelineConfig(\n    source=\"contracts.pdf\",\n    template=\"templates.Contract\",\n    export_format=\"cypher\",\n    output_dir=\"neo4j_import\"\n)\n\nrun_pipeline(config)\n\n# Import to Neo4j\n# cat neo4j_import/graph.cypher | cypher-shell\n</code></pre>"},{"location":"fundamentals/graph-management/#workflow-3-programmatic-access","title":"Workflow 3: Programmatic Access","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nimport json\n\n# Extract and access programmatically\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    output_dir=\"data\"\n)\n\nrun_pipeline(config)\n\n# Load graph data\nwith open(\"data/graph_data.json\") as f:\n    graph_data = json.load(f)\n\n# Process nodes\nfor node in graph_data[\"nodes\"]:\n    print(f\"{node['type']}: {node['id']}\")\n</code></pre>"},{"location":"fundamentals/graph-management/#graph-statistics","title":"Graph Statistics","text":""},{"location":"fundamentals/graph-management/#automatic-statistics","title":"Automatic Statistics","text":"<p>Every pipeline run generates statistics:</p> <pre><code>{\n  \"node_count\": 15,\n  \"edge_count\": 18,\n  \"node_types\": {\n    \"BillingDocument\": 1,\n    \"Organization\": 2,\n    \"Address\": 3,\n    \"LineItem\": 9\n  },\n  \"edge_types\": {\n    \"ISSUED_BY\": 1,\n    \"SENT_TO\": 1,\n    \"LOCATED_AT\": 5,\n    \"CONTAINS_LINE\": 9\n  },\n  \"avg_degree\": 2.4,\n  \"density\": 0.17\n}\n</code></pre>"},{"location":"fundamentals/graph-management/#using-statistics","title":"Using Statistics","text":"<pre><code>import json\n\n# Load statistics\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nprint(f\"Graph has {stats['node_count']} nodes\")\nprint(f\"Most common node type: {max(stats['node_types'], key=stats['node_types'].get)}\")\n</code></pre>"},{"location":"fundamentals/graph-management/#visualization-preview","title":"Visualization Preview","text":""},{"location":"fundamentals/graph-management/#interactive-html","title":"Interactive HTML","text":"<p>Every pipeline run generates an interactive visualization:</p> <pre><code>outputs/\n\u2514\u2500\u2500 visualization.html  # Open in browser\n</code></pre> <p>Features: - Zoom and pan - Node inspection - Search functionality - Export to image</p>"},{"location":"fundamentals/graph-management/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/#choose-the-right-format","title":"\ud83d\udc4d Choose the Right Format","text":"<pre><code># \u2705 Good - Match format to use case\nif use_case == \"neo4j\":\n    export_format = \"cypher\"\nelif use_case == \"analysis\":\n    export_format = \"csv\"\nelse:\n    export_format = \"csv\"  # Default\n</code></pre>"},{"location":"fundamentals/graph-management/#validate-graph-structure","title":"\ud83d\udc4d Validate Graph Structure","text":"<pre><code># \u2705 Good - Enable validation\nconverter = GraphConverter(validate_graph=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/#use-automatic-cleanup","title":"\ud83d\udc4d Use Automatic Cleanup","text":"<pre><code># \u2705 Good - Enable cleanup\nconverter = GraphConverter(auto_cleanup=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/#check-statistics","title":"\ud83d\udc4d Check Statistics","text":"<pre><code># \u2705 Good - Verify graph quality\nif metadata.node_count == 0:\n    print(\"Warning: Empty graph\")\n\nif metadata.edge_count == 0:\n    print(\"Warning: No relationships\")\n</code></pre>"},{"location":"fundamentals/graph-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/#empty-graph","title":"\ud83d\udc1b Empty Graph","text":"<p>Solution: <pre><code># Check if models were extracted\nif not models:\n    print(\"No models extracted\")\n\n# Check if models have relationships\nfor model in models:\n    print(f\"Model: {model}\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/#missing-relationships","title":"\ud83d\udc1b Missing Relationships","text":"<p>Solution: <pre><code># Ensure entities are properly defined\nclass Organization(BaseModel):\n    name: str\n    # Must be entity to create nodes\n    model_config = {\"is_entity\": True}\n</code></pre></p>"},{"location":"fundamentals/graph-management/#export-fails","title":"\ud83d\udc1b Export Fails","text":"<p>Solution: <pre><code># Check output directory exists\nimport os\nos.makedirs(\"outputs\", exist_ok=True)\n\n# Check graph is not empty\nif graph.number_of_nodes() == 0:\n    print(\"Cannot export empty graph\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/#next-steps","title":"Next Steps","text":"<p>Ready to dive deeper? Start with:</p> <ol> <li>Graph Conversion \u2192 - Learn graph conversion</li> <li>Export Formats \u2192 - Choose export format</li> <li>Visualization \u2192 - Visualize your graphs</li> </ol>"},{"location":"fundamentals/graph-management/export-formats/","title":"Export Formats","text":""},{"location":"fundamentals/graph-management/export-formats/#overview","title":"Overview","text":"<p>Export formats determine how your knowledge graph is saved and shared. Docling Graph supports CSV, Cypher, and JSON formats, each optimized for different use cases.</p> <p>In this guide: - CSV format (spreadsheets, analysis) - Cypher format (Neo4j import) - JSON format (programmatic access) - Format selection criteria - Integration examples</p>"},{"location":"fundamentals/graph-management/export-formats/#format-comparison","title":"Format Comparison","text":"Format Best For Output Use Case CSV Analysis, spreadsheets <code>nodes.csv</code>, <code>edges.csv</code> Excel, Pandas, SQL Cypher Graph databases <code>graph.cypher</code> Neo4j import JSON APIs, processing <code>graph.json</code> Python, JavaScript"},{"location":"fundamentals/graph-management/export-formats/#csv-export","title":"CSV Export","text":""},{"location":"fundamentals/graph-management/export-formats/#what-is-csv-export","title":"What is CSV Export?","text":"<p>CSV export creates separate files for nodes and edges in comma-separated format, perfect for spreadsheet analysis and SQL databases.</p>"},{"location":"fundamentals/graph-management/export-formats/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"csv\",  # CSV export (default)\n    output_dir=\"outputs\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#output-files","title":"Output Files","text":"<pre><code>outputs/\n\u251c\u2500\u2500 nodes.csv          # All nodes with properties\n\u251c\u2500\u2500 edges.csv          # All edges with relationships\n\u251c\u2500\u2500 graph_stats.json   # Graph statistics\n\u2514\u2500\u2500 visualization.html # Interactive visualization\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#nodescsv-format","title":"nodes.csv Format","text":"<pre><code>id,label,type,__class__,invoice_number,total,name,street,city\ninvoice_001,Invoice,entity,Invoice,INV-001,1000,,,\norg_acme,Organization,entity,Organization,,,Acme Corp,,\naddr_123,Address,entity,Address,,,,123 Main St,Paris\n</code></pre> <p>Columns: - <code>id</code>: Unique node identifier - <code>label</code>: Node type/class - <code>type</code>: Always \"entity\" - <code>__class__</code>: Python class name - Additional columns for each property</p>"},{"location":"fundamentals/graph-management/export-formats/#edgescsv-format","title":"edges.csv Format","text":"<pre><code>source,target,label\ninvoice_001,org_acme,issued_by\norg_acme,addr_123,located_at\ninvoice_001,item_001,contains_item\n</code></pre> <p>Columns: - <code>source</code>: Source node ID - <code>target</code>: Target node ID - <code>label</code>: Relationship type</p>"},{"location":"fundamentals/graph-management/export-formats/#manual-csv-export","title":"Manual CSV Export","text":"<pre><code>from docling_graph.core.exporters import CSVExporter\nfrom docling_graph.core.converters import GraphConverter\n\n# Convert models to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Export to CSV\nexporter = CSVExporter()\nexporter.export(graph, output_dir=\"csv_output\")\n\nprint(\"Exported to csv_output/nodes.csv and csv_output/edges.csv\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#using-csv-with-pandas","title":"Using CSV with Pandas","text":"<pre><code>import pandas as pd\n\n# Load CSV files\nnodes = pd.read_csv(\"outputs/nodes.csv\")\nedges = pd.read_csv(\"outputs/edges.csv\")\n\n# Analyze nodes\nprint(f\"Total nodes: {len(nodes)}\")\nprint(f\"Node types:\\n{nodes['label'].value_counts()}\")\n\n# Analyze edges\nprint(f\"Total edges: {len(edges)}\")\nprint(f\"Edge types:\\n{edges['label'].value_counts()}\")\n\n# Filter specific node type\ninvoices = nodes[nodes['label'] == 'Invoice']\nprint(f\"Found {len(invoices)} invoices\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#using-csv-with-sql","title":"Using CSV with SQL","text":"<pre><code>import sqlite3\nimport pandas as pd\n\n# Load CSV\nnodes = pd.read_csv(\"outputs/nodes.csv\")\nedges = pd.read_csv(\"outputs/edges.csv\")\n\n# Create database\nconn = sqlite3.connect(\"graph.db\")\n\n# Import to SQL\nnodes.to_sql(\"nodes\", conn, if_exists=\"replace\", index=False)\nedges.to_sql(\"edges\", conn, if_exists=\"replace\", index=False)\n\n# Query\nresult = pd.read_sql(\"\"\"\n    SELECT n.label, COUNT(*) as count\n    FROM nodes n\n    GROUP BY n.label\n\"\"\", conn)\n\nprint(result)\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#cypher-export","title":"Cypher Export","text":""},{"location":"fundamentals/graph-management/export-formats/#what-is-cypher-export","title":"What is Cypher Export?","text":"<p>Cypher export generates Cypher statements for direct import into Neo4j graph databases.</p>"},{"location":"fundamentals/graph-management/export-formats/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"cypher\",  # Cypher export\n    output_dir=\"outputs\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#output-files_1","title":"Output Files","text":"<pre><code>outputs/\n\u251c\u2500\u2500 graph.cypher       # Cypher statements\n\u251c\u2500\u2500 graph_stats.json   # Graph statistics\n\u2514\u2500\u2500 visualization.html # Interactive visualization\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#graphcypher-format","title":"graph.cypher Format","text":"<pre><code>// Cypher script generated by docling-graph\n// Import this into Neo4j\n\n// --- Create Nodes ---\nCREATE (invoice_001:Invoice {invoice_number: \"INV-001\", total: 1000, node_id: \"invoice_001\"})\nCREATE (org_acme:Organization {name: \"Acme Corp\", node_id: \"org_acme\"})\nCREATE (addr_123:Address {street: \"123 Main St\", city: \"Paris\", node_id: \"addr_123\"})\n\n// --- Create Relationships ---\nMATCH (invoice_001), (org_acme)\nCREATE (invoice_001)-[:ISSUED_BY]-&gt;(org_acme)\n\nMATCH (org_acme), (addr_123)\nCREATE (org_acme)-[:LOCATED_AT]-&gt;(addr_123)\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#manual-cypher-export","title":"Manual Cypher Export","text":"<pre><code>from docling_graph.core.exporters import CypherExporter\nfrom docling_graph.core.converters import GraphConverter\nfrom pathlib import Path\n\n# Convert models to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Export to Cypher\nexporter = CypherExporter()\nexporter.export(graph, Path(\"outputs/graph.cypher\"))\n\nprint(\"Exported to outputs/graph.cypher\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#importing-to-neo4j","title":"Importing to Neo4j","text":""},{"location":"fundamentals/graph-management/export-formats/#method-1-cypher-shell","title":"Method 1: cypher-shell","text":"<pre><code># Import using cypher-shell\ncat outputs/graph.cypher | cypher-shell -u neo4j -p password\n\n# Or with file\ncypher-shell -u neo4j -p password -f outputs/graph.cypher\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#method-2-neo4j-browser","title":"Method 2: Neo4j Browser","text":"<ol> <li>Open Neo4j Browser (http://localhost:7474)</li> <li>Copy contents of <code>graph.cypher</code></li> <li>Paste into query editor</li> <li>Execute</li> </ol>"},{"location":"fundamentals/graph-management/export-formats/#method-3-python-driver","title":"Method 3: Python Driver","text":"<pre><code>from neo4j import GraphDatabase\n\n# Connect to Neo4j\ndriver = GraphDatabase.driver(\n    \"bolt://localhost:7687\",\n    auth=(\"neo4j\", \"password\")\n)\n\n# Read Cypher file\nwith open(\"outputs/graph.cypher\") as f:\n    cypher_script = f.read()\n\n# Execute\nwith driver.session() as session:\n    session.run(cypher_script)\n\ndriver.close()\nprint(\"Imported to Neo4j\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#json-export","title":"JSON Export","text":""},{"location":"fundamentals/graph-management/export-formats/#what-is-json-export","title":"What is JSON Export?","text":"<p>JSON export is automatically generated alongside CSV or Cypher, providing structured data for programmatic access.</p>"},{"location":"fundamentals/graph-management/export-formats/#output-files_2","title":"Output Files","text":"<pre><code>outputs/\n\u251c\u2500\u2500 extracted_data.json  # Pydantic models\n\u251c\u2500\u2500 graph_data.json      # Graph structure\n\u251c\u2500\u2500 graph_stats.json     # Statistics\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#extracted_datajson-format","title":"extracted_data.json Format","text":"<pre><code>{\n  \"models\": [\n    {\n      \"invoice_number\": \"INV-001\",\n      \"total\": 1000,\n      \"issued_by\": {\n        \"name\": \"Acme Corp\",\n        \"located_at\": {\n          \"street\": \"123 Main St\",\n          \"city\": \"Paris\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#graph_datajson-format","title":"graph_data.json Format","text":"<pre><code>{\n  \"nodes\": [\n    {\n      \"id\": \"invoice_001\",\n      \"label\": \"Invoice\",\n      \"type\": \"entity\",\n      \"properties\": {\n        \"invoice_number\": \"INV-001\",\n        \"total\": 1000\n      }\n    },\n    {\n      \"id\": \"org_acme\",\n      \"label\": \"Organization\",\n      \"type\": \"entity\",\n      \"properties\": {\n        \"name\": \"Acme Corp\"\n      }\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"invoice_001\",\n      \"target\": \"org_acme\",\n      \"label\": \"issued_by\"\n    }\n  ]\n}\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#manual-json-export","title":"Manual JSON Export","text":"<pre><code>from docling_graph.core.exporters import JSONExporter\nfrom docling_graph.core.converters import GraphConverter\nfrom pathlib import Path\n\n# Convert models to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Export to JSON\nexporter = JSONExporter()\nexporter.export(graph, Path(\"outputs/graph.json\"))\n\nprint(\"Exported to outputs/graph.json\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#using-json-in-python","title":"Using JSON in Python","text":"<pre><code>import json\n\n# Load graph data\nwith open(\"outputs/graph_data.json\") as f:\n    graph_data = json.load(f)\n\n# Access nodes\nfor node in graph_data[\"nodes\"]:\n    print(f\"{node['label']}: {node['id']}\")\n\n# Access edges\nfor edge in graph_data[\"edges\"]:\n    print(f\"{edge['source']} --[{edge['label']}]--&gt; {edge['target']}\")\n\n# Filter by type\ninvoices = [n for n in graph_data[\"nodes\"] if n[\"label\"] == \"Invoice\"]\nprint(f\"Found {len(invoices)} invoices\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#format-selection","title":"Format Selection","text":""},{"location":"fundamentals/graph-management/export-formats/#decision-matrix","title":"Decision Matrix","text":"Use Case Recommended Format Reason Excel analysis CSV Direct import to Excel Neo4j database Cypher Direct import Python processing JSON Easy to parse SQL database CSV Standard import Data science CSV Pandas compatible API integration JSON Standard format Graph queries Cypher Neo4j native"},{"location":"fundamentals/graph-management/export-formats/#by-tool","title":"By Tool","text":"Tool Format Import Method Excel CSV File \u2192 Open Neo4j Cypher cypher-shell Python JSON json.load() Pandas CSV pd.read_csv() SQL CSV COPY/LOAD DATA Power BI CSV Get Data Tableau CSV Connect to File"},{"location":"fundamentals/graph-management/export-formats/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/graph-management/export-formats/#csv-for-analysis","title":"\ud83d\udccd CSV for Analysis","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nimport pandas as pd\n\n# Extract and export to CSV\nconfig = PipelineConfig(\n    source=\"invoices.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"csv\",\n    output_dir=\"analysis\"\n)\n\nrun_pipeline(config)\n\n# Analyze with Pandas\nnodes = pd.read_csv(\"analysis/nodes.csv\")\nedges = pd.read_csv(\"analysis/edges.csv\")\n\n# Calculate statistics\nprint(f\"Total invoices: {len(nodes[nodes['label'] == 'Invoice'])}\")\nprint(f\"Total organizations: {len(nodes[nodes['label'] == 'Organization'])}\")\nprint(f\"Total relationships: {len(edges)}\")\n\n# Export summary\nsummary = nodes.groupby('label').size()\nsummary.to_csv(\"analysis/summary.csv\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#cypher-for-neo4j","title":"\ud83d\udccd Cypher for Neo4j","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nimport subprocess\n\n# Extract and export to Cypher\nconfig = PipelineConfig(\n    source=\"contracts.pdf\",\n    template=\"templates.Contract\",\n    export_format=\"cypher\",\n    output_dir=\"neo4j_import\"\n)\n\nrun_pipeline(config)\n\n# Import to Neo4j\nresult = subprocess.run([\n    \"cypher-shell\",\n    \"-u\", \"neo4j\",\n    \"-p\", \"password\",\n    \"-f\", \"neo4j_import/graph.cypher\"\n], capture_output=True, text=True)\n\nif result.returncode == 0:\n    print(\"\u2705 Successfully imported to Neo4j\")\nelse:\n    print(f\"\u274c Import failed: {result.stderr}\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#json-for-api","title":"\ud83d\udccd JSON for API","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nimport json\nimport requests\n\n# Extract and export\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"csv\",  # JSON always generated\n    output_dir=\"api_data\"\n)\n\nrun_pipeline(config)\n\n# Load JSON\nwith open(\"api_data/extracted_data.json\") as f:\n    data = json.load(f)\n\n# Send to API\nresponse = requests.post(\n    \"https://api.example.com/invoices\",\n    json=data,\n    headers={\"Content-Type\": \"application/json\"}\n)\n\nprint(f\"API response: {response.status_code}\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/export-formats/#choose-format-by-use-case","title":"\ud83d\udc4d Choose Format by Use Case","text":"<pre><code># \u2705 Good - Match format to use case\nif use_case == \"neo4j\":\n    export_format = \"cypher\"\nelif use_case == \"analysis\":\n    export_format = \"csv\"\nelse:\n    export_format = \"csv\"  # Default\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#organize-output-directories","title":"\ud83d\udc4d Organize Output Directories","text":"<pre><code># \u2705 Good - Structured outputs\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\noutput_dir = f\"exports/{export_format}/{timestamp}\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=export_format,\n    output_dir=output_dir\n)\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#validate-exports","title":"\ud83d\udc4d Validate Exports","text":"<pre><code># \u2705 Good - Check exports exist\nimport os\n\nrun_pipeline(config)\n\nif export_format == \"csv\":\n    assert os.path.exists(f\"{output_dir}/nodes.csv\")\n    assert os.path.exists(f\"{output_dir}/edges.csv\")\nelif export_format == \"cypher\":\n    assert os.path.exists(f\"{output_dir}/graph.cypher\")\n\nprint(\"\u2705 Exports validated\")\n</code></pre>"},{"location":"fundamentals/graph-management/export-formats/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/export-formats/#empty-csv-files","title":"\ud83d\udc1b Empty CSV Files","text":"<p>Solution: <pre><code># Check if graph has nodes\nimport json\n\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nif stats[\"node_count\"] == 0:\n    print(\"No nodes in graph - check extraction\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/export-formats/#cypher-import-fails","title":"\ud83d\udc1b Cypher Import Fails","text":"<p>Solution: <pre><code># Check Cypher syntax\nhead -20 outputs/graph.cypher\n\n# Test connection\ncypher-shell -u neo4j -p password \"RETURN 1\"\n\n# Import with error logging\ncat outputs/graph.cypher | cypher-shell -u neo4j -p password 2&gt;&amp;1 | tee import.log\n</code></pre></p>"},{"location":"fundamentals/graph-management/export-formats/#json-parsing-error","title":"\ud83d\udc1b JSON Parsing Error","text":"<p>Solution: <pre><code># Validate JSON\nimport json\n\ntry:\n    with open(\"outputs/graph_data.json\") as f:\n        data = json.load(f)\n    print(\"\u2705 Valid JSON\")\nexcept json.JSONDecodeError as e:\n    print(f\"\u274c Invalid JSON: {e}\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/export-formats/#next-steps","title":"Next Steps","text":"<p>Now that you understand export formats:</p> <ol> <li>Visualization \u2192 - Visualize your graphs</li> <li>Neo4j Integration \u2192 - Deep dive into Neo4j</li> <li>Graph Analysis \u2192 - Analyze graph structure</li> </ol>"},{"location":"fundamentals/graph-management/graph-analysis/","title":"Graph Analysis","text":""},{"location":"fundamentals/graph-management/graph-analysis/#overview","title":"Overview","text":"<p>Graph analysis helps you understand the structure, quality, and characteristics of your knowledge graphs through metrics, statistics, and validation.</p> <p>In this guide: - Graph metrics - Quality checks - Connectivity analysis - Performance optimization - Validation techniques</p>"},{"location":"fundamentals/graph-management/graph-analysis/#graph-metrics","title":"Graph Metrics","text":""},{"location":"fundamentals/graph-management/graph-analysis/#basic-metrics","title":"Basic Metrics","text":"<pre><code>from docling_graph.core.converters import GraphConverter\n\n# Create graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Basic metrics\nprint(f\"Nodes: {metadata.node_count}\")\nprint(f\"Edges: {metadata.edge_count}\")\nprint(f\"Density: {metadata.density:.3f}\")\nprint(f\"Avg degree: {metadata.avg_degree:.2f}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#node-metrics","title":"Node Metrics","text":""},{"location":"fundamentals/graph-management/graph-analysis/#node-count-by-type","title":"Node Count by Type","text":"<pre><code># Node type distribution\nfor node_type, count in metadata.node_types.items():\n    percentage = (count / metadata.node_count) * 100\n    print(f\"{node_type}: {count} ({percentage:.1f}%)\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#node-degree","title":"Node Degree","text":"<pre><code>import networkx as nx\n\n# Calculate node degrees\ndegrees = dict(graph.degree())\n\n# Statistics\navg_degree = sum(degrees.values()) / len(degrees)\nmax_degree = max(degrees.values())\nmin_degree = min(degrees.values())\n\nprint(f\"Average degree: {avg_degree:.2f}\")\nprint(f\"Max degree: {max_degree}\")\nprint(f\"Min degree: {min_degree}\")\n\n# Find high-degree nodes (hubs)\nhubs = [(node, deg) for node, deg in degrees.items() if deg &gt; avg_degree * 2]\nprint(f\"Hub nodes: {len(hubs)}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#edge-metrics","title":"Edge Metrics","text":""},{"location":"fundamentals/graph-management/graph-analysis/#edge-count-by-type","title":"Edge Count by Type","text":"<pre><code># Edge type distribution\nfor edge_type, count in metadata.edge_types.items():\n    percentage = (count / metadata.edge_count) * 100\n    print(f\"{edge_type}: {count} ({percentage:.1f}%)\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#edge-density","title":"Edge Density","text":"<pre><code># Graph density (actual edges / possible edges)\ndensity = metadata.density\n\nif density &lt; 0.1:\n    print(\"Sparse graph\")\nelif density &lt; 0.5:\n    print(\"Medium density graph\")\nelse:\n    print(\"Dense graph\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#connectivity-analysis","title":"Connectivity Analysis","text":""},{"location":"fundamentals/graph-management/graph-analysis/#connected-components","title":"Connected Components","text":"<pre><code>import networkx as nx\n\n# Find connected components\ncomponents = list(nx.weakly_connected_components(graph))\n\nprint(f\"Connected components: {len(components)}\")\nprint(f\"Largest component: {len(max(components, key=len))} nodes\")\n\n# Check if graph is connected\nis_connected = nx.is_weakly_connected(graph)\nprint(f\"Graph is connected: {is_connected}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#isolated-nodes","title":"Isolated Nodes","text":"<pre><code># Find isolated nodes (no connections)\nisolated = [node for node, degree in graph.degree() if degree == 0]\n\nprint(f\"Isolated nodes: {len(isolated)}\")\nif isolated:\n    print(\"Warning: Graph has isolated nodes\")\n    for node in isolated[:5]:\n        print(f\"  - {node}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#quality-checks","title":"Quality Checks","text":""},{"location":"fundamentals/graph-management/graph-analysis/#validation","title":"Validation","text":"<pre><code>from docling_graph.core.utils import validate_graph_structure\n\ntry:\n    validate_graph_structure(graph, raise_on_error=True)\n    print(\"\u2705 Graph structure valid\")\nexcept ValueError as e:\n    print(f\"\u274c Validation failed: {e}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#completeness-check","title":"Completeness Check","text":"<pre><code>def check_completeness(graph, metadata):\n    \"\"\"Check graph completeness.\"\"\"\n    issues = []\n\n    # Check for nodes\n    if metadata.node_count == 0:\n        issues.append(\"No nodes in graph\")\n\n    # Check for edges\n    if metadata.edge_count == 0:\n        issues.append(\"No edges in graph\")\n\n    # Check for isolated nodes\n    isolated = [n for n, d in graph.degree() if d == 0]\n    if isolated:\n        issues.append(f\"{len(isolated)} isolated nodes\")\n\n    # Check node attributes\n    nodes_without_label = [\n        n for n, data in graph.nodes(data=True)\n        if 'label' not in data\n    ]\n    if nodes_without_label:\n        issues.append(f\"{len(nodes_without_label)} nodes without labels\")\n\n    return issues\n\n# Run check\nissues = check_completeness(graph, metadata)\nif issues:\n    print(\"Graph issues found:\")\n    for issue in issues:\n        print(f\"  - {issue}\")\nelse:\n    print(\"\u2705 Graph is complete\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/graph-management/graph-analysis/#comprehensive-analysis","title":"\ud83d\udccd Comprehensive Analysis","text":"<pre><code>from docling_graph.core.converters import GraphConverter\nimport networkx as nx\n\n# Create graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\nprint(\"=== Graph Analysis ===\\n\")\n\n# Basic metrics\nprint(\"Basic Metrics:\")\nprint(f\"  Nodes: {metadata.node_count}\")\nprint(f\"  Edges: {metadata.edge_count}\")\nprint(f\"  Density: {metadata.density:.3f}\")\nprint(f\"  Avg degree: {metadata.avg_degree:.2f}\\n\")\n\n# Node types\nprint(\"Node Types:\")\nfor node_type, count in sorted(metadata.node_types.items(), key=lambda x: x[1], reverse=True):\n    percentage = (count / metadata.node_count) * 100\n    print(f\"  {node_type}: {count} ({percentage:.1f}%)\")\n\n# Edge types\nprint(\"\\nEdge Types:\")\nfor edge_type, count in sorted(metadata.edge_types.items(), key=lambda x: x[1], reverse=True):\n    percentage = (count / metadata.edge_count) * 100\n    print(f\"  {edge_type}: {count} ({percentage:.1f}%)\")\n\n# Connectivity\nprint(\"\\nConnectivity:\")\ncomponents = list(nx.weakly_connected_components(graph))\nprint(f\"  Connected components: {len(components)}\")\nprint(f\"  Largest component: {len(max(components, key=len))} nodes\")\n\n# Quality\nprint(\"\\nQuality:\")\nisolated = [n for n, d in graph.degree() if d == 0]\nprint(f\"  Isolated nodes: {len(isolated)}\")\nprint(f\"  Graph is connected: {nx.is_weakly_connected(graph)}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#batch-analysis","title":"\ud83d\udccd Batch Analysis","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom pathlib import Path\nimport json\nimport pandas as pd\n\n# Analyze multiple documents\nresults = []\n\nfor pdf_file in Path(\"documents\").glob(\"*.pdf\"):\n    # Process document\n    output_dir = f\"analysis/{pdf_file.stem}\"\n\n    config = PipelineConfig(\n        source=str(pdf_file),\n        template=\"templates.BillingDocument\",\n        output_dir=output_dir\n    )\n\n    run_pipeline(config)\n\n    # Load statistics\n    with open(f\"{output_dir}/graph_stats.json\") as f:\n        stats = json.load(f)\n\n    results.append({\n        \"document\": pdf_file.name,\n        \"nodes\": stats[\"node_count\"],\n        \"edges\": stats[\"edge_count\"],\n        \"density\": stats[\"density\"],\n        \"avg_degree\": stats[\"avg_degree\"]\n    })\n\n# Create summary\ndf = pd.DataFrame(results)\nprint(\"\\n=== Batch Analysis Summary ===\")\nprint(df.describe())\n\n# Export\ndf.to_csv(\"batch_analysis.csv\", index=False)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#quality-report","title":"\ud83d\udccd Quality Report","text":"<pre><code>from docling_graph.core.converters import GraphConverter\nimport networkx as nx\n\ndef generate_quality_report(graph, metadata):\n    \"\"\"Generate comprehensive quality report.\"\"\"\n\n    report = {\n        \"basic_metrics\": {\n            \"nodes\": metadata.node_count,\n            \"edges\": metadata.edge_count,\n            \"density\": metadata.density,\n            \"avg_degree\": metadata.avg_degree\n        },\n        \"quality_checks\": {},\n        \"warnings\": []\n    }\n\n    # Check 1: Empty graph\n    if metadata.node_count == 0:\n        report[\"warnings\"].append(\"Graph is empty\")\n        return report\n\n    # Check 2: Isolated nodes\n    isolated = [n for n, d in graph.degree() if d == 0]\n    report[\"quality_checks\"][\"isolated_nodes\"] = len(isolated)\n    if isolated:\n        report[\"warnings\"].append(f\"{len(isolated)} isolated nodes found\")\n\n    # Check 3: Connectivity\n    is_connected = nx.is_weakly_connected(graph)\n    report[\"quality_checks\"][\"is_connected\"] = is_connected\n    if not is_connected:\n        components = list(nx.weakly_connected_components(graph))\n        report[\"warnings\"].append(f\"Graph has {len(components)} disconnected components\")\n\n    # Check 4: Node attributes\n    nodes_without_label = sum(1 for _, data in graph.nodes(data=True) if 'label' not in data)\n    report[\"quality_checks\"][\"nodes_without_label\"] = nodes_without_label\n    if nodes_without_label &gt; 0:\n        report[\"warnings\"].append(f\"{nodes_without_label} nodes missing labels\")\n\n    # Check 5: Self-loops\n    self_loops = list(nx.selfloop_edges(graph))\n    report[\"quality_checks\"][\"self_loops\"] = len(self_loops)\n    if self_loops:\n        report[\"warnings\"].append(f\"{len(self_loops)} self-loops found\")\n\n    return report\n\n# Generate report\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\nreport = generate_quality_report(graph, metadata)\n\n# Print report\nprint(\"=== Quality Report ===\\n\")\nprint(\"Basic Metrics:\")\nfor key, value in report[\"basic_metrics\"].items():\n    print(f\"  {key}: {value}\")\n\nprint(\"\\nQuality Checks:\")\nfor key, value in report[\"quality_checks\"].items():\n    print(f\"  {key}: {value}\")\n\nif report[\"warnings\"]:\n    print(\"\\nWarnings:\")\n    for warning in report[\"warnings\"]:\n        print(f\"  \u26a0 {warning}\")\nelse:\n    print(\"\\n\u2705 No quality issues found\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#advanced-analysis","title":"Advanced Analysis","text":""},{"location":"fundamentals/graph-management/graph-analysis/#centrality-measures","title":"Centrality Measures","text":"<pre><code>import networkx as nx\n\n# Degree centrality\ndegree_centrality = nx.degree_centrality(graph)\ntop_nodes = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n\nprint(\"Top 5 nodes by degree centrality:\")\nfor node, centrality in top_nodes:\n    print(f\"  {node}: {centrality:.3f}\")\n\n# Betweenness centrality (for undirected view)\nundirected = graph.to_undirected()\nbetweenness = nx.betweenness_centrality(undirected)\ntop_between = sorted(betweenness.items(), key=lambda x: x[1], reverse=True)[:5]\n\nprint(\"\\nTop 5 nodes by betweenness centrality:\")\nfor node, centrality in top_between:\n    print(f\"  {node}: {centrality:.3f}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#path-analysis","title":"Path Analysis","text":"<pre><code>import networkx as nx\n\n# Average shortest path length (for connected graphs)\nif nx.is_weakly_connected(graph):\n    avg_path_length = nx.average_shortest_path_length(graph.to_undirected())\n    print(f\"Average shortest path length: {avg_path_length:.2f}\")\n\n# Diameter (longest shortest path)\nif nx.is_weakly_connected(graph):\n    diameter = nx.diameter(graph.to_undirected())\n    print(f\"Graph diameter: {diameter}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#performance-optimization","title":"Performance Optimization","text":""},{"location":"fundamentals/graph-management/graph-analysis/#graph-size-optimization","title":"Graph Size Optimization","text":"<pre><code># Check graph size\nimport sys\n\ngraph_size = sys.getsizeof(graph)\nprint(f\"Graph size: {graph_size / 1024:.2f} KB\")\n\n# Optimize by removing unnecessary attributes\ndef optimize_graph(graph):\n    \"\"\"Remove unnecessary node attributes.\"\"\"\n    for node, data in graph.nodes(data=True):\n        # Keep only essential attributes\n        essential = ['id', 'label', 'type']\n        to_remove = [k for k in data.keys() if k not in essential and data[k] is None]\n        for key in to_remove:\n            del data[key]\n\n    return graph\n\noptimized = optimize_graph(graph.copy())\noptimized_size = sys.getsizeof(optimized)\nprint(f\"Optimized size: {optimized_size / 1024:.2f} KB\")\nprint(f\"Reduction: {(1 - optimized_size/graph_size) * 100:.1f}%\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/graph-analysis/#always-validate","title":"\ud83d\udc4d Always Validate","text":"<pre><code># \u2705 Good - Validate after creation\nfrom docling_graph.core.utils import validate_graph_structure\n\ntry:\n    validate_graph_structure(graph, raise_on_error=True)\nexcept ValueError as e:\n    print(f\"Validation failed: {e}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#check-statistics","title":"\ud83d\udc4d Check Statistics","text":"<pre><code># \u2705 Good - Review statistics\nif metadata.node_count == 0:\n    print(\"Warning: Empty graph\")\n\nif metadata.edge_count == 0:\n    print(\"Warning: No relationships\")\n\nif metadata.density &lt; 0.01:\n    print(\"Warning: Very sparse graph\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#monitor-quality","title":"\ud83d\udc4d Monitor Quality","text":"<pre><code># \u2705 Good - Regular quality checks\nisolated = [n for n, d in graph.degree() if d == 0]\nif len(isolated) &gt; metadata.node_count * 0.1:\n    print(f\"Warning: {len(isolated)} isolated nodes (&gt;10%)\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-analysis/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/graph-analysis/#low-density","title":"\ud83d\udc1b Low Density","text":"<p>Solution: <pre><code># Check if entities are properly connected\n# Ensure relationships are defined in Pydantic models\n\nclass BillingDocument(BaseModel):\n    issued_by: Organization  # Creates edge\n    line_items: List[LineItem]  # Creates edges\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-analysis/#many-isolated-nodes","title":"\ud83d\udc1b Many Isolated Nodes","text":"<p>Solution: <pre><code># Enable auto cleanup\nconverter = GraphConverter(auto_cleanup=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Or manually remove isolated nodes\nisolated = [n for n, d in graph.degree() if d == 0]\ngraph.remove_nodes_from(isolated)\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-analysis/#disconnected-components","title":"\ud83d\udc1b Disconnected Components","text":"<p>Solution: <pre><code># Find largest component\nimport networkx as nx\n\ncomponents = list(nx.weakly_connected_components(graph))\nlargest = max(components, key=len)\n\n# Extract largest component\nsubgraph = graph.subgraph(largest).copy()\nprint(f\"Largest component: {len(subgraph.nodes())} nodes\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-analysis/#next-steps","title":"Next Steps","text":"<p>Now that you understand graph analysis:</p> <ol> <li>CLI Guide \u2192 - Use command-line tools</li> <li>API Reference \u2192 - Programmatic access</li> <li>Examples \u2192 - Real-world examples</li> </ol>"},{"location":"fundamentals/graph-management/graph-conversion/","title":"Graph Conversion","text":""},{"location":"fundamentals/graph-management/graph-conversion/#overview","title":"Overview","text":"<p>Graph conversion transforms Pydantic models into NetworkX directed graphs, creating nodes for entities and edges for relationships. This is the foundation of knowledge graph creation.</p> <p>In this guide: - Conversion process - Node and edge creation - Node ID registry - Graph validation - Automatic cleanup</p>"},{"location":"fundamentals/graph-management/graph-conversion/#conversion-process","title":"Conversion Process","text":""},{"location":"fundamentals/graph-management/graph-conversion/#high-level-flow","title":"High-Level Flow","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Pydantic Models\" }\n\n    B@{ shape: lin-proc, label: \"Pre-register Models\" }\n    C@{ shape: procs, label: \"Create Nodes\" }\n    D@{ shape: procs, label: \"Create Edges\" }\n\n    E@{ shape: tag-proc, label: \"Auto Cleanup\" }\n    F@{ shape: tag-proc, label: \"Validate Graph\" }\n    G@{ shape: tag-proc, label: \"Calculate Stats\" }\n\n    H@{ shape: doc, label: \"NetworkX Graph\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n    F --&gt; G\n    G --&gt; H\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D process\n    class E,F,G operator\n    class H output</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#graphconverter","title":"GraphConverter","text":""},{"location":"fundamentals/graph-management/graph-conversion/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph.core.converters import GraphConverter\n\n# Create converter\nconverter = GraphConverter()\n\n# Convert models to graph\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\nprint(f\"Created graph with {metadata.node_count} nodes and {metadata.edge_count} edges\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#with-configuration","title":"With Configuration","text":"<pre><code>from docling_graph.core.converters import GraphConverter\n\nconverter = GraphConverter(\n    add_reverse_edges=False,  # Don't create bidirectional edges\n    validate_graph=True,      # Validate structure\n    auto_cleanup=True         # Remove phantom nodes\n)\n\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#node-creation","title":"Node Creation","text":""},{"location":"fundamentals/graph-management/graph-conversion/#what-becomes-a-node","title":"What Becomes a Node?","text":"<p>Entities (models with <code>is_entity=True</code>) become nodes:</p> <pre><code>from pydantic import BaseModel\n\n# \u2705 Becomes a node\nclass Organization(BaseModel):\n    name: str\n    model_config = {\"is_entity\": True}  # Default\n\n# \u274c Does NOT become a node\nclass Address(BaseModel):\n    street: str\n    city: str\n    model_config = {\"is_entity\": False}  # Component\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#node-structure","title":"Node Structure","text":"<pre><code># Node in graph\n{\n    \"id\": \"organization_acme_corp\",\n    \"label\": \"Organization\",\n    \"type\": \"entity\",\n    \"__class__\": \"Organization\",\n    \"name\": \"Acme Corp\",\n    \"address\": None  # Reference to nested entity\n}\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#edge-creation","title":"Edge Creation","text":""},{"location":"fundamentals/graph-management/graph-conversion/#automatic-edge-generation","title":"Automatic Edge Generation","text":"<p>Edges are created automatically from model relationships:</p> <pre><code>class BillingDocument(BaseModel):\n    document_no: str\n    issued_by: Organization  # Creates edge: BillingDocument -&gt; Organization\n    line_items: List[LineItem]  # Creates edges: BillingDocument -&gt; LineItem (multiple)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#edge-structure","title":"Edge Structure","text":"<pre><code># Edge in graph\n{\n    \"source\": \"invoice_001\",\n    \"target\": \"organization_acme_corp\",\n    \"label\": \"issued_by\",\n    \"properties\": {}\n}\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#custom-edge-labels","title":"Custom Edge Labels","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass BillingDocument(BaseModel):\n    issued_by: Organization = Field(\n        json_schema_extra={\"edge_label\": \"ISSUED_BY\"}\n    )\n</code></pre> <p>Result: Edge label becomes <code>ISSUED_BY</code> instead of <code>issued_by</code></p>"},{"location":"fundamentals/graph-management/graph-conversion/#node-id-registry","title":"Node ID Registry","text":""},{"location":"fundamentals/graph-management/graph-conversion/#what-is-node-id-registry","title":"What is Node ID Registry?","text":"<p>The NodeIDRegistry ensures consistent, deterministic node IDs across multiple extractions.</p>"},{"location":"fundamentals/graph-management/graph-conversion/#how-it-works","title":"How It Works","text":"<pre><code># Same entity always gets same ID\norg1 = Organization(name=\"Acme Corp\")\norg2 = Organization(name=\"Acme Corp\")\n\n# Both get ID: \"organization_acme_corp\"\nid1 = registry.get_node_id(org1)\nid2 = registry.get_node_id(org2)\n\nassert id1 == id2  # True\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#id-generation","title":"ID Generation","text":"<pre><code>def generate_node_id(model: BaseModel) -&gt; str:\n    \"\"\"Generate deterministic node ID.\"\"\"\n    class_name = model.__class__.__name__.lower()\n\n    # Use stable fields for identity\n    stable_fields = {\n        k: v for k, v in model.model_dump().items()\n        if k not in {\"id\", \"__class__\"} and v is not None\n    }\n\n    # Create content hash\n    content = json.dumps(stable_fields, sort_keys=True)\n    hash_suffix = hashlib.blake2b(content.encode()).hexdigest()[:8]\n\n    return f\"{class_name}_{hash_suffix}\"\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#graph-validation","title":"Graph Validation","text":""},{"location":"fundamentals/graph-management/graph-conversion/#automatic-validation","title":"Automatic Validation","text":"<p>Validation checks graph structure:</p> <pre><code>converter = GraphConverter(validate_graph=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Validates:\n# - No isolated nodes\n# - Valid node IDs\n# - Valid edge connections\n# - No self-loops (optional)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#manual-validation","title":"Manual Validation","text":"<pre><code>from docling_graph.core.utils import validate_graph_structure\n\ntry:\n    validate_graph_structure(graph, raise_on_error=True)\n    print(\"\u2705 Graph structure valid\")\nexcept ValueError as e:\n    print(f\"\u274c Validation failed: {e}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#automatic-cleanup","title":"Automatic Cleanup","text":""},{"location":"fundamentals/graph-management/graph-conversion/#what-gets-cleaned","title":"What Gets Cleaned?","text":"<p>Automatic cleanup removes:</p> <ol> <li>Phantom nodes - Nodes with no data</li> <li>Duplicate nodes - Same entity multiple times</li> <li>Orphaned edges - Edges to non-existent nodes</li> <li>Empty attributes - Null or empty values</li> </ol>"},{"location":"fundamentals/graph-management/graph-conversion/#configuration","title":"Configuration","text":"<pre><code>converter = GraphConverter(\n    auto_cleanup=True  # Enable cleanup (default)\n)\n\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#manual-cleanup","title":"Manual Cleanup","text":"<pre><code>from docling_graph.core.utils import GraphCleaner\n\ncleaner = GraphCleaner(verbose=True)\ncleaned_graph = cleaner.clean_graph(graph)\n\nprint(f\"Removed {graph.number_of_nodes() - cleaned_graph.number_of_nodes()} phantom nodes\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/graph-management/graph-conversion/#basic-conversion","title":"\ud83d\udccd Basic Conversion","text":"<pre><code>from docling_graph.core.converters import GraphConverter\nfrom my_templates import BillingDocument, Organization, LineItem\n\n# Create sample models\nmodels = [\n    BillingDocument(\n        document_no=\"INV-001\",\n        issued_by=Organization(name=\"Acme Corp\"),\n        line_items=[\n            LineItem(description=\"Product A\", total=100),\n            LineItem(description=\"Product B\", total=200)\n        ],\n        total=300\n    )\n]\n\n# Convert to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\nprint(f\"Nodes: {metadata.node_count}\")\nprint(f\"Edges: {metadata.edge_count}\")\nprint(f\"Node types: {metadata.node_types}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#with-reverse-edges","title":"\ud83d\udccd With Reverse Edges","text":"<pre><code>from docling_graph.core.converters import GraphConverter\n\n# Create bidirectional edges\nconverter = GraphConverter(add_reverse_edges=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Original edge: BillingDocument -&gt; Organization (ISSUED_BY)\n# Reverse edge: Organization -&gt; Invoice (reverse_ISSUED_BY)\n\nprint(f\"Total edges (with reverse): {metadata.edge_count}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#shared-registry-for-batches","title":"\ud83d\udccd Shared Registry for Batches","text":"<pre><code>from docling_graph.core.converters import GraphConverter, NodeIDRegistry\n\n# Create shared registry\nregistry = NodeIDRegistry()\n\n# Convert first batch\nconverter1 = GraphConverter(registry=registry)\ngraph1, _ = converter1.pydantic_list_to_graph(batch1_models)\n\n# Convert second batch (same registry)\nconverter2 = GraphConverter(registry=registry)\ngraph2, _ = converter2.pydantic_list_to_graph(batch2_models)\n\n# Same entities get same IDs across batches\nprint(f\"Registry has {registry.get_stats()['total_entities']} unique entities\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#custom-configuration","title":"\ud83d\udccd Custom Configuration","text":"<pre><code>from docling_graph.core.converters import GraphConverter, GraphConfig\n\n# Create custom config\nconfig = GraphConfig(\n    add_reverse_edges=True,\n    validate_graph=True,\n    node_id_prefix=\"doc_\"\n)\n\nconverter = GraphConverter(config=config)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#graph-metadata","title":"Graph Metadata","text":""},{"location":"fundamentals/graph-management/graph-conversion/#metadata-structure","title":"Metadata Structure","text":"<pre><code>@dataclass\nclass GraphMetadata:\n    node_count: int\n    edge_count: int\n    node_types: Dict[str, int]\n    edge_types: Dict[str, int]\n    avg_degree: float\n    density: float\n    source_model_count: int\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#using-metadata","title":"Using Metadata","text":"<pre><code>graph, metadata = converter.pydantic_list_to_graph(models)\n\nprint(f\"Graph Statistics:\")\nprint(f\"  Nodes: {metadata.node_count}\")\nprint(f\"  Edges: {metadata.edge_count}\")\nprint(f\"  Density: {metadata.density:.2f}\")\nprint(f\"  Avg degree: {metadata.avg_degree:.2f}\")\n\nprint(f\"\\nNode Types:\")\nfor node_type, count in metadata.node_types.items():\n    print(f\"  {node_type}: {count}\")\n\nprint(f\"\\nEdge Types:\")\nfor edge_type, count in metadata.edge_types.items():\n    print(f\"  {edge_type}: {count}\")\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#advanced-features","title":"Advanced Features","text":""},{"location":"fundamentals/graph-management/graph-conversion/#reverse-edges","title":"Reverse Edges","text":"<p>Create bidirectional relationships:</p> <pre><code>converter = GraphConverter(add_reverse_edges=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# For each edge A -&gt; B, creates B -&gt; A\n# Useful for graph traversal in both directions\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#custom-node-ids","title":"Custom Node IDs","text":"<p>Provide custom node ID logic:</p> <pre><code>from docling_graph.core.converters import NodeIDRegistry\n\nclass CustomRegistry(NodeIDRegistry):\n    def generate_node_id(self, model: BaseModel) -&gt; str:\n        # Custom ID generation\n        return f\"custom_{model.__class__.__name__}_{hash(model)}\"\n\nregistry = CustomRegistry()\nconverter = GraphConverter(registry=registry)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#performance-optimization","title":"Performance Optimization","text":""},{"location":"fundamentals/graph-management/graph-conversion/#batch-processing","title":"Batch Processing","text":"<pre><code># Process large model lists efficiently\nconverter = GraphConverter(auto_cleanup=True)\n\n# Convert in single call (efficient)\ngraph, metadata = converter.pydantic_list_to_graph(all_models)\n\n# Don't convert one by one (inefficient)\n# for model in models:\n#     graph, _ = converter.pydantic_list_to_graph([model])\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#memory-management","title":"Memory Management","text":"<pre><code># For very large graphs\nconverter = GraphConverter(\n    auto_cleanup=True,  # Remove unnecessary nodes\n    validate_graph=False  # Skip validation for speed\n)\n\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Clear registry after conversion\nconverter.registry.clear()\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/graph-conversion/#empty-graph","title":"\ud83d\udc1b Empty Graph","text":"<p>Solution: <pre><code># Check if models have entities\nfor model in models:\n    if hasattr(model, 'model_config'):\n        is_entity = model.model_config.get('is_entity', True)\n        print(f\"{model.__class__.__name__}: is_entity={is_entity}\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-conversion/#missing-edges","title":"\ud83d\udc1b Missing Edges","text":"<p>Solution: <pre><code># Ensure relationships are defined\nclass BillingDocument(BaseModel):\n    issued_by: Organization  # Must be typed as entity\n    # Not: issued_by: dict  # Won't create edge\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-conversion/#duplicate-nodes","title":"\ud83d\udc1b Duplicate Nodes","text":"<p>Solution: <pre><code># Enable auto cleanup\nconverter = GraphConverter(auto_cleanup=True)\ngraph, metadata = converter.pydantic_list_to_graph(models)\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-conversion/#validation-fails","title":"\ud83d\udc1b Validation Fails","text":"<p>Solution: <pre><code># Check graph structure\nprint(f\"Nodes: {graph.number_of_nodes()}\")\nprint(f\"Edges: {graph.number_of_edges()}\")\n\n# Inspect nodes\nfor node_id, data in list(graph.nodes(data=True))[:5]:\n    print(f\"Node: {node_id}, Data: {data}\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/graph-conversion/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/graph-conversion/#use-shared-registry-for-batches","title":"\ud83d\udc4d Use Shared Registry for Batches","text":"<pre><code># \u2705 Good - Consistent IDs across batches\nregistry = NodeIDRegistry()\n\nfor batch in batches:\n    converter = GraphConverter(registry=registry)\n    graph, _ = converter.pydantic_list_to_graph(batch)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#enable-auto-cleanup","title":"\ud83d\udc4d Enable Auto Cleanup","text":"<pre><code># \u2705 Good - Clean graphs\nconverter = GraphConverter(auto_cleanup=True)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#validate-in-development","title":"\ud83d\udc4d Validate in Development","text":"<pre><code># \u2705 Good - Catch issues early\nconverter = GraphConverter(validate_graph=True)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#disable-validation-in-production","title":"\ud83d\udc4d Disable Validation in Production","text":"<pre><code># \u2705 Good - Faster in production\nconverter = GraphConverter(validate_graph=False)\n</code></pre>"},{"location":"fundamentals/graph-management/graph-conversion/#next-steps","title":"Next Steps","text":"<p>Now that you understand graph conversion:</p> <ol> <li>Export Formats \u2192 - Export graphs to CSV, Cypher, JSON</li> <li>Visualization \u2192 - Visualize your graphs</li> <li>Neo4j Integration \u2192 - Import into Neo4j</li> </ol>"},{"location":"fundamentals/graph-management/neo4j-integration/","title":"Neo4j Integration","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#overview","title":"Overview","text":"<p>Neo4j integration enables you to import knowledge graphs into Neo4j graph database for powerful querying, analysis, and visualization using Cypher query language.</p> <p>In this guide: - Neo4j setup - Cypher import - Query examples - Best practices - Troubleshooting</p>"},{"location":"fundamentals/graph-management/neo4j-integration/#why-neo4j","title":"Why Neo4j?","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#benefits","title":"Benefits","text":"<p>\u2705 Graph-native database - Optimized for graph queries - Fast relationship traversal - ACID transactions</p> <p>\u2705 Cypher query language - Intuitive pattern matching - Powerful aggregations - Path finding algorithms</p> <p>\u2705 Visualization - Built-in graph browser - Interactive exploration - Custom styling</p> <p>\u2705 Scalability - Handles millions of nodes - Distributed architecture - High performance</p>"},{"location":"fundamentals/graph-management/neo4j-integration/#neo4j-setup","title":"Neo4j Setup","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#installation","title":"Installation","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#option-1-neo4j-desktop-recommended","title":"Option 1: Neo4j Desktop (Recommended)","text":"<pre><code># Download from https://neo4j.com/download/\n# Install and create a new database\n# Default credentials: neo4j/neo4j (change on first login)\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#option-2-docker","title":"Option 2: Docker","text":"<pre><code># Run Neo4j in Docker\ndocker run \\\n    --name neo4j \\\n    -p 7474:7474 -p 7687:7687 \\\n    -e NEO4J_AUTH=neo4j/password \\\n    neo4j:latest\n\n# Access at http://localhost:7474\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#option-3-cloud-neo4j-aura","title":"Option 3: Cloud (Neo4j Aura)","text":"<pre><code># Sign up at https://neo4j.com/cloud/aura/\n# Create free instance\n# Note connection URI and credentials\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#verify-installation","title":"Verify Installation","text":"<pre><code># Check Neo4j is running\ncurl http://localhost:7474\n\n# Test cypher-shell\ncypher-shell -u neo4j -p password \"RETURN 1\"\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#exporting-for-neo4j","title":"Exporting for Neo4j","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#generate-cypher-script","title":"Generate Cypher Script","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"cypher\",  # Generate Cypher script\n    output_dir=\"neo4j_import\"\n)\n\nrun_pipeline(config)\n\n# Generates: neo4j_import/graph.cypher\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#importing-to-neo4j","title":"Importing to Neo4j","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#method-1-cypher-shell-recommended","title":"Method 1: cypher-shell (Recommended)","text":"<pre><code># Import Cypher script\ncat neo4j_import/graph.cypher | cypher-shell -u neo4j -p password\n\n# Or with file\ncypher-shell -u neo4j -p password -f neo4j_import/graph.cypher\n\n# With error logging\ncat neo4j_import/graph.cypher | cypher-shell -u neo4j -p password 2&gt;&amp;1 | tee import.log\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#method-2-neo4j-browser","title":"Method 2: Neo4j Browser","text":"<ol> <li>Open Neo4j Browser (http://localhost:7474)</li> <li>Login with credentials</li> <li>Open <code>graph.cypher</code> file</li> <li>Copy contents</li> <li>Paste into query editor</li> <li>Click \"Run\" or press Ctrl+Enter</li> </ol>"},{"location":"fundamentals/graph-management/neo4j-integration/#method-3-python-driver","title":"Method 3: Python Driver","text":"<pre><code>from neo4j import GraphDatabase\n\n# Connect to Neo4j\ndriver = GraphDatabase.driver(\n    \"bolt://localhost:7687\",\n    auth=(\"neo4j\", \"password\")\n)\n\n# Read Cypher file\nwith open(\"neo4j_import/graph.cypher\") as f:\n    cypher_script = f.read()\n\n# Execute\nwith driver.session() as session:\n    session.run(cypher_script)\n\ndriver.close()\nprint(\"\u2705 Imported to Neo4j\")\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#method-4-automated-import","title":"Method 4: Automated Import","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nimport subprocess\n\n# Extract and export\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"cypher\",\n    output_dir=\"neo4j_import\"\n)\n\nrun_pipeline(config)\n\n# Import to Neo4j\nresult = subprocess.run([\n    \"cypher-shell\",\n    \"-u\", \"neo4j\",\n    \"-p\", \"password\",\n    \"-f\", \"neo4j_import/graph.cypher\"\n], capture_output=True, text=True)\n\nif result.returncode == 0:\n    print(\"\u2705 Successfully imported to Neo4j\")\nelse:\n    print(f\"\u274c Import failed: {result.stderr}\")\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#querying-neo4j","title":"Querying Neo4j","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#basic-queries","title":"Basic Queries","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#count-nodes","title":"Count Nodes","text":"<pre><code>// Count all nodes\nMATCH (n)\nRETURN count(n) as total_nodes\n\n// Count by type\nMATCH (n)\nRETURN labels(n) as type, count(n) as count\nORDER BY count DESC\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#count-relationships","title":"Count Relationships","text":"<pre><code>// Count all relationships\nMATCH ()-[r]-&gt;()\nRETURN count(r) as total_relationships\n\n// Count by type\nMATCH ()-[r]-&gt;()\nRETURN type(r) as relationship_type, count(r) as count\nORDER BY count DESC\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#finding-nodes","title":"Finding Nodes","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#find-specific-node","title":"Find Specific Node","text":"<pre><code>// Find invoice by number\nMATCH (i:BillingDocument {document_no: \"INV-001\"})\nRETURN i\n\n// Find organization by name\nMATCH (o:Organization {name: \"Acme Corp\"})\nRETURN o\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#find-all-of-type","title":"Find All of Type","text":"<pre><code>// Find all invoices\nMATCH (i:BillingDocument)\nRETURN i\nLIMIT 10\n\n// Find all organizations\nMATCH (o:Organization)\nRETURN o.name, o.address\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#relationship-queries","title":"Relationship Queries","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#direct-relationships","title":"Direct Relationships","text":"<pre><code>// Find who issued an invoice\nMATCH (i:BillingDocument {document_no: \"INV-001\"})-[:ISSUED_BY]-&gt;(o:Organization)\nRETURN i.document_no, o.name\n\n// Find all line items in an invoice\nMATCH (i:BillingDocument)-[:CONTAINS_LINE]-&gt;(item:LineItem)\nWHERE i.document_no = \"INV-001\"\nRETURN item.description, item.total\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#multi-hop-relationships","title":"Multi-Hop Relationships","text":"<pre><code>// Find invoice -&gt; organization -&gt; address\nMATCH (i:BillingDocument)-[:ISSUED_BY]-&gt;(o:Organization)-[:LOCATED_AT]-&gt;(a:Address)\nRETURN i.document_no, o.name, a.city\n\n// Find all paths between two nodes\nMATCH path = (start:BillingDocument)-[*..3]-(end:Address)\nWHERE start.document_no = \"INV-001\"\nRETURN path\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#aggregation-queries","title":"Aggregation Queries","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#sum-and-average","title":"Sum and Average","text":"<pre><code>// Total invoice amount\nMATCH (i:BillingDocument)\nRETURN sum(i.total) as total_amount\n\n// Average invoice amount\nMATCH (i:BillingDocument)\nRETURN avg(i.total) as average_amount\n\n// Count invoices per organization\nMATCH (o:Organization)&lt;-[:ISSUED_BY]-(i:BillingDocument)\nRETURN o.name, count(i) as invoice_count\nORDER BY invoice_count DESC\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#pattern-matching","title":"Pattern Matching","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#complex-patterns","title":"Complex Patterns","text":"<pre><code>// Find invoices with specific pattern\nMATCH (i:BillingDocument)-[:ISSUED_BY]-&gt;(o:Organization),\n      (i)-[:SENT_TO]-&gt;(c:Organization),\n      (i)-[:CONTAINS_LINE]-&gt;(item:LineItem)\nWHERE i.total &gt; 1000\nRETURN i, o, c, collect(item) as items\n\n// Find organizations that both issue and receive invoices\nMATCH (o:Organization)&lt;-[:ISSUED_BY]-(i1:BillingDocument),\n      (o)&lt;-[:SENT_TO]-(i2:BillingDocument)\nRETURN o.name, count(DISTINCT i1) as issued, count(DISTINCT i2) as received\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#import-and-query","title":"\ud83d\udccd Import and Query","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom neo4j import GraphDatabase\n\n# 1. Extract and export\nconfig = PipelineConfig(\n    source=\"invoices.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"cypher\",\n    output_dir=\"neo4j_data\"\n)\n\nrun_pipeline(config)\n\n# 2. Import to Neo4j\ndriver = GraphDatabase.driver(\n    \"bolt://localhost:7687\",\n    auth=(\"neo4j\", \"password\")\n)\n\nwith open(\"neo4j_data/graph.cypher\") as f:\n    cypher_script = f.read()\n\nwith driver.session() as session:\n    session.run(cypher_script)\n\n# 3. Query\nwith driver.session() as session:\n    result = session.run(\"\"\"\n        MATCH (i:BillingDocument)\n        RETURN i.document_no, i.total\n        ORDER BY i.total DESC\n        LIMIT 5\n    \"\"\")\n\n    for record in result:\n        print(f\"{record['i.document_no']}: ${record['i.total']}\")\n\ndriver.close()\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#batch-import","title":"\ud83d\udccd Batch Import","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom pathlib import Path\nimport subprocess\n\n# Process multiple documents\nfor pdf_file in Path(\"documents\").glob(\"*.pdf\"):\n    print(f\"Processing {pdf_file.name}\")\n\n    # Extract\n    config = PipelineConfig(\n        source=str(pdf_file),\n        template=\"templates.BillingDocument\",\n        export_format=\"cypher\",\n        output_dir=f\"neo4j_batch/{pdf_file.stem}\"\n    )\n\n    run_pipeline(config)\n\n    # Import\n    cypher_file = f\"neo4j_batch/{pdf_file.stem}/graph.cypher\"\n    subprocess.run([\n        \"cypher-shell\",\n        \"-u\", \"neo4j\",\n        \"-p\", \"password\",\n        \"-f\", cypher_file\n    ])\n\nprint(\"\u2705 Batch import complete\")\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#query-and-export","title":"\ud83d\udccd Query and Export","text":"<pre><code>from neo4j import GraphDatabase\nimport pandas as pd\n\n# Connect\ndriver = GraphDatabase.driver(\n    \"bolt://localhost:7687\",\n    auth=(\"neo4j\", \"password\")\n)\n\n# Query\nwith driver.session() as session:\n    result = session.run(\"\"\"\n        MATCH (i:BillingDocument)-[:ISSUED_BY]-&gt;(o:Organization)\n        RETURN i.document_no as invoice,\n               o.name as organization,\n               i.total as amount\n        ORDER BY i.total DESC\n    \"\"\")\n\n    # Convert to DataFrame\n    df = pd.DataFrame([dict(record) for record in result])\n\n    # Export\n    df.to_csv(\"invoice_summary.csv\", index=False)\n    print(f\"Exported {len(df)} records\")\n\ndriver.close()\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#clear-database-before-import","title":"\ud83d\udc4d Clear Database Before Import","text":"<pre><code>// Delete all nodes and relationships\nMATCH (n)\nDETACH DELETE n\n\n// Verify empty\nMATCH (n)\nRETURN count(n)\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#create-indexes","title":"\ud83d\udc4d Create Indexes","text":"<pre><code>// Create index on invoice number\nCREATE INDEX document_no_idx FOR (i:BillingDocument) ON (i.document_no)\n\n// Create index on organization name\nCREATE INDEX org_name_idx FOR (o:Organization) ON (o.name)\n\n// List indexes\nSHOW INDEXES\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#use-constraints","title":"\ud83d\udc4d Use Constraints","text":"<pre><code>// Unique constraint on invoice number\nCREATE CONSTRAINT invoice_unique FOR (i:BillingDocument) REQUIRE i.document_no IS UNIQUE\n\n// Existence constraint\nCREATE CONSTRAINT document_no_exists FOR (i:BillingDocument) REQUIRE i.document_no IS NOT NULL\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#batch-imports","title":"\ud83d\udc4d Batch Imports","text":"<pre><code># \u2705 Good - Import in batches\nfrom neo4j import GraphDatabase\n\ndriver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n\n# Process in batches\nbatch_size = 1000\nfor i in range(0, len(statements), batch_size):\n    batch = statements[i:i+batch_size]\n\n    with driver.session() as session:\n        for statement in batch:\n            session.run(statement)\n\n    print(f\"Imported batch {i//batch_size + 1}\")\n\ndriver.close()\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#connection-refused","title":"\ud83d\udc1b Connection Refused","text":"<p>Solution: <pre><code># Check Neo4j is running\ndocker ps | grep neo4j\n\n# Or check service\nsystemctl status neo4j\n\n# Restart if needed\ndocker restart neo4j\n</code></pre></p>"},{"location":"fundamentals/graph-management/neo4j-integration/#authentication-failed","title":"\ud83d\udc1b Authentication Failed","text":"<p>Solution: <pre><code># Reset password\ncypher-shell -u neo4j -p neo4j\n# Then change password when prompted\n\n# Or set in Docker\ndocker run -e NEO4J_AUTH=neo4j/newpassword neo4j\n</code></pre></p>"},{"location":"fundamentals/graph-management/neo4j-integration/#import-fails","title":"\ud83d\udc1b Import Fails","text":"<p>Solution: <pre><code># Check Cypher syntax\nhead -20 neo4j_import/graph.cypher\n\n# Test small portion\nhead -100 neo4j_import/graph.cypher | cypher-shell -u neo4j -p password\n\n# Check logs\ndocker logs neo4j\n</code></pre></p>"},{"location":"fundamentals/graph-management/neo4j-integration/#slow-queries","title":"\ud83d\udc1b Slow Queries","text":"<p>Solution: <pre><code>// Create indexes\nCREATE INDEX FOR (i:BillingDocument) ON (i.document_no)\n\n// Use EXPLAIN to analyze\nEXPLAIN MATCH (i:BillingDocument) WHERE i.total &gt; 1000 RETURN i\n\n// Use PROFILE for detailed analysis\nPROFILE MATCH (i:BillingDocument) WHERE i.total &gt; 1000 RETURN i\n</code></pre></p>"},{"location":"fundamentals/graph-management/neo4j-integration/#advanced-topics","title":"Advanced Topics","text":""},{"location":"fundamentals/graph-management/neo4j-integration/#graph-algorithms","title":"Graph Algorithms","text":"<pre><code>// Find shortest path\nMATCH path = shortestPath(\n    (start:BillingDocument {document_no: \"INV-001\"})-[*]-(end:Address)\n)\nRETURN path\n\n// PageRank (requires APOC or GDS)\nCALL gds.pageRank.stream('myGraph')\nYIELD nodeId, score\nRETURN gds.util.asNode(nodeId).name AS name, score\nORDER BY score DESC\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#full-text-search","title":"Full-Text Search","text":"<pre><code>// Create full-text index\nCREATE FULLTEXT INDEX organization_search FOR (o:Organization) ON EACH [o.name, o.description]\n\n// Search\nCALL db.index.fulltext.queryNodes('organization_search', 'Acme')\nYIELD node, score\nRETURN node.name, score\n</code></pre>"},{"location":"fundamentals/graph-management/neo4j-integration/#next-steps","title":"Next Steps","text":"<p>Now that you understand Neo4j integration:</p> <ol> <li>Graph Analysis \u2192 - Analyze graph structure</li> <li>CLI Guide \u2192 - Use command-line tools</li> <li>API Reference \u2192 - Programmatic access</li> </ol>"},{"location":"fundamentals/graph-management/visualization/","title":"Visualization","text":""},{"location":"fundamentals/graph-management/visualization/#overview","title":"Overview","text":"<p>Visualization transforms your knowledge graphs into interactive, explorable visualizations. Docling Graph automatically generates HTML visualizations and markdown reports for every pipeline run.</p> <p>In this guide: - Interactive HTML graphs - Markdown reports - Graph statistics - Customization options - Integration examples</p>"},{"location":"fundamentals/graph-management/visualization/#automatic-visualization","title":"Automatic Visualization","text":""},{"location":"fundamentals/graph-management/visualization/#what-gets-generated","title":"What Gets Generated?","text":"<p>Every pipeline run automatically creates:</p> <pre><code>outputs/\n\u251c\u2500\u2500 visualization.html  # Interactive graph\n\u251c\u2500\u2500 report.md          # Markdown report\n\u2514\u2500\u2500 graph_stats.json   # Statistics\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    output_dir=\"outputs\"\n)\n\nrun_pipeline(config)\n\n# Automatically generates:\n# - outputs/visualization.html\n# - outputs/report.md\n# - outputs/graph_stats.json\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#interactive-html-visualization","title":"Interactive HTML Visualization","text":""},{"location":"fundamentals/graph-management/visualization/#features","title":"Features","text":"<p>\u2705 Interactive exploration - Zoom and pan - Node selection - Search functionality - Layout algorithms</p> <p>\u2705 Visual styling - Color-coded node types - Edge labels - Hover tooltips - Responsive design</p> <p>\u2705 Export options - Save as image - Share via URL - Embed in websites</p>"},{"location":"fundamentals/graph-management/visualization/#opening-visualization","title":"Opening Visualization","text":"<pre><code># Open in browser\nopen outputs/visualization.html  # macOS\nxdg-open outputs/visualization.html  # Linux\nstart outputs/visualization.html  # Windows\n\n# Or double-click the file\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#manual-generation","title":"Manual Generation","text":"<pre><code>from docling_graph.core.visualizers import InteractiveVisualizer\nfrom docling_graph.core.converters import GraphConverter\n\n# Convert models to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Generate visualization\nvisualizer = InteractiveVisualizer()\nvisualizer.save_cytoscape_graph(\n    graph=graph,\n    output_path=\"my_graph.html\",\n    open_browser=True  # Automatically open\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#markdown-reports","title":"Markdown Reports","text":""},{"location":"fundamentals/graph-management/visualization/#whats-in-the-report","title":"What's in the Report?","text":"<p>Markdown reports contain:</p> <ol> <li>Overview - Node/edge counts, timestamps</li> <li>Node Distribution - Types and percentages</li> <li>Edge Distribution - Relationship types</li> <li>Sample Nodes - Example entities</li> <li>Sample Edges - Example relationships</li> </ol>"},{"location":"fundamentals/graph-management/visualization/#example-report","title":"Example Report","text":"<pre><code># Knowledge Graph Report\n\nAutomatically generated by docling-graph.\n\n## Overview\n\n- **Total Nodes**: 15\n- **Total Edges**: 18\n- **Source Models**: 1\n- **Generated**: 2024-01-15 14:30:00\n\n## Node Type Distribution\n\n| Node Type | Count | Percentage |\n|-----------|-------|------------|\n| LineItem | 9 | 60.0% |\n| Address | 3 | 20.0% |\n| Organization | 2 | 13.3% |\n| Invoice | 1 | 6.7% |\n\n## Edge Type Distribution\n\n| Edge Type | Count | Percentage |\n|-----------|-------|------------|\n| contains_item | 9 | 50.0% |\n| located_at | 5 | 27.8% |\n| has_total | 2 | 11.1% |\n| issued_by | 1 | 5.6% |\n| sent_to | 1 | 5.6% |\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#manual-report-generation","title":"Manual Report Generation","text":"<pre><code>from docling_graph.core.visualizers import ReportGenerator\nfrom docling_graph.core.converters import GraphConverter\n\n# Convert models to graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Generate report\ngenerator = ReportGenerator()\ngenerator.visualize(\n    graph=graph,\n    output_path=\"my_report.md\",\n    source_model_count=len(models),\n    include_samples=True\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#graph-statistics","title":"Graph Statistics","text":""},{"location":"fundamentals/graph-management/visualization/#graph_statsjson-format","title":"graph_stats.json Format","text":"<pre><code>{\n  \"node_count\": 15,\n  \"edge_count\": 18,\n  \"node_types\": {\n    \"BillingDocument\": 1,\n    \"Organization\": 2,\n    \"Address\": 3,\n    \"LineItem\": 9\n  },\n  \"edge_types\": {\n    \"issued_by\": 1,\n    \"sent_to\": 1,\n    \"located_at\": 5,\n    \"contains_item\": 9,\n    \"has_total\": 2\n  },\n  \"avg_degree\": 2.4,\n  \"density\": 0.17,\n  \"source_models\": 1,\n  \"created_at\": \"2024-01-15T14:30:00\"\n}\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#using-statistics","title":"Using Statistics","text":"<pre><code>import json\n\n# Load statistics\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\n# Analyze\nprint(f\"Graph has {stats['node_count']} nodes\")\nprint(f\"Average degree: {stats['avg_degree']:.2f}\")\nprint(f\"Density: {stats['density']:.2f}\")\n\n# Most common node type\nmost_common = max(stats['node_types'], key=stats['node_types'].get)\nprint(f\"Most common node type: {most_common}\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#complete-examples","title":"Complete Examples","text":""},{"location":"fundamentals/graph-management/visualization/#basic-visualization","title":"\ud83d\udccd Basic Visualization","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Run pipeline (automatic visualization)\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.BillingDocument\",\n    output_dir=\"outputs\"\n)\n\nrun_pipeline(config)\n\n# Open visualization\nimport webbrowser\nwebbrowser.open(\"file://outputs/visualization.html\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#custom-visualization","title":"\ud83d\udccd Custom Visualization","text":"<pre><code>from docling_graph.core.visualizers import InteractiveVisualizer\nfrom docling_graph.core.converters import GraphConverter\n\n# Create graph\nconverter = GraphConverter()\ngraph, metadata = converter.pydantic_list_to_graph(models)\n\n# Generate custom visualization\nvisualizer = InteractiveVisualizer()\nhtml_path = visualizer.save_cytoscape_graph(\n    graph=graph,\n    output_path=\"custom_graph.html\",\n    open_browser=False\n)\n\nprint(f\"Visualization saved to {html_path}\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#batch-visualization","title":"\ud83d\udccd Batch Visualization","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom pathlib import Path\n\n# Process multiple documents\nfor pdf_file in Path(\"documents\").glob(\"*.pdf\"):\n    output_dir = f\"visualizations/{pdf_file.stem}\"\n\n    config = PipelineConfig(\n        source=str(pdf_file),\n        template=\"templates.BillingDocument\",\n        output_dir=output_dir\n    )\n\n    run_pipeline(config)\n\n    print(f\"Visualization: {output_dir}/visualization.html\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#report-analysis","title":"\ud83d\udccd Report Analysis","text":"<pre><code>import json\nfrom pathlib import Path\n\n# Analyze multiple reports\nreports = []\n\nfor stats_file in Path(\"outputs\").rglob(\"graph_stats.json\"):\n    with open(stats_file) as f:\n        stats = json.load(f)\n        reports.append({\n            \"file\": stats_file.parent.name,\n            \"nodes\": stats[\"node_count\"],\n            \"edges\": stats[\"edge_count\"],\n            \"density\": stats[\"density\"]\n        })\n\n# Summary\nimport pandas as pd\ndf = pd.DataFrame(reports)\nprint(df.describe())\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#visualization-from-csv","title":"Visualization from CSV","text":""},{"location":"fundamentals/graph-management/visualization/#load-and-visualize-csv","title":"Load and Visualize CSV","text":"<pre><code>from docling_graph.core.visualizers import InteractiveVisualizer\nfrom pathlib import Path\n\n# Load CSV and create visualization\nvisualizer = InteractiveVisualizer()\nhtml_path = visualizer.display_cytoscape_graph(\n    path=Path(\"outputs\"),  # Directory with nodes.csv and edges.csv\n    input_format=\"csv\",\n    output_path=\"from_csv.html\",\n    open_browser=True\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#visualization-from-json","title":"Visualization from JSON","text":""},{"location":"fundamentals/graph-management/visualization/#load-and-visualize-json","title":"Load and Visualize JSON","text":"<pre><code>from docling_graph.core.visualizers import InteractiveVisualizer\nfrom pathlib import Path\n\n# Load JSON and create visualization\nvisualizer = InteractiveVisualizer()\nhtml_path = visualizer.display_cytoscape_graph(\n    path=Path(\"outputs/graph_data.json\"),\n    input_format=\"json\",\n    output_path=\"from_json.html\",\n    open_browser=True\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#customization","title":"Customization","text":""},{"location":"fundamentals/graph-management/visualization/#custom-report","title":"Custom Report","text":"<pre><code>from docling_graph.core.visualizers import ReportGenerator\n\ngenerator = ReportGenerator()\ngenerator.visualize(\n    graph=graph,\n    output_path=\"custom_report.md\",\n    source_model_count=len(models),\n    include_samples=False  # Exclude sample nodes/edges\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#custom-statistics","title":"Custom Statistics","text":"<pre><code>from docling_graph.core.utils import calculate_graph_stats\n\n# Calculate custom statistics\nmetadata = calculate_graph_stats(graph, source_model_count=len(models))\n\nprint(f\"Nodes: {metadata.node_count}\")\nprint(f\"Edges: {metadata.edge_count}\")\nprint(f\"Density: {metadata.density:.3f}\")\nprint(f\"Avg degree: {metadata.avg_degree:.2f}\")\n\n# Node type distribution\nfor node_type, count in metadata.node_types.items():\n    percentage = (count / metadata.node_count) * 100\n    print(f\"{node_type}: {count} ({percentage:.1f}%)\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#integration-examples","title":"Integration Examples","text":""},{"location":"fundamentals/graph-management/visualization/#web-dashboard","title":"\ud83d\udccd Web Dashboard","text":"<pre><code>from flask import Flask, render_template\nfrom docling_graph import run_pipeline, PipelineConfig\nimport json\n\napp = Flask(__name__)\n\n@app.route('/visualize/&lt;doc_id&gt;')\ndef visualize(doc_id):\n    # Load graph data\n    with open(f\"outputs/{doc_id}/graph_stats.json\") as f:\n        stats = json.load(f)\n\n    return render_template('dashboard.html', \n                         stats=stats,\n                         viz_url=f\"/static/{doc_id}/visualization.html\")\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#automated-reports","title":"\ud83d\udccd Automated Reports","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom pathlib import Path\nimport smtplib\nfrom email.mime.text import MIMEText\n\ndef process_and_email(pdf_path, recipient):\n    \"\"\"Process document and email report.\"\"\"\n\n    # Process document\n    config = PipelineConfig(\n        source=pdf_path,\n        template=\"templates.BillingDocument\",\n        output_dir=\"temp_output\"\n    )\n    run_pipeline(config)\n\n    # Read report\n    with open(\"temp_output/report.md\") as f:\n        report = f.read()\n\n    # Email report\n    msg = MIMEText(report)\n    msg['Subject'] = f'Graph Report: {Path(pdf_path).name}'\n    msg['To'] = recipient\n\n    # Send email (configure SMTP)\n    # smtp.send_message(msg)\n\n    print(f\"Report sent to {recipient}\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/graph-management/visualization/#always-generate-visualizations","title":"\ud83d\udc4d Always Generate Visualizations","text":"<pre><code># \u2705 Good - Keep visualizations enabled\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    # Visualizations generated automatically\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#check-statistics","title":"\ud83d\udc4d Check Statistics","text":"<pre><code># \u2705 Good - Verify graph quality\nimport json\n\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nif stats[\"node_count\"] == 0:\n    print(\"Warning: Empty graph\")\n\nif stats[\"edge_count\"] == 0:\n    print(\"Warning: No relationships\")\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#organize-visualizations","title":"\ud83d\udc4d Organize Visualizations","text":"<pre><code># \u2705 Good - Structured output\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\noutput_dir = f\"visualizations/{timestamp}\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    output_dir=output_dir\n)\n</code></pre>"},{"location":"fundamentals/graph-management/visualization/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/graph-management/visualization/#visualization-not-opening","title":"\ud83d\udc1b Visualization Not Opening","text":"<p>Solution: <pre><code># Check file exists\nimport os\n\nviz_path = \"outputs/visualization.html\"\nif os.path.exists(viz_path):\n    print(f\"\u2705 File exists: {viz_path}\")\n\n    # Open manually\n    import webbrowser\n    webbrowser.open(f\"file://{os.path.abspath(viz_path)}\")\nelse:\n    print(f\"\u274c File not found: {viz_path}\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/visualization/#empty-visualization","title":"\ud83d\udc1b Empty Visualization","text":"<p>Solution: <pre><code># Check graph has nodes\nimport json\n\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nif stats[\"node_count\"] == 0:\n    print(\"Graph is empty - check extraction\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/visualization/#report-generation-fails","title":"\ud83d\udc1b Report Generation Fails","text":"<p>Solution: <pre><code># Check graph validity\nfrom docling_graph.core.visualizers import ReportGenerator\n\ngenerator = ReportGenerator()\n\nif generator.validate_graph(graph):\n    print(\"\u2705 Graph is valid\")\nelse:\n    print(\"\u274c Graph is empty\")\n</code></pre></p>"},{"location":"fundamentals/graph-management/visualization/#next-steps","title":"Next Steps","text":"<p>Now that you understand visualization:</p> <ol> <li>Neo4j Integration \u2192 - Import into Neo4j</li> <li>Graph Analysis \u2192 - Analyze graph structure</li> <li>CLI Guide \u2192 - Use command-line tools</li> </ol>"},{"location":"fundamentals/installation/","title":"Installation","text":""},{"location":"fundamentals/installation/#overview","title":"Overview","text":"<p>Docling Graph is available on PyPI. Install with pip for the recommended experience, or clone the repository and use uv for development.</p>"},{"location":"fundamentals/installation/#what-youll-install","title":"What You'll Install","text":"<ol> <li>Core Package: Docling Graph with VLM support</li> <li>Optional Features: LLM providers (local and/or remote) via LiteLLM (included by default)</li> <li>GPU Support (optional): PyTorch with CUDA for local inference</li> <li>API Keys (optional): For remote LLM providers</li> </ol>"},{"location":"fundamentals/installation/#quick-start","title":"Quick Start","text":""},{"location":"fundamentals/installation/#install-from-pypi-recommended","title":"Install from PyPI (Recommended)","text":"<pre><code>pip install docling-graph\n</code></pre> <p>This installs:</p> <ul> <li>\u2705 Docling (document conversion)</li> <li>\u2705 VLM backend (NuExtract models)</li> <li>\u2705 Core graph functionality</li> <li>\u2705 LiteLLM (for LLM providers; no extra install needed)</li> </ul> <p>Run the CLI with:</p> <pre><code>docling-graph --version\ndocling-graph --help\n</code></pre>"},{"location":"fundamentals/installation/#install-from-source-development","title":"Install from Source (Development)","text":"<p>To contribute or use the latest development version:</p> <pre><code>git clone https://github.com/docling-project/docling-graph\ncd docling-graph\nuv sync\n</code></pre> <p>Use <code>uv run docling-graph</code> when running the CLI from a source checkout.</p>"},{"location":"fundamentals/installation/#system-requirements","title":"System Requirements","text":""},{"location":"fundamentals/installation/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>Python: 3.10, 3.11, or 3.12</li> <li>RAM: 8 GB minimum</li> <li>Disk: 5 GB free space</li> <li>OS: Linux, macOS, or Windows (with WSL recommended)</li> </ul>"},{"location":"fundamentals/installation/#recommended-for-local-inference","title":"Recommended for Local Inference","text":"<ul> <li>GPU: NVIDIA GPU with 8+ GB VRAM</li> <li>CUDA: 11.8 or 12.1</li> <li>RAM: 16 GB or more</li> <li>Disk: 20 GB free space (for models)</li> </ul>"},{"location":"fundamentals/installation/#for-vlm-only","title":"For VLM Only","text":"<ul> <li>GPU: NVIDIA GPU with 4+ GB VRAM (for NuExtract-2B)</li> <li>GPU: NVIDIA GPU with 8+ GB VRAM (for NuExtract-8B)</li> </ul>"},{"location":"fundamentals/installation/#for-remote-api-only","title":"For Remote API Only","text":"<ul> <li>No GPU required</li> <li>Internet connection required</li> <li>API keys required</li> </ul>"},{"location":"fundamentals/installation/#verification","title":"Verification","text":""},{"location":"fundamentals/installation/#check-installation","title":"Check Installation","text":"<pre><code># Check version (use docling-graph if installed via pip; uv run docling-graph if from source)\ndocling-graph --version\n\n# Test CLI\ndocling-graph --help\n</code></pre> <p>Expected output: <pre><code>Docling Graph v1.2.0\nUsage: docling-graph [OPTIONS] COMMAND [ARGS]...\n</code></pre></p>"},{"location":"fundamentals/installation/#test-import","title":"Test Import","text":"<pre><code>python -c \"import docling_graph; print(docling_graph.__version__)\"\n</code></pre> <p>Expected output: <pre><code>v1.2.0\n</code></pre></p>"},{"location":"fundamentals/installation/#next-steps","title":"Next Steps","text":"<p>After installation, you need to:</p> <ol> <li>Set Up Requirements - Verify system requirements</li> <li>Configure GPU (optional) - Set up CUDA for local inference</li> <li>Set Up API Keys (optional) - Configure remote providers</li> <li>Define Schema - Create your first Pydantic template</li> </ol>"},{"location":"fundamentals/installation/#common-issues","title":"Common Issues","text":""},{"location":"fundamentals/installation/#uv-not-found-source-install-only","title":"\ud83d\udc1b <code>uv</code> not found (source install only)","text":"<p>If you install from source, you need uv. Install it with:</p> <pre><code># Linux/macOS\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows (PowerShell)\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# Or with pip\npip install uv\n</code></pre>"},{"location":"fundamentals/installation/#python-version-mismatch-source-install","title":"\ud83d\udc1b Python version mismatch (source install)","text":"<p>When using uv from source, specify Python version if needed:</p> <pre><code>uv python install 3.10\nuv sync\n</code></pre>"},{"location":"fundamentals/installation/#import-errors-after-installation","title":"\ud83d\udc1b Import errors after installation","text":"<p>Solution: If you installed from source with uv, run scripts and the CLI via <code>uv run</code>:</p> <pre><code>uv run python script.py\nuv run docling-graph --help\n</code></pre> <p>If you installed with pip, use <code>python</code> and <code>docling-graph</code> directly.</p>"},{"location":"fundamentals/installation/#gpu-not-detected","title":"\ud83d\udc1b GPU not detected","text":"<p>Solution: See GPU Setup Guide</p>"},{"location":"fundamentals/installation/#performance-notes","title":"Performance Notes","text":"<p>New in v1.2.0: Significant CLI performance improvements:</p> <ul> <li>Init command: 75-85% faster with intelligent dependency caching</li> <li>First run: ~1-1.5s (checks dependencies)</li> <li>Subsequent runs: ~0.5-1s (uses cache)</li> <li>Dependency validation: 90-95% faster (2-3s \u2192 0.1-0.2s)</li> <li>Lazy loading: Configuration constants loaded on-demand</li> </ul>"},{"location":"fundamentals/installation/#development-installation","title":"Development Installation","text":"<p>For contributing to the project:</p> <pre><code># Clone repository\ngit clone https://github.com/docling-project/docling-graph\ncd docling-graph\n\n# Install with development dependencies\nuv sync --all-extras --dev\n\n# Install pre-commit hooks\nuv run pre-commit install\n\n# Run tests\nuv run pytest\n</code></pre>"},{"location":"fundamentals/installation/#updating","title":"Updating","text":"<p>If you installed from PyPI:</p> <pre><code>pip install -U docling-graph\n</code></pre> <p>If you installed from source:</p> <pre><code>git pull origin main\nuv sync\n</code></pre>"},{"location":"fundamentals/installation/#uninstalling","title":"Uninstalling","text":"<p>If you installed from PyPI:</p> <pre><code>pip uninstall docling-graph\n</code></pre> <p>If you installed from source:</p> <pre><code>rm -rf .venv\ncd ..\nrm -rf docling-graph\n</code></pre>"},{"location":"fundamentals/installation/api-keys/","title":"API Keys Setup","text":""},{"location":"fundamentals/installation/api-keys/#overview","title":"Overview","text":"<p>Remote LLM providers require API keys for authentication. This guide covers:</p> <ul> <li>OpenAI (GPT-4, GPT-3.5-turbo)</li> <li>Mistral AI (Mistral Small, Medium, Large)</li> <li>Google Gemini (Gemini Pro, Gemini Flash)</li> <li>IBM WatsonX (Granite, Llama, Mixtral)</li> </ul> <p>API Keys Not Required</p> <p>API keys are not required for:</p> <ul> <li>Local VLM (NuExtract)</li> <li>Local LLM (vLLM, Ollama, LM Studio)</li> </ul>"},{"location":"fundamentals/installation/api-keys/#quick-setup","title":"Quick Setup","text":""},{"location":"fundamentals/installation/api-keys/#linuxmacos","title":"Linux/macOS","text":"<p>Add to your shell configuration file (<code>~/.bashrc</code>, <code>~/.zshrc</code>, or <code>~/.bash_profile</code>):</p> <pre><code># OpenAI\nexport OPENAI_API_KEY=\"sk-...\"\n\n# Mistral AI\nexport MISTRAL_API_KEY=\"...\"\n\n# Google Gemini\nexport GEMINI_API_KEY=\"...\"\n\n# IBM WatsonX\nexport WATSONX_API_KEY=\"...\"\nexport WATSONX_PROJECT_ID=\"...\"\nexport WATSONX_URL=\"https://us-south.ml.cloud.ibm.com\"  # Optional\n</code></pre> <p>Then reload: <pre><code>source ~/.bashrc  # or ~/.zshrc\n</code></pre></p>"},{"location":"fundamentals/installation/api-keys/#windows-powershell","title":"Windows (PowerShell)","text":"<pre><code># OpenAI\n$env:OPENAI_API_KEY=\"sk-...\"\n\n# Mistral AI\n$env:MISTRAL_API_KEY=\"...\"\n\n# Google Gemini\n$env:GEMINI_API_KEY=\"...\"\n\n# IBM WatsonX\n$env:WATSONX_API_KEY=\"...\"\n$env:WATSONX_PROJECT_ID=\"...\"\n$env:WATSONX_URL=\"https://us-south.ml.cloud.ibm.com\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#windows-command-prompt","title":"Windows (Command Prompt)","text":"<pre><code>set OPENAI_API_KEY=sk-...\nset MISTRAL_API_KEY=...\nset GEMINI_API_KEY=...\nset WATSONX_API_KEY=...\nset WATSONX_PROJECT_ID=...\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#using-env-file-recommended","title":"Using .env File (Recommended)","text":"<p>Create a <code>.env</code> file in your project root:</p> <pre><code># .env file\nOPENAI_API_KEY=sk-...\nMISTRAL_API_KEY=...\nGEMINI_API_KEY=...\nWATSONX_API_KEY=...\nWATSONX_PROJECT_ID=...\nWATSONX_URL=https://us-south.ml.cloud.ibm.com\n</code></pre> <p>Security: Add <code>.env</code> to <code>.gitignore</code>: <pre><code>echo \".env\" &gt;&gt; .gitignore\n</code></pre></p>"},{"location":"fundamentals/installation/api-keys/#config-based-api-key-and-custom-endpoints","title":"Config-based API key and custom endpoints","text":"<p>You can set the API key or endpoint URL in <code>config.yaml</code> under <code>llm_overrides.connection</code>:</p> <ul> <li><code>api_key</code>: API key value (prefer env or <code>.env</code> for secrets)</li> <li><code>base_url</code>: Custom base URL (e.g. for on-prem OpenAI-compatible servers)</li> </ul> <p>For on-prem or custom OpenAI-compatible endpoints, use the fixed env vars:</p> <pre><code>export CUSTOM_LLM_BASE_URL=\"https://your-llm.example.com/v1\"\nexport CUSTOM_LLM_API_KEY=\"your-api-key\"\n</code></pre> <p>Run <code>docling-graph init</code> and choose \"Use custom endpoint\" for guided setup.</p>"},{"location":"fundamentals/installation/api-keys/#lm-studio-optional-api-key","title":"LM Studio (optional API key)","text":"<p>The LM Studio local server usually does not require an API key when running on localhost. When an API key is needed (e.g. remote LM Studio or a secured server), set it in the environment or in config:</p> <ul> <li>Environment: <code>export LM_STUDIO_API_KEY=\"your-key\"</code></li> <li>Config: Set <code>llm_overrides.connection.api_key</code> in your <code>config.yaml</code> (prefer env for secrets)</li> </ul> <p>To use a non-default server URL (e.g. a different port or host), set:</p> <pre><code>export LM_STUDIO_API_BASE=\"http://localhost:1234/v1\"\n</code></pre> <p>See Model Configuration for full LM Studio setup with <code>provider=lmstudio</code>.</p>"},{"location":"fundamentals/installation/api-keys/#provider-specific-setup","title":"Provider-Specific Setup","text":""},{"location":"fundamentals/installation/api-keys/#openai","title":"OpenAI","text":""},{"location":"fundamentals/installation/api-keys/#1-get-api-key","title":"1. Get API Key","text":"<ol> <li>Visit OpenAI Platform</li> <li>Sign up or log in</li> <li>Navigate to API Keys</li> <li>Click \"Create new secret key\"</li> <li>Copy the key (starts with <code>sk-</code>)</li> </ol>"},{"location":"fundamentals/installation/api-keys/#2-set-environment-variable","title":"2. Set Environment Variable","text":"<pre><code>export OPENAI_API_KEY=\"sk-...\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#3-verify","title":"3. Verify","text":"<pre><code>uv run python -c \"import os; print('OpenAI key set:', bool(os.getenv('OPENAI_API_KEY')))\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#4-test","title":"4. Test","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider openai \\\n    --model gpt-4-turbo\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#available-models","title":"Available Models","text":"Model Context Cost (per 1M tokens) Best For gpt-4-turbo 128K $10 / $30 Complex extraction gpt-4 8K $30 / $60 High quality gpt-3.5-turbo 16K $0.50 / $1.50 Fast, cost-effective"},{"location":"fundamentals/installation/api-keys/#mistral-ai","title":"Mistral AI","text":""},{"location":"fundamentals/installation/api-keys/#1-get-api-key_1","title":"1. Get API Key","text":"<ol> <li>Visit Mistral AI Console</li> <li>Sign up or log in</li> <li>Navigate to API Keys</li> <li>Create new API key</li> <li>Copy the key</li> </ol>"},{"location":"fundamentals/installation/api-keys/#2-set-environment-variable_1","title":"2. Set Environment Variable","text":"<pre><code>export MISTRAL_API_KEY=\"...\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#3-verify_1","title":"3. Verify","text":"<pre><code>uv run python -c \"import os; print('Mistral key set:', bool(os.getenv('MISTRAL_API_KEY')))\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#4-test_1","title":"4. Test","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider mistral \\\n    --model mistral-medium-latest\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#available-models_1","title":"Available Models","text":"Model Context Cost (per 1M tokens) Best For mistral-large-latest 32K $4 / $12 Complex tasks mistral-medium-latest 32K $2.7 / $8.1 Balanced mistral-small-latest 32K $1 / $3 Fast, affordable"},{"location":"fundamentals/installation/api-keys/#google-gemini","title":"Google Gemini","text":""},{"location":"fundamentals/installation/api-keys/#1-get-api-key_2","title":"1. Get API Key","text":"<ol> <li>Visit Google AI Studio</li> <li>Sign in with Google account</li> <li>Click \"Create API Key\"</li> <li>Copy the key</li> </ol>"},{"location":"fundamentals/installation/api-keys/#2-set-environment-variable_2","title":"2. Set Environment Variable","text":"<pre><code>export GEMINI_API_KEY=\"...\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#3-verify_2","title":"3. Verify","text":"<pre><code>uv run python -c \"import os; print('Gemini key set:', bool(os.getenv('GEMINI_API_KEY')))\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#4-test_2","title":"4. Test","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider gemini \\\n    --model gemini-2.5-flash\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#available-models_2","title":"Available Models","text":"Model Context Cost (per 1M tokens) Best For gemini-2.5-flash 1M $0.075 / $0.30 Very fast, cheap gemini-pro 32K $0.50 / $1.50 Balanced"},{"location":"fundamentals/installation/api-keys/#ibm-watsonx","title":"IBM WatsonX","text":""},{"location":"fundamentals/installation/api-keys/#1-get-credentials","title":"1. Get Credentials","text":"<ol> <li>Visit IBM Cloud</li> <li>Create or log into account</li> <li>Navigate to WatsonX</li> <li>Create a project</li> <li>Get API key and project ID from project settings</li> </ol>"},{"location":"fundamentals/installation/api-keys/#2-set-environment-variables","title":"2. Set Environment Variables","text":"<pre><code>export WATSONX_API_KEY=\"...\"\nexport WATSONX_PROJECT_ID=\"...\"\nexport WATSONX_URL=\"https://us-south.ml.cloud.ibm.com\"  # Optional, defaults to US South\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#3-verify_3","title":"3. Verify","text":"<pre><code>uv run python -c \"import os; print('WatsonX key set:', bool(os.getenv('WATSONX_API_KEY'))); print('WatsonX project set:', bool(os.getenv('WATSONX_PROJECT_ID')))\"\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#4-test_3","title":"4. Test","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider watsonx \\\n    --model ibm/granite-13b-chat-v2\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#available-models_3","title":"Available Models","text":"Model Context Best For ibm/granite-13b-chat-v2 8K General purpose meta-llama/llama-3-70b-instruct 8K High quality mistralai/mixtral-8x7b-instruct-v01 32K Complex tasks <p>WatsonX Configuration</p> <p>For detailed WatsonX configuration, refer to the Model Configuration guide.</p>"},{"location":"fundamentals/installation/api-keys/#verification","title":"Verification","text":""},{"location":"fundamentals/installation/api-keys/#check-all-keys","title":"Check All Keys","text":"<pre><code>uv run python &lt;&lt; EOF\nimport os\n\nproviders = {\n    'OpenAI': 'OPENAI_API_KEY',\n    'Mistral': 'MISTRAL_API_KEY',\n    'Gemini': 'GEMINI_API_KEY',\n    'WatsonX API': 'WATSONX_API_KEY',\n    'WatsonX Project': 'WATSONX_PROJECT_ID'\n}\n\nfor name, var in providers.items():\n    value = os.getenv(var)\n    status = '\u2705 Set' if value else '\u274c Not set'\n    print(f'{name:20} {status}')\nEOF\n</code></pre> <p>Expected output: <pre><code>OpenAI               \u2705 Set\nMistral              \u2705 Set\nGemini               \u2705 Set\nWatsonX API          \u2705 Set\nWatsonX Project      \u2705 Set\n</code></pre></p>"},{"location":"fundamentals/installation/api-keys/#test-connection","title":"Test Connection","text":"<pre><code># Test with a simple extraction\nuv run docling-graph convert docs/examples/data/sample.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider openai \\\n    --model gpt-3.5-turbo \\\n    --output-dir test_output\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#security-best-practices","title":"Security Best Practices","text":""},{"location":"fundamentals/installation/api-keys/#1-never-commit-api-keys","title":"1. Never Commit API Keys","text":"<pre><code># Add to .gitignore\necho \".env\" &gt;&gt; .gitignore\necho \"*.key\" &gt;&gt; .gitignore\necho \"secrets/\" &gt;&gt; .gitignore\n</code></pre>"},{"location":"fundamentals/installation/api-keys/#2-use-environment-variables","title":"2. Use Environment Variables","text":"<p>Don't: <pre><code># \u274c Hardcoded in code\napi_key = \"sk-...\"\n</code></pre></p> <p>Do: <pre><code># \u2705 From environment\nimport os\napi_key = os.getenv('OPENAI_API_KEY')\n</code></pre></p>"},{"location":"fundamentals/installation/api-keys/#3-rotate-keys-regularly","title":"3. Rotate Keys Regularly","text":"<ul> <li>Rotate API keys every 90 days</li> <li>Immediately rotate if compromised</li> <li>Use separate keys for dev/prod</li> </ul>"},{"location":"fundamentals/installation/api-keys/#4-limit-key-permissions","title":"4. Limit Key Permissions","text":"<ul> <li>Use read-only keys when possible</li> <li>Set usage limits</li> <li>Monitor usage regularly</li> </ul>"},{"location":"fundamentals/installation/api-keys/#5-use-secret-management","title":"5. Use Secret Management","text":"<p>For production: - AWS Secrets Manager - Azure Key Vault - Google Secret Manager - HashiCorp Vault</p>"},{"location":"fundamentals/installation/api-keys/#cost-management","title":"Cost Management","text":""},{"location":"fundamentals/installation/api-keys/#monitor-usage","title":"Monitor Usage","text":"<p>OpenAI: - Dashboard: https://platform.openai.com/usage</p> <p>Mistral: - Console: https://console.mistral.ai/usage</p> <p>Gemini: - Console: https://makersuite.google.com/</p> <p>WatsonX: - IBM Cloud Dashboard</p>"},{"location":"fundamentals/installation/api-keys/#set-usage-limits","title":"Set Usage Limits","text":"<p>OpenAI: 1. Go to Usage Limits 2. Set monthly budget 3. Enable email alerts</p> <p>Mistral: 1. Go to Console 2. Set budget alerts 3. Monitor usage</p>"},{"location":"fundamentals/installation/api-keys/#cost-optimization-tips","title":"Cost Optimization Tips","text":"<ol> <li>Use appropriate models:</li> <li>GPT-3.5-turbo for simple tasks</li> <li> <p>GPT-4 only when needed</p> </li> <li> <p>Enable chunking:</p> </li> <li>Reduces token usage</li> <li> <p>Processes only relevant parts</p> </li> <li> <p>Cache results:</p> </li> <li> <p>Avoid re-processing same documents</p> </li> <li> <p>Batch processing:</p> </li> <li> <p>Process multiple documents together</p> </li> <li> <p>Monitor costs:</p> </li> <li>Check usage daily</li> <li>Set alerts</li> </ol>"},{"location":"fundamentals/installation/api-keys/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/installation/api-keys/#api-key-not-recognized","title":"\ud83d\udc1b API key not recognized","text":"<p>Check: <pre><code>echo $OPENAI_API_KEY  # Should show your key\n</code></pre></p> <p>If empty: <pre><code># Re-export\nexport OPENAI_API_KEY=\"sk-...\"\n\n# Or reload shell config\nsource ~/.bashrc\n</code></pre></p>"},{"location":"fundamentals/installation/api-keys/#authentication-failed","title":"\ud83d\udc1b Authentication failed","text":"<p>Symptoms: <pre><code>Error: Invalid API key\n</code></pre></p> <p>Solutions:</p> <ol> <li>Verify key is correct:</li> <li>Check for typos</li> <li>Ensure no extra spaces</li> <li> <p>Verify key hasn't expired</p> </li> <li> <p>Check key format:</p> </li> <li>OpenAI: starts with <code>sk-</code></li> <li>Mistral: alphanumeric string</li> <li> <p>Gemini: alphanumeric string</p> </li> <li> <p>Regenerate key:</p> </li> <li>Go to provider dashboard</li> <li>Create new key</li> <li>Update environment variable</li> </ol>"},{"location":"fundamentals/installation/api-keys/#rate-limit-exceeded","title":"\ud83d\udc1b Rate limit exceeded","text":"<p>Symptoms: <pre><code>Error: Rate limit exceeded\n</code></pre></p> <p>Solutions:</p> <ol> <li>Wait and retry:</li> <li> <p>Most limits reset after 1 minute</p> </li> <li> <p>Upgrade plan:</p> </li> <li> <p>Increase rate limits</p> </li> <li> <p>Use different provider:</p> </li> <li>Switch to provider with higher limits</li> </ol>"},{"location":"fundamentals/installation/api-keys/#insufficient-credits","title":"\ud83d\udc1b Insufficient credits","text":"<p>Symptoms: <pre><code>Error: Insufficient credits\n</code></pre></p> <p>Solutions:</p> <ol> <li>Add credits:</li> <li>Go to billing dashboard</li> <li> <p>Add payment method</p> </li> <li> <p>Use different provider:</p> </li> <li> <p>Switch to provider with credits</p> </li> <li> <p>Use local inference:</p> </li> <li>No API costs</li> </ol>"},{"location":"fundamentals/installation/api-keys/#provider-comparison","title":"Provider Comparison","text":"Provider Pros Cons Best For OpenAI High quality, reliable Expensive Complex extraction Mistral Good balance, affordable Smaller context General purpose Gemini Very cheap, fast Newer, less tested High volume WatsonX Enterprise features Setup complexity Enterprise use"},{"location":"fundamentals/installation/api-keys/#next-steps","title":"Next Steps","text":"<p>API keys configured! Now:</p> <ol> <li>Schema Definition - Create your first template</li> <li>Pipeline Configuration - Configure extraction</li> <li>Quick Start - Run your first extraction</li> </ol>"},{"location":"fundamentals/installation/basic-setup/","title":"Basic Setup","text":""},{"location":"fundamentals/installation/basic-setup/#installation-methods","title":"Installation Methods","text":""},{"location":"fundamentals/installation/basic-setup/#method-1-from-pypi-recommended","title":"Method 1: From PyPI (Recommended)","text":"<p>Install the latest release from PyPI:</p> <pre><code>pip install docling-graph\n</code></pre> <p>This installs the core package with VLM support and LiteLLM (for LLM providers). No extra steps are required for remote or local LLM backends.</p> <p>Verify installation:</p> <pre><code>docling-graph --version\ndocling-graph --help\npython -c \"import docling_graph; print(docling_graph.__version__)\"\n</code></pre> <p>Expected output: <pre><code>Docling Graph v1.2.0\nUsage: docling-graph [OPTIONS] COMMAND [ARGS]...\nv1.2.0\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#method-2-from-source-development","title":"Method 2: From Source (Development)","text":"<p>Use this method to contribute or run the latest development version.</p>"},{"location":"fundamentals/installation/basic-setup/#step-1-install-uv","title":"Step 1: Install uv","text":"<p>Install the uv package manager:</p> <p>Linux/macOS: <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre></p> <p>Windows (PowerShell): <pre><code>powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre></p> <p>Alternative (using pip): <pre><code>pip install uv\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#step-2-clone-repository","title":"Step 2: Clone Repository","text":"<pre><code>git clone https://github.com/docling-project/docling-graph\ncd docling-graph\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#step-3-install-dependencies","title":"Step 3: Install Dependencies","text":"<pre><code>uv sync\n</code></pre> <p>This installs the same core package as PyPI (VLM + LiteLLM). Use <code>uv sync --extra dev</code> for development tools.</p>"},{"location":"fundamentals/installation/basic-setup/#step-4-verify-installation","title":"Step 4: Verify Installation","text":"<p>When installed from source, run the CLI with <code>uv run</code>:</p> <pre><code>uv run docling-graph --version\nuv run docling-graph --help\nuv run python -c \"import docling_graph; print(docling_graph.__version__)\"\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#installation-scenarios","title":"Installation Scenarios","text":""},{"location":"fundamentals/installation/basic-setup/#scenario-1-quick-start-remote-llm","title":"Scenario 1: Quick Start (Remote LLM)","text":"<p>For users who want to get started quickly without GPU:</p> <pre><code># Install from PyPI\npip install docling-graph\n\n# Set API key\nexport OPENAI_API_KEY=\"your-key-here\"\n\n# Test\ndocling-graph --version\n</code></pre> <p>Time: ~1-2 minutes Requirements: Internet connection, API key GPU: Not required</p>"},{"location":"fundamentals/installation/basic-setup/#scenario-2-local-vlm-gpu-required","title":"Scenario 2: Local VLM (GPU Required)","text":"<p>For users with GPU who want local inference:</p> <pre><code># Install from PyPI\npip install docling-graph\n\n# Verify GPU\nnvidia-smi\n\n# Test\ndocling-graph --version\n</code></pre> <p>Time: ~2-5 minutes Requirements: NVIDIA GPU with 4+ GB VRAM GPU: Required</p>"},{"location":"fundamentals/installation/basic-setup/#scenario-3-full-local-setup-gpu-required","title":"Scenario 3: Full Local Setup (GPU Required)","text":"<p>For users who want all local capabilities:</p> <pre><code># Install from PyPI\npip install docling-graph\n\n# Verify GPU\nnvidia-smi\n\n# Test\ndocling-graph --version\n</code></pre> <p>Time: ~5-10 minutes Requirements: NVIDIA GPU with 8+ GB VRAM GPU: Required</p>"},{"location":"fundamentals/installation/basic-setup/#scenario-4-hybrid-local-remote","title":"Scenario 4: Hybrid (Local + Remote)","text":"<p>For maximum flexibility:</p> <pre><code># Install from PyPI\npip install docling-graph\n\n# Set API keys (optional)\nexport OPENAI_API_KEY=\"your-key-here\"\nexport MISTRAL_API_KEY=\"your-key-here\"\n\n# Test\ndocling-graph --version\n</code></pre> <p>Time: ~2-5 minutes Requirements: GPU recommended, API keys optional GPU: Optional</p>"},{"location":"fundamentals/installation/basic-setup/#post-installation-configuration","title":"Post-Installation Configuration","text":""},{"location":"fundamentals/installation/basic-setup/#initialize-configuration","title":"Initialize Configuration","text":"<p>Run the interactive configuration wizard:</p> <pre><code>docling-graph init\n</code></pre> <p>(Use <code>uv run docling-graph init</code> if you installed from source.)</p> <p>This creates a <code>config.yaml</code> file with your preferences.</p> <p>New in v1.2.0: Init command is 75-85% faster with intelligent caching!</p>"},{"location":"fundamentals/installation/basic-setup/#verify-installation","title":"Verify Installation","text":"<p>Run a simple test:</p> <pre><code># Check all commands work (use uv run ... if from source)\ndocling-graph --help\ndocling-graph init --help\ndocling-graph convert --help\ndocling-graph inspect --help\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#test-with-example","title":"Test with Example","text":"<pre><code># Run a simple example (requires API key or GPU; from repo only)\npython docs/examples/scripts/02_quickstart_llm_pdf.py\n# Or from source: uv run python docs/examples/scripts/02_quickstart_llm_pdf.py\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#directory-structure-source-install-only","title":"Directory Structure (Source Install Only)","text":"<p>When you install from source, your directory should look like:</p> <pre><code>docling-graph/\n\u251c\u2500\u2500 .venv/                  # Virtual environment (created by uv)\n\u251c\u2500\u2500 docs/                   # Documentation\n\u251c\u2500\u2500 docling_graph/          # Source code\n\u251c\u2500\u2500 examples/               # Example scripts and templates\n\u251c\u2500\u2500 tests/                  # Test suite\n\u251c\u2500\u2500 pyproject.toml          # Project configuration\n\u251c\u2500\u2500 uv.lock                 # Dependency lock file\n\u2514\u2500\u2500 README.md               # Project readme\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#environment-variables","title":"Environment Variables","text":""},{"location":"fundamentals/installation/basic-setup/#optional-configuration","title":"Optional Configuration","text":"<p>Set these environment variables for customization:</p> <pre><code># Logging level\nexport LOG_LEVEL=\"INFO\"  # DEBUG, INFO, WARNING, ERROR\n\n# Temporary directory\nexport TEMP_DIR=\"/tmp/docling\"\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#api-keys-if-using-remote-providers","title":"API Keys (if using remote providers)","text":"<p>See API Keys Setup for detailed instructions.</p>"},{"location":"fundamentals/installation/basic-setup/#updating","title":"Updating","text":""},{"location":"fundamentals/installation/basic-setup/#update-to-latest-version","title":"Update to Latest Version","text":"<pre><code># Navigate to repository\ncd docling-graph\n\n# Pull latest changes\ngit pull origin main\n\n# Update dependencies\nuv sync\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#update-specific-components","title":"Update Specific Components","text":"<pre><code># Update only remote providers\nuv sync\n\n# Update only local providers\nuv sync\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/installation/basic-setup/#uv-command-not-found","title":"\ud83d\udc1b <code>uv</code> command not found","text":"<p>Cause: uv not in PATH</p> <p>Solution: <pre><code># Add to PATH (Linux/macOS)\nexport PATH=\"$HOME/.cargo/bin:$PATH\"\n\n# Or reinstall\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#permission-denied","title":"\ud83d\udc1b Permission denied","text":"<p>Cause: Insufficient permissions</p> <p>Solution: <pre><code># Don't use sudo with uv\n# If you used sudo, remove and reinstall:\nrm -rf .venv\nuv sync\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#import-errors-source-install","title":"\ud83d\udc1b Import errors (source install)","text":"<p>Cause: When installed from source, scripts must be run with <code>uv run</code> so they use the project environment.</p> <p>Solution: <pre><code># From source: use uv run\nuv run python script.py\nuv run docling-graph --help\n</code></pre> If you installed with pip, use <code>python</code> and <code>docling-graph</code> directly.</p>"},{"location":"fundamentals/installation/basic-setup/#slow-installation","title":"\ud83d\udc1b Slow installation","text":"<p>Cause: Network or disk speed</p> <p>Solution: <pre><code># Use verbose mode to see progress\nuv sync --verbose\n\n# Or install in stages\nuv sync                    # Core first\nuv sync     # Then remote\nuv sync     # Then local\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#cuda-not-found-for-gpu-users","title":"\ud83d\udc1b CUDA not found (for GPU users)","text":"<p>Cause: CUDA not installed or not in PATH</p> <p>Solution: See GPU Setup Guide</p>"},{"location":"fundamentals/installation/basic-setup/#out-of-disk-space","title":"\ud83d\udc1b Out of disk space","text":"<p>Cause: Insufficient disk space</p> <p>Solution: <pre><code># Check disk space\ndf -h\n\n# Clean up if needed\nuv cache clean\n\n# Or install minimal version\nuv sync  # No extras\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#verification-checklist","title":"Verification Checklist","text":"<p>After installation, verify:</p> <ul> <li> <code>docling-graph --version</code> works (or <code>uv run docling-graph --version</code> if from source)</li> <li> <code>docling-graph --help</code> shows commands</li> <li> <code>python -c \"import docling_graph\"</code> succeeds</li> <li> GPU detected (if using local inference): <code>nvidia-smi</code></li> <li> API keys set (if using remote): <code>echo $OPENAI_API_KEY</code></li> <li> Config initialized: <code>docling-graph init</code></li> </ul>"},{"location":"fundamentals/installation/basic-setup/#performance-notes","title":"Performance Notes","text":""},{"location":"fundamentals/installation/basic-setup/#installation-speed","title":"Installation Speed","text":"<p>New in v1.2.0: - First install: ~2-5 minutes (depending on extras) - Subsequent updates: ~30-60 seconds - Dependency caching: 90-95% faster validation</p>"},{"location":"fundamentals/installation/basic-setup/#disk-usage","title":"Disk Usage","text":"<pre><code>Minimal install:     ~2.5 GB\nFull install:        ~5 GB\nWith models:         ~20 GB (varies by model)\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#memory-usage","title":"Memory Usage","text":"<pre><code>Installation:        ~1 GB RAM\nRuntime (minimal):   ~2 GB RAM\nRuntime (with GPU):  ~8-16 GB RAM\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#development-setup","title":"Development Setup","text":"<p>For contributors:</p> <pre><code># Clone repository\ngit clone https://github.com/docling-project/docling-graph\ncd docling-graph\n\n# Install with dev dependencies\nuv sync --all-extras --dev\n\n# Install pre-commit hooks\nuv run pre-commit install\n\n# Run tests\nuv run pytest\n\n# Run linting\nuv run ruff check .\n\n# Run type checking\nuv run mypy docling_graph\n</code></pre>"},{"location":"fundamentals/installation/basic-setup/#uninstalling","title":"Uninstalling","text":"<p>If you installed from PyPI: <pre><code>pip uninstall docling-graph\n</code></pre></p> <p>If you installed from source: <pre><code>cd docling-graph\nrm -rf .venv\ncd ..\nrm -rf docling-graph\n# Optional: remove cache\nrm -rf ~/.cache/docling-graph\n</code></pre></p>"},{"location":"fundamentals/installation/basic-setup/#next-steps","title":"Next Steps","text":"<p>Installation complete! Now:</p> <ol> <li>GPU Setup (if using local inference) - Configure CUDA</li> <li>API Keys (if using remote) - Set up API keys</li> <li>Schema Definition - Create your first template</li> <li>Quick Start - Run your first extraction</li> </ol>"},{"location":"fundamentals/installation/gpu-setup/","title":"GPU Setup","text":""},{"location":"fundamentals/installation/gpu-setup/#overview","title":"Overview","text":"<p>GPU acceleration significantly improves performance for:</p> <ul> <li>VLM Backend: NuExtract models (4-8 GB VRAM)</li> <li>Local LLM: vLLM inference (8-24 GB VRAM)</li> </ul> <p>Remote Inference</p> <p>Remote LLM providers (OpenAI, Mistral, Gemini, WatsonX) do not require a GPU, but using one could still improve Docling conversion performance.</p>"},{"location":"fundamentals/installation/gpu-setup/#important-package-conflict-notice","title":"Important: Package Conflict Notice","text":"<p>Workaround for Dependency Conflicts</p> <p><code>uv</code> handles installing PyTorch with GPU support automatically in most cases. </p> <p>Only follow this guide as a workaround if you are encountering a specific dependency conflict when using <code>docling[vlm]</code> alongside GPU-enabled torch.</p> <p>Workaround: Manual installation using <code>pip</code> (see below).</p>"},{"location":"fundamentals/installation/gpu-setup/#prerequisites","title":"Prerequisites","text":""},{"location":"fundamentals/installation/gpu-setup/#1-nvidia-gpu","title":"1. NVIDIA GPU","text":"<p>Verify you have a compatible NVIDIA GPU:</p> <pre><code>nvidia-smi\n</code></pre> <p>Expected output: <pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03   Driver Version: 535.129.03   CUDA Version: 12.2   |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n| 30%   45C    P8    15W / 250W |    500MiB /  8192MiB |      2%      Default |\n+-------------------------------+----------------------+----------------------+\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#2-cuda-toolkit","title":"2. CUDA Toolkit","text":"<p>Check your CUDA version from <code>nvidia-smi</code> output above.</p> <p>Supported CUDA Versions: - CUDA 11.8 (recommended) - CUDA 12.1 (recommended) - CUDA 12.2+</p>"},{"location":"fundamentals/installation/gpu-setup/#3-cuda-toolkit-installation","title":"3. CUDA Toolkit Installation","text":"<p>If CUDA is not installed:</p> <p>Linux (Ubuntu/Debian): <pre><code># CUDA 12.1\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb\nsudo dpkg -i cuda-keyring_1.0-1_all.deb\nsudo apt-get update\nsudo apt-get -y install cuda-12-1\n\n# Add to PATH\necho 'export PATH=/usr/local/cuda-12.1/bin:$PATH' &gt;&gt; ~/.bashrc\necho 'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre></p> <p>Windows: 1. Download CUDA Toolkit from NVIDIA website 2. Run installer 3. Verify installation: <code>nvcc --version</code></p>"},{"location":"fundamentals/installation/gpu-setup/#manual-gpu-setup-workaround","title":"Manual GPU Setup (Workaround)","text":"<p>Due to the package conflict, follow these steps for GPU support:</p>"},{"location":"fundamentals/installation/gpu-setup/#step-1-create-virtual-environment","title":"Step 1: Create Virtual Environment","text":"<pre><code># Navigate to docling-graph directory\ncd docling-graph\n\n# Create virtual environment\npython -m venv .venv\n\n# Activate virtual environment\n# Linux/macOS:\nsource .venv/bin/activate\n\n# Windows PowerShell:\n.\\.venv\\Scripts\\Activate\n\n# Windows CMD:\n.venv\\Scripts\\activate.bat\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#step-2-install-docling-graph","title":"Step 2: Install Docling Graph","text":"<p>Choose the installation that matches your needs:</p> <p>Minimal (VLM only): <pre><code>pip install -e .\n</code></pre></p> <p>Full (all features): <pre><code>pip install -e .[all]\n</code></pre></p> <p>Local LLM only: <pre><code>pip install -e .[local]\n</code></pre></p> <p>Remote API only: <pre><code>pip install -e .[remote]\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#step-3-uninstall-cpu-only-pytorch","title":"Step 3: Uninstall CPU-only PyTorch","text":"<pre><code>pip uninstall torch torchvision torchaudio -y\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#step-4-install-gpu-enabled-pytorch","title":"Step 4: Install GPU-enabled PyTorch","text":"<p>Visit PyTorch installation page for the exact command matching your CUDA version.</p> <p>CUDA 11.8: <pre><code>pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n</code></pre></p> <p>CUDA 12.1: <pre><code>pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n</code></pre></p> <p>CUDA 12.2+: <pre><code>pip3 install torch torchvision torchaudio\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#step-5-verify-gpu-installation","title":"Step 5: Verify GPU Installation","text":"<pre><code>python -c \"import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}'); print(f'GPU count: {torch.cuda.device_count()}'); print(f'GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \\\"N/A\\\"}')\"\n</code></pre> <p>Expected output: <pre><code>PyTorch version: 2.2.0+cu121\nCUDA available: True\nCUDA version: 12.1\nGPU count: 1\nGPU name: NVIDIA GeForce RTX 3060\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#cli-usage-with-gpu-setup","title":"CLI Usage with GPU Setup","text":"<p>Important: Manual GPU Setup</p> <p>When using the manual GPU setup (pip-based virtual environment), do not use <code>uv run</code>. Instead, call commands directly:</p>"},{"location":"fundamentals/installation/gpu-setup/#correct-usage-with-gpu-setup","title":"Correct Usage (with GPU setup)","text":"<pre><code># Activate virtual environment first\nsource .venv/bin/activate  # Linux/macOS\n# or\n.\\venv\\Scripts\\Activate  # Windows\n\n# Then use direct commands\ndocling-graph --version\ndocling-graph init\ndocling-graph convert document.pdf --template \"templates.BillingDocument\"\ndocling-graph inspect outputs\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#incorrect-usage-will-not-work","title":"Incorrect Usage (will not work)","text":"<pre><code># Don't use uv run with manual GPU setup\nuv run docling-graph convert document.pdf  # \u274c Wrong\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#testing-gpu-performance","title":"Testing GPU Performance","text":""},{"location":"fundamentals/installation/gpu-setup/#test-vlm-with-gpu","title":"Test VLM with GPU","text":"<pre><code># Activate virtual environment\nsource .venv/bin/activate\n\n# Run VLM example\npython docs/examples/scripts/01_quickstart_vlm_image.py\n</code></pre> <p>Monitor GPU usage: <pre><code># In another terminal\nwatch -n 1 nvidia-smi\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#test-local-llm-with-gpu","title":"Test Local LLM with GPU","text":"<pre><code># Activate virtual environment\nsource .venv/bin/activate\n\n# Start vLLM server (if using vLLM)\npython -m vllm.entrypoints.openai.api_server \\\n    --model ibm-granite/granite-4.0-1b \\\n    --port 8000\n\n# In another terminal, run extraction\ndocling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --inference local \\\n    --provider vllm\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#performance-expectations","title":"Performance Expectations","text":""},{"location":"fundamentals/installation/gpu-setup/#vlm-performance","title":"VLM Performance","text":"Model GPU Processing Speed (per page) NuExtract-2B RTX 3060 (8GB) 2-3 seconds NuExtract-2B RTX 4090 (24GB) 1-2 seconds NuExtract-8B RTX 3060 (8GB) 5-7 seconds NuExtract-8B RTX 4090 (24GB) 2-3 seconds"},{"location":"fundamentals/installation/gpu-setup/#local-llm-performance","title":"Local LLM Performance","text":"Model Size GPU Processing Speed (per chunk) 1B-4B RTX 3060 (8GB) 5-10 seconds 1B-4B RTX 4090 (24GB) 2-5 seconds 7B-8B RTX 3080 (16GB) 10-20 seconds 7B-8B RTX 4090 (24GB) 5-10 seconds"},{"location":"fundamentals/installation/gpu-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/installation/gpu-setup/#cuda-not-available","title":"\ud83d\udc1b CUDA not available","text":"<p>Check: <pre><code>python -c \"import torch; print(torch.cuda.is_available())\"\n</code></pre></p> <p>If False:</p> <ol> <li> <p>Verify NVIDIA driver:    <pre><code>nvidia-smi\n</code></pre></p> </li> <li> <p>Check CUDA installation:    <pre><code>nvcc --version\n</code></pre></p> </li> <li> <p>Reinstall PyTorch with correct CUDA version:    <pre><code>pip uninstall torch torchvision torchaudio -y\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n</code></pre></p> </li> </ol>"},{"location":"fundamentals/installation/gpu-setup/#out-of-memory","title":"\ud83d\udc1b Out of memory","text":"<p>Symptoms: <pre><code>RuntimeError: CUDA out of memory\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Use smaller model:    <pre><code># Use NuExtract-2B instead of 8B\n# Or use smaller LLM\n</code></pre></p> </li> <li> <p>Enable chunking:    <pre><code>docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --use-chunking\n</code></pre></p> </li> <li> <p>Reduce batch size:    <pre><code>config = PipelineConfig(\n    max_batch_size=1,  # Process one chunk at a time\n    use_chunking=True\n)\n</code></pre></p> </li> <li> <p>Clear GPU memory:    <pre><code># Kill other GPU processes\nnvidia-smi\n# Note PIDs and kill if needed\nkill -9 &lt;PID&gt;\n</code></pre></p> </li> </ol>"},{"location":"fundamentals/installation/gpu-setup/#slow-performance","title":"\ud83d\udc1b Slow performance","text":"<p>Check GPU utilization: <pre><code>nvidia-smi\n</code></pre></p> <p>If GPU utilization is low:</p> <ol> <li> <p>Verify GPU is being used:    <pre><code>import torch\nprint(torch.cuda.is_available())\nprint(torch.cuda.current_device())\n</code></pre></p> </li> <li> <p>Check for CPU fallback:</p> </li> <li>Look for warnings in output</li> <li> <p>Verify PyTorch CUDA version matches system CUDA</p> </li> <li> <p>Optimize batch size:</p> </li> <li>Increase batch size if memory allows</li> <li>Monitor with <code>nvidia-smi</code></li> </ol>"},{"location":"fundamentals/installation/gpu-setup/#driver-version-mismatch","title":"\ud83d\udc1b Driver version mismatch","text":"<p>Symptoms: <pre><code>CUDA driver version is insufficient for CUDA runtime version\n</code></pre></p> <p>Solution: <pre><code># Update NVIDIA driver\n# Ubuntu/Debian:\nsudo apt update\nsudo apt install nvidia-driver-535\n\n# Or download from NVIDIA website\n</code></pre></p>"},{"location":"fundamentals/installation/gpu-setup/#gpu-memory-management","title":"GPU Memory Management","text":""},{"location":"fundamentals/installation/gpu-setup/#monitor-memory-usage","title":"Monitor Memory Usage","text":"<pre><code># Real-time monitoring\nwatch -n 1 nvidia-smi\n\n# Or use Python\npython -c \"import torch; print(f'Allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB'); print(f'Reserved: {torch.cuda.memory_reserved()/1024**3:.2f} GB')\"\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#clear-gpu-cache","title":"Clear GPU Cache","text":"<pre><code>import torch\ntorch.cuda.empty_cache()\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#best-practices","title":"Best Practices","text":"<ol> <li>Process documents sequentially for large batches</li> <li>Use chunking for large documents</li> <li>Monitor memory with <code>nvidia-smi</code></li> <li>Close unused processes to free VRAM</li> <li>Use appropriate model size for your GPU</li> </ol>"},{"location":"fundamentals/installation/gpu-setup/#alternative-cloud-gpu","title":"Alternative: Cloud GPU","text":"<p>If you don't have a local GPU, consider cloud options:</p>"},{"location":"fundamentals/installation/gpu-setup/#google-colab","title":"Google Colab","text":"<pre><code># In Colab notebook\n!git clone https://github.com/docling-project/docling-graph\n%cd docling-graph\n!pip install -e .[all]\n\n# GPU is automatically available\nimport torch\nprint(torch.cuda.is_available())  # Should be True\n</code></pre>"},{"location":"fundamentals/installation/gpu-setup/#awsazuregcp","title":"AWS/Azure/GCP","text":"<ul> <li>Launch GPU instance (e.g., g4dn.xlarge on AWS)</li> <li>Follow Linux installation instructions</li> <li>GPU drivers usually pre-installed</li> </ul>"},{"location":"fundamentals/installation/gpu-setup/#next-steps","title":"Next Steps","text":"<p>GPU setup complete! Now:</p> <ol> <li>API Keys (optional) - Set up remote providers</li> <li>Schema Definition - Create your first template</li> <li>Quick Start - Run your first extraction</li> </ol>"},{"location":"fundamentals/installation/requirements/","title":"System Requirements","text":""},{"location":"fundamentals/installation/requirements/#python-requirements","title":"Python Requirements","text":""},{"location":"fundamentals/installation/requirements/#supported-versions","title":"Supported Versions","text":"<ul> <li>Python 3.10 \u2705</li> <li>Python 3.11 \u2705</li> <li>Python 3.12 \u2705</li> </ul>"},{"location":"fundamentals/installation/requirements/#check-your-python-version","title":"Check Your Python Version","text":"<pre><code>python --version\n# or\npython3 --version\n</code></pre>"},{"location":"fundamentals/installation/requirements/#installing-python","title":"Installing Python","text":"<p>If you need to install or upgrade Python:</p> <p>Linux (Ubuntu/Debian): <pre><code>sudo apt update\nsudo apt install python3.10 python3.10-venv python3.10-dev\n</code></pre></p> <p>macOS: <pre><code>brew install python@3.10\n</code></pre></p> <p>Windows: Download from python.org</p>"},{"location":"fundamentals/installation/requirements/#hardware-requirements","title":"Hardware Requirements","text":""},{"location":"fundamentals/installation/requirements/#minimum-configuration","title":"Minimum Configuration","text":"<p>For basic usage (VLM with small documents or remote LLM):</p> Component Requirement CPU 4 cores, 2.0 GHz+ RAM 8 GB Disk 5 GB free space GPU Not required (for remote LLM only) Network Required for remote LLM"},{"location":"fundamentals/installation/requirements/#recommended-configuration","title":"Recommended Configuration","text":"<p>For optimal performance with local inference:</p> Component Requirement CPU 8+ cores, 3.0 GHz+ RAM 16 GB or more Disk 20 GB free space (for models) GPU NVIDIA GPU with 8+ GB VRAM CUDA 11.8 or 12.1 Network Optional (for remote LLM)"},{"location":"fundamentals/installation/requirements/#gpu-requirements-by-use-case","title":"GPU Requirements by Use Case","text":""},{"location":"fundamentals/installation/requirements/#vlm-only-nuextract","title":"VLM Only (NuExtract)","text":"Model VRAM Required Recommended GPU NuExtract-2B 4 GB GTX 1650, RTX 3050 NuExtract-8B 8 GB RTX 3060, RTX 4060"},{"location":"fundamentals/installation/requirements/#local-llm-vllm","title":"Local LLM (vLLM)","text":"Model Size VRAM Required Recommended GPU 1B-4B params 8 GB RTX 3060, RTX 4060 7B-8B params 16 GB RTX 3080, RTX 4070 Ti 13B+ params 24 GB+ RTX 3090, RTX 4090, A100"},{"location":"fundamentals/installation/requirements/#remote-llm-only","title":"Remote LLM Only","text":"Requirement Value GPU Not required Network Stable internet connection API Keys Required for chosen provider"},{"location":"fundamentals/installation/requirements/#operating-system-requirements","title":"Operating System Requirements","text":""},{"location":"fundamentals/installation/requirements/#linux","title":"Linux","text":"<p>Supported Distributions: - Ubuntu 20.04, 22.04, 24.04 - Debian 11, 12 - CentOS 8+ - Fedora 35+ - Arch Linux (latest)</p> <p>Required Packages: <pre><code># Ubuntu/Debian\nsudo apt install build-essential python3-dev git\n\n# CentOS/Fedora\nsudo dnf install gcc gcc-c++ python3-devel git\n\n# Arch\nsudo pacman -S base-devel python git\n</code></pre></p>"},{"location":"fundamentals/installation/requirements/#macos","title":"macOS","text":"<p>Supported Versions: - macOS 11 (Big Sur) or later - macOS 12 (Monterey) - macOS 13 (Ventura) - macOS 14 (Sonoma)</p> <p>Required Tools: <pre><code># Install Xcode Command Line Tools\nxcode-select --install\n\n# Install Homebrew (if not installed)\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre></p> <p>macOS GPU Limitation</p> <p>GPU acceleration not available on macOS (Apple Silicon or Intel). Use remote LLM for best performance.</p>"},{"location":"fundamentals/installation/requirements/#windows","title":"Windows","text":"<p>Supported Versions: - Windows 10 (version 1903 or later) - Windows 11</p> <p>Recommended Setup: - WSL2 (Windows Subsystem for Linux) for best compatibility - Native Windows supported but WSL2 recommended</p> <p>WSL2 Setup: <pre><code># Enable WSL2\nwsl --install\n\n# Install Ubuntu\nwsl --install -d Ubuntu-22.04\n\n# Inside WSL2, follow Linux instructions\n</code></pre></p> <p>Native Windows Requirements: - Visual Studio Build Tools or Visual Studio 2019+ - Git for Windows - CUDA Toolkit (for GPU support)</p>"},{"location":"fundamentals/installation/requirements/#gpu-and-cuda-requirements","title":"GPU and CUDA Requirements","text":""},{"location":"fundamentals/installation/requirements/#nvidia-gpu","title":"NVIDIA GPU","text":"<p>Supported GPUs: - GeForce RTX 20/30/40 series - GeForce GTX 16 series (limited) - Quadro RTX series - Tesla/A100/H100 series</p> <p>Check GPU: <pre><code># Linux\nnvidia-smi\n\n# Windows\nnvidia-smi.exe\n</code></pre></p>"},{"location":"fundamentals/installation/requirements/#cuda-toolkit","title":"CUDA Toolkit","text":"<p>Supported Versions: - CUDA 11.8 (recommended) - CUDA 12.1 (recommended) - CUDA 12.2+</p> <p>Check CUDA Version: <pre><code>nvcc --version\n# or\nnvidia-smi\n</code></pre></p> <p>Installation: See GPU Setup Guide</p>"},{"location":"fundamentals/installation/requirements/#amd-gpu","title":"AMD GPU","text":"<p>Status: Not currently supported - AMD ROCm support planned for future release - Use remote LLM as alternative</p>"},{"location":"fundamentals/installation/requirements/#apple-silicon-m1m2m3","title":"Apple Silicon (M1/M2/M3)","text":"<p>Status: Limited support - VLM works via CPU (slower) - Local LLM not optimized - Recommended: Use remote LLM providers</p>"},{"location":"fundamentals/installation/requirements/#network-requirements","title":"Network Requirements","text":""},{"location":"fundamentals/installation/requirements/#for-remote-llm","title":"For Remote LLM","text":"Requirement Specification Bandwidth 1 Mbps minimum, 10+ Mbps recommended Latency &lt; 200ms to provider Stability Consistent connection required Firewall Allow HTTPS (port 443)"},{"location":"fundamentals/installation/requirements/#for-local-inference","title":"For Local Inference","text":"Requirement Specification Network Optional (for downloading models) Bandwidth Only needed for initial model download"},{"location":"fundamentals/installation/requirements/#disk-space-requirements","title":"Disk Space Requirements","text":""},{"location":"fundamentals/installation/requirements/#base-installation","title":"Base Installation","text":"<pre><code>Core Package:           ~500 MB\nPython Dependencies:    ~2 GB\nTotal:                  ~2.5 GB\n</code></pre>"},{"location":"fundamentals/installation/requirements/#with-models","title":"With Models","text":"<pre><code>VLM Models:\n  - NuExtract-2B:       ~4 GB\n  - NuExtract-8B:       ~16 GB\n\nLLM Models (examples):\n  - Granite-1B:         ~2 GB\n  - Llama-7B:           ~14 GB\n  - Llama-13B:          ~26 GB\n\nRecommended Free Space: 20 GB\n</code></pre>"},{"location":"fundamentals/installation/requirements/#for-processing","title":"For Processing","text":"<pre><code>Temporary Files:        ~1 GB per document\nOutput Files:           ~100 MB per document\nCache:                  ~500 MB\n\nRecommended Free Space: 5 GB for active processing\n</code></pre>"},{"location":"fundamentals/installation/requirements/#memory-ram-requirements","title":"Memory (RAM) Requirements","text":""},{"location":"fundamentals/installation/requirements/#by-use-case","title":"By Use Case","text":"Use Case Minimum RAM Recommended RAM Remote LLM only 4 GB 8 GB VLM (NuExtract-2B) 8 GB 16 GB VLM (NuExtract-8B) 12 GB 24 GB Local LLM (1B-4B) 16 GB 32 GB Local LLM (7B-8B) 24 GB 48 GB Local LLM (13B+) 32 GB 64 GB+"},{"location":"fundamentals/installation/requirements/#memory-usage-patterns","title":"Memory Usage Patterns","text":"<pre><code>Base Process:           ~500 MB\nDocument Processing:    ~1-2 GB per document\nModel Loading:          Varies by model size\nGraph Construction:     ~100 MB per 1000 nodes\n</code></pre>"},{"location":"fundamentals/installation/requirements/#software-dependencies","title":"Software Dependencies","text":""},{"location":"fundamentals/installation/requirements/#required","title":"Required","text":"<ul> <li>Python: 3.10, 3.11, or 3.12</li> <li>uv: Package manager (installed automatically)</li> <li>Git: For cloning repository</li> </ul>"},{"location":"fundamentals/installation/requirements/#optional-installed-by-uv","title":"Optional (Installed by uv)","text":"<ul> <li>PyTorch: For GPU acceleration</li> <li>CUDA Toolkit: For NVIDIA GPU support</li> <li>Docling: Document conversion</li> <li>NetworkX: Graph operations</li> <li>Pydantic: Data validation</li> </ul>"},{"location":"fundamentals/installation/requirements/#compatibility-matrix","title":"Compatibility Matrix","text":""},{"location":"fundamentals/installation/requirements/#backend-compatibility","title":"Backend Compatibility","text":"Backend Linux macOS Windows GPU Required VLM (NuExtract) \u2705 \u2705 \u2705 Recommended LLM (vLLM) \u2705 \u274c \u26a0\ufe0f Yes LLM (Ollama) \u2705 \u2705 \u2705 Optional LLM (Remote APIs) \u2705 \u2705 \u2705 No <p>Legend:</p> <ul> <li>\u2705 Fully supported</li> <li>\u26a0\ufe0f Supported with limitations</li> <li>\u274c Not supported</li> </ul>"},{"location":"fundamentals/installation/requirements/#provider-compatibility","title":"Provider Compatibility","text":"Provider Local Remote GPU Required API Key Required NuExtract (VLM) \u2705 \u274c Recommended No vLLM \u2705 \u274c Yes No Ollama \u2705 \u274c Optional No OpenAI \u274c \u2705 No Yes Mistral \u274c \u2705 No Yes Gemini \u274c \u2705 No Yes WatsonX \u274c \u2705 No Yes"},{"location":"fundamentals/installation/requirements/#verification-checklist","title":"Verification Checklist","text":"<p>Before proceeding with installation, verify:</p> <ul> <li> Python 3.10+ installed</li> <li> Sufficient disk space (5 GB minimum, 20 GB recommended)</li> <li> Sufficient RAM (8 GB minimum, 16 GB recommended)</li> <li> GPU available (if using local inference)</li> <li> CUDA installed (if using NVIDIA GPU)</li> <li> Network connection (if using remote LLM)</li> <li> API keys ready (if using remote LLM)</li> </ul>"},{"location":"fundamentals/installation/requirements/#expected-memory-usage","title":"Expected Memory Usage","text":"Configuration Peak Memory Sustained Memory Remote LLM 2-4 GB 1-2 GB VLM (2B) 6-8 GB 4-6 GB VLM (8B) 12-16 GB 10-12 GB Local LLM (7B) 20-24 GB 16-20 GB"},{"location":"fundamentals/installation/requirements/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/installation/requirements/#check-system-resources","title":"Check System Resources","text":"<pre><code># Check RAM\nfree -h  # Linux\nvm_stat  # macOS\n\n# Check disk space\ndf -h\n\n# Check GPU\nnvidia-smi  # NVIDIA\n</code></pre>"},{"location":"fundamentals/installation/requirements/#insufficient-resources","title":"Insufficient Resources","text":"<p>Problem: Not enough RAM/VRAM</p> <p>Solutions: 1. Use remote LLM instead of local 2. Use smaller models (NuExtract-2B instead of 8B) 3. Enable chunking to reduce memory usage 4. Close other applications</p> <p>Problem: No GPU available</p> <p>Solutions: 1. Use remote LLM providers (no GPU needed) 2. Use Ollama with CPU (slower but works) 3. Consider cloud GPU instances</p>"},{"location":"fundamentals/installation/requirements/#next-steps","title":"Next Steps","text":"<p>Requirements verified? Continue with:</p> <ol> <li>Basic Setup - Install Docling Graph</li> <li>GPU Setup - Configure CUDA (if using GPU)</li> <li>API Keys - Set up remote providers (if using APIs)</li> </ol>"},{"location":"fundamentals/pipeline-configuration/","title":"Pipeline Configuration","text":""},{"location":"fundamentals/pipeline-configuration/#overview","title":"Overview","text":"<p>Pipeline configuration controls how Docling Graph processes documents and extracts knowledge graphs. The <code>PipelineConfig</code> class provides a type-safe, programmatic way to configure all aspects of the extraction pipeline.</p> <p>In this section: - Understanding PipelineConfig - Backend selection (LLM vs VLM) - Model configuration - Processing modes - Export settings - Advanced configuration</p>"},{"location":"fundamentals/pipeline-configuration/#what-is-pipeline-configuration","title":"What is Pipeline Configuration?","text":"<p>Pipeline configuration defines:</p> <ol> <li>What to extract - Source document and template</li> <li>How to extract - Backend, model, and processing mode</li> <li>How to process - Chunking, consolidation, and validation</li> <li>What to export - Output formats and locations</li> </ol>"},{"location":"fundamentals/pipeline-configuration/#configuration-methods","title":"Configuration Methods","text":"<p>You can configure the pipeline in three ways:</p>"},{"location":"fundamentals/pipeline-configuration/#1-python-api-recommended","title":"1. Python API (Recommended)","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\",\n    output_dir=\"outputs\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#2-cli-with-flags","title":"2. CLI with Flags","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --inference remote \\\n    --output-dir outputs\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#3-yaml-configuration-file","title":"3. YAML Configuration File","text":"<pre><code># config.yaml\ndefaults:\n  backend: llm\n  inference: remote\n  processing_mode: many-to-one\n  export_format: csv\n\nmodels:\n  llm:\n    remote:\n      model: \"mistral-small-latest\"\n      provider: \"mistral\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#quick-start","title":"Quick Start","text":""},{"location":"fundamentals/pipeline-configuration/#minimal-configuration","title":"Minimal Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Minimal config - uses all defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\"\n)\n\nrun_pipeline(config)\n</code></pre> <p>Defaults: - Backend: <code>llm</code> - Inference: <code>local</code> - Processing mode: <code>many-to-one</code> - Export format: <code>csv</code> - Output directory: <code>outputs</code></p>"},{"location":"fundamentals/pipeline-configuration/#common-configurations","title":"Common Configurations","text":""},{"location":"fundamentals/pipeline-configuration/#remote-api-extraction","title":"Remote API Extraction","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#local-gpu-extraction","title":"Local GPU Extraction","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\",\n    provider_override=\"vllm\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#vlm-vision-extraction","title":"VLM (Vision) Extraction","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\",\n    inference=\"local\",  # VLM only supports local\n    docling_config=\"vision\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#configuration-architecture","title":"Configuration Architecture","text":""},{"location":"fundamentals/pipeline-configuration/#configuration-flow","title":"Configuration Flow","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% Subgraph Styling (Transparent with dashed border for visibility)\n    classDef subgraph_style fill:none,stroke:#969696,stroke-width:2px,stroke-dasharray: 5,color:#969696\n\n    %% 2. Define Nodes &amp; Subgraphs\n    A@{ shape: procs, label: \"PipelineConfig\" }\n\n    subgraph Backends [\"Backend Configuration\"]\n        B@{ shape: lin-proc, label: \"Backend Selection\" }\n        F@{ shape: tag-proc, label: \"LLM Backend\" }\n        G@{ shape: tag-proc, label: \"VLM Backend\" }\n    end\n\n    subgraph Models [\"Inference Settings\"]\n        C@{ shape: lin-proc, label: \"Model Selection\" }\n        H@{ shape: tag-proc, label: \"Local Inference\" }\n        I@{ shape: tag-proc, label: \"Remote Inference\" }\n    end\n\n    subgraph Strategy [\"Processing Mode\"]\n        D@{ shape: lin-proc, label: \"Processing Mode\" }\n        J@{ shape: tag-proc, label: \"One-to-One\" }\n        K@{ shape: tag-proc, label: \"Many-to-One\" }\n    end\n\n    subgraph Exports [\"Output Settings\"]\n        E@{ shape: lin-proc, label: \"Export Settings\" }\n        L@{ shape: tag-proc, label: \"CSV Export\" }\n        M@{ shape: tag-proc, label: \"Cypher Export\" }\n    end\n\n    %% 3. Define Connections\n    A --&gt; B &amp; C &amp; D &amp; E\n\n    B --&gt; F &amp; G\n    C --&gt; H &amp; I\n    D --&gt; J &amp; K\n    E --&gt; L &amp; M\n\n    %% 4. Apply Classes\n    class A config\n    class B,C,D,E process\n    class F,G,H,I,J,K operator\n    class L,M output\n    class Backends,Models,Strategy,Exports subgraph_style</code></pre>"},{"location":"fundamentals/pipeline-configuration/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<pre><code>PipelineConfig\n\u251c\u2500\u2500 Source &amp; Template (required)\n\u2502   \u251c\u2500\u2500 source: Path to document\n\u2502   \u2514\u2500\u2500 template: Pydantic template\n\u2502\n\u251c\u2500\u2500 Backend Configuration\n\u2502   \u251c\u2500\u2500 backend: llm | vlm\n\u2502   \u251c\u2500\u2500 inference: local | remote\n\u2502   \u2514\u2500\u2500 models: Model configurations\n\u2502\n\u251c\u2500\u2500 Processing Configuration\n\u2502   \u251c\u2500\u2500 processing_mode: one-to-one | many-to-one\n\u2502   \u251c\u2500\u2500 docling_config: ocr | vision\n\u2502   \u2514\u2500\u2500 use_chunking: bool\n\u2502\n\u251c\u2500\u2500 Export Configuration\n\u2502   \u251c\u2500\u2500 export_format: csv | cypher\n\u2502   \u251c\u2500\u2500 export_docling: bool\n\u2502   \u2514\u2500\u2500 output_dir: Path\n\u2502\n\u2514\u2500\u2500 Advanced Settings\n    \u251c\u2500\u2500 max_batch_size: int\n    \u251c\u2500\u2500 reverse_edges: bool\n    \u2514\u2500\u2500 chunker_config: dict\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#key-configuration-decisions","title":"Key Configuration Decisions","text":""},{"location":"fundamentals/pipeline-configuration/#1-backend-llm-vs-vlm","title":"1. Backend: LLM vs VLM","text":"<p>Choose LLM when: - Processing text-heavy documents - Need remote API support - Want flexible model selection - Cost is a concern (remote APIs)</p> <p>Choose VLM when: - Processing image-heavy documents - Need vision understanding - Have local GPU available - Want highest accuracy for complex layouts</p> <p>See: Backend Selection</p>"},{"location":"fundamentals/pipeline-configuration/#2-inference-local-vs-remote","title":"2. Inference: Local vs Remote","text":"<p>Choose Local when: - Have GPU available - Processing sensitive data - Need offline capability - Want to avoid API costs</p> <p>Choose Remote when: - No GPU available - Need quick setup - Want latest models - Processing non-sensitive data</p> <p>See: Model Configuration</p>"},{"location":"fundamentals/pipeline-configuration/#3-processing-mode-one-to-one-vs-many-to-one","title":"3. Processing Mode: One-to-One vs Many-to-One","text":"<p>Choose One-to-One when: - Documents have distinct pages - Need page-level granularity - Pages are independent</p> <p>Choose Many-to-One when: - Document is a single entity - Need document-level view - Want consolidated output</p> <p>See: Processing Modes</p>"},{"location":"fundamentals/pipeline-configuration/#configuration-validation","title":"Configuration Validation","text":"<p>PipelineConfig validates your configuration:</p> <pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# This will raise ValidationError\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.BillingDocument\",\n        backend=\"vlm\",\n        inference=\"remote\"  # \u274c VLM doesn't support remote\n    )\nexcept ValueError as e:\n    print(f\"Configuration error: {e}\")\n    # Output: VLM backend currently only supports local inference\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#common-validation-errors","title":"Common Validation Errors","text":"Error Cause Solution VLM remote inference VLM + remote Use <code>inference=\"local\"</code> or <code>backend=\"llm\"</code> Missing source No source specified Provide <code>source=\"path/to/doc\"</code> Missing template No template specified Provide <code>template=\"module.Class\"</code> Invalid backend Wrong backend value Use <code>\"llm\"</code> or <code>\"vlm\"</code> Invalid inference Wrong inference value Use <code>\"local\"</code> or <code>\"remote\"</code>"},{"location":"fundamentals/pipeline-configuration/#default-values","title":"Default Values","text":"<p>PipelineConfig provides sensible defaults:</p> <pre><code># All defaults\nPipelineConfig(\n    source=\"\",  # Required at runtime\n    template=\"\",  # Required at runtime\n    backend=\"llm\",\n    inference=\"local\",\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n    export_format=\"csv\",\n    export_docling=True,\n    export_docling_json=True,\n    export_markdown=True,\n    export_per_page_markdown=False,\n    reverse_edges=False,\n    output_dir=\"outputs\",\n    max_batch_size=1\n)\n</code></pre> <p>See: Configuration Basics for details on each setting.</p>"},{"location":"fundamentals/pipeline-configuration/#environment-variables","title":"Environment Variables","text":"<p>Some settings can be configured via environment variables:</p> <pre><code># API Keys\nexport OPENAI_API_KEY=\"your-key\"\nexport MISTRAL_API_KEY=\"your-key\"\nexport GEMINI_API_KEY=\"your-key\"\nexport WATSONX_API_KEY=\"your-key\"\n\n# Model Configuration\nexport VLLM_BASE_URL=\"http://localhost:8000/v1\"\nexport OLLAMA_BASE_URL=\"http://localhost:11434\"\n</code></pre> <p>See: Installation: API Keys</p>"},{"location":"fundamentals/pipeline-configuration/#configuration-best-practices","title":"Configuration Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/#1-start-simple","title":"1. Start Simple","text":"<pre><code># \u2705 Good - Start with defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\n# \u274c Bad - Over-configure initially\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"local\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    # ... many more settings\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#2-override-only-whats-needed","title":"2. Override Only What's Needed","text":"<pre><code># \u2705 Good - Override specific settings\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\",  # Only change this\n    model_override=\"gpt-4-turbo\"  # And this\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#3-use-type-hints","title":"3. Use Type Hints","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# \u2705 Good - Type hints help catch errors\nconfig: PipelineConfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#4-validate-early","title":"4. Validate Early","text":"<pre><code># \u2705 Good - Validate config before running\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\",\n    inference=\"local\"\n)\n\n# Check config is valid\nprint(f\"Backend: {config.backend}\")\nprint(f\"Inference: {config.inference}\")\n\n# Then run\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/#next-steps","title":"Next Steps","text":"<p>Ready to configure your pipeline?</p> <ol> <li>Configuration Basics \u2192 - Learn PipelineConfig fundamentals</li> <li>Backend Selection - Choose the right backend</li> <li>Configuration Examples - See complete scenarios</li> </ol>"},{"location":"fundamentals/pipeline-configuration/backend-selection/","title":"Backend Selection: LLM vs VLM","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#overview","title":"Overview","text":"<p>Docling Graph supports two extraction backends: LLM (Language Model) for text-based extraction and VLM (Vision-Language Model) for vision-based extraction. Choosing the right backend is crucial for extraction quality and performance.</p> <p>In this guide: - LLM vs VLM comparison - When to use each backend - Performance characteristics - Cost considerations - Switching between backends</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#backend-comparison","title":"Backend Comparison","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#quick-comparison-table","title":"Quick Comparison Table","text":"Aspect LLM Backend VLM Backend Input Markdown text Document images Best For Text-heavy documents Complex layouts, images Inference Local or Remote Local only Speed Fast Slower Accuracy High for text Highest for complex layouts GPU Required Optional (remote) Yes (local only) Cost Low (local) to Medium (remote) Medium (GPU required) Setup Easy Moderate"},{"location":"fundamentals/pipeline-configuration/backend-selection/#llm-backend","title":"LLM Backend","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#what-is-llm-backend","title":"What is LLM Backend?","text":"<p>The LLM backend uses language models to extract structured data from markdown text. Documents are first converted to markdown using Docling, then processed by the LLM.</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#architecture","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: procs, label: \"Docling Conversion\" }\n    C@{ shape: doc, label: \"Markdown Text\" }\n    D@{ shape: tag-proc, label: \"Chunking Optional\" }\n    E@{ shape: procs, label: \"LLM Extraction\" }\n\n    F@{ shape: doc, label: \"Structured Data\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B,E process\n    class C data\n    class D operator\n    class F output</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",  # LLM backend\n    inference=\"local\"  # or \"remote\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#when-to-use-llm","title":"When to Use LLM","text":"<p>\u2705 Use LLM when: - Documents are primarily text-based - Layout is standard (invoices, contracts, reports) - You need remote API support - Cost efficiency is important - You want fast processing - You don't have GPU available (use remote)</p> <p>\u274c Don't use LLM when: - Documents have complex visual layouts - Images contain critical information - Tables have complex structures - Handwriting needs to be processed</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#llm-advantages","title":"LLM Advantages","text":"<ol> <li>Flexible Inference</li> <li>Local: Use your own GPU/CPU</li> <li> <p>Remote: Use cloud APIs (OpenAI, Mistral, Gemini)</p> </li> <li> <p>Fast Processing</p> </li> <li>Quick markdown conversion</li> <li>Efficient text processing</li> <li> <p>Parallel chunking support</p> </li> <li> <p>Cost Effective</p> </li> <li>Local inference: Free (after GPU cost)</li> <li>Remote inference: Pay per token</li> <li> <p>Generally cheaper than VLM</p> </li> <li> <p>Easy Setup</p> </li> <li>No GPU required for remote</li> <li>Simple API key configuration</li> <li>Wide model selection</li> </ol>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#llm-limitations","title":"LLM Limitations","text":"<ol> <li>Text-Only Processing</li> <li>Loses visual information</li> <li>May miss layout cues</li> <li> <p>Can't process images directly</p> </li> <li> <p>OCR Dependency</p> </li> <li>Relies on Docling OCR quality</li> <li>May struggle with poor scans</li> <li> <p>Handwriting not well supported</p> </li> <li> <p>Context Limits</p> </li> <li>Large documents need chunking</li> <li>May lose cross-page context</li> <li>Requires consolidation for coherence</li> </ol>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#vlm-backend","title":"VLM Backend","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#what-is-vlm-backend","title":"What is VLM Backend?","text":"<p>The VLM backend uses vision-language models to extract structured data directly from document images. It processes visual information alongside text, understanding layout and structure.</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#architecture_1","title":"Architecture","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    InputPDF@{ shape: terminal, label: \"PDF Document\" }\n    InputImg@{ shape: terminal, label: \"Images\" }\n\n    Convert@{ shape: procs, label: \"PDF to Image&lt;br&gt;Conversion\" }\n    PageImgs@{ shape: doc, label: \"Page Images\" }\n\n    VLM@{ shape: procs, label: \"VLM Processing\" }\n    Understand@{ shape: lin-proc, label: \"Visual Understanding\" }\n    Extract@{ shape: tag-proc, label: \"Direct Extraction\" }\n\n    Output@{ shape: doc, label: \"Pydantic Models\" }\n\n    %% 3. Define Connections\n    %% Path A: PDF requires conversion\n    InputPDF --&gt; Convert\n    Convert --&gt; PageImgs\n    PageImgs --&gt; VLM\n\n    %% Path B: Direct Image Input (Merges here)\n    InputImg --&gt; VLM\n\n    %% Shared Processing Chain\n    VLM --&gt; Understand\n    Understand --&gt; Extract\n    Extract --&gt; Output\n\n    %% 4. Apply Classes\n    class InputPDF,InputImg input\n    class Convert,VLM,Understand process\n    class PageImgs data\n    class Extract operator\n    class Output output</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\",  # VLM backend\n    inference=\"local\",  # VLM only supports local\n    docling_config=\"vision\"  # Optional: use vision pipeline\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#when-to-use-vlm","title":"When to Use VLM","text":"<p>\u2705 Use VLM when: - Documents have complex visual layouts - Images contain critical information - Tables have intricate structures - Forms have specific visual patterns - Highest accuracy is required - You have GPU available</p> <p>\u274c Don't use VLM when: - Documents are simple text - You need remote API support - GPU is not available - Processing speed is critical - Cost is a major concern</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#vlm-advantages","title":"VLM Advantages","text":"<ol> <li>Visual Understanding</li> <li>Processes layout and structure</li> <li>Understands visual relationships</li> <li>Handles complex tables</li> <li> <p>Processes embedded images</p> </li> <li> <p>Higher Accuracy</p> </li> <li>Best for complex documents</li> <li>Understands visual context</li> <li>Fewer extraction errors</li> <li> <p>Better table handling</p> </li> <li> <p>No OCR Dependency</p> </li> <li>Direct image processing</li> <li>Better with poor scans</li> <li>Handles handwriting better</li> <li>Preserves visual information</li> </ol>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#vlm-limitations","title":"VLM Limitations","text":"<ol> <li>Local Only</li> <li>Requires local GPU</li> <li>No remote API support</li> <li>Higher setup complexity</li> <li> <p>GPU memory requirements</p> </li> <li> <p>Slower Processing</p> </li> <li>Image processing overhead</li> <li>Larger model size</li> <li>More GPU memory needed</li> <li> <p>Longer inference time</p> </li> <li> <p>Higher Cost</p> </li> <li>GPU required</li> <li>More expensive hardware</li> <li>Higher power consumption</li> <li>Larger storage needs</li> </ol>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#decision-matrix","title":"Decision Matrix","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#by-document-type","title":"By Document Type","text":"Document Type Recommended Backend Reason Invoices LLM Standard layout, text-heavy Contracts LLM Text-heavy, standard format Rheology Researchs LLM Text-heavy, standard layout Forms VLM Visual structure important ID Cards VLM Visual layout critical Complex Tables VLM Visual structure needed Handwritten VLM Visual processing required Mixed Content VLM Images and text combined"},{"location":"fundamentals/pipeline-configuration/backend-selection/#by-infrastructure","title":"By Infrastructure","text":"Infrastructure Recommended Backend Configuration No GPU LLM Remote <code>backend=\"llm\", inference=\"remote\"</code> CPU Only LLM Remote <code>backend=\"llm\", inference=\"remote\"</code> GPU Available LLM or VLM Local <code>backend=\"llm/vlm\", inference=\"local\"</code> Cloud/API LLM Remote <code>backend=\"llm\", inference=\"remote\"</code>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#by-priority","title":"By Priority","text":"Priority Recommended Backend Reason Speed LLM Faster processing Accuracy VLM Better visual understanding Cost LLM Local No API costs Simplicity LLM Remote Easy setup Offline LLM or VLM Local No internet needed"},{"location":"fundamentals/pipeline-configuration/backend-selection/#performance-comparison","title":"Performance Comparison","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#processing-speed","title":"Processing Speed","text":"<pre><code>Document: 10-page invoice PDF\n\nLLM Local (GPU):     ~30 seconds\nLLM Remote (API):    ~45 seconds\nVLM Local (GPU):     ~90 seconds\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#accuracy-comparison","title":"Accuracy Comparison","text":"<pre><code>Document Type: Complex invoice with tables\n\nLLM Accuracy:  92% field extraction\nVLM Accuracy:  97% field extraction\n\nDocument Type: Simple text contract\n\nLLM Accuracy:  98% field extraction\nVLM Accuracy:  96% field extraction\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#cost-comparison","title":"Cost Comparison","text":"<pre><code>Processing 1000 documents:\n\nLLM Local:     $0 (GPU amortized)\nLLM Remote:    $50-200 (API costs)\nVLM Local:     $0 (GPU amortized)\nVLM Remote:    Not available\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#switching-between-backends","title":"Switching Between Backends","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#from-llm-to-vlm","title":"From LLM to VLM","text":"<pre><code># Original LLM config\nconfig_llm = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\n\n# Switch to VLM\nconfig_vlm = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\",  # Change backend\n    inference=\"local\",  # Must be local for VLM\n    docling_config=\"vision\"  # Optional: use vision pipeline\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#from-vlm-to-llm","title":"From VLM to LLM","text":"<pre><code># Original VLM config\nconfig_vlm = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\",\n    inference=\"local\"\n)\n\n# Switch to LLM\nconfig_llm = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",  # Change backend\n    inference=\"remote\",  # Can now use remote\n    model_override=\"gpt-4-turbo\"  # Specify model\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#hybrid-approach","title":"Hybrid Approach","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#strategy-1-document-type-based","title":"Strategy 1: Document Type Based","text":"<pre><code>def get_config(document_path: str, document_type: str):\n    \"\"\"Choose backend based on document type.\"\"\"\n    if document_type in [\"invoice\", \"contract\", \"report\"]:\n        # Use LLM for text-heavy documents\n        return PipelineConfig(\n            source=document_path,\n            template=\"templates.BillingDocument\",\n            backend=\"llm\",\n            inference=\"remote\"\n        )\n    else:\n        # Use VLM for complex layouts\n        return PipelineConfig(\n            source=document_path,\n            template=\"templates.Form\",\n            backend=\"vlm\",\n            inference=\"local\"\n        )\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#strategy-2-fallback-pattern","title":"Strategy 2: Fallback Pattern","text":"<pre><code>def extract_with_fallback(document_path: str):\n    \"\"\"Try LLM first, fallback to VLM if needed.\"\"\"\n    try:\n        # Try LLM first (faster)\n        config = PipelineConfig(\n            source=document_path,\n            template=\"templates.BillingDocument\",\n            backend=\"llm\",\n            inference=\"remote\"\n        )\n        run_pipeline(config)\n    except ExtractionError:\n        # Fallback to VLM for better accuracy\n        config = PipelineConfig(\n            source=document_path,\n            template=\"templates.BillingDocument\",\n            backend=\"vlm\",\n            inference=\"local\"\n        )\n        run_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#backend-specific-settings","title":"Backend-Specific Settings","text":""},{"location":"fundamentals/pipeline-configuration/backend-selection/#llm-specific-settings","title":"LLM-Specific Settings","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n\n    # LLM-specific\n    use_chunking=True,  # Split large documents\n    max_batch_size=5  # Process multiple chunks\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#vlm-specific-settings","title":"VLM-Specific Settings","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\",\n\n    # VLM-specific\n    docling_config=\"vision\",  # Use vision pipeline\n    processing_mode=\"one-to-one\"  # Process pages individually\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#common-questions","title":"Common Questions","text":"<p>Q: Can I use VLM with remote inference?</p> <p>A: No, VLM currently only supports local inference. Use LLM backend for remote API support.</p> <p>Q: Which backend is more accurate?</p> <p>A: VLM is generally more accurate for complex layouts and visual documents. LLM is more accurate for simple text documents.</p> <p>Q: Which backend is faster?</p> <p>A: LLM is faster, especially with remote APIs. VLM requires more processing time due to image analysis.</p> <p>Q: Can I switch backends mid-project?</p> <p>A: Yes, backends are interchangeable. Just change the <code>backend</code> parameter in your config.</p> <p>Q: Do I need different templates for different backends?</p> <p>A: No, the same Pydantic template works with both backends.</p>"},{"location":"fundamentals/pipeline-configuration/backend-selection/#next-steps","title":"Next Steps","text":"<p>Now that you understand backend selection:</p> <ol> <li>Model Configuration \u2192 - Configure models for your chosen backend</li> <li>Processing Modes - Choose processing strategy</li> <li>Configuration Examples - See complete scenarios</li> </ol>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/","title":"Configuration Basics","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#overview","title":"Overview","text":"<p>The <code>PipelineConfig</code> class is the foundation of Docling Graph configuration. It provides type-safe, validated configuration for all pipeline operations. This guide covers the fundamentals of creating and using pipeline configurations.</p> <p>In this guide: - PipelineConfig structure - Required vs optional settings - Creating configurations - Configuration validation - Common patterns</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pipelineconfig-structure","title":"PipelineConfig Structure","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#core-components","title":"Core Components","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    # Required (at runtime)\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n\n    # Backend settings\n    backend=\"llm\",              # \"llm\" or \"vlm\"\n    inference=\"local\",          # \"local\" or \"remote\"\n\n    # Processing settings\n    processing_mode=\"many-to-one\",  # \"one-to-one\" or \"many-to-one\"\n    docling_config=\"ocr\",           # \"ocr\" or \"vision\"\n    use_chunking=True,\n\n    # Export settings\n    export_format=\"csv\",        # \"csv\" or \"cypher\"\n    output_dir=\"outputs\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#configuration-categories","title":"Configuration Categories","text":"Category Settings Purpose Source <code>source</code>, <code>template</code> What to extract Backend <code>backend</code>, <code>inference</code>, <code>models</code> How to extract Processing <code>processing_mode</code>, <code>extraction_contract</code>, <code>docling_config</code>, <code>use_chunking</code> How to process Export <code>export_format</code>, <code>output_dir</code>, <code>export_*</code> What to output Advanced <code>staged_*</code> (staged extraction), <code>reverse_edges</code>, <code>chunker_config</code> Optimization"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#required-settings","title":"Required Settings","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#1-source-document","title":"1. Source Document","text":"<pre><code># File path (string or Path)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\n# Also accepts Path objects\nfrom pathlib import Path\nconfig = PipelineConfig(\n    source=Path(\"documents/invoice.pdf\"),\n    template=\"templates.BillingDocument\"\n)\n</code></pre> <p>Supported formats: - PDF documents - Images (PNG, JPG, JPEG) - DOCX files</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#2-pydantic-template","title":"2. Pydantic Template","text":"<pre><code># Dotted path string (recommended)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\n# Direct class reference (alternative)\nfrom templates.billing_document import BillingDocument\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=Invoice\n)\n</code></pre> <p>Template must: - Be a valid Pydantic BaseModel - Have proper <code>model_config</code> (graph_id_fields or is_entity) - Include the <code>edge()</code> helper function - Follow template best practices</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#backend-settings","title":"Backend Settings","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#backend-type","title":"Backend Type","text":"<pre><code># LLM backend (default) - for text extraction\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\"\n)\n\n# VLM backend - for vision-based extraction\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\"\n)\n</code></pre> <p>See: Backend Selection for detailed comparison.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#inference-location","title":"Inference Location","text":"<pre><code># Local inference (default) - uses local GPU/CPU\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"local\"\n)\n\n# Remote inference - uses API providers\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\"\n)\n</code></pre> <p>See: Model Configuration for setup details.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#model-overrides","title":"Model Overrides","text":"<pre><code># Override default model\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#processing-settings","title":"Processing Settings","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#processing-mode","title":"Processing Mode","text":"<pre><code># Many-to-one (default) - whole document as single entity\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"many-to-one\"\n)\n\n# One-to-one - process each page separately\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"one-to-one\"\n)\n</code></pre> <p>See: Processing Modes for when to use each.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#docling-configuration","title":"Docling Configuration","text":"<pre><code># OCR pipeline (default) - traditional OCR\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"ocr\"\n)\n\n# Vision pipeline - VLM-based conversion\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"vision\"\n)\n</code></pre> <p>See: Docling Settings for details.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#chunking","title":"Chunking","text":"<pre><code># With chunking (default) - splits large documents\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    use_chunking=True\n)\n\n# Without chunking - processes entire document\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    use_chunking=False\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#llm-consolidation","title":"LLM Consolidation","text":"<pre><code># Without consolidation (default)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n)\n\n# With consolidation - merges results using LLM\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#export-settings","title":"Export Settings","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#export-format","title":"Export Format","text":"<pre><code># CSV format (default)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"csv\"\n)\n\n# Cypher format - for Neo4j import\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"cypher\"\n)\n</code></pre> <p>See: Export Configuration for format details.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#output-directory","title":"Output Directory","text":"<pre><code># Default output directory\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    output_dir=\"outputs\"\n)\n\n# Custom output directory\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    output_dir=\"my_results/invoice_001\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#docling-exports","title":"Docling Exports","text":"<pre><code># Control Docling document exports\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_docling=True,           # Export Docling document\n    export_docling_json=True,      # Export as JSON\n    export_markdown=True,          # Export as markdown\n    export_per_page_markdown=False # Export per-page markdown\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#creating-configurations","title":"Creating Configurations","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#method-1-direct-instantiation","title":"Method 1: Direct Instantiation","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\n\n# Run the pipeline\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#method-2-programmatic-building","title":"Method 2: Programmatic Building","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Start with defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\n# Modify as needed\nif use_gpu:\n    config.inference = \"local\"\n    config.model_override = \"ibm-granite/granite-4.0-1b\"\nelse:\n    config.inference = \"remote\"\n    config.model_override = \"gpt-4-turbo\"\n\n# Run\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#method-3-from-dictionary","title":"Method 3: From Dictionary","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig_dict = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\"\n}\n\nconfig = PipelineConfig(**config_dict)\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#method-4-using-run_pipeline","title":"Method 4: Using run_pipeline","text":"<pre><code>from docling_graph import run_pipeline\n\n# Pass config dict directly\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\"\n})\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#configuration-validation","title":"Configuration Validation","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#automatic-validation","title":"Automatic Validation","text":"<p>PipelineConfig validates settings automatically:</p> <pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# This raises ValueError\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.BillingDocument\",\n        backend=\"vlm\",\n        inference=\"remote\"  # \u274c VLM doesn't support remote\n    )\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n    # Output: VLM backend currently only supports local inference\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#common-validation-errors","title":"Common Validation Errors","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#error-1-vlm-remote-inference","title":"Error 1: VLM Remote Inference","text":"<pre><code># \u274c Wrong\nconfig = PipelineConfig(\n    backend=\"vlm\",\n    inference=\"remote\"\n)\n\n# \u2705 Correct\nconfig = PipelineConfig(\n    backend=\"vlm\",\n    inference=\"local\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#error-2-invalid-backend","title":"Error 2: Invalid Backend","text":"<pre><code># \u274c Wrong\nconfig = PipelineConfig(\n    backend=\"gpt\"  # Not a valid backend\n)\n\n# \u2705 Correct\nconfig = PipelineConfig(\n    backend=\"llm\"  # or \"vlm\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#error-3-invalid-processing-mode","title":"Error 3: Invalid Processing Mode","text":"<pre><code># \u274c Wrong\nconfig = PipelineConfig(\n    processing_mode=\"batch\"  # Not valid\n)\n\n# \u2705 Correct\nconfig = PipelineConfig(\n    processing_mode=\"many-to-one\"  # or \"one-to-one\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#default-values-reference","title":"Default Values Reference","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#all-defaults","title":"All Defaults","text":"<pre><code>PipelineConfig(\n    # Required (no defaults)\n    source=\"\",\n    template=\"\",\n\n    # Backend defaults\n    backend=\"llm\",\n    inference=\"local\",\n    model_override=None,\n    provider_override=None,\n\n    # Processing defaults\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n    max_batch_size=1,\n\n    # Export defaults\n    export_format=\"csv\",\n    export_docling=True,\n    export_docling_json=True,\n    export_markdown=True,\n    export_per_page_markdown=False,\n\n    # Graph defaults\n    reverse_edges=False,\n\n    # Output defaults\n    output_dir=\"outputs\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#model-defaults","title":"Model Defaults","text":"<pre><code># LLM Local\nmodel=\"ibm-granite/granite-4.0-1b\"\nprovider=\"vllm\"\n\n# LLM Remote\nmodel=\"mistral-small-latest\"\nprovider=\"mistral\"\n\n# VLM Local\nmodel=\"numind/NuExtract-2.0-8B\"\nprovider=\"docling\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#common-configuration-patterns","title":"Common Configuration Patterns","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pattern-1-quick-local-test","title":"Pattern 1: Quick Local Test","text":"<pre><code># Minimal config for quick testing\nconfig = PipelineConfig(\n    source=\"test.pdf\",\n    template=\"templates.BillingDocument\"\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pattern-2-production-remote","title":"Pattern 2: Production Remote","text":"<pre><code># Production config with remote API\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\",\n    output_dir=\"production_outputs\"\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pattern-3-gpu-accelerated-local","title":"Pattern 3: GPU-Accelerated Local","text":"<pre><code># Local GPU extraction\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\",\n    provider_override=\"vllm\"\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pattern-4-vision-based-extraction","title":"Pattern 4: Vision-Based Extraction","text":"<pre><code># VLM extraction for complex layouts\nconfig = PipelineConfig(\n    source=\"complex_layout.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\",\n    inference=\"local\",\n    docling_config=\"vision\"\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#pattern-5-page-by-page-processing","title":"Pattern 5: Page-by-Page Processing","text":"<pre><code># Process each page separately\nconfig = PipelineConfig(\n    source=\"multi_page.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"one-to-one\",\n    export_per_page_markdown=True\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#configuration-inspection","title":"Configuration Inspection","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#view-configuration","title":"View Configuration","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\"\n)\n\n# Print configuration\nprint(f\"Backend: {config.backend}\")\nprint(f\"Inference: {config.inference}\")\nprint(f\"Processing mode: {config.processing_mode}\")\nprint(f\"Output dir: {config.output_dir}\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#convert-to-dictionary","title":"Convert to Dictionary","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\n# Get as dictionary\nconfig_dict = config.to_dict()\nprint(config_dict)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#serialize-to-json","title":"Serialize to JSON","text":"<pre><code>import json\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\n# Serialize\njson_str = config.model_dump_json(indent=2)\nprint(json_str)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/configuration-basics/#use-type-hints","title":"\ud83d\udc4d Use Type Hints","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# \u2705 Good - Type hints help catch errors\nconfig: PipelineConfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#validate-early","title":"\ud83d\udc4d Validate Early","text":"<pre><code># \u2705 Good - Create and validate before processing\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\",\n    inference=\"local\"\n)\n\n# Verify settings\nassert config.backend == \"vlm\"\nassert config.inference == \"local\"\n\n# Then run\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#use-defaults","title":"\ud83d\udc4d Use Defaults","text":"<pre><code># \u2705 Good - Rely on sensible defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\n# \u274c Bad - Over-specify defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",  # Already default\n    inference=\"local\",  # Already default\n    processing_mode=\"many-to-one\",  # Already default\n    use_chunking=True,  # Already default\n    # ... etc\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#document-custom-configs","title":"\ud83d\udc4d Document Custom Configs","text":"<pre><code># \u2705 Good - Document why you override defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    # Use remote API for better accuracy on complex documents\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    # Disable chunking for short documents\n    use_chunking=False\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-basics/#next-steps","title":"Next Steps","text":"<p>Now that you understand configuration basics:</p> <ol> <li>Backend Selection \u2192 - Choose between LLM and VLM</li> <li>Model Configuration - Configure models</li> <li>Configuration Examples - See complete scenarios</li> </ol>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/","title":"Complete Configuration Examples","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#overview","title":"Overview","text":"<p>This guide provides complete, real-world configuration examples for common use cases. Each example includes full configuration, expected outputs, and integration patterns.</p> <p>In this guide: - Production-ready configurations - Common use case patterns - Integration examples - Troubleshooting scenarios - Best practices</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#quick-navigation","title":"Quick Navigation","text":"Use Case Backend Inference Processing Local Development LLM Local Many-to-one Production API LLM Remote Many-to-one High Accuracy VLM Local One-to-one Batch Processing LLM Remote Many-to-one Rheology Researchs LLM Remote Many-to-one Invoices LLM Local Many-to-one Forms VLM Local One-to-one Multi-language LLM Remote Many-to-one"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-1-local-development","title":"Example 1: Local Development","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case","title":"Use Case","text":"<p>Fast iteration during template development using local models.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    # Source and template\n    source=\"test_document.pdf\",\n    template=\"templates.BillingDocument\",\n\n    # Local LLM for fast iteration\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n\n    # Fast processing\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n\n    # CSV for easy inspection\n    export_format=\"csv\",\n    export_markdown=True,\n\n    # Development output\n    output_dir=\"dev_outputs\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#prerequisites","title":"Prerequisites","text":"<pre><code># Install Ollama\ncurl -fsSL https://ollama.com/install.sh | sh\n\n# Pull model\nollama pull llama3.1:8b\n\n# Verify\nollama list\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#expected-output","title":"Expected Output","text":"<pre><code>dev_outputs/\n\u251c\u2500\u2500 nodes.csv              # Easy to inspect in Excel\n\u251c\u2500\u2500 edges.csv\n\u251c\u2500\u2500 document.md            # Check markdown conversion\n\u251c\u2500\u2500 graph_stats.json       # Quick metrics\n\u2514\u2500\u2500 visualization.html     # Visual inspection\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use","title":"When to Use","text":"<p>\u2705 Use for: - Template development - Quick testing - Debugging extraction - Offline development</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-2-production-api","title":"Example 2: Production API","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_1","title":"Use Case","text":"<p>Production deployment using remote API for reliability and scale.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nimport os\n\nconfig = PipelineConfig(\n    # Source and template\n    source=\"production_document.pdf\",\n    template=\"templates.BillingDocument\",\n\n    # Remote API for reliability\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n\n    # Robust processing\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n\n    # Cypher for Neo4j\n    export_format=\"cypher\",\n    export_docling=False,  # Minimal exports\n    export_markdown=False,\n\n    # Production output\n    output_dir=f\"production/{os.getenv('DOCUMENT_ID')}\"\n)\n\n# Set API key\nos.environ[\"MISTRAL_API_KEY\"] = \"your_api_key\"\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#environment-setup","title":"Environment Setup","text":"<pre><code># .env file\nMISTRAL_API_KEY=your_api_key_here\nDOCUMENT_ID=doc_12345\n\n# Load environment\nuv run python -c \"from dotenv import load_dotenv; load_dotenv()\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#expected-output_1","title":"Expected Output","text":"<pre><code>production/doc_12345/\n\u251c\u2500\u2500 graph.cypher           # Ready for Neo4j import\n\u251c\u2500\u2500 graph_data.json        # Backup\n\u251c\u2500\u2500 graph_stats.json       # Metrics\n\u2514\u2500\u2500 visualization.html     # QA check\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#integration","title":"Integration","text":"<pre><code># Import to Neo4j\nimport subprocess\n\ncypher_file = f\"production/{os.getenv('DOCUMENT_ID')}/graph.cypher\"\nsubprocess.run([\n    \"cypher-shell\",\n    \"-u\", \"neo4j\",\n    \"-p\", os.getenv(\"NEO4J_PASSWORD\"),\n    \"-f\", cypher_file\n])\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_1","title":"When to Use","text":"<p>\u2705 Use for: - Production deployments - High reliability needs - Scalable processing - API-based workflows</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-3-high-accuracy-extraction","title":"Example 3: High Accuracy Extraction","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_2","title":"Use Case","text":"<p>Maximum accuracy for complex documents using VLM.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_2","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    # Source and template\n    source=\"complex_document.pdf\",\n    template=\"templates.ScholarlyRheologyPaper\",\n\n    # VLM for visual understanding\n    backend=\"vlm\",\n    inference=\"local\",\n    model_override=\"numind/NuExtract-2.0-8B\",\n\n    # Page-by-page for accuracy\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\",  # Vision pipeline\n\n    # No chunking for VLM\n    use_chunking=False,\n\n    # CSV for analysis\n    export_format=\"csv\",\n    export_per_page_markdown=True,  # Debug per page\n\n    output_dir=\"high_accuracy_outputs\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#prerequisites_1","title":"Prerequisites","text":"<pre><code># GPU required\nnvidia-smi\n\n# Install with GPU support\nuv pip install \"docling-graph[gpu]\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#expected-output_2","title":"Expected Output","text":"<pre><code>high_accuracy_outputs/\n\u251c\u2500\u2500 nodes.csv\n\u251c\u2500\u2500 edges.csv\n\u251c\u2500\u2500 pages/\n\u2502   \u251c\u2500\u2500 page_001.md       # Per-page markdown\n\u2502   \u251c\u2500\u2500 page_002.md\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 visualization.html\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_2","title":"When to Use","text":"<p>\u2705 Use for: - Complex layouts - Visual elements - High accuracy needs - Rheology researchs</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-4-batch-processing","title":"Example 4: Batch Processing","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_3","title":"Use Case","text":"<p>Process multiple documents efficiently.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_3","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom pathlib import Path\nimport logging\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef process_batch(input_dir: str, template: str):\n    \"\"\"Process all PDFs in a directory.\"\"\"\n\n    input_path = Path(input_dir)\n    results = []\n\n    for pdf_file in input_path.glob(\"*.pdf\"):\n        logger.info(f\"Processing {pdf_file.name}\")\n\n        try:\n            config = PipelineConfig(\n                source=str(pdf_file),\n                template=template,\n\n                # Remote for reliability\n                backend=\"llm\",\n                inference=\"remote\",\n                provider_override=\"mistral\",\n\n                # Efficient processing\n                processing_mode=\"many-to-one\",\n                use_chunking=True,\n\n                # Organized outputs\n                output_dir=f\"batch_outputs/{pdf_file.stem}\",\n                export_format=\"csv\"\n            )\n\n            run_pipeline(config)\n            results.append({\"file\": pdf_file.name, \"status\": \"success\"})\n\n        except Exception as e:\n            logger.error(f\"Failed to process {pdf_file.name}: {e}\")\n            results.append({\"file\": pdf_file.name, \"status\": \"failed\", \"error\": str(e)})\n\n    return results\n\n# Process batch\nresults = process_batch(\"documents/invoices\", \"templates.BillingDocument\")\n\n# Summary\nsuccess_count = sum(1 for r in results if r[\"status\"] == \"success\")\nprint(f\"Processed {success_count}/{len(results)} documents successfully\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#expected-output_3","title":"Expected Output","text":"<pre><code>batch_outputs/\n\u251c\u2500\u2500 invoice_001/\n\u2502   \u251c\u2500\u2500 nodes.csv\n\u2502   \u2514\u2500\u2500 edges.csv\n\u251c\u2500\u2500 invoice_002/\n\u2502   \u251c\u2500\u2500 nodes.csv\n\u2502   \u2514\u2500\u2500 edges.csv\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_3","title":"When to Use","text":"<p>\u2705 Use for: - Multiple documents - Automated workflows - Scheduled processing - Data pipelines</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-5-rheology-researchs","title":"Example 5: Rheology Researchs","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_4","title":"Use Case","text":"<p>Extract structured data from academic papers.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_4","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    # Rheology research\n    source=\"research_paper.pdf\",\n    template=\"templates.ScholarlyRheologyPaper\",\n\n    # Remote LLM for understanding\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",\n\n    # Full document context\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n\n    # CSV for analysis\n    export_format=\"csv\",\n    export_markdown=True,\n\n    output_dir=\"research_outputs\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#template-example","title":"Template Example","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import List\n\nclass Author(BaseModel):\n    \"\"\"Rheology research author.\"\"\"\n    name: str\n    affiliation: str | None = None\n    email: str | None = None\n\nclass Citation(BaseModel):\n    \"\"\"Paper citation.\"\"\"\n    title: str\n    authors: str\n    year: int | None = None\n\nclass ResearchPaper(BaseModel):\n    \"\"\"Rheology research extraction template.\"\"\"\n\n    title: str = Field(description=\"Paper title\")\n    authors: List[Author] = Field(description=\"Paper authors\")\n    abstract: str = Field(description=\"Paper abstract\")\n\n    keywords: List[str] = Field(description=\"Paper keywords\")\n    methodology: str = Field(description=\"Research methodology\")\n    findings: List[str] = Field(description=\"Key findings\")\n\n    citations: List[Citation] = Field(description=\"Referenced papers\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_4","title":"When to Use","text":"<p>\u2705 Use for: - Academic papers - Literature reviews - Citation extraction - Research analysis</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-6-billing-document-processing","title":"Example 6: Billing Document Processing","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_5","title":"Use Case","text":"<p>Extract invoice data for accounting systems.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_5","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    # BillingDocument document\n    source=\"invoice.pdf\",\n    template=\"templates.BillingDocument\",\n\n    # Local for cost efficiency\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n\n    # Fast processing\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n\n    # CSV for accounting software\n    export_format=\"csv\",\n\n    output_dir=\"invoices/processed\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#template-example_1","title":"Template Example","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import List\nfrom datetime import date\n\nclass LineItem(BaseModel):\n    \"\"\"Invoice line item.\"\"\"\n    description: str\n    quantity: float\n    unit_price: float\n    total: float\n\nclass Address(BaseModel):\n    \"\"\"Address information.\"\"\"\n    street: str\n    city: str\n    postal_code: str\n    country: str\n\nclass Organization(BaseModel):\n    \"\"\"Organization details.\"\"\"\n    name: str\n    address: Address\n    tax_id: str | None = None\n\nclass BillingDocument(BaseModel):\n    \"\"\"BillingDocument extraction template.\"\"\"\n\n    document_no: str = Field(description=\"Invoice number\")\n    invoice_date: date = Field(description=\"Invoice date\")\n    due_date: date | None = Field(description=\"Payment due date\")\n\n    issued_by: Organization = Field(description=\"Issuing organization\")\n    sent_to: Organization = Field(description=\"Recipient organization\")\n\n    line_items: List[LineItem] = Field(description=\"Invoice line items\")\n\n    subtotal: float = Field(description=\"Subtotal amount\")\n    tax: float = Field(description=\"Tax amount\")\n    total: float = Field(description=\"Total amount\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#integration-with-accounting","title":"Integration with Accounting","text":"<pre><code>import pandas as pd\n\n# Load extracted data\nnodes = pd.read_csv(\"invoices/processed/nodes.csv\")\n\n# Filter invoices\ninvoices = nodes[nodes['node_type'] == 'BillingDocument']\n\n# Export to accounting system\ninvoices.to_csv(\"accounting_import.csv\", index=False)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_5","title":"When to Use","text":"<p>\u2705 Use for: - Invoice processing - Accounting automation - Financial data extraction - ERP integration</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-7-form-extraction","title":"Example 7: Form Extraction","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_6","title":"Use Case","text":"<p>Extract data from structured forms using VLM.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_6","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    # Form document\n    source=\"application_form.pdf\",\n    template=\"templates.ApplicationForm\",\n\n    # VLM for form structure\n    backend=\"vlm\",\n    inference=\"local\",\n\n    # Page-by-page for forms\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\",\n    use_chunking=False,\n\n    # CSV for database import\n    export_format=\"csv\",\n\n    output_dir=\"forms/processed\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#template-example_2","title":"Template Example","text":"<pre><code>from pydantic import BaseModel, Field, EmailStr\nfrom datetime import date\n\nclass Applicant(BaseModel):\n    \"\"\"Applicant information.\"\"\"\n    first_name: str\n    last_name: str\n    email: EmailStr\n    phone: str\n    date_of_birth: date\n\nclass Address(BaseModel):\n    \"\"\"Address information.\"\"\"\n    street: str\n    city: str\n    state: str\n    zip_code: str\n\nclass ApplicationForm(BaseModel):\n    \"\"\"Application form template.\"\"\"\n\n    application_id: str = Field(description=\"Application ID\")\n    submission_date: date = Field(description=\"Submission date\")\n\n    applicant: Applicant = Field(description=\"Applicant details\")\n    address: Address = Field(description=\"Applicant address\")\n\n    employment_status: str = Field(description=\"Employment status\")\n    annual_income: float | None = Field(description=\"Annual income\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_6","title":"When to Use","text":"<p>\u2705 Use for: - Application forms - Registration forms - Survey responses - Structured documents</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#example-8-multi-language-documents","title":"Example 8: Multi-language Documents","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#use-case_7","title":"Use Case","text":"<p>Process documents in multiple languages.</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration_7","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    # Multi-language document\n    source=\"multilingual_document.pdf\",\n    template=\"templates.Contract\",\n\n    # Remote LLM with multi-language support\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",  # Good multi-language support\n\n    # Full document context\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n\n    # CSV export\n    export_format=\"csv\",\n\n    output_dir=\"multilingual_outputs\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#when-to-use_7","title":"When to Use","text":"<p>\u2705 Use for: - International documents - Multi-language contracts - Global operations - Translation workflows</p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#pattern-1-error-handling","title":"Pattern 1: Error Handling","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import PipelineError, ExtractionError\nimport logging\n\nlogger = logging.getLogger(__name__)\n\ndef safe_process(source: str, template: str) -&gt; bool:\n    \"\"\"Process document with error handling.\"\"\"\n\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=template,\n            backend=\"llm\",\n            inference=\"remote\"\n        )\n\n        run_pipeline(config)\n        logger.info(f\"Successfully processed {source}\")\n        return True\n\n    except ExtractionError as e:\n        logger.error(f\"Extraction failed for {source}: {e}\")\n        return False\n\n    except PipelineError as e:\n        logger.error(f\"Pipeline error for {source}: {e}\")\n        return False\n\n    except Exception as e:\n        logger.error(f\"Unexpected error for {source}: {e}\")\n        return False\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#pattern-2-configuration-validation","title":"Pattern 2: Configuration Validation","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom pydantic import ValidationError\n\ndef validate_config(config_dict: dict) -&gt; bool:\n    \"\"\"Validate configuration before running.\"\"\"\n\n    try:\n        config = PipelineConfig(**config_dict)\n        print(\"\u2705 Configuration valid\")\n        return True\n\n    except ValidationError as e:\n        print(f\"\u274c Configuration invalid:\")\n        for error in e.errors():\n            print(f\"  - {error['loc']}: {error['msg']}\")\n        return False\n\n# Test configuration\nconfig_dict = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\"\n}\n\nif validate_config(config_dict):\n    config = PipelineConfig(**config_dict)\n    run_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#pattern-3-dynamic-configuration","title":"Pattern 3: Dynamic Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nimport os\n\ndef get_config_for_document(doc_path: str) -&gt; PipelineConfig:\n    \"\"\"Generate configuration based on document type.\"\"\"\n\n    # Determine document type\n    if \"invoice\" in doc_path.lower():\n        template = \"templates.BillingDocument\"\n        processing_mode = \"many-to-one\"\n\n    elif \"form\" in doc_path.lower():\n        template = \"templates.Form\"\n        processing_mode = \"one-to-one\"\n\n    else:\n        template = \"templates.Generic\"\n        processing_mode = \"many-to-one\"\n\n    # Choose backend based on environment\n    if os.getenv(\"USE_GPU\") == \"true\":\n        backend = \"vlm\"\n        inference = \"local\"\n    else:\n        backend = \"llm\"\n        inference = \"remote\"\n\n    return PipelineConfig(\n        source=doc_path,\n        template=template,\n        backend=backend,\n        inference=inference,\n        processing_mode=processing_mode\n    )\n\n# Use dynamic configuration\nconfig = get_config_for_document(\"documents/invoice_001.pdf\")\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#best-practices-summary","title":"Best Practices Summary","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#choose-the-right-backend","title":"\ud83d\udc4d Choose the Right Backend","text":"<pre><code># \u2705 Good - Match backend to use case\nif document_has_complex_layout:\n    backend = \"vlm\"\nelif need_fast_iteration:\n    backend = \"llm\"\n    inference = \"local\"\nelse:\n    backend = \"llm\"\n    inference = \"remote\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#organize-outputs","title":"\ud83d\udc4d Organize Outputs","text":"<pre><code># \u2705 Good - Structured output directories\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\noutput_dir = f\"outputs/{document_type}/{timestamp}\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#handle-errors-gracefully","title":"\ud83d\udc4d Handle Errors Gracefully","text":"<pre><code># \u2705 Good - Comprehensive error handling\ntry:\n    run_pipeline(config)\nexcept ExtractionError:\n    # Handle extraction failures\n    pass\nexcept PipelineError:\n    # Handle pipeline failures\n    pass\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#validate-before-running","title":"\ud83d\udc4d Validate Before Running","text":"<pre><code># \u2705 Good - Validate configuration\ntry:\n    config = PipelineConfig(**config_dict)\nexcept ValidationError as e:\n    print(f\"Invalid configuration: {e}\")\n    exit(1)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/pipeline-configuration/configuration-examples/#configuration-validation-fails","title":"\ud83d\udc1b Configuration Validation Fails","text":"<p>Solution: <pre><code>from pydantic import ValidationError\n\ntry:\n    config = PipelineConfig(**config_dict)\nexcept ValidationError as e:\n    print(\"Configuration errors:\")\n    for error in e.errors():\n        print(f\"  {error['loc']}: {error['msg']}\")\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#extraction-produces-no-results","title":"\ud83d\udc1b Extraction Produces No Results","text":"<p>Solution: <pre><code># Check extraction output\nimport json\n\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nif stats[\"node_count\"] == 0:\n    print(\"No nodes extracted - check template and document\")\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#out-of-memory","title":"\ud83d\udc1b Out of Memory","text":"<p>Solution: <pre><code># Use chunking and smaller batch sizes\nconfig = PipelineConfig(\n    source=\"large_document.pdf\",\n    template=\"templates.BillingDocument\",\n    use_chunking=True,  # Enable chunking\n    max_batch_size=1,   # Smaller batches\n    backend=\"llm\",\n    inference=\"remote\"  # Use remote to save memory\n)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/configuration-examples/#next-steps","title":"Next Steps","text":"<p>Now that you understand complete configurations:</p> <ol> <li>Extraction Process \u2192 - Learn how extraction works</li> <li>Graph Management - Work with extracted graphs</li> <li>CLI Guide - Use command-line interface</li> </ol>"},{"location":"fundamentals/pipeline-configuration/docling-settings/","title":"Docling Settings","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#overview","title":"Overview","text":"<p>Docling settings control how documents are converted before extraction. Docling Graph uses the Docling library to convert PDFs and images into structured formats (markdown or JSON) that can be processed by LLMs or VLMs.</p> <p>In this guide: - OCR vs Vision pipeline - Export options - Pipeline selection - Performance considerations - Troubleshooting</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#docling-pipeline-types","title":"Docling Pipeline Types","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#quick-comparison","title":"Quick Comparison","text":"Aspect OCR Pipeline Vision Pipeline Method Traditional OCR Vision-Language Model Speed Fast Slower Accuracy Good for standard docs Best for complex layouts GPU Required No Yes Best For Text-heavy documents Complex visual layouts Default Yes No"},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-pipeline","title":"OCR Pipeline","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#what-is-ocr-pipeline","title":"What is OCR Pipeline?","text":"<p>The OCR pipeline uses traditional Optical Character Recognition to extract text from documents. It's fast, accurate for standard documents, and doesn't require a GPU.</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"ocr\"  # OCR pipeline (default)\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#how-it-works","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Image / PDF Document\" }\n\n    B@{ shape: procs, label: \"OCR Engine\" }\n    C@{ shape: lin-proc, label: \"Text Extraction\" }\n    D@{ shape: lin-proc, label: \"Layout Analysis\" }\n\n    E@{ shape: doc, label: \"Markdown\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D process\n    class E output</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#when-to-use-ocr","title":"When to Use OCR","text":"<p>\u2705 Use OCR when: - Documents are text-heavy - Layout is standard (invoices, contracts, reports) - Speed is important - GPU is not available - Documents are high-quality scans - Cost efficiency is a priority</p> <p>\u274c Don't use OCR when: - Documents have complex visual layouts - Tables have intricate structures - Handwriting needs processing - Images contain critical information - Document quality is poor</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-advantages","title":"OCR Advantages","text":"<ol> <li>Fast Processing</li> <li>Quick text extraction</li> <li>No GPU required</li> <li> <p>Efficient for batch processing</p> </li> <li> <p>Good Accuracy</p> </li> <li>Excellent for standard documents</li> <li>Reliable text extraction</li> <li> <p>Handles most layouts well</p> </li> <li> <p>Low Resource Usage</p> </li> <li>CPU-only processing</li> <li>Lower memory requirements</li> <li>No special hardware needed</li> </ol>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-limitations","title":"OCR Limitations","text":"<ol> <li>Layout Challenges</li> <li>May struggle with complex tables</li> <li>Can miss visual relationships</li> <li> <p>Limited understanding of structure</p> </li> <li> <p>Quality Dependent</p> </li> <li>Poor scans reduce accuracy</li> <li>Handwriting not well supported</li> <li>Image quality matters</li> </ol>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#vision-pipeline","title":"Vision Pipeline","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#what-is-vision-pipeline","title":"What is Vision Pipeline?","text":"<p>The Vision pipeline uses Vision-Language Models (VLMs) to understand documents visually. It processes layout, structure, and visual relationships alongside text.</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"vision\"  # Vision pipeline\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#how-it-works_1","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Images / PDF Document\" }\n\n    B@{ shape: doc, label: \"Page Images\" }\n    C@{ shape: procs, label: \"VLM Processing\" }\n    D@{ shape: lin-proc, label: \"Visual Understanding\" }\n\n    E@{ shape: doc, label: \"Structured Output\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B data\n    class C,D process\n    class E output</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#when-to-use-vision","title":"When to Use Vision","text":"<p>\u2705 Use Vision when: - Documents have complex layouts - Tables have intricate structures - Visual relationships are important - Forms have specific patterns - Highest accuracy is required - GPU is available</p> <p>\u274c Don't use Vision when: - Documents are simple text - Speed is critical - GPU is not available - Cost is a major concern - Processing large batches</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#vision-advantages","title":"Vision Advantages","text":"<ol> <li>Visual Understanding</li> <li>Processes layout and structure</li> <li>Understands visual relationships</li> <li>Handles complex tables</li> <li> <p>Better with forms</p> </li> <li> <p>Higher Accuracy</p> </li> <li>Best for complex documents</li> <li>Understands context visually</li> <li>Fewer extraction errors</li> <li> <p>Better table handling</p> </li> <li> <p>Robust to Quality</p> </li> <li>Handles poor scans better</li> <li>Works with handwriting</li> <li>Processes images directly</li> </ol>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#vision-limitations","title":"Vision Limitations","text":"<ol> <li>Resource Intensive</li> <li>Requires GPU</li> <li>Higher memory usage</li> <li>Slower processing</li> <li> <p>More expensive hardware</p> </li> <li> <p>Setup Complexity</p> </li> <li>GPU drivers required</li> <li>Model downloads needed</li> <li>More configuration</li> </ol>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#export-options","title":"Export Options","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#docling-document-export","title":"Docling Document Export","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n\n    # Docling export settings\n    export_docling=True,  # Export Docling document (default)\n    export_docling_json=True,  # Export as JSON (default)\n    export_markdown=True,  # Export as markdown (default)\n    export_per_page_markdown=False  # Export per-page markdown\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#export-options-explained","title":"Export Options Explained","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#1-export_docling","title":"1. export_docling","text":"<p>Controls whether to export the Docling document object.</p> <pre><code>export_docling=True  # Default\n</code></pre> <p>Output: <code>outputs/docling_document.pkl</code> (Python pickle)</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#2-export_docling_json","title":"2. export_docling_json","text":"<p>Exports the full Docling document structure as JSON.</p> <pre><code>export_docling_json=True  # Default\n</code></pre> <p>Output: <code>outputs/docling_document.json</code></p> <p>Contains: - Document metadata - Layout information - Tables and figures - Text content - Page structure</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#3-export_markdown","title":"3. export_markdown","text":"<p>Exports the document as markdown (full document).</p> <pre><code>export_markdown=True  # Default\n</code></pre> <p>Output: <code>outputs/document.md</code></p> <p>Best for: - Human-readable output - Documentation - Text analysis - Debugging</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#4-export_per_page_markdown","title":"4. export_per_page_markdown","text":"<p>Exports markdown for each page separately.</p> <pre><code>export_per_page_markdown=False  # Default\n</code></pre> <p>Output: <code>outputs/pages/page_001.md</code>, <code>page_002.md</code>, etc.</p> <p>Best for: - Page-by-page analysis - One-to-one processing - Page-level debugging</p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#complete-configuration-examples","title":"Complete Configuration Examples","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-with-full-exports","title":"\ud83d\udccd OCR with Full Exports","text":"<pre><code>config = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.BillingDocument\",\n\n    # OCR pipeline\n    docling_config=\"ocr\",\n\n    # Export everything\n    export_docling=True,\n    export_docling_json=True,\n    export_markdown=True,\n    export_per_page_markdown=True\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#vision-with-minimal-exports","title":"\ud83d\udccd Vision with Minimal Exports","text":"<pre><code>config = PipelineConfig(\n    source=\"complex_form.pdf\",\n    template=\"templates.Form\",\n\n    # Vision pipeline\n    docling_config=\"vision\",\n\n    # Minimal exports (save space)\n    export_docling=False,\n    export_docling_json=False,\n    export_markdown=False,\n    export_per_page_markdown=False\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-with-page-level-exports","title":"\ud83d\udccd OCR with Page-Level Exports","text":"<pre><code>config = PipelineConfig(\n    source=\"batch_invoices.pdf\",\n    template=\"templates.BillingDocument\",\n\n    # OCR pipeline\n    docling_config=\"ocr\",\n\n    # Page-level exports for one-to-one processing\n    processing_mode=\"one-to-one\",\n    export_per_page_markdown=True,\n    export_markdown=False  # Don't need full document\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#pipeline-selection-strategy","title":"Pipeline Selection Strategy","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#by-document-type","title":"By Document Type","text":"Document Type Recommended Pipeline Reason Invoices OCR Standard layout, text-heavy Contracts OCR Text-heavy, standard format Rheology Researchs OCR Text-heavy, standard layout Forms Vision Visual structure important ID Cards Vision Visual layout critical Complex Tables Vision Visual structure needed Handwritten Vision Visual processing required Mixed Content Vision Images and text combined"},{"location":"fundamentals/pipeline-configuration/docling-settings/#by-quality","title":"By Quality","text":"<pre><code>def get_docling_config(scan_quality: str):\n    \"\"\"Choose pipeline based on scan quality.\"\"\"\n    if scan_quality == \"high\":\n        return \"ocr\"  # OCR works well\n    elif scan_quality == \"medium\":\n        return \"ocr\"  # OCR still acceptable\n    else:\n        return \"vision\"  # Vision better for poor quality\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#by-infrastructure","title":"By Infrastructure","text":"<pre><code>def get_docling_config(has_gpu: bool):\n    \"\"\"Choose pipeline based on available hardware.\"\"\"\n    if has_gpu:\n        return \"vision\"  # Can use vision\n    else:\n        return \"ocr\"  # Must use OCR\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#performance-comparison","title":"Performance Comparison","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#processing-speed","title":"Processing Speed","text":"<pre><code>Document: 10-page invoice PDF\n\nOCR Pipeline:         ~10 seconds\nVision Pipeline:      ~60 seconds\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#accuracy-comparison","title":"Accuracy Comparison","text":"<pre><code>Document Type: Complex invoice with tables\n\nOCR Accuracy:   92% field extraction\nVision Accuracy: 97% field extraction\n\nDocument Type: Simple text contract\n\nOCR Accuracy:   98% field extraction\nVision Accuracy: 96% field extraction\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#resource-usage","title":"Resource Usage","text":"<pre><code>OCR Pipeline:\n- CPU: 50-70%\n- Memory: 2-4GB\n- GPU: Not required\n\nVision Pipeline:\n- CPU: 30-40%\n- Memory: 6-8GB\n- GPU: Required (4-8GB VRAM)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#combining-with-backend-settings","title":"Combining with Backend Settings","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-llm-backend","title":"OCR + LLM Backend","text":"<pre><code># Most common combination\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n\n    # OCR for conversion\n    docling_config=\"ocr\",\n\n    # LLM for extraction\n    backend=\"llm\",\n    inference=\"remote\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#vision-vlm-backend","title":"Vision + VLM Backend","text":"<pre><code># Highest accuracy combination\nconfig = PipelineConfig(\n    source=\"complex_document.pdf\",\n    template=\"templates.Form\",\n\n    # Vision for conversion\n    docling_config=\"vision\",\n\n    # VLM for extraction\n    backend=\"vlm\",\n    inference=\"local\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#ocr-vlm-backend","title":"OCR + VLM Backend","text":"<pre><code># Mixed approach (less common)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n\n    # OCR for conversion (faster)\n    docling_config=\"ocr\",\n\n    # VLM for extraction (higher accuracy)\n    backend=\"vlm\",\n    inference=\"local\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#poor-ocr-quality","title":"\ud83d\udc1b Poor OCR Quality","text":"<p>Symptoms: Missing text, garbled characters</p> <p>Solutions: <pre><code># 1. Try vision pipeline\nconfig = PipelineConfig(\n    source=\"poor_scan.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"vision\"  # Better for poor quality\n)\n\n# 2. Pre-process document (external tool)\n# - Increase resolution\n# - Enhance contrast\n# - Deskew pages\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#vision-pipeline-too-slow","title":"\ud83d\udc1b Vision Pipeline Too Slow","text":"<p>Symptoms: Long processing times</p> <p>Solutions: <pre><code># 1. Use OCR if acceptable\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"ocr\"  # Faster\n)\n\n# 2. Process fewer pages\n# 3. Use more powerful GPU\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#missing-tables","title":"\ud83d\udc1b Missing Tables","text":"<p>Symptoms: Table data not extracted</p> <p>Solutions: <pre><code># Use vision pipeline for better table handling\nconfig = PipelineConfig(\n    source=\"document_with_tables.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"vision\"  # Better table extraction\n)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/docling-settings/#start-with-ocr","title":"\ud83d\udc4d Start with OCR","text":"<pre><code># \u2705 Good - Start with faster option\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"ocr\"  # Try OCR first\n)\n\n# If accuracy insufficient, switch to vision\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#match-pipeline-to-document","title":"\ud83d\udc4d Match Pipeline to Document","text":"<pre><code># \u2705 Good - Choose based on document type\nif document_has_complex_layout:\n    docling_config = \"vision\"\nelse:\n    docling_config = \"ocr\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=docling_config\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#enable-appropriate-exports","title":"\ud83d\udc4d Enable Appropriate Exports","text":"<pre><code># \u2705 Good - Export what you need\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    docling_config=\"ocr\",\n\n    # Enable useful exports\n    export_markdown=True,  # For debugging\n    export_docling_json=False,  # Don't need full structure\n    export_per_page_markdown=False  # Not doing page-level\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/docling-settings/#next-steps","title":"Next Steps","text":"<p>Now that you understand Docling settings:</p> <ol> <li>Export Configuration \u2192 - Configure output formats</li> <li>Configuration Examples - Complete scenarios</li> <li>Model Configuration - Model settings</li> </ol>"},{"location":"fundamentals/pipeline-configuration/export-configuration/","title":"Export Configuration","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#overview","title":"Overview","text":"<p>Export configuration controls how Docling Graph outputs extracted data and knowledge graphs. Multiple export formats are supported, allowing you to integrate with various downstream tools and databases.</p> <p>In this guide: - Export formats (CSV, Cypher, JSON) - Output directory structure - Format-specific options - Export best practices - Integration scenarios</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#export-formats","title":"Export Formats","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#quick-comparison","title":"Quick Comparison","text":"Format Best For File Type Use Case CSV Analysis, spreadsheets <code>.csv</code> Data analysis, Excel Cypher Neo4j import <code>.cypher</code> Graph database import JSON APIs, processing <code>.json</code> Programmatic access"},{"location":"fundamentals/pipeline-configuration/export-configuration/#csv-export","title":"CSV Export","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#what-is-csv-export","title":"What is CSV Export?","text":"<p>CSV export creates separate CSV files for nodes and edges, making it easy to analyze data in spreadsheets or import into databases.</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"csv\"  # CSV export (default)\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#output-structure","title":"Output Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 nodes.csv          # All nodes\n\u251c\u2500\u2500 edges.csv          # All edges\n\u251c\u2500\u2500 graph_stats.json   # Graph statistics\n\u2514\u2500\u2500 visualization.html # Interactive visualization\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#csv-files-format","title":"CSV Files Format","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#nodescsv","title":"nodes.csv","text":"<pre><code>node_id,node_type,properties\ninvoice_001,Invoice,\"{\"\"document_no\"\": \"\"INV-001\"\", \"\"total\"\": 1000}\"\norg_acme,Organization,\"{\"\"name\"\": \"\"Acme Corp\"\"}\"\naddr_123,Address,\"{\"\"street\"\": \"\"123 Main St\"\", \"\"city\"\": \"\"Paris\"\"}\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#edgescsv","title":"edges.csv","text":"<pre><code>source_id,edge_type,target_id\ninvoice_001,ISSUED_BY,org_acme\norg_acme,LOCATED_AT,addr_123\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#when-to-use-csv","title":"When to Use CSV","text":"<p>\u2705 Use CSV when: - Analyzing data in Excel/spreadsheets - Importing into SQL databases - Need human-readable format - Performing data analysis - Creating reports</p> <p>\u274c Don't use CSV when: - Need direct Neo4j import - Want programmatic access - Require nested structures - Need type preservation</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#cypher-export","title":"Cypher Export","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#what-is-cypher-export","title":"What is Cypher Export?","text":"<p>Cypher export creates Cypher statements for direct import into Neo4j graph databases.</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"cypher\"  # Cypher export\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#output-structure_1","title":"Output Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 graph.cypher       # Cypher statements\n\u251c\u2500\u2500 graph_stats.json   # Graph statistics\n\u2514\u2500\u2500 visualization.html # Interactive visualization\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#cypher-file-format","title":"Cypher File Format","text":"<pre><code>// Create nodes\nCREATE (:BillingDocument {document_no: \"INV-001\", total: 1000, node_id: \"invoice_001\"})\nCREATE (:Organization {name: \"Acme Corp\", node_id: \"org_acme\"})\nCREATE (:Address {street: \"123 Main St\", city: \"Paris\", node_id: \"addr_123\"})\n\n// Create relationships\nMATCH (a {node_id: \"invoice_001\"}), (b {node_id: \"org_acme\"})\nCREATE (a)-[:ISSUED_BY]-&gt;(b)\n\nMATCH (a {node_id: \"org_acme\"}), (b {node_id: \"addr_123\"})\nCREATE (a)-[:LOCATED_AT]-&gt;(b)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#when-to-use-cypher","title":"When to Use Cypher","text":"<p>\u2705 Use Cypher when: - Importing into Neo4j - Building graph databases - Need graph queries - Want graph visualization - Performing graph analytics</p> <p>\u274c Don't use Cypher when: - Not using Neo4j - Need tabular format - Want simple data analysis - Require Excel compatibility</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#neo4j-import","title":"Neo4j Import","text":"<pre><code># Import into Neo4j\ncat outputs/graph.cypher | cypher-shell -u neo4j -p password\n\n# Or use Neo4j Browser\n# 1. Open Neo4j Browser\n# 2. Copy contents of graph.cypher\n# 3. Paste and execute\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#json-export","title":"JSON Export","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#what-is-json-export","title":"What is JSON Export?","text":"<p>JSON export is always generated alongside CSV or Cypher, providing structured data for programmatic access.</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#output-structure_2","title":"Output Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 extracted_data.json  # Extracted Pydantic models\n\u251c\u2500\u2500 graph_data.json      # Graph structure\n\u251c\u2500\u2500 graph_stats.json     # Graph statistics\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#json-files-format","title":"JSON Files Format","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#extracted_datajson","title":"extracted_data.json","text":"<pre><code>{\n  \"models\": [\n    {\n      \"document_no\": \"INV-001\",\n      \"total\": 1000,\n      \"issued_by\": {\n        \"name\": \"Acme Corp\",\n        \"located_at\": {\n          \"street\": \"123 Main St\",\n          \"city\": \"Paris\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#graph_datajson","title":"graph_data.json","text":"<pre><code>{\n  \"nodes\": [\n    {\n      \"id\": \"invoice_001\",\n      \"type\": \"BillingDocument\",\n      \"properties\": {\n        \"document_no\": \"INV-001\",\n        \"total\": 1000\n      }\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"invoice_001\",\n      \"type\": \"ISSUED_BY\",\n      \"target\": \"org_acme\"\n    }\n  ]\n}\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#when-to-use-json","title":"When to Use JSON","text":"<p>\u2705 Use JSON when: - Building APIs - Programmatic processing - Need nested structures - Want type preservation - Integrating with applications</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#output-directory-structure","title":"Output Directory Structure","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#default-structure","title":"Default Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 extracted_data.json      # Pydantic models\n\u251c\u2500\u2500 graph_data.json          # Graph structure\n\u251c\u2500\u2500 graph_stats.json         # Statistics\n\u251c\u2500\u2500 nodes.csv                # Nodes (CSV format)\n\u251c\u2500\u2500 edges.csv                # Edges (CSV format)\n\u251c\u2500\u2500 graph.cypher             # Cypher (Cypher format)\n\u251c\u2500\u2500 visualization.html       # Interactive viz\n\u251c\u2500\u2500 report.md                # Markdown report\n\u251c\u2500\u2500 docling_document.json    # Docling output\n\u251c\u2500\u2500 document.md              # Markdown export\n\u2514\u2500\u2500 pages/                   # Per-page exports\n    \u251c\u2500\u2500 page_001.md\n    \u251c\u2500\u2500 page_002.md\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#custom-output-directory","title":"Custom Output Directory","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    output_dir=\"my_results/invoice_001\"  # Custom directory\n)\n</code></pre> <p>Output: <code>my_results/invoice_001/nodes.csv</code>, etc.</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#complete-configuration-examples","title":"Complete Configuration Examples","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#csv-export-with-full-outputs","title":"\ud83d\udccd CSV Export with Full Outputs","text":"<pre><code>config = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.BillingDocument\",\n\n    # CSV export\n    export_format=\"csv\",\n\n    # Enable all exports\n    export_docling=True,\n    export_docling_json=True,\n    export_markdown=True,\n\n    # Custom output directory\n    output_dir=\"results/invoice_001\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#cypher-export-for-neo4j","title":"\ud83d\udccd Cypher Export for Neo4j","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n\n    # Cypher export for Neo4j\n    export_format=\"cypher\",\n\n    # Minimal other exports\n    export_docling=False,\n    export_markdown=False,\n\n    output_dir=\"neo4j_import\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#batch-processing-with-organized-outputs","title":"\ud83d\udccd Batch Processing with Organized Outputs","text":"<pre><code>import os\nfrom pathlib import Path\n\nfor doc_path in Path(\"documents\").glob(\"*.pdf\"):\n    # Create output directory per document\n    output_dir = f\"results/{doc_path.stem}\"\n\n    config = PipelineConfig(\n        source=str(doc_path),\n        template=\"templates.BillingDocument\",\n        export_format=\"csv\",\n        output_dir=output_dir\n    )\n\n    run_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#graph-statistics","title":"Graph Statistics","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#graph_statsjson","title":"graph_stats.json","text":"<p>Always generated, contains graph metrics:</p> <pre><code>{\n  \"node_count\": 15,\n  \"edge_count\": 18,\n  \"node_types\": {\n    \"BillingDocument\": 1,\n    \"Organization\": 2,\n    \"Address\": 3,\n    \"LineItem\": 9\n  },\n  \"edge_types\": {\n    \"ISSUED_BY\": 1,\n    \"SENT_TO\": 1,\n    \"LOCATED_AT\": 5,\n    \"CONTAINS_LINE\": 9,\n    \"HAS_TOTAL\": 2\n  },\n  \"avg_degree\": 2.4,\n  \"density\": 0.17\n}\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#using-statistics","title":"Using Statistics","text":"<pre><code>import json\n\n# Load statistics\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nprint(f\"Nodes: {stats['node_count']}\")\nprint(f\"Edges: {stats['edge_count']}\")\nprint(f\"Node types: {stats['node_types']}\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#visualization","title":"Visualization","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#interactive-html-visualization","title":"Interactive HTML Visualization","text":"<p>Always generated: <code>outputs/visualization.html</code></p> <p>Features: - Interactive graph visualization - Node and edge inspection - Zoom and pan - Search functionality - Export to image</p> <p>Open in browser: <pre><code># Open visualization\nopen outputs/visualization.html  # macOS\nxdg-open outputs/visualization.html  # Linux\nstart outputs/visualization.html  # Windows\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#markdown-report","title":"Markdown Report","text":"<p>Always generated: <code>outputs/report.md</code></p> <p>Contains: - Extraction summary - Graph statistics - Node and edge counts - Processing time - Configuration used</p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#export-format-selection","title":"Export Format Selection","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#by-use-case","title":"By Use Case","text":"Use Case Recommended Format Reason Data Analysis CSV Excel/spreadsheet compatible Graph Database Cypher Direct Neo4j import API Integration JSON Programmatic access Reporting CSV + Markdown Human-readable Machine Learning JSON Structured data Visualization Any HTML viz always generated"},{"location":"fundamentals/pipeline-configuration/export-configuration/#by-tool","title":"By Tool","text":"Tool Format Import Method Excel CSV Open directly Neo4j Cypher cypher-shell or Browser Python JSON json.load() Pandas CSV pd.read_csv() SQL Database CSV COPY or LOAD DATA Power BI CSV Import data"},{"location":"fundamentals/pipeline-configuration/export-configuration/#advanced-export-options","title":"Advanced Export Options","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#reverse-edges","title":"Reverse Edges","text":"<p>Create bidirectional relationships:</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"cypher\",\n    reverse_edges=True  # Create reverse relationships\n)\n</code></pre> <p>Effect: <pre><code>// Original\nCREATE (a)-[:ISSUED_BY]-&gt;(b)\n\n// With reverse_edges=True\nCREATE (a)-[:ISSUED_BY]-&gt;(b)\nCREATE (b)-[:ISSUES]-&gt;(a)  # Reverse edge added\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#integration-scenarios","title":"Integration Scenarios","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#scenario-1-excel-analysis","title":"Scenario 1: Excel Analysis","text":"<pre><code># Export for Excel analysis\nconfig = PipelineConfig(\n    source=\"invoices.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"csv\",\n    output_dir=\"excel_analysis\"\n)\n\nrun_pipeline(config)\n\n# Open in Excel\n# File -&gt; Open -&gt; excel_analysis/nodes.csv\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#scenario-2-neo4j-graph-database","title":"Scenario 2: Neo4j Graph Database","text":"<pre><code># Export for Neo4j\nconfig = PipelineConfig(\n    source=\"documents.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"cypher\",\n    output_dir=\"neo4j_import\"\n)\n\nrun_pipeline(config)\n\n# Import to Neo4j\n# cat neo4j_import/graph.cypher | cypher-shell\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#scenario-3-python-data-processing","title":"Scenario 3: Python Data Processing","text":"<pre><code># Export and process in Python\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"csv\",\n    output_dir=\"python_processing\"\n)\n\nrun_pipeline(config)\n\n# Load and process\nimport pandas as pd\n\nnodes = pd.read_csv(\"python_processing/nodes.csv\")\nedges = pd.read_csv(\"python_processing/edges.csv\")\n\nprint(f\"Total nodes: {len(nodes)}\")\nprint(f\"Total edges: {len(edges)}\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#scenario-4-api-integration","title":"Scenario 4: API Integration","text":"<pre><code># Export for API\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"csv\",  # Format doesn't matter, JSON always generated\n    output_dir=\"api_data\"\n)\n\nrun_pipeline(config)\n\n# Load JSON for API\nimport json\n\nwith open(\"api_data/extracted_data.json\") as f:\n    data = json.load(f)\n\n# Send to API\n# requests.post(\"https://api.example.com/invoices\", json=data)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#choose-format-by-use-case","title":"\ud83d\udc4d Choose Format by Use Case","text":"<pre><code># \u2705 Good - Match format to use case\nif use_case == \"neo4j\":\n    export_format = \"cypher\"\nelif use_case == \"excel\":\n    export_format = \"csv\"\nelse:\n    export_format = \"csv\"  # Default\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=export_format\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#organize-output-directories","title":"\ud83d\udc4d Organize Output Directories","text":"<pre><code># \u2705 Good - Organized structure\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\noutput_dir = f\"results/{document_type}/{timestamp}\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    output_dir=output_dir\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#enable-useful-exports","title":"\ud83d\udc4d Enable Useful Exports","text":"<pre><code># \u2705 Good - Enable what you need\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    export_format=\"csv\",\n\n    # Enable for debugging\n    export_markdown=True,\n\n    # Disable if not needed\n    export_docling=False,\n    export_docling_json=False\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#check-output-files","title":"\ud83d\udc4d Check Output Files","text":"<pre><code># \u2705 Good - Verify outputs\nrun_pipeline(config)\n\nimport os\noutput_dir = config.output_dir\n\n# Check files exist\nassert os.path.exists(f\"{output_dir}/nodes.csv\")\nassert os.path.exists(f\"{output_dir}/edges.csv\")\nassert os.path.exists(f\"{output_dir}/graph_stats.json\")\n\nprint(\"\u2705 All outputs generated successfully\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/pipeline-configuration/export-configuration/#output-directory-not-created","title":"\ud83d\udc1b Output Directory Not Created","text":"<p>Solution: <pre><code># Ensure parent directory exists\nimport os\nos.makedirs(\"results/invoices\", exist_ok=True)\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    output_dir=\"results/invoices/invoice_001\"\n)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#csv-files-empty","title":"\ud83d\udc1b CSV Files Empty","text":"<p>Solution: <pre><code># Check extraction succeeded\nrun_pipeline(config)\n\n# Verify graph has nodes\nimport json\nwith open(\"outputs/graph_stats.json\") as f:\n    stats = json.load(f)\n\nif stats[\"node_count\"] == 0:\n    print(\"Warning: No nodes extracted\")\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#cypher-import-fails","title":"\ud83d\udc1b Cypher Import Fails","text":"<p>Solution: <pre><code># Check Cypher syntax\ncat outputs/graph.cypher | head -20\n\n# Import with error handling\ncat outputs/graph.cypher | cypher-shell -u neo4j -p password 2&gt;&amp;1 | tee import.log\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/export-configuration/#next-steps","title":"Next Steps","text":"<p>Now that you understand export configuration:</p> <ol> <li>Configuration Examples \u2192 - Complete scenarios</li> <li>Model Configuration - Model settings</li> <li>Graph Management - Working with graphs</li> </ol>"},{"location":"fundamentals/pipeline-configuration/input-formats/","title":"Input Formats","text":"<p>Docling Graph uses a unified ingestion path: all inputs go through Docling except DoclingDocument JSON (which skips conversion), using a unified path: all inputs are converted through Docling; only DoclingDocument JSON skips conversion. See Docling supported formats for what Docling accepts.</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#input-normalization-process","title":"Input Normalization Process","text":"<p>The pipeline automatically detects and validates input types, routing them through the appropriate processing stages:</p> <pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    Start@{ shape: terminal, label: \"Input Source\" }\n    Detect@{ shape: procs, label: \"Input Type Detection\" }\n\n    %% Validators\n    ValPDF@{ shape: lin-proc, label: \"Validate PDF\" }\n    ValImg@{ shape: lin-proc, label: \"Validate Image\" }\n    ValText@{ shape: lin-proc, label: \"Validate Text\" }\n    ValMD@{ shape: lin-proc, label: \"Validate MD\" }\n    ValDoc@{ shape: lin-proc, label: \"Validate Docling\" }\n\n    %% URL Specifics\n    ValURL@{ shape: lin-proc, label: \"Validate &amp; Download URL\" }\n    CheckDL{\"Type?\"}\n\n    %% Handlers\n    HandVisual@{ shape: tag-proc, label: \"Visual Handler\" }\n    HandText@{ shape: tag-proc, label: \"Text Handler\" }\n    HandDoc@{ shape: tag-proc, label: \"Object Handler\" }\n\n    %% Outcomes\n    SetFlags@{ shape: procs, label: \"Set Processing Flags\" }\n    Output@{ shape: doc, label: \"Normalized Context\" }\n\n    %% 3. Define Connections\n    Start --&gt; Detect\n\n    %% Input Detection Routing\n    Detect -- PDF --&gt; ValPDF\n    Detect -- Image --&gt; ValImg\n    Detect -- Text --&gt; ValText\n    Detect -- MD --&gt; ValMD\n    Detect -- Docling --&gt; ValDoc\n    Detect -- URL --&gt; ValURL\n\n    %% URL Routing (Feeds back into validators)\n    ValURL --&gt; CheckDL\n    CheckDL -- PDF --&gt; ValPDF\n    CheckDL -- Image --&gt; ValImg\n    CheckDL -- Text --&gt; ValText\n    CheckDL -- MD --&gt; ValMD\n\n    %% Validation to Handlers (The \"Happy Path\")\n    ValPDF &amp; ValImg --&gt; HandVisual\n    ValText &amp; ValMD --&gt; HandText\n    ValDoc --&gt; HandDoc\n\n    %% Converge Handlers to Output\n    HandVisual &amp; HandText &amp; HandDoc --&gt; SetFlags --&gt; Output\n\n    %% 4. Apply Classes\n    class Start input\n    class Detect,SetFlags process\n    class ValPDF,ValImg,ValText,ValMD,ValURL,ValDoc process\n    class HandVisual,HandText,HandDoc operator\n    class CheckDL decision\n    class Output output</code></pre> <p>Key behavior: - DoclingDocument JSON: Loaded directly; conversion is skipped. - All other inputs: Normalized (e.g. URL download, text to temp .md), then sent to Docling. Docling validates format; unsupported types raise Docling errors. - URLs: Downloaded to a temp file; path is passed to Docling.</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#supported-input-formats","title":"Supported Input Formats","text":"<p>Docling Graph does not whitelist extensions. Any file or URL is sent to Docling; Docling supported formats include PDF, Office (DOCX, XLSX, PPTX), images, HTML, Markdown, LaTeX, AsciiDoc, CSV. Unsupported formats produce a Docling conversion error (e.g. <code>ExtractionError: Conversion failed in Docling: ...</code>).</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#document-inputs-files-raw-text","title":"Document inputs (files, raw text)","text":"<p>Any Docling-supported file, or raw text (API only). Text and .txt are normalized to markdown, then sent to Docling.</p> <p>CLI: <code>docling-graph convert document.pdf -t templates.billing_document.BillingDocument</code> API: Same; for raw text use <code>source=\"text content\"</code> and <code>run_pipeline(config, mode=\"api\")</code>.</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#urls","title":"URLs","text":"<p>Description: Download and process documents from HTTP/HTTPS URLs.</p> <p>Processing: Content is downloaded to a temporary file; the path is passed to Docling. Supported formats are those Docling supports.</p> <p>Requirements: Valid http/https URL; file size under limit (default: 100MB).</p> <p>CLI Example: <pre><code># PDF from URL\ndocling-graph convert https://example.com/invoice.pdf -t templates.billing_document.BillingDocument\n\n# Image from URL\ndocling-graph convert https://example.com/scan.jpg -t templates.form.Form\n\n# Text from URL\ndocling-graph convert https://example.com/notes.txt -t templates.report.Report --backend llm\n</code></pre></p> <p>Python API Example: <pre><code>config = PipelineConfig(\n    source=\"https://example.com/document.pdf\",\n    template=\"templates.billing_document.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\",\n    output_dir=\"outputs\",\n    export_format=\"csv\"\n)\n\nrun_pipeline(config)\n</code></pre></p> <p>URL Configuration: <pre><code>from docling_graph.core.input.handlers import URLInputHandler\n\n# Custom timeout and size limit\nhandler = URLInputHandler(\n    timeout=30,      # seconds\n    max_size_mb=50   # megabytes\n)\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#plain-text-strings-python-api-only","title":"Plain text strings (Python API only)","text":"<p>Raw text: pass a string as <code>source</code> and call <code>run_pipeline(config, mode=\"api\")</code>. It is normalized to a temporary markdown file and sent to Docling. CLI does not accept plain text (file path or URL only).</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#doclingdocument-json-skip-conversion","title":"DoclingDocument JSON (skip conversion)","text":"<p>Description: Pre-processed DoclingDocument JSON files.</p> <p>File Extensions: <code>.json</code> (with DoclingDocument schema)</p> <p>Processing: Skips document conversion. Uses pre-existing structure.</p> <p>Use Cases: - Reprocessing previously converted documents - Custom document preprocessing pipelines - Integration with external Docling workflows</p> <p>Requirements: - Valid DoclingDocument JSON schema - Must include <code>schema_name: \"DoclingDocument\"</code> - Must include <code>version</code> field</p> <p>CLI Example: <pre><code>docling-graph convert processed_document.json -t templates.custom.Custom\n</code></pre></p> <p>Python API Example: <pre><code>config = PipelineConfig(\n    source=\"preprocessed.json\",\n    template=\"templates.custom.Custom\",\n    backend=\"llm\",\n    inference=\"local\",\n    processing_mode=\"many-to-one\",\n    output_dir=\"outputs\",\n    export_format=\"csv\"\n)\n\nrun_pipeline(config)\n</code></pre></p> <p>DoclingDocument JSON Structure: <pre><code>{\n  \"schema_name\": \"DoclingDocument\",\n  \"version\": \"1.0.0\",\n  \"name\": \"document_name\",\n  \"pages\": {\n    \"0\": {\n      \"page_no\": 0,\n      \"size\": {\"width\": 612, \"height\": 792}\n    }\n  },\n  \"body\": {\n    \"self_ref\": \"#/body\",\n    \"children\": []\n  },\n  \"furniture\": {}\n}\n</code></pre></p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#input-format-detection","title":"Input Format Detection","text":"<ul> <li>URL: String starting with <code>http://</code> or <code>https://</code>.</li> <li>DoclingDocument: <code>.json</code> file with DoclingDocument schema (e.g. <code>schema_name</code>, <code>version</code>, <code>pages</code>).</li> <li>Document: Everything else (any file path or, in API mode, raw text). Passed to Docling; no extension whitelist in docling-graph.</li> </ul>"},{"location":"fundamentals/pipeline-configuration/input-formats/#processing-pipeline-by-input-type","title":"Processing Pipeline by Input Type","text":""},{"location":"fundamentals/pipeline-configuration/input-formats/#all-inputs-except-doclingdocument","title":"All inputs except DoclingDocument","text":"<pre><code>Input \u2192 Normalize (e.g. URL download, text \u2192 .md) \u2192 Docling conversion \u2192\nDoclingDocument \u2192 Chunking \u2192 Extraction \u2192 Graph \u2192 Export\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#doclingdocument-json","title":"DoclingDocument JSON","text":"<pre><code>Input \u2192 Load DoclingDocument \u2192 Chunking / Extraction \u2192 Graph \u2192 Export\n(Conversion skipped)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#backend-compatibility","title":"Backend Compatibility","text":"Input type LLM Backend VLM Backend Documents (files, URLs) Yes Yes (PDF/images at Docling level) DoclingDocument JSON Yes Yes Plain text (API) Yes Converted via Docling <p>VLM backend only supports certain inputs at the Docling level (e.g. PDF, images). Other formats may raise Docling or backend errors.</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#error-handling","title":"Error Handling","text":""},{"location":"fundamentals/pipeline-configuration/input-formats/#unsupported-format-from-docling","title":"Unsupported format (from Docling)","text":"<p>When the file type is not supported by Docling: <pre><code>ExtractionError: Conversion failed in Docling: ...\nDetails: source=/path/to/file.xyz\n</code></pre> Use a Docling-supported format or convert the file first.</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#empty-text","title":"Empty text","text":"<p><code>ValidationError: Text input is empty</code> \u2014 ensure content is non-empty.</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#file-not-found-cli","title":"File not found (CLI)","text":"<p><code>ConfigurationError: File not found</code> \u2014 use a valid file path or URL.</p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#invalid-url","title":"Invalid URL","text":"<p><code>ValidationError: URL must use http or https scheme</code></p>"},{"location":"fundamentals/pipeline-configuration/input-formats/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/input-formats/#choose-the-right-backend","title":"\ud83d\udc4d Choose the Right Backend","text":"<ul> <li>PDFs and Images: Use VLM for complex layouts, LLM for text-heavy documents</li> <li>Text Files: Always use LLM backend</li> <li>Mixed Workflows: Use LLM backend for maximum compatibility</li> </ul>"},{"location":"fundamentals/pipeline-configuration/input-formats/#validate-input-files","title":"\ud83d\udc4d Validate Input Files","text":"<pre><code>from pathlib import Path\n\nsource_path = Path(\"document.txt\")\nif not source_path.exists():\n    raise FileNotFoundError(f\"Input file not found: {source_path}\")\n\nif source_path.stat().st_size == 0:\n    raise ValueError(\"Input file is empty\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#handle-urls-safely","title":"\ud83d\udc4d Handle URLs Safely","text":"<pre><code>from docling_graph.core.input.validators import URLValidator\n\nvalidator = URLValidator()\ntry:\n    validator.validate(url)\nexcept ValidationError as e:\n    print(f\"Invalid URL: {e.message}\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#use-appropriate-processing-modes","title":"\ud83d\udc4d Use Appropriate Processing Modes","text":"<ul> <li>one-to-one: Best for multi-page PDFs where each page is independent</li> <li>many-to-one: Best for text files and single-entity documents</li> </ul>"},{"location":"fundamentals/pipeline-configuration/input-formats/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/pipeline-configuration/input-formats/#plain-text-input-is-only-supported-via-python-api","title":"\ud83d\udc1b Plain text input is only supported via Python API","text":"<p>Cause: Trying to pass plain text string via CLI</p> <p>Solution: Use Python API or save text to a <code>.txt</code> file first</p> <pre><code># Option 1: Use Python API\nrun_pipeline(config, mode=\"api\")\n\n# Option 2: Save to file\nPath(\"temp.txt\").write_text(text_content)\nconfig.source = \"temp.txt\"\nrun_pipeline(config, mode=\"cli\")\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#vlm-backend-does-not-support-text-only-inputs","title":"\ud83d\udc1b VLM backend does not support text-only inputs","text":"<p>Cause: Using VLM backend with text files</p> <p>Solution: Switch to LLM backend</p> <pre><code>docling-graph convert notes.txt -t templates.Report --backend llm\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#url-download-timeout","title":"\ud83d\udc1b URL download timeout","text":"<p>Cause: Slow network or large file</p> <p>Solution: Increase timeout or download manually</p> <pre><code>from docling_graph.core.input.handlers import URLInputHandler\n\nhandler = URLInputHandler(timeout=60)  # 60 seconds\ntemp_path = handler.load(url)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/input-formats/#next-steps","title":"Next Steps","text":"<ul> <li>Backend Selection - Choose the right backend for your input</li> <li>Processing Modes - Understand one-to-one vs many-to-one</li> <li>Configuration Examples - See complete configuration examples</li> </ul>"},{"location":"fundamentals/pipeline-configuration/model-configuration/","title":"Model Configuration","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#overview","title":"Overview","text":"<p>Model configuration determines which AI model processes your documents. Docling Graph supports multiple providers for both local and remote inference, giving you flexibility in choosing the right model for your needs.</p> <p>In this guide: - Local vs remote inference - Supported providers and models - Model selection strategies - Provider-specific configuration - Performance and cost considerations</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#local-vs-remote-inference","title":"Local vs Remote Inference","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#quick-comparison","title":"Quick Comparison","text":"Aspect Local Inference Remote Inference Location Your GPU/CPU Cloud API Setup Complex (GPU drivers, models) Simple (API key) Cost Hardware + electricity Pay per token Speed Fast (with GPU) Variable (network dependent) Privacy Complete Data sent to provider Offline Yes No Models Limited by hardware Latest models available"},{"location":"fundamentals/pipeline-configuration/model-configuration/#local-inference","title":"Local Inference","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#overview_1","title":"Overview","text":"<p>Local inference runs models on your own hardware (GPU or CPU). Best for privacy, offline use, and high-volume processing.</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"local\",  # Local inference\n    model_override=\"ibm-granite/granite-4.0-1b\",\n    provider_override=\"vllm\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#supported-local-providers","title":"Supported Local Providers","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#1-vllm-recommended-for-llm","title":"1. vLLM (Recommended for LLM)","text":"<p>Best for: Fast local LLM inference with GPU</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\",\n    provider_override=\"vllm\"\n)\n</code></pre> <p>Setup: <pre><code># Install vLLM\nuv add vllm\n\n# Start vLLM server\nuv run python -m vllm.entrypoints.openai.api_server \\\n    --model ibm-granite/granite-4.0-1b \\\n    --port 8000\n</code></pre></p> <p>Supported Models: - <code>ibm-granite/granite-4.0-1b</code> (default, fast) - <code>ibm-granite/granite-4.0-3b</code> (balanced) - <code>meta-llama/Llama-3.1-8B</code> (high quality) - Any HuggingFace model compatible with vLLM</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#2-ollama","title":"2. Ollama","text":"<p>Best for: Easy local setup, multiple models</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"local\",\n    model_override=\"llama-3.1-8b\",\n    provider_override=\"ollama\"\n)\n</code></pre> <p>Setup: <pre><code># Install Ollama (see ollama.ai)\n# Pull model\nollama pull llama3.1:8b\n\n# Ollama runs automatically on localhost:11434\n</code></pre></p> <p>Supported Models: - <code>llama3.1:8b</code> (recommended) - <code>mistral:7b</code> - <code>mixtral:8x7b</code> - Any model in Ollama library</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#3-lm-studio","title":"3. LM Studio","text":"<p>Best for: Local inference via the LM Studio app (OpenAI-compatible server)</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"local\",\n    model_override=\"llama-3.2-3b-instruct\",  # Must match model name in LM Studio\n    provider_override=\"lmstudio\"\n)\n</code></pre> <p>Setup:</p> <ol> <li>Install LM Studio and load a model</li> <li>Enable Local Server (OpenAI-compatible API)</li> <li>Default URL: <code>http://localhost:1234/v1</code></li> </ol> <p>Environment variables:</p> <ul> <li><code>LM_STUDIO_API_BASE</code> (optional): Override base URL (e.g. <code>http://localhost:1234/v1</code>)</li> <li><code>LM_STUDIO_API_KEY</code> (optional): Only if the server requires authentication</li> </ul> <p>Model name: Must match the model identifier shown in LM Studio's server/API (user-defined when you load the model).</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#4-docling-vlm-for-vlm-backend","title":"4. Docling VLM (For VLM Backend)","text":"<p>Best for: Vision-based extraction</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"vlm\",\n    inference=\"local\",\n    model_override=\"numind/NuExtract-2.0-8B\",\n    provider_override=\"docling\"\n)\n</code></pre> <p>Supported Models: - <code>numind/NuExtract-2.0-8B</code> (default, recommended) - <code>numind/NuExtract-2.0-2B</code> (faster, less accurate)</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#local-inference-requirements","title":"Local Inference Requirements","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#hardware-requirements","title":"Hardware Requirements","text":"<p>Minimum (CPU only): - 16GB RAM - 50GB disk space - Slow processing</p> <p>Recommended (GPU): - NVIDIA GPU with 8GB+ VRAM - 32GB RAM - 100GB disk space - CUDA 12.1+</p> <p>Optimal (GPU): - NVIDIA GPU with 24GB+ VRAM (RTX 4090, A100) - 64GB RAM - 200GB SSD - CUDA 12.1+</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#software-requirements","title":"Software Requirements","text":"<pre><code># CUDA drivers (for GPU)\nnvidia-smi  # Verify CUDA installation\n\n# Python packages\nuv add vllm  # For vLLM\n# or\n# Install Ollama from ollama.ai\n# or\n# Install LM Studio from lmstudio.ai and start Local Server\n</code></pre> <p>See: Installation: GPU Setup</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#remote-inference","title":"Remote Inference","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#overview_2","title":"Overview","text":"<p>Remote inference uses cloud API providers. Best for quick setup, latest models, and no hardware requirements.</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\",  # Remote inference\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#supported-remote-providers","title":"Supported Remote Providers","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#1-openai","title":"1. OpenAI","text":"<p>Best for: Highest quality, latest models</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\"\n)\n</code></pre> <p>Setup: <pre><code># Set API key\nexport OPENAI_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Supported Models: - <code>gpt-4-turbo</code> (recommended, best quality) - <code>gpt-4</code> (high quality) - <code>gpt-3.5-turbo</code> (fast, economical)</p> <p>Pricing (approximate): - GPT-4 Turbo: $0.01/1K input tokens, $0.03/1K output tokens - GPT-3.5 Turbo: $0.0005/1K input tokens, $0.0015/1K output tokens</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#2-mistral-ai","title":"2. Mistral AI","text":"<p>Best for: European provider, good balance</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\",\n    model_override=\"mistral-small-latest\",\n    provider_override=\"mistral\"\n)\n</code></pre> <p>Setup: <pre><code># Set API key\nexport MISTRAL_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Supported Models: - <code>mistral-small-latest</code> (default, economical) - <code>mistral-medium-latest</code> (balanced) - <code>mistral-large-latest</code> (highest quality)</p> <p>Pricing (approximate): - Small: $0.001/1K tokens - Medium: $0.0027/1K tokens - Large: $0.008/1K tokens</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#3-google-gemini","title":"3. Google Gemini","text":"<p>Best for: Multimodal capabilities, competitive pricing</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\",\n    model_override=\"gemini-2.5-flash\",\n    provider_override=\"gemini\"\n)\n</code></pre> <p>Setup: <pre><code># Set API key\nexport GEMINI_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Supported Models: - <code>gemini-2.5-flash</code> (default, fast) - <code>gemini-2.0-pro</code> (high quality)</p> <p>Pricing (approximate): - Flash: $0.00025/1K input tokens, $0.00075/1K output tokens - Pro: $0.00125/1K input tokens, $0.005/1K output tokens</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#4-ibm-watsonx","title":"4. IBM WatsonX","text":"<p>Best for: Enterprise deployments, IBM ecosystem</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\",\n    model_override=\"ibm/granite-13b-chat-v2\",\n    provider_override=\"watsonx\"\n)\n</code></pre> <p>Setup: <pre><code># Set API key and project ID\nexport WATSONX_API_KEY=\"your-api-key\"\nexport WATSONX_PROJECT_ID=\"your-project-id\"\n</code></pre></p> <p>See: API Keys Setup for WatsonX configuration details.</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#model-selection-strategies","title":"Model Selection Strategies","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#by-document-complexity","title":"By Document Complexity","text":"<pre><code>def get_model_config(document_complexity: str):\n    \"\"\"Choose model based on document complexity.\"\"\"\n    if document_complexity == \"simple\":\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"ibm-granite/granite-4.0-1b\",\n            \"provider_override\": \"vllm\"\n        }\n    elif document_complexity == \"medium\":\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"llama3.1:8b\",\n            \"provider_override\": \"ollama\"\n        }\n    else:\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"gpt-4-turbo\",\n            \"provider_override\": \"openai\"\n        }\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#by-volume","title":"By Volume","text":"<pre><code>def get_model_config(document_count: int):\n    \"\"\"Choose model based on processing volume.\"\"\"\n    if document_count &lt; 100:\n        # Low volume: use best quality\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"gpt-4-turbo\",\n            \"provider_override\": \"openai\"\n        }\n    elif document_count &lt; 1000:\n        # Medium volume: balanced\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"mistral-small-latest\",\n            \"provider_override\": \"mistral\"\n        }\n    else:\n        # High volume: use local to avoid costs\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"ibm-granite/granite-4.0-1b\",\n            \"provider_override\": \"vllm\"\n        }\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#by-budget","title":"By Budget","text":"<pre><code>def get_model_config(budget: str):\n    \"\"\"Choose model based on budget.\"\"\"\n    if budget == \"minimal\":\n        # Minimal cost: local inference\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"ibm-granite/granite-4.0-1b\",\n            \"provider_override\": \"vllm\"\n        }\n    elif budget == \"moderate\":\n        # Moderate cost: economical API\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"mistral-small-latest\",\n            \"provider_override\": \"mistral\"\n        }\n    else:\n        # No budget constraint: best quality\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"gpt-4-turbo\",\n            \"provider_override\": \"openai\"\n        }\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#by-quality-requirements","title":"By Quality Requirements","text":"<pre><code>def get_model_by_quality(quality_requirement: str):\n    \"\"\"Choose model based on quality requirements.\"\"\"\n    if quality_requirement == \"acceptable\":\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"ibm-granite/granite-4.0-1b\",\n            \"provider_override\": \"vllm\"\n        }\n    elif quality_requirement == \"high\":\n        return {\n            \"inference\": \"local\",\n            \"model_override\": \"llama3.1:8b\",\n            \"provider_override\": \"ollama\"\n        }\n    else:  # critical\n        return {\n            \"inference\": \"remote\",\n            \"model_override\": \"gpt-4-turbo\",\n            \"provider_override\": \"openai\",\n        }\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#provider-specific-configuration","title":"Provider-Specific Configuration","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#vllm-configuration","title":"vLLM Configuration","text":"<pre><code># Custom vLLM base URL\nimport os\nos.environ[\"VLLM_BASE_URL\"] = \"http://localhost:8000/v1\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"local\",\n    provider_override=\"vllm\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#ollama-configuration","title":"Ollama Configuration","text":"<pre><code># Custom Ollama base URL\nimport os\nos.environ[\"OLLAMA_BASE_URL\"] = \"http://localhost:11434\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"local\",\n    provider_override=\"ollama\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#api-key-configuration","title":"API Key Configuration","text":"<pre><code># Set via environment variables (recommended)\nexport OPENAI_API_KEY=\"your-key\"\nexport MISTRAL_API_KEY=\"your-key\"\nexport GEMINI_API_KEY=\"your-key\"\nexport WATSONX_API_KEY=\"your-key\"\nexport WATSONX_PROJECT_ID=\"your-project-id\"\n</code></pre> <p>Or via <code>.env</code> file: <pre><code># .env file\nOPENAI_API_KEY=your-key\nMISTRAL_API_KEY=your-key\nGEMINI_API_KEY=your-key\n</code></pre></p> <p>See: Installation: API Keys</p>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#performance-comparison","title":"Performance Comparison","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#speed-comparison","title":"Speed Comparison","text":"<pre><code>Document: 10-page invoice PDF\n\nLocal (vLLM, GPU):        ~30 seconds\nLocal (Ollama, GPU):      ~45 seconds\nRemote (GPT-3.5):         ~40 seconds\nRemote (GPT-4):           ~60 seconds\nRemote (Mistral Small):   ~35 seconds\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#quality-comparison","title":"Quality Comparison","text":"<pre><code>Extraction Accuracy (Complex Documents):\n\nGPT-4 Turbo:              97%\nGPT-3.5 Turbo:            92%\nMistral Large:            95%\nMistral Small:            90%\nGranite 4.0-1B (local):   88%\nLlama 3.1-8B (local):     93%\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#cost-comparison","title":"Cost Comparison","text":"<pre><code>Processing 1000 documents (10 pages each):\n\nLocal (vLLM):             $0 (GPU amortized)\nLocal (Ollama):           $0 (GPU amortized)\nRemote (GPT-4):           $150-300\nRemote (GPT-3.5):         $10-20\nRemote (Mistral Small):   $5-15\nRemote (Gemini Flash):    $3-10\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#local-inference-issues","title":"Local Inference Issues","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#cuda-out-of-memory","title":"\ud83d\udc1b CUDA Out of Memory","text":"<pre><code># Solution: Use smaller model\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\",  # Smaller model\n    provider_override=\"vllm\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#vllm-server-not-running","title":"\ud83d\udc1b vLLM Server Not Running","text":"<pre><code># Check if server is running\ncurl http://localhost:8000/v1/models\n\n# Start server if needed\nuv run python -m vllm.entrypoints.openai.api_server \\\n    --model ibm-granite/granite-4.0-1b \\\n    --port 8000\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#remote-inference-issues","title":"Remote Inference Issues","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#api-key-not-found","title":"\ud83d\udc1b API Key Not Found","text":"<pre><code># Verify API key is set\necho $OPENAI_API_KEY\n\n# Set if missing\nexport OPENAI_API_KEY=\"your-key\"\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#rate-limit-exceeded","title":"\ud83d\udc1b Rate Limit Exceeded","text":"<pre><code># Solution: Add retry logic or switch provider\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\",\n    model_override=\"mistral-small-latest\",  # Different provider\n    provider_override=\"mistral\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#start-with-remote-for-testing","title":"\ud83d\udc4d Start with Remote for Testing","text":"<pre><code># \u2705 Good - Quick setup for testing\nconfig = PipelineConfig(\n    source=\"test.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\",\n    model_override=\"gpt-3.5-turbo\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#use-local-for-production-volume","title":"\ud83d\udc4d Use Local for Production Volume","text":"<pre><code># \u2705 Good - Cost-effective for high volume\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#match-model-to-document-complexity","title":"\ud83d\udc4d Match Model to Document Complexity","text":"<pre><code># \u2705 Good - Use appropriate model\nif document_is_complex:\n    model = \"gpt-4-turbo\"\nelse:\n    model = \"gpt-3.5-turbo\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\",\n    model_override=model\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#monitor-costs","title":"\ud83d\udc4d Monitor Costs","text":"<pre><code># \u2705 Good - Track API usage\nimport logging\n\nlogging.info(f\"Processing {document_count} documents\")\nlogging.info(f\"Estimated cost: ${estimated_cost}\")\n\nrun_pipeline(config)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#model-recommendations-by-use-case","title":"Model Recommendations by Use Case","text":""},{"location":"fundamentals/pipeline-configuration/model-configuration/#high-volume-processing","title":"High-Volume Processing","text":"<pre><code># Use SIMPLE tier for speed and cost efficiency\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"local\",\n    model_override=\"ibm-granite/granite-4.0-1b\",  # SIMPLE tier\n    provider_override=\"vllm\",\n    use_chunking=True,\n)\n</code></pre> <p>Benefits:</p> <ul> <li>\ud83d\udd35 Good Accuracy</li> <li>\u26a1 Fast Processing</li> </ul>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#critical-documents","title":"Critical Documents","text":"<pre><code># Use ADVANCED tier for maximum accuracy\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"templates.Contract\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",  # ADVANCED tier\n    provider_override=\"openai\",\n    use_chunking=True,\n)\n</code></pre> <p>Benefits:</p> <ul> <li>\ud83d\udfe2 High Accuracy</li> <li>\ud83c\udf00 Multi-turn consolidation</li> </ul>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#balanced-approach","title":"Balanced Approach","text":"<pre><code># Use STANDARD tier for general documents\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.Report\",\n    inference=\"local\",\n    model_override=\"llama3.1:8b\",  # STANDARD tier\n    provider_override=\"ollama\",\n    use_chunking=True,\n)\n</code></pre> <p>Benefits:</p> <ul> <li>\ud83d\udd35 Good Accuracy</li> <li>\u2696\ufe0f Good Balance of Speed and Quality</li> </ul>"},{"location":"fundamentals/pipeline-configuration/model-configuration/#next-steps","title":"Next Steps","text":"<p>Now that you understand model configuration:</p> <ol> <li>Staged Extraction \u2192 - Multi-pass extraction</li> <li>Processing Modes \u2192 - Choose processing strategy</li> <li>Configuration Examples - See complete scenarios</li> <li>Extraction Process - Understand extraction</li> <li>Performance Tuning \u2192 - Optimize performance</li> </ol>"},{"location":"fundamentals/pipeline-configuration/processing-modes/","title":"Processing Modes","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#overview","title":"Overview","text":"<p>Processing modes determine how Docling Graph handles multi-page documents. The choice between one-to-one and many-to-one modes significantly affects extraction results and graph structure.</p> <p>In this guide: - One-to-one vs many-to-one comparison - When to use each mode - Graph structure differences - Performance implications - Mode-specific configuration</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#processing-mode-comparison","title":"Processing Mode Comparison","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#quick-comparison","title":"Quick Comparison","text":"Aspect One-to-One Many-to-One Processing Each page separately Whole document together Output N models (one per page) 1 merged model Best For Independent pages Single document entity Graph Nodes More nodes Fewer nodes Context Page-level Document-level Speed Slower (N extractions) Faster (1 extraction) Accuracy Page-specific Document-wide"},{"location":"fundamentals/pipeline-configuration/processing-modes/#one-to-one-mode","title":"One-to-One Mode","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#what-is-one-to-one","title":"What is One-to-One?","text":"<p>One-to-one mode processes each page independently, creating separate extraction results for each page. Best for documents where pages are independent entities.</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#configuration","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"one-to-one\"  # Process each page separately\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#how-it-works","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: doc, label: \"Page 1\" }\n    C@{ shape: doc, label: \"Page 2\" }\n    D@{ shape: doc, label: \"Page 3\" }\n\n    E@{ shape: tag-proc, label: \"Extract 1\" }\n    F@{ shape: tag-proc, label: \"Extract 2\" }\n    G@{ shape: tag-proc, label: \"Extract 3\" }\n\n    H@{ shape: procs, label: \"Model 1\" }\n    I@{ shape: procs, label: \"Model 2\" }\n    J@{ shape: procs, label: \"Model 3\" }\n\n    %% 3. Define Connections\n    A --&gt; B &amp; C &amp; D\n\n    B --&gt; E\n    C --&gt; F\n    D --&gt; G\n\n    E --&gt; H\n    F --&gt; I\n    G --&gt; J\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,D data\n    class E,F,G operator\n    class H,I,J output</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#when-to-use-one-to-one","title":"When to Use One-to-One","text":"<p>\u2705 Use one-to-one when: - Each page is an independent document (e.g., batch of invoices) - Pages have different structures - You need page-level granularity - Pages represent separate entities - You want to track which page data came from</p> <p>\u274c Don't use one-to-one when: - Document is a single entity spanning multiple pages - Pages are continuation of same content - You need document-wide context - You want a single consolidated result</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#example-use-cases","title":"Example Use Cases","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-1-batch-invoice-processing","title":"Use Case 1: Batch Invoice Processing","text":"<pre><code># Multiple invoices in one PDF\nconfig = PipelineConfig(\n    source=\"invoices_batch.pdf\",  # 10 invoices, 1 page each\n    template=\"templates.BillingDocument\",\n    processing_mode=\"one-to-one\"  # Each page is separate invoice\n)\n</code></pre> <p>Result: 10 BillingDocument models, one per page</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-2-form-collection","title":"Use Case 2: Form Collection","text":"<pre><code># Multiple forms in one PDF\nconfig = PipelineConfig(\n    source=\"forms_collection.pdf\",  # 20 forms\n    template=\"templates.ApplicationForm\",\n    processing_mode=\"one-to-one\"  # Each page is separate form\n)\n</code></pre> <p>Result: 20 ApplicationForm models</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-3-id-card-batch","title":"Use Case 3: ID Card Batch","text":"<pre><code># Multiple ID cards scanned together\nconfig = PipelineConfig(\n    source=\"id_cards_batch.pdf\",  # 50 ID cards\n    template=\"templates.IDCard\",\n    processing_mode=\"one-to-one\"  # Each page is separate ID\n)\n</code></pre> <p>Result: 50 IDCard models</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#graph-structure","title":"Graph Structure","text":"<p>One-to-one creates multiple root nodes:</p> <pre><code>Invoice-Page1 (node)\n  \u251c\u2500 ISSUED_BY \u2192 Organization-A\n  \u2514\u2500 SENT_TO \u2192 Client-A\n\nInvoice-Page2 (node)\n  \u251c\u2500 ISSUED_BY \u2192 Organization-B\n  \u2514\u2500 SENT_TO \u2192 Client-B\n\nInvoice-Page3 (node)\n  \u251c\u2500 ISSUED_BY \u2192 Organization-C\n  \u2514\u2500 SENT_TO \u2192 Client-C\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#performance-characteristics","title":"Performance Characteristics","text":"<pre><code>Document: 10-page PDF\n\nOne-to-One Processing:\n- Extractions: 10 (one per page)\n- Memory: Moderate (sequential processing)\n- Output: 10 separate models\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#many-to-one-mode","title":"Many-to-One Mode","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#what-is-many-to-one","title":"What is Many-to-One?","text":"<p>Many-to-one mode processes the entire document as a single entity, merging all pages into one extraction result. Best for documents that represent a single entity.</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#configuration_1","title":"Configuration","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"many-to-one\"  # Process whole document (default)\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#how-it-works_1","title":"How It Works","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart LR\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"PDF Document\" }\n\n    B@{ shape: doc, label: \"All Pages\" }\n    C@{ shape: tag-proc, label: \"Chunking\" }\n    D@{ shape: procs, label: \"Extract Chunks\" }\n    E@{ shape: lin-proc, label: \"Merge Results\" }\n\n    F@{ shape: procs, label: \"Single Model\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n\n    %% 4. Apply Classes\n    class A input\n    class B data\n    class C operator\n    class D,E process\n    class F output</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#when-to-use-many-to-one","title":"When to Use Many-to-One","text":"<p>\u2705 Use many-to-one when: - Document is a single entity (e.g., one invoice spanning multiple pages) - Pages are continuation of same content - You need document-wide context - You want a single consolidated result - Document has cross-page relationships</p> <p>\u274c Don't use many-to-one when: - Each page is independent - Pages have different structures - You need page-level tracking - Pages represent separate entities</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#example-use-cases_1","title":"Example Use Cases","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-1-multi-page-invoice","title":"Use Case 1: Multi-Page Invoice","text":"<pre><code># Single invoice spanning 3 pages\nconfig = PipelineConfig(\n    source=\"invoice_multipage.pdf\",  # 1 invoice, 3 pages\n    template=\"templates.BillingDocument\",\n    processing_mode=\"many-to-one\"  # Merge all pages\n)\n</code></pre> <p>Result: 1 BillingDocument model with data from all pages</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-2-rheology-research","title":"Use Case 2: Rheology Research","text":"<pre><code># Rheology research with 15 pages\nconfig = PipelineConfig(\n    source=\"research_paper.pdf\",  # 1 paper, 15 pages\n    template=\"templates.ScholarlyRheologyPaper\",\n    processing_mode=\"many-to-one\"  # Single paper entity\n)\n</code></pre> <p>Result: 1 Research model</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#use-case-3-contract-document","title":"Use Case 3: Contract Document","text":"<pre><code># Contract with 20 pages\nconfig = PipelineConfig(\n    source=\"contract.pdf\",  # 1 contract, 20 pages\n    template=\"templates.Contract\",\n    processing_mode=\"many-to-one\"  # Single contract\n)\n</code></pre> <p>Result: 1 Contract model</p>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#graph-structure_1","title":"Graph Structure","text":"<p>Many-to-one creates single root node:</p> <pre><code>BillingDocument-001 (node)\n  \u251c\u2500 ISSUED_BY \u2192 Organization-A\n  \u251c\u2500 SENT_TO \u2192 Client-A\n  \u251c\u2500 CONTAINS_LINE \u2192 LineItem-1\n  \u251c\u2500 CONTAINS_LINE \u2192 LineItem-2\n  \u2514\u2500 CONTAINS_LINE \u2192 LineItem-3\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#performance-characteristics_1","title":"Performance Characteristics","text":"<pre><code>Document: 10-page PDF\n\nMany-to-One Processing:\n- Extractions: 1 (whole document)\n- Time: ~30 seconds (single extraction)\n- Memory: Higher (all pages in context)\n- Output: 1 merged model\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#detailed-comparison","title":"Detailed Comparison","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#processing-flow","title":"Processing Flow","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#one-to-one-flow","title":"One-to-One Flow","text":"<pre><code>1. Convert PDF to pages\n2. For each page:\n   a. Convert to markdown\n   b. Extract with LLM\n   c. Create model instance\n3. Return list of models\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#many-to-one-flow","title":"Many-to-One Flow","text":"<pre><code>1. Convert PDF to markdown (all pages)\n2. Chunk markdown if needed\n3. Extract from chunks\n4. Merge chunk results\n5. Return single model\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#context-handling","title":"Context Handling","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#one-to-one-context","title":"One-to-One Context","text":"<pre><code># Each page has isolated context\nPage 1: \"Invoice #001, Total: $100\"\nPage 2: \"Invoice #002, Total: $200\"\nPage 3: \"Invoice #003, Total: $300\"\n\n# Result: 3 separate invoices\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#many-to-one-context","title":"Many-to-One Context","text":"<pre><code># All pages share context\nPage 1: \"Invoice #001\"\nPage 2: \"Line items continued...\"\nPage 3: \"Total: $1000\"\n\n# Result: 1 invoice with all information\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#memory-usage","title":"Memory Usage","text":"<pre><code>Document: 100-page PDF\n\nOne-to-One:\n- Peak memory: ~2GB (one page at a time)\n- Sustained: Low (sequential)\n\nMany-to-One:\n- Peak memory: ~8GB (all pages loaded)\n- Sustained: High (full document)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#choosing-the-right-mode","title":"Choosing the Right Mode","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#decision-tree","title":"Decision Tree","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A(\"Start\")\n\n    B{\"Are pages&lt;br/&gt;independent?\"}\n    D{\"Single entity&lt;br/&gt;across pages?\"}\n    F{\"Need page-level&lt;br/&gt;tracking?\"}\n\n    C@{ shape: tag-proc, label: \"One-to-One\" }\n    E@{ shape: tag-proc, label: \"Many-to-One\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n\n    B -- Yes --&gt; C\n    B -- No --&gt; D\n\n    D -- Yes --&gt; E\n    D -- No --&gt; F\n\n    F -- Yes --&gt; C\n    F -- No --&gt; E\n\n    %% 4. Apply Classes\n    class A input\n    class B,D,F decision\n    class C,E output</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#by-document-type","title":"By Document Type","text":"Document Type Recommended Mode Reason Single Invoice (multi-page) Many-to-One Single entity Batch Invoices (1 per page) One-to-One Independent pages Rheology Research Many-to-One Single document Form Collection One-to-One Independent forms Contract Many-to-One Single contract ID Card Batch One-to-One Independent IDs Report Many-to-One Single report Receipt Stack One-to-One Independent receipts"},{"location":"fundamentals/pipeline-configuration/processing-modes/#mode-specific-configuration","title":"Mode-Specific Configuration","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#one-to-one-configuration","title":"One-to-One Configuration","text":"<pre><code>config = PipelineConfig(\n    source=\"batch.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"one-to-one\",\n\n    # One-to-one specific settings\n    export_per_page_markdown=True,  # Export markdown per page\n    use_chunking=False  # No chunking needed (pages are small)\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#many-to-one-configuration","title":"Many-to-One Configuration","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"many-to-one\",\n\n    # Many-to-one specific settings\n    use_chunking=True,  # Enable chunking for large docs\n    max_batch_size=5  # Process chunks in batches\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#switching-between-modes","title":"Switching Between Modes","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#from-many-to-one-to-one-to-one","title":"From Many-to-One to One-to-One","text":"<pre><code># Original: many-to-one\nconfig_many = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"many-to-one\"\n)\n\n# Switch to one-to-one\nconfig_one = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"one-to-one\",  # Change mode\n    export_per_page_markdown=True  # Add page-specific export\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#from-one-to-one-to-many-to-one","title":"From One-to-One to Many-to-One","text":"<pre><code># Original: one-to-one\nconfig_one = PipelineConfig(\n    source=\"batch.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"one-to-one\"\n)\n\n# Switch to many-to-one\nconfig_many = PipelineConfig(\n    source=\"batch.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"many-to-one\",  # Change mode\n    use_chunking=True,  # Enable chunking\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#common-patterns","title":"Common Patterns","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#batch-processing-with-one-to-one","title":"\ud83d\udccd Batch Processing with One-to-One","text":"<pre><code># Process batch of documents\nconfig = PipelineConfig(\n    source=\"invoices_batch.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"one-to-one\",\n    export_per_page_markdown=True\n)\n\n# Result: One invoice per page\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#single-document-with-many-to-one","title":"\ud83d\udccd Single Document with Many-to-One","text":"<pre><code># Process single multi-page document\nconfig = PipelineConfig(\n    source=\"contract.pdf\",\n    template=\"templates.Contract\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n)\n\n# Result: One contract with all pages\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#conditional-mode-selection","title":"\ud83d\udccd Conditional Mode Selection","text":"<pre><code>def get_processing_mode(page_count: int, is_batch: bool):\n    \"\"\"Choose mode based on document characteristics.\"\"\"\n    if is_batch:\n        return \"one-to-one\"\n    elif page_count &gt; 10:\n        return \"many-to-one\"  # Use chunking for large docs\n    else:\n        return \"many-to-one\"  # Small doc, process as one\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=get_processing_mode(page_count=15, is_batch=False)\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/pipeline-configuration/processing-modes/#match-mode-to-document-structure","title":"\ud83d\udc4d Match Mode to Document Structure","text":"<pre><code># \u2705 Good - Mode matches document structure\nif document_is_batch:\n    mode = \"one-to-one\"\nelse:\n    mode = \"many-to-one\"\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=mode\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#enable-appropriate-settings","title":"\ud83d\udc4d Enable Appropriate Settings","text":"<pre><code># \u2705 Good - Settings match mode\nif mode == \"one-to-one\":\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.BillingDocument\",\n        processing_mode=\"one-to-one\",\n        export_per_page_markdown=True  # Page-specific\n    )\nelse:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.BillingDocument\",\n        processing_mode=\"many-to-one\",\n        use_chunking=True,  # Document-wide\n    )\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#consider-performance","title":"\ud83d\udc4d Consider Performance","text":"<pre><code># \u2705 Good - Consider document size\nif page_count &gt; 50:\n    # Large batch: one-to-one might be slow\n    print(\"Warning: Processing 50+ pages individually\")\n\nconfig = PipelineConfig(\n    source=\"large_batch.pdf\",\n    template=\"templates.BillingDocument\",\n    processing_mode=\"one-to-one\"\n)\n</code></pre>"},{"location":"fundamentals/pipeline-configuration/processing-modes/#next-steps","title":"Next Steps","text":"<p>Now that you understand processing modes:</p> <ol> <li>Docling Settings \u2192 - Configure document conversion</li> <li>Export Configuration - Set output formats</li> <li>Configuration Examples - See complete scenarios</li> </ol>"},{"location":"fundamentals/schema-definition/","title":"Schema Definition","text":"<p>Pydantic templates are the schema contract for all extraction modes (<code>direct</code>, <code>staged</code>, <code>delta</code>).</p>"},{"location":"fundamentals/schema-definition/#core-rules","title":"Core rules","text":"<ul> <li>Use explicit entities (<code>graph_id_fields</code>) and components (<code>is_entity=False</code>).</li> <li>Keep identity fields short, stable, and required when possible; prefer descriptive IDs over raw section/figure labels.</li> <li>Prefer 2-4 nesting levels; flatten deeply recursive structures.</li> <li>Use <code>edge(label=...)</code> consistently for relationship-bearing fields.</li> <li>Write extraction-oriented descriptions and realistic examples for every important field.</li> <li>Use validators to correct semantic errors (e.g. wrong unit in amount) and to deduplicate root-level lists when using chunked extraction.</li> </ul>"},{"location":"fundamentals/schema-definition/#extraction-focused-design","title":"Extraction-focused design","text":"<ul> <li>Direct: optimize semantic clarity and validation tolerance.</li> <li>Staged: optimize ID discovery and parent linkage determinism.</li> <li>Delta: optimize path fidelity, flat properties, canonicalized values, and merge-safe identities.</li> </ul>"},{"location":"fundamentals/schema-definition/#recommended-reading-order","title":"Recommended reading order","text":"<ol> <li><code>template-basics.md</code></li> <li><code>entities-vs-components.md</code></li> <li><code>field-definitions.md</code></li> <li><code>relationships.md</code></li> <li><code>best-practices.md</code></li> <li><code>staged-extraction-schema.md</code></li> <li><code>validation.md</code></li> <li><code>advanced-patterns.md</code></li> </ol>"},{"location":"fundamentals/schema-definition/advanced-patterns/","title":"Advanced Patterns","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#overview","title":"Overview","text":"<p>This guide covers advanced Pydantic patterns for complex document structures, reusable components, and sophisticated validation scenarios. These patterns are drawn from production templates across multiple domains.</p> <p>In this guide: - Flexible measurement models - Nested list patterns with edges - Multiple address support - Optional edges and conditional fields - Reusable component library</p>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-1-flexible-measurement-with-range-support","title":"Pattern 1: Flexible Measurement with Range Support","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge","title":"The Challenge","text":"<p>Scientific and technical documents often contain measurements in various formats: - Single values: \"25\u00b0C\", \"1.6 mPa.s\" - Ranges: \"80-90\u00b0C\", \"1.5-2.0 mm\" - Text values: \"High\", \"Low\", \"Stable\"</p>"},{"location":"fundamentals/schema-definition/advanced-patterns/#the-solution","title":"The Solution","text":"<pre><code>from typing import Union, Optional, Self\nfrom pydantic import BaseModel, ConfigDict, Field, model_validator\n\nclass Measurement(BaseModel):\n    \"\"\"\n    Flexible measurement supporting single values, ranges, or text.\n    Can represent '25\u00b0C', '1.6 mPa.s', '80-90\u00b0C', or 'High'.\n    \"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    name: str = Field(\n        description=\"Name of the measured property\",\n        examples=[\"Temperature\", \"Viscosity\", \"pH\", \"Concentration\"]\n    )\n\n    text_value: Optional[str] = Field(\n        default=None,\n        description=\"Textual value if not numerical\",\n        examples=[\"High\", \"Low\", \"Stable\", \"Increasing\"]\n    )\n\n    numeric_value: Optional[Union[float, int]] = Field(\n        default=None,\n        description=\"Single numerical value\",\n        examples=[25.0, 1.6, 8.2]\n    )\n\n    numeric_value_min: Optional[Union[float, int]] = Field(\n        default=None,\n        description=\"Minimum value for range measurements\",\n        examples=[80.0, 1.5]\n    )\n\n    numeric_value_max: Optional[Union[float, int]] = Field(\n        default=None,\n        description=\"Maximum value for range measurements\",\n        examples=[90.0, 2.0]\n    )\n\n    unit: Optional[str] = Field(\n        default=None,\n        description=\"Unit of measurement\",\n        examples=[\"\u00b0C\", \"mPa.s\", \"wt%\", \"kg\"]\n    )\n\n    condition: Optional[str] = Field(\n        default=None,\n        description=\"Measurement conditions or context\",\n        examples=[\"at 25\u00b0C\", \"after 24h\", \"under normal pressure\"]\n    )\n\n    @model_validator(mode=\"after\")\n    def validate_value_consistency(self) -&gt; Self:\n        \"\"\"Ensure value fields don't conflict.\"\"\"\n        has_single = self.numeric_value is not None\n        has_min = self.numeric_value_min is not None\n        has_max = self.numeric_value_max is not None\n\n        # Reject ambiguous cases\n        if has_single and has_min and has_max:\n            raise ValueError(\n                \"Cannot specify all three: numeric_value, \"\n                \"numeric_value_min, and numeric_value_max\"\n            )\n\n        # Allow implicit range: if numeric_value + min/max, treat as range\n        if has_single and (has_min or has_max):\n            if has_max and not has_min:\n                # Treat numeric_value as min\n                self.numeric_value_min = self.numeric_value\n                self.numeric_value = None\n            elif has_min and not has_max:\n                # Treat numeric_value as max\n                self.numeric_value_max = self.numeric_value\n                self.numeric_value = None\n\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#usage-examples","title":"Usage Examples","text":"<pre><code># Single value\ntemp = Measurement(\n    name=\"Temperature\",\n    numeric_value=25.0,\n    unit=\"\u00b0C\"\n)\n\n# Range\ntemp_range = Measurement(\n    name=\"Temperature\",\n    numeric_value_min=80.0,\n    numeric_value_max=90.0,\n    unit=\"\u00b0C\"\n)\n\n# Text value\nquality = Measurement(\n    name=\"Quality\",\n    text_value=\"High\"\n)\n\n# With condition\nviscosity = Measurement(\n    name=\"Viscosity\",\n    numeric_value=1.6,\n    unit=\"mPa.s\",\n    condition=\"at 25\u00b0C\"\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-2-nested-list-with-edges","title":"Pattern 2: Nested List with Edges","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_1","title":"The Challenge","text":"<p>Complex documents have nested structures where list items themselves have relationships:</p> <pre><code>Assembly\n  \u2514\u2500 Components (list)\n      \u251c\u2500 Material (edge)\n      \u251c\u2500 Role\n      \u2514\u2500 Amount (edge)\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#the-solution_1","title":"The Solution","text":"<pre><code>from typing import Any, List\nfrom pydantic import BaseModel, ConfigDict, Field\nfrom enum import Enum\n\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\nclass RoleEnum(str, Enum):\n    PRIMARY = \"Primary\"\n    SECONDARY = \"Secondary\"\n    ADDITIVE = \"Additive\"\n\nclass Material(BaseModel):\n    \"\"\"Material entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(\n        description=\"Material name\",\n        examples=[\"Steel\", \"Aluminum\", \"Polymer\"]\n    )\n\n    grade: Optional[str] = Field(\n        None,\n        description=\"Material grade or specification\",\n        examples=[\"304\", \"6061\", \"ABS\"]\n    )\n\nclass Component(BaseModel):\n    \"\"\"Component with material, role, and amount.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"material\", \"role\"])\n\n    # Edge to Material entity\n    material: Material = edge(\n        label=\"USES_MATERIAL\",\n        description=\"The material used in this component\"\n    )\n\n    role: RoleEnum = Field(\n        description=\"Function of this component\",\n        examples=[\"Primary\", \"Secondary\", \"Additive\"]\n    )\n\n    # Edge to Measurement component\n    amount: Optional[Measurement] = edge(\n        label=\"HAS_AMOUNT\",\n        description=\"Amount specification\"\n    )\n\nclass Assembly(BaseModel):\n    \"\"\"Root assembly containing components.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"assembly_id\"])\n\n    assembly_id: str = Field(...)\n\n    # List edge to Component entities\n    components: List[Component] = edge(\n        label=\"HAS_COMPONENT\",\n        default_factory=list,\n        description=\"List of components in this assembly\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#graph-structure","title":"Graph Structure","text":"<pre><code>Assembly-001\n  \u251c\u2500 HAS_COMPONENT \u2192 Component-1\n  \u2502                   \u251c\u2500 USES_MATERIAL \u2192 Material(Steel)\n  \u2502                   \u2514\u2500 HAS_AMOUNT \u2192 Measurement(12.0 kg)\n  \u2514\u2500 HAS_COMPONENT \u2192 Component-2\n                      \u251c\u2500 USES_MATERIAL \u2192 Material(Aluminum)\n                      \u2514\u2500 HAS_AMOUNT \u2192 Measurement(5.0 kg)\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-3-multiple-address-support","title":"Pattern 3: Multiple Address Support","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_2","title":"The Challenge","text":"<p>Entities often have multiple addresses (home, work, billing, shipping):</p> <pre><code>class Entity(BaseModel):\n    \"\"\"Entity that may have multiple addresses.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n\n    # Support multiple addresses\n    addresses: List[Address] = edge(\n        label=\"LOCATED_AT\",\n        default_factory=list,\n        description=\"Physical addresses (headquarters, branches, etc.)\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#enhanced-with-address-types","title":"Enhanced with Address Types","text":"<pre><code>from enum import Enum\n\nclass AddressType(str, Enum):\n    HOME = \"Home\"\n    WORK = \"Work\"\n    BILLING = \"Billing\"\n    SHIPPING = \"Shipping\"\n    HEADQUARTERS = \"Headquarters\"\n    BRANCH = \"Branch\"\n\nclass TypedAddress(BaseModel):\n    \"\"\"Address with type classification.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    address_type: AddressType = Field(\n        description=\"Type of address\",\n        examples=[\"Home\", \"Work\", \"Billing\"]\n    )\n\n    street_address: Optional[str] = Field(None)\n    city: Optional[str] = Field(None)\n    postal_code: Optional[str] = Field(None)\n    country: Optional[str] = Field(None)\n\nclass Organization(BaseModel):\n    \"\"\"Organization with typed addresses.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n\n    addresses: List[TypedAddress] = edge(\n        label=\"LOCATED_AT\",\n        default_factory=list,\n        description=\"Physical addresses with types\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-4-optional-edges","title":"Pattern 4: Optional Edges","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_3","title":"The Challenge","text":"<p>Some relationships are conditional - they may or may not exist:</p> <pre><code>class Document(BaseModel):\n    \"\"\"Document that may or may not have a verifier.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_id\"])\n\n    document_id: str = Field(...)\n\n    # Required edge\n    issued_by: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Organization that issued this document\"\n    )\n\n    # Optional edge - document may not be verified\n    verified_by: Optional[Person] = edge(\n        label=\"VERIFIED_BY\",\n        description=\"Person who verified this document, if verified\"\n    )\n\n    # Optional edge - document may not be approved\n    approved_by: Optional[Person] = edge(\n        label=\"APPROVED_BY\",\n        description=\"Person who approved this document, if approved\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#graph-behavior","title":"Graph Behavior","text":"<pre><code># Verified document\nDocument-001 --ISSUED_BY--&gt; Org-A\nDocument-001 --VERIFIED_BY--&gt; Person-A\n\n# Unverified document\nDocument-002 --ISSUED_BY--&gt; Org-B\n# No VERIFIED_BY edge\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-5-conditional-fields-with-validators","title":"Pattern 5: Conditional Fields with Validators","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_4","title":"The Challenge","text":"<p>Some fields are only relevant for certain document types:</p> <pre><code>class Document(BaseModel):\n    \"\"\"Document with type-specific fields.\"\"\"\n\n    document_type: str = Field(\n        description=\"Type of document\",\n        examples=[\"Invoice\", \"Receipt\", \"Credit Note\"]\n    )\n\n    # Field only relevant for invoices\n    payment_terms: Optional[str] = Field(\n        None,\n        description=\"Payment terms (primarily for invoices)\",\n        examples=[\"Net 30\", \"Due on receipt\", \"Net 60\"]\n    )\n\n    # Field only relevant for credit notes\n    original_document_ref: Optional[str] = Field(\n        None,\n        description=\"Reference to original document (for credit notes)\",\n        examples=[\"INV-2024-001\", \"DOC-123456\"]\n    )\n\n    @model_validator(mode=\"after\")\n    def validate_type_specific_fields(self) -&gt; Self:\n        \"\"\"Validate fields based on document type.\"\"\"\n        if self.document_type == \"Invoice\":\n            if not self.payment_terms:\n                # Could warn or set default\n                self.payment_terms = \"Net 30\"\n\n        if self.document_type == \"Credit Note\":\n            if not self.original_document_ref:\n                raise ValueError(\n                    \"original_document_ref required for Credit Note\"\n                )\n\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-6-polymorphic-fields","title":"Pattern 6: Polymorphic Fields","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_5","title":"The Challenge","text":"<p>A field might accept multiple types:</p> <pre><code>class FlexibleValue(BaseModel):\n    \"\"\"Value that can be numeric or textual.\"\"\"\n\n    value: Union[str, int, float] = Field(\n        ...,\n        description=(\n            \"Value can be numeric (int/float) or textual. \"\n            \"Extract as-is: '100', '25.5', or 'High'.\"\n        ),\n        examples=[100, 25.5, \"High\", \"Medium\"]\n    )\n\n    @field_validator(\"value\", mode=\"before\")\n    @classmethod\n    def coerce_value(cls, v: Any) -&gt; Any:\n        \"\"\"Try to convert to number if possible.\"\"\"\n        if isinstance(v, str):\n            # Try numeric conversion\n            try:\n                if \".\" in v:\n                    return float(v)\n                return int(v)\n            except ValueError:\n                # Keep as string\n                return v\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-7-hierarchical-structures","title":"Pattern 7: Hierarchical Structures","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_6","title":"The Challenge","text":"<p>Documents with nested sections or chapters:</p> <pre><code>class Section(BaseModel):\n    \"\"\"Document section.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"section_number\"])\n\n    section_number: str = Field(...)\n    title: str = Field(...)\n    content: str = Field(...)\n\n    # Recursive: sections can contain subsections\n    subsections: List[\"Section\"] = edge(\n        label=\"HAS_SUBSECTION\",\n        default_factory=list,\n        description=\"Nested subsections\"\n    )\n\nclass Document(BaseModel):\n    \"\"\"Document with hierarchical structure.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_id\"])\n\n    document_id: str = Field(...)\n\n    sections: List[Section] = edge(\n        label=\"HAS_SECTION\",\n        default_factory=list,\n        description=\"Top-level sections\"\n    )\n</code></pre> <p>Pydantic forward references</p> <p>Pydantic requires forward references for recursive models. Use string quotes for the type hint.</p>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-8-reusable-component-library","title":"Pattern 8: Reusable Component Library","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#common-components","title":"Common Components","text":"<p>Build a library of reusable components:</p> <pre><code># --- Address Component ---\nclass Address(BaseModel):\n    \"\"\"Physical address component (deduplicated by content).\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street_address: Optional[str] = Field(None)\n    city: Optional[str] = Field(None)\n    state_or_province: Optional[str] = Field(None)\n    postal_code: Optional[str] = Field(None)\n    country: Optional[str] = Field(None)\n\n    def __str__(self) -&gt; str:\n        parts = [\n            self.street_address,\n            self.city,\n            self.state_or_province,\n            self.postal_code,\n            self.country\n        ]\n        return \", \".join(p for p in parts if p)\n\n# --- Monetary Amount Component ---\nclass MonetaryAmount(BaseModel):\n    \"\"\"Monetary value with currency (deduplicated by content).\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    value: float = Field(...)\n    currency: Optional[str] = Field(None)\n\n    @field_validator(\"value\")\n    @classmethod\n    def validate_positive(cls, v: Any) -&gt; Any:\n        if v &lt; 0:\n            raise ValueError(\"Amount must be non-negative\")\n        return v\n\n    @field_validator(\"currency\")\n    @classmethod\n    def validate_currency_format(cls, v: Any) -&gt; Any:\n        if v and not (len(v) == 3 and v.isupper()):\n            raise ValueError(\"Currency must be 3 uppercase letters (ISO 4217)\")\n        return v\n\n    def __str__(self) -&gt; str:\n        return f\"{self.value} {self.currency or ''}\".strip()\n\n# --- Contact Information Component ---\nclass ContactInfo(BaseModel):\n    \"\"\"Contact information component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    email: Optional[str] = Field(None)\n    phone: Optional[str] = Field(None)\n    website: Optional[str] = Field(None)\n\n    @field_validator(\"email\", mode=\"before\")\n    @classmethod\n    def normalize_email(cls, v: Any) -&gt; Any:\n        if v:\n            return v.lower().strip()\n        return v\n\n# --- Date Range Component ---\nclass DateRange(BaseModel):\n    \"\"\"Date range component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    start_date: Optional[date] = Field(None)\n    end_date: Optional[date] = Field(None)\n\n    @model_validator(mode=\"after\")\n    def validate_date_order(self) -&gt; Self:\n        if self.start_date and self.end_date:\n            if self.end_date &lt; self.start_date:\n                raise ValueError(\"end_date must be after start_date\")\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#common-entities","title":"Common Entities","text":"<pre><code># --- Person Entity ---\nclass Person(BaseModel):\n    \"\"\"Person entity (unique by name and date of birth).\"\"\"\n    model_config = ConfigDict(\n        graph_id_fields=[\"first_name\", \"last_name\", \"date_of_birth\"]\n    )\n\n    first_name: Optional[str] = Field(None)\n    last_name: Optional[str] = Field(None)\n    date_of_birth: Optional[date] = Field(None)\n\n    contact: Optional[ContactInfo] = Field(None)\n\n    addresses: List[Address] = edge(\n        label=\"LIVES_AT\",\n        default_factory=list,\n        description=\"Residential addresses\"\n    )\n\n    def __str__(self) -&gt; str:\n        parts = [self.first_name, self.last_name]\n        return \" \".join(p for p in parts if p) or \"Unknown\"\n\n# --- Organization Entity ---\nclass Organization(BaseModel):\n    \"\"\"Organization entity (unique by name).\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n    tax_id: Optional[str] = Field(None)\n\n    contact: Optional[ContactInfo] = Field(None)\n\n    addresses: List[Address] = edge(\n        label=\"LOCATED_AT\",\n        default_factory=list,\n        description=\"Business addresses\"\n    )\n\n    def __str__(self) -&gt; str:\n        return self.name\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-9-string-representations","title":"Pattern 9: String Representations","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#purpose","title":"Purpose","text":"<p>Add <code>__str__</code> methods for debugging, logging, and visualization:</p> <pre><code># Simple concatenation\nclass Person(BaseModel):\n    first_name: Optional[str] = Field(...)\n    last_name: Optional[str] = Field(...)\n\n    def __str__(self) -&gt; str:\n        parts = [self.first_name, self.last_name]\n        return \" \".join(p for p in parts if p) or \"Unknown\"\n\n# With list handling\nclass Person(BaseModel):\n    given_names: Optional[List[str]] = Field(...)\n    last_name: Optional[str] = Field(...)\n\n    def __str__(self) -&gt; str:\n        first_names = \" \".join(self.given_names) if self.given_names else \"\"\n        parts = [first_names, self.last_name]\n        return \" \".join(p for p in parts if p) or \"Unknown\"\n\n# Address formatting\nclass Address(BaseModel):\n    street_address: Optional[str] = Field(...)\n    city: Optional[str] = Field(...)\n    postal_code: Optional[str] = Field(...)\n    country: Optional[str] = Field(...)\n\n    def __str__(self) -&gt; str:\n        parts = [self.street_address, self.city, self.postal_code, self.country]\n        return \", \".join(p for p in parts if p)\n\n# Value with unit\nclass MonetaryAmount(BaseModel):\n    value: float = Field(...)\n    currency: Optional[str] = Field(None)\n\n    def __str__(self) -&gt; str:\n        return f\"{self.value} {self.currency or ''}\".strip()\n\n# With identifier\nclass Document(BaseModel):\n    document_type: str = Field(...)\n    document_number: str = Field(...)\n\n    def __str__(self) -&gt; str:\n        return f\"{self.document_type} {self.document_number}\"\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#pattern-10-template-composition","title":"Pattern 10: Template Composition","text":""},{"location":"fundamentals/schema-definition/advanced-patterns/#the-challenge_7","title":"The Challenge","text":"<p>Large templates can become unwieldy. Break them into modules:</p> <pre><code># common_components.py\n\"\"\"Reusable components for all templates.\"\"\"\n\nclass Address(BaseModel):\n    \"\"\"Physical address component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    # ... fields\n\nclass MonetaryAmount(BaseModel):\n    \"\"\"Monetary value component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    # ... fields\n\n# common_entities.py\n\"\"\"Reusable entities for all templates.\"\"\"\n\nfrom .common_components import Address\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\"])\n    # ... fields\n    addresses: List[Address] = edge(label=\"LIVES_AT\", default_factory=list)\n\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n    # ... fields\n    addresses: List[Address] = edge(label=\"LOCATED_AT\", default_factory=list)\n\n# invoice_template.py\n\"\"\"Invoice-specific template.\"\"\"\n\nfrom .common_components import Address, MonetaryAmount\nfrom .common_entities import Person, Organization\n\nclass LineItem(BaseModel):\n    \"\"\"Invoice line item.\"\"\"\n    # ... fields\n\nclass Invoice(BaseModel):\n    \"\"\"Invoice document.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n    # ... fields\n    issued_by: Organization = edge(label=\"ISSUED_BY\")\n    sent_to: Person = edge(label=\"SENT_TO\")\n</code></pre>"},{"location":"fundamentals/schema-definition/advanced-patterns/#next-steps","title":"Next Steps","text":"<p>Now that you understand advanced patterns:</p> <ol> <li>Best Practices \u2192 - Complete template checklist</li> <li>Examples - See patterns in production templates</li> <li>Pipeline Configuration - Configure extraction</li> </ol>"},{"location":"fundamentals/schema-definition/best-practices/","title":"Best Practices","text":""},{"location":"fundamentals/schema-definition/best-practices/#template-checklist","title":"Template checklist","text":"<ul> <li>Define root identity with <code>graph_id_fields</code>.</li> <li>Keep entity IDs stable, short, and required.</li> <li>Use components for value objects (<code>is_entity=False</code>).</li> <li>Use explicit <code>edge(label=...)</code> where relationship materialization matters.</li> <li>Limit nesting depth (2-4 recommended).</li> <li>Use consistent naming and canonical examples.</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#deterministic-extraction-guidance","title":"Deterministic extraction guidance","text":"<ul> <li>Prefer schema fields that appear explicitly in source documents.</li> <li>Add canonicalization hints for dates, units, and codes.</li> <li>Avoid identity fields that require invention by the model.</li> <li>Use lenient validators that normalize values instead of rejecting entire output.</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#delta-specific-quality-guidance","title":"Delta-specific quality guidance","text":"<ul> <li>Keep node properties flat (primitives or list of primitives).</li> <li>Use path-consistent relationship structures.</li> <li>Design local entities with parent context available in schema.</li> <li>Avoid ambiguous fallback identities by exposing meaningful discriminator fields.</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#identity-and-descriptive-ids","title":"Identity and descriptive IDs","text":"<ul> <li>Prefer descriptive, human-readable identifiers (e.g. <code>STUDY-TEMPERATURE-DEPENDENCE</code>, <code>Phenomenological fitting</code>) over bare section labels.</li> <li>Avoid using only a section letter or Roman numeral (e.g. <code>C</code>, <code>V</code>, <code>VI</code>) as an identity field when the document uses them as headings; in the Field description, add: \u201cAvoid using only a section letter or Roman numeral; prefer a descriptive label or combine with topic.\u201d</li> <li>Give 2\u20135 concrete examples that show the desired style (e.g. <code>FIG-4</code>, <code>STUDY-BINDER-MW</code>); avoid examples that look like raw headings (e.g. <code>3.1</code>, <code>Section-3</code>) if you want the model to prefer descriptive IDs.</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#optionality-for-often-missing-fields","title":"Optionality for often-missing fields","text":"<ul> <li>Keep identity fields required when possible; the pipeline uses them for merge and linkage.</li> <li>For non-identity fields that the LLM often omits (e.g. objective, protocol details, axis labels), consider making them <code>Optional</code> with default <code>None</code> so validation passes without salvage and the graph does not store synthetic placeholders.</li> <li>Use optionality when the value is genuinely sparse in the source (e.g. \u201cif not in Methods, leave empty\u201d) rather than making every field optional.</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#deduplicating-root-level-lists-chunked-extraction","title":"Deduplicating root-level lists (chunked extraction)","text":"<p>In delta (and other chunked) extraction, root-level list fields without identity (e.g. <code>authors</code>) can receive the same item from multiple batches, so the merged list may contain duplicates.</p> <ul> <li>Add a model_validator (<code>mode=\"after\"</code>) on the root model that deduplicates the list by a stable key (e.g. <code>full_name</code> for authors: keep first occurrence per normalized name).</li> <li>This keeps the pipeline domain-agnostic; dedup logic lives in the template and applies after validation.</li> </ul>"},{"location":"fundamentals/schema-definition/best-practices/#common-failure-causes","title":"Common failure causes","text":"<ul> <li>Optional identity fields.</li> <li>Over-nested schemas with weak parent identifiers.</li> <li>Vague descriptions with no extraction hints.</li> <li>Inconsistent examples across equivalent fields.</li> <li>Edge labels omitted on relationship-bearing fields.</li> <li>Identity field descriptions that encourage raw section/figure labels (e.g. \u201csection number\u201d) without discouraging single-letter or Roman-numeral-only IDs.</li> </ul>"},{"location":"fundamentals/schema-definition/entities-vs-components/","title":"Entities vs Components","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#overview","title":"Overview","text":"<p>The most critical decision when designing a Pydantic template is classifying each model as either an Entity or a Component. This distinction fundamentally affects how your knowledge graph is constructed and how nodes are deduplicated.</p> <p>In this guide: - Understanding the Entity vs Component distinction - When to use each classification - How to configure <code>graph_id_fields</code> and <code>is_entity</code> - Real-world examples and decision trees</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#the-critical-distinction","title":"The Critical Distinction","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#quick-comparison","title":"Quick Comparison","text":"Aspect Entity Component Purpose Unique, identifiable objects Value objects, content-based deduplication Configuration <code>graph_id_fields=[...]</code> <code>is_entity=False</code> Deduplication By specified ID fields By all field values When to Use Track individually (people, documents, organizations) Shared values (addresses, amounts, measurements) Graph Behavior One node per unique ID combination One node per unique content combination"},{"location":"fundamentals/schema-definition/entities-vs-components/#visual-example","title":"Visual Example","text":"<pre><code># Entity: Person (unique by name + DOB)\nPerson(first_name=\"John\", last_name=\"Doe\", dob=\"1990-01-01\")\nPerson(first_name=\"John\", last_name=\"Doe\", dob=\"1990-01-01\")\n\u2192 Creates 1 node (same ID fields)\n\nPerson(first_name=\"John\", last_name=\"Doe\", dob=\"1991-01-01\")\n\u2192 Creates 2nd node (different DOB)\n\n# Component: Address (unique by content)\nAddress(street=\"123 Main St\", city=\"Paris\")\nAddress(street=\"123 Main St\", city=\"Paris\")\n\u2192 Creates 1 node (identical content)\n\nAddress(street=\"123 Main St\", city=\"London\")\n\u2192 Creates 2nd node (different city)\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#entities-unique-identifiable-objects","title":"Entities: Unique, Identifiable Objects","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#what-is-an-entity","title":"What is an Entity?","text":"<p>An Entity is a model that represents a unique, identifiable object that should be tracked individually in your knowledge graph. Entities are deduplicated based on specific identifying fields.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#configuration","title":"Configuration","text":"<pre><code>class Person(BaseModel):\n    \"\"\"\n    A person entity.\n    Uniquely identified by first name, last name, and date of birth.\n    \"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\", \"date_of_birth\"])\n\n    first_name: Optional[str] = Field(...)\n    last_name: Optional[str] = Field(...)\n    date_of_birth: Optional[date] = Field(...)\n    email: Optional[str] = Field(None)  # Not part of ID\n    phone: Optional[str] = Field(None)  # Not part of ID\n</code></pre> <p>Key Points: - Use <code>graph_id_fields</code> to specify which fields form the unique identifier - Only fields in <code>graph_id_fields</code> are used for deduplication - Other fields can vary without creating new nodes</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#when-to-use-entities","title":"When to Use Entities","text":"<p>Use entities for models that represent:</p> <p>\u2705 People - Individuals with unique identities <pre><code>model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\", \"date_of_birth\"])\n</code></pre></p> <p>\u2705 Organizations - Companies, institutions <pre><code>model_config = ConfigDict(graph_id_fields=[\"name\"])\n</code></pre></p> <p>\u2705 Documents - Invoices, contracts, reports <pre><code>model_config = ConfigDict(graph_id_fields=[\"document_number\"])\n</code></pre></p> <p>\u2705 Products - Items with SKUs or unique identifiers <pre><code>model_config = ConfigDict(graph_id_fields=[\"sku\"])\n</code></pre></p> <p>\u2705 Experiments - Research experiments with IDs <pre><code>model_config = ConfigDict(graph_id_fields=[\"experiment_id\"])\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#choosing-graph_id_fields","title":"Choosing graph_id_fields","text":"<p>Select fields that: 1. Together form a natural unique identifier 2. Are stable (don't change frequently) 3. Are likely to be present in extracted data</p> <p>Staged and delta extraction: When using <code>extraction_contract=\"staged\"</code> or <code>\"delta\"</code>, the catalog collects identity examples from (1) the parent field's list-of-dict examples and (2) the child model's identity fields' scalar <code>examples</code>. Provide identity examples either on the parent field (e.g. <code>studies = Field(examples=[{\"study_id\": \"3.1\", ...}])</code>) or on the entity's ID fields (e.g. <code>study_id = Field(examples=[\"3.1\", \"STUDY-BINDER-MW\"])</code>) so the LLM sees valid-ID formats. Prefer required, short, document-derived ID fields. See Schema design for staged extraction.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#examples","title":"Examples","text":"<pre><code># Single field ID\nclass Organization(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n    name: str = Field(...)\n\n# Multi-field ID\nclass Person(BaseModel):\n    model_config = ConfigDict(\n        graph_id_fields=[\"first_name\", \"last_name\", \"date_of_birth\"]\n    )\n    first_name: Optional[str] = Field(...)\n    last_name: Optional[str] = Field(...)\n    date_of_birth: Optional[date] = Field(...)\n\n# Complex ID\nclass Measurement(BaseModel):\n    model_config = ConfigDict(\n        graph_id_fields=[\"name\", \"text_value\", \"numeric_value\", \"unit\"]\n    )\n    name: str = Field(...)\n    text_value: Optional[str] = Field(None)\n    numeric_value: Optional[float] = Field(None)\n    unit: Optional[str] = Field(None)\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#entity-examples","title":"Entity Examples","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#person-entity","title":"\ud83d\udccd Person Entity","text":"<pre><code>class Person(BaseModel):\n    \"\"\"\n    Person entity.\n    Uniquely identified by name and date of birth.\n    \"\"\"\n    model_config = ConfigDict(\n        graph_id_fields=[\"first_name\", \"last_name\", \"date_of_birth\"]\n    )\n\n    first_name: Optional[str] = Field(\n        None,\n        description=\"Person's given name\",\n        examples=[\"Jean\", \"Maria\", \"John\"]\n    )\n\n    last_name: Optional[str] = Field(\n        None,\n        description=\"Person's family name\",\n        examples=[\"Dupont\", \"Garcia\", \"Smith\"]\n    )\n\n    date_of_birth: Optional[date] = Field(\n        None,\n        description=\"Date of birth in YYYY-MM-DD format\",\n        examples=[\"1985-03-12\", \"1990-06-20\"]\n    )\n\n    # These fields don't affect identity\n    email: Optional[str] = Field(None)\n    phone: Optional[str] = Field(None)\n\n    def __str__(self) -&gt; str:\n        parts = [self.first_name, self.last_name]\n        return \" \".join(p for p in parts if p) or \"Unknown\"\n</code></pre> <p>Graph Behavior: <pre><code>Person(first_name=\"John\", last_name=\"Doe\", dob=\"1990-01-01\", email=\"john@email.com\")\nPerson(first_name=\"John\", last_name=\"Doe\", dob=\"1990-01-01\", email=\"john@work.com\")\n\u2192 Same node (same ID fields, email difference ignored)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#document-entity","title":"\ud83d\udccd Document Entity","text":"<pre><code>class BillingDocument(BaseModel):\n    \"\"\"\n    BillingDocument document entity.\n    Uniquely identified by invoice number.\n    \"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_no\"])\n\n    document_no: str = Field(\n        ...,\n        description=\"Unique invoice identifier\",\n        examples=[\"INV-2024-001\", \"12345\"]\n    )\n\n    date: Optional[str] = Field(None)\n    total: Optional[float] = Field(None)\n\n    def __str__(self) -&gt; str:\n        return f\"Invoice {self.document_no}\"\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#components-value-objects","title":"Components: Value Objects","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#what-is-a-component","title":"What is a Component?","text":"<p>A Component is a model that represents a value object - it's deduplicated by its entire content. If two components have identical field values, they share the same graph node.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#configuration_1","title":"Configuration","text":"<pre><code>class Address(BaseModel):\n    \"\"\"\n    Physical address component.\n    Deduplicated by content - identical addresses share the same node.\n    \"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street_address: Optional[str] = Field(...)\n    city: Optional[str] = Field(...)\n    postal_code: Optional[str] = Field(...)\n    country: Optional[str] = Field(...)\n</code></pre> <p>Key Points: - Use <code>is_entity=False</code> to mark as component - All fields are used for deduplication - Identical content = same node</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#when-to-use-components","title":"When to Use Components","text":"<p>Use components for models that represent:</p> <p>\u2705 Addresses - Physical locations <pre><code>model_config = ConfigDict(is_entity=False)\n</code></pre></p> <p>\u2705 Monetary Amounts - Values with currency <pre><code>model_config = ConfigDict(is_entity=False)\n</code></pre></p> <p>\u2705 Measurements - Quantities with units <pre><code>model_config = ConfigDict(is_entity=False)\n</code></pre></p> <p>\u2705 Dates/Times - Temporal values <pre><code>model_config = ConfigDict(is_entity=False)\n</code></pre></p> <p>\u2705 Coordinates - Geographic points <pre><code>model_config = ConfigDict(is_entity=False)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#component-examples","title":"Component Examples","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#address-component","title":"\ud83d\udccd Address Component","text":"<pre><code>class Address(BaseModel):\n    \"\"\"\n    Physical address component.\n    Deduplicated by content - identical addresses share the same node.\n    \"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street_address: Optional[str] = Field(\n        None,\n        description=\"Street name and number\",\n        examples=[\"123 Main Street\", \"45 Avenue des Champs-\u00c9lys\u00e9es\"]\n    )\n\n    city: Optional[str] = Field(\n        None,\n        description=\"City name\",\n        examples=[\"Paris\", \"London\", \"New York\"]\n    )\n\n    postal_code: Optional[str] = Field(\n        None,\n        description=\"Postal or ZIP code\",\n        examples=[\"75001\", \"SW1A 1AA\", \"10001\"]\n    )\n\n    country: Optional[str] = Field(\n        None,\n        description=\"Country name or code\",\n        examples=[\"France\", \"FR\", \"United Kingdom\"]\n    )\n\n    def __str__(self) -&gt; str:\n        parts = [self.street_address, self.city, self.postal_code, self.country]\n        return \", \".join(p for p in parts if p)\n</code></pre> <p>Graph Behavior: <pre><code>Address(street=\"123 Main St\", city=\"Paris\", postal_code=\"75001\")\nAddress(street=\"123 Main St\", city=\"Paris\", postal_code=\"75001\")\n\u2192 Same node (identical content)\n\nAddress(street=\"123 Main St\", city=\"Paris\", postal_code=\"75002\")\n\u2192 Different node (postal code differs)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#monetary-amount-component","title":"\ud83d\udccd Monetary Amount Component","text":"<pre><code>class MonetaryAmount(BaseModel):\n    \"\"\"\n    Monetary value with currency.\n    Deduplicated by content - same value and currency share a node.\n    \"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    value: float = Field(\n        ...,\n        description=\"Numeric amount\",\n        examples=[500.00, 1250.50, 89.99]\n    )\n\n    currency: Optional[str] = Field(\n        None,\n        description=\"ISO 4217 currency code\",\n        examples=[\"EUR\", \"USD\", \"GBP\"]\n    )\n\n    @field_validator(\"value\")\n    @classmethod\n    def validate_positive(cls, v: Any) -&gt; Any:\n        if v &lt; 0:\n            raise ValueError(\"Amount must be non-negative\")\n        return v\n\n    def __str__(self) -&gt; str:\n        return f\"{self.value} {self.currency or ''}\".strip()\n</code></pre> <p>Graph Behavior: <pre><code>MonetaryAmount(value=100.00, currency=\"EUR\")\nMonetaryAmount(value=100.00, currency=\"EUR\")\n\u2192 Same node (identical value and currency)\n\nMonetaryAmount(value=100.00, currency=\"USD\")\n\u2192 Different node (different currency)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#decision-tree","title":"Decision Tree","text":"<p>Use this decision tree to classify your models:</p> <pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TD\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"New Model\" }\n\n    B{\"Should this be&lt;br/&gt;tracked individually?\"}\n    C{\"Does it have a&lt;br/&gt;natural unique ID?\"}\n    F{\"Can you create&lt;br/&gt;a composite ID?\"}\n    G{\"Is it a value&lt;br/&gt;that's shared?\"}\n\n    %% Outcomes\n    D@{ shape: tag-proc, label: \"Component&lt;br/&gt;is_entity=False\" }\n    E@{ shape: procs, label: \"Entity&lt;br/&gt;graph_id_fields\" }\n    H@{ shape: lin-proc, label: \"Consider redesigning&lt;br/&gt;or use content-based ID\" }\n\n    %% 3. Define Connections\n    A --&gt; B\n    B -- Yes --&gt; C\n    B -- No --&gt; D\n\n    C -- Yes --&gt; E\n    C -- No --&gt; F\n\n    F -- Yes --&gt; E\n    F -- No --&gt; G\n\n    G -- Yes --&gt; D\n    G -- No --&gt; H\n\n    %% 4. Apply Classes\n    class A input\n    class B,C,F,G decision\n    class E output\n    class D data\n    class H config</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#questions-to-ask","title":"Questions to Ask","text":"<ol> <li>\"Should this be tracked individually?\"</li> <li>Yes \u2192 Likely an Entity</li> <li> <p>No \u2192 Likely a Component</p> </li> <li> <p>\"If I see this twice with identical values, should it be one thing or two?\"</p> </li> <li>One thing \u2192 Component</li> <li> <p>Two things \u2192 Entity</p> </li> <li> <p>\"Does this represent a unique object or a shared value?\"</p> </li> <li>Unique object \u2192 Entity</li> <li> <p>Shared value \u2192 Component</p> </li> <li> <p>\"Would I want to query for all instances of this specific thing?\"</p> </li> <li>Yes \u2192 Entity</li> <li>No \u2192 Component</li> </ol>"},{"location":"fundamentals/schema-definition/entities-vs-components/#real-world-examples","title":"Real-World Examples","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#invoice-processing","title":"\ud83d\udccd Invoice Processing","text":"<pre><code># ENTITY: BillingDocument (unique document)\nclass BillingDocument(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"document_no\"])\n    document_no: str = Field(...)\n    # Each invoice is unique\n\n# ENTITY: Organization (unique company)\nclass Organization(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n    name: str = Field(...)\n    # Each organization is unique\n\n# COMPONENT: Address (shared value)\nclass Address(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    street: str = Field(...)\n    city: str = Field(...)\n    # Multiple organizations can share the same address\n\n# COMPONENT: MonetaryAmount (shared value)\nclass MonetaryAmount(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    value: float = Field(...)\n    currency: str = Field(...)\n    # Multiple invoices can have the same amount\n</code></pre> <p>Graph Structure: <pre><code>BillingDocument-001 --ISSUED_BY--&gt; Acme Corp --LOCATED_AT--&gt; Address(123 Main St, Paris)\nBillingDocument-002 --ISSUED_BY--&gt; Tech Ltd --LOCATED_AT--&gt; Address(123 Main St, Paris)\n                                                      \u2191 Same address node shared\n</code></pre></p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#rheology-research","title":"\ud83d\udccd Rheology Research","text":"<pre><code># ENTITY: Research (unique paper)\nclass Research(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"title\"])\n    title: str = Field(...)\n\n# ENTITY: Experiment (unique experiment)\nclass Experiment(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"experiment_id\"])\n    experiment_id: str = Field(...)\n\n# ENTITY: Material (unique material type)\nclass Material(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"material_type\"])\n    material_type: str = Field(...)\n\n# COMPONENT: Measurement (shared value)\nclass Measurement(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    name: str = Field(...)\n    value: float = Field(...)\n    unit: str = Field(...)\n    # Multiple experiments can have the same measurement\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#id-card","title":"\ud83d\udccd ID Card","text":"<pre><code># ENTITY: IDCard (unique document)\nclass IDCard(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"document_number\"])\n    document_number: str = Field(...)\n\n# ENTITY: Person (unique individual)\nclass Person(BaseModel):\n    model_config = ConfigDict(\n        graph_id_fields=[\"given_names\", \"last_name\", \"date_of_birth\"]\n    )\n    given_names: List[str] = Field(...)\n    last_name: str = Field(...)\n    date_of_birth: date = Field(...)\n\n# COMPONENT: Address (shared value)\nclass Address(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    street_address: str = Field(...)\n    city: str = Field(...)\n    # Multiple people can live at the same address\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#common-patterns","title":"Common Patterns","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#pattern-1-shared-addresses","title":"Pattern 1: Shared Addresses","text":"<p>Scenario: Multiple people or organizations at the same address.</p> <p>Solution: Make Address a component.</p> <pre><code>class Address(BaseModel):\n    \"\"\"Component - shared by multiple entities.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    # ...\n\nclass Person(BaseModel):\n    \"\"\"Entity - unique individual.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\"])\n    # ...\n    addresses: List[Address] = edge(label=\"LIVES_AT\", default_factory=list)\n\nclass Organization(BaseModel):\n    \"\"\"Entity - unique company.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n    # ...\n    addresses: List[Address] = edge(label=\"LOCATED_AT\", default_factory=list)\n</code></pre> <p>Result: Same address node is shared across multiple people/organizations.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#staged-extraction-considerations","title":"Staged extraction considerations","text":"<p>When using staged extraction (<code>extraction_contract=\"staged\"</code>):</p> <ul> <li>Entities that should participate in the ID pass must have <code>graph_id_fields</code>. Components (<code>is_entity=False</code>) do not appear as separate identity paths when <code>staged_id_identity_only=True</code>.</li> <li>Components are included in the staged catalog only when the relationship uses <code>edge()</code> with an <code>edge_label</code>. Components without an edge label are not separate catalog nodes.</li> <li>Parent linkage in the fill/merge phase uses <code>(path, id_tuple)</code> and parent <code>(parent_path, parent_id_tuple)</code>. Ensure parent entities have stable, extractable <code>graph_id_fields</code> so references resolve and the quality gate (e.g. <code>staged_quality_max_parent_lookup_miss</code>) can pass.</li> </ul> <p>For full guidance (identity choices, depth, troubleshooting), see Schema design for staged extraction.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#pattern-2-measurements-in-research","title":"Pattern 2: Measurements in Research","text":"<p>Scenario: Multiple experiments report the same measurement value.</p> <p>Solution: Make Measurement a component.</p> <pre><code>class Measurement(BaseModel):\n    \"\"\"Component - shared measurement value.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    name: str = Field(...)\n    value: float = Field(...)\n    unit: str = Field(...)\n\nclass Experiment(BaseModel):\n    \"\"\"Entity - unique experiment.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"experiment_id\"])\n    # ...\n    measurements: List[Measurement] = Field(default_factory=list)\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#pattern-3-line-items","title":"Pattern 3: Line Items","text":"<p>Scenario: Invoice line items - should each be unique or shared?</p> <p>Decision: Usually neither - line items are typically embedded data, not separate nodes.</p> <pre><code>class LineItem(BaseModel):\n    \"\"\"Line item - embedded in invoice, not a separate node.\"\"\"\n    # No model_config needed - this won't become a node\n    description: str = Field(...)\n    quantity: float = Field(...)\n    unit_price: float = Field(...)\n\nclass BillingDocument(BaseModel):\n    \"\"\"Entity - unique invoice.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_no\"])\n    # ...\n    # Use regular Field, not edge() - these are embedded\n    items: List[LineItem] = Field(default_factory=list)\n</code></pre> <p>Line items as nodes</p> <p>If you want line items as nodes, use edge() and decide if they're entities or components.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#common-mistakes","title":"Common Mistakes","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#making-everything-an-entity","title":"\u274c Making Everything an Entity","text":"<pre><code># WRONG - Address as entity\nclass Address(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"street\", \"city\"])\n    # This creates separate nodes for identical addresses\n</code></pre> <p>Problem: Identical addresses create separate nodes, losing the benefit of shared locations.</p> <p>Fix: Make Address a component.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#making-everything-a-component","title":"\u274c Making Everything a Component","text":"<pre><code># WRONG - Person as component\nclass Person(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    # This merges people with identical names\n</code></pre> <p>Problem: Two people with the same name become one node.</p> <p>Fix: Make Person an entity with appropriate <code>graph_id_fields</code>.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#wrong-id-fields","title":"\u274c Wrong ID Fields","text":"<pre><code># WRONG - Using non-stable fields\nclass Person(BaseModel):\n    model_config = ConfigDict(graph_id_fields=[\"email\"])\n    # Email can change, creating duplicate nodes\n</code></pre> <p>Problem: When email changes, a new node is created for the same person.</p> <p>Fix: Use stable fields like name + date of birth.</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#testing-your-classification","title":"Testing Your Classification","text":""},{"location":"fundamentals/schema-definition/entities-vs-components/#test-1-deduplication-behavior","title":"Test 1: Deduplication Behavior","text":"<pre><code># Test entity deduplication\nperson1 = Person(first_name=\"John\", last_name=\"Doe\", email=\"john@email.com\")\nperson2 = Person(first_name=\"John\", last_name=\"Doe\", email=\"john@work.com\")\n# Should create 1 node (same ID fields)\n\n# Test component deduplication\naddr1 = Address(street=\"123 Main St\", city=\"Paris\")\naddr2 = Address(street=\"123 Main St\", city=\"Paris\")\n# Should create 1 node (identical content)\n\naddr3 = Address(street=\"123 Main St\", city=\"London\")\n# Should create 2nd node (different city)\n</code></pre>"},{"location":"fundamentals/schema-definition/entities-vs-components/#test-2-graph-structure","title":"Test 2: Graph Structure","text":"<p>Run extraction and check the graph:</p> <pre><code>uv run docling-graph convert document.pdf \\\n    --template \"my_template.MyTemplate\" \\\n    --export-format csv \\\n    --output-dir test_output\n</code></pre> <p>Check <code>test_output/nodes.csv</code>: - Entities should have one row per unique ID combination - Components should have one row per unique content combination</p>"},{"location":"fundamentals/schema-definition/entities-vs-components/#next-steps","title":"Next Steps","text":"<p>Now that you understand entities vs components:</p> <ol> <li>Field Definitions \u2192 - Learn to write effective field descriptions</li> <li>Relationships - Connect entities and components with edges</li> <li>Advanced Patterns - Complex entity/component patterns</li> </ol>"},{"location":"fundamentals/schema-definition/field-definitions/","title":"Field Definitions","text":"<p>Field definitions are the main quality lever for extraction consistency.</p>"},{"location":"fundamentals/schema-definition/field-definitions/#required-patterns","title":"Required patterns","text":"<ul> <li>Use <code>Field(..., description=..., examples=[...])</code> for core fields.</li> <li>Keep examples format-aligned with description rules.</li> <li>Normalize value formats in descriptions (dates, units, codes, casing).</li> <li>Use <code>default_factory=list</code> for list fields.</li> <li>Avoid nested object payloads for Delta-critical scalar properties.</li> </ul>"},{"location":"fundamentals/schema-definition/field-definitions/#identity-fields","title":"Identity fields","text":"<ul> <li>Identity fields in <code>graph_id_fields</code> should be required and concise.</li> <li>Avoid long free text as identity (<code>description</code>, <code>resume</code>, paragraph fields).</li> <li>Include 2-5 examples for each identity field.</li> <li>For local identities (for example line indexes), add context fields in schema to disambiguate.</li> </ul>"},{"location":"fundamentals/schema-definition/field-definitions/#optionality-guidance","title":"Optionality guidance","text":"<ul> <li>Required for identity and structural anchor fields.</li> <li>Optional for sparse enrichments that may not exist in source documents.</li> <li>Avoid optional identity fields in staged and delta extraction (both use catalog identity for merge and linkage).</li> </ul>"},{"location":"fundamentals/schema-definition/field-definitions/#description-style","title":"Description style","text":"<ul> <li>Mention where the value appears in the document.</li> <li>Mention normalization/canonicalization rules.</li> <li>Mention ambiguity resolution when relevant.</li> </ul> <p>Example:</p> <pre><code>currency_code: str = Field(\n    ...,\n    description=\"ISO 4217 currency code from totals section. Normalize to uppercase 3-letter code.\",\n    examples=[\"EUR\", \"USD\", \"GBP\"],\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/field-definitions/#where-to-look-hints","title":"Where-to-look hints","text":"<p>For fields that are often missed (e.g. protocol parameters, axis labels), add short \u201cwhere to look\u201d hints so the LLM searches the right part of the document:</p> <ul> <li>Methods section: e.g. \u201cLook in Methods for \u2018pre-shear\u2019, \u2018equilibration\u2019, \u2018gap\u2019; extract values even if they appear mid-paragraph.\u201d</li> <li>Figure captions / axis labels: e.g. \u201cLook in figure captions and axis labels for the quantity name.\u201d</li> </ul> <p>These hints improve extraction of explicit numbers and reduce empty shells when the schema has many optional fields.</p>"},{"location":"fundamentals/schema-definition/field-definitions/#enum-synonyms-and-mapping","title":"Enum synonyms and mapping","text":"<p>When an enum is used (e.g. geometry type, test mode), document synonyms and discourage overuse of \u201cOther\u201d:</p> <ul> <li>In the Field description, list common document phrases that map to each value, e.g. \u201cMap \u2018parallel plate\u2019, \u2018parallel disk\u2019, or \u2018plate-plate\u2019 to \u2018Plate-Plate\u2019. Do not use Other when the text matches a known type.\u201d</li> <li>Optionally add a <code>mode=\"before\"</code> field validator that maps frequent phrases (e.g. string containing \u201cparallel\u201d and \u201cplate\u201d) to the correct enum member before calling a generic enum normalizer.</li> </ul> <p>This reduces \u201cOther\u201d when the document clearly states a known type in different wording.</p> <p>See also: Best practices (identity and descriptive IDs, optionality, deduplication), Validation (semantic sanity validators, enum mapping, list deduplication).</p>"},{"location":"fundamentals/schema-definition/relationships/","title":"Relationships: Edge Definitions","text":"<p>Note: The examples in this document use simplified field names and structures for teaching purposes.  The actual <code>BillingDocument</code> schema at <code>docs/examples/templates/billing_document.py</code> is more comprehensive  with 30+ classes, EN 16931/Peppol BIS compliance, and uses <code>CONTAINS_LINE</code> for line items.</p>"},{"location":"fundamentals/schema-definition/relationships/#overview","title":"Overview","text":"<p>Relationships (edges) connect nodes in your knowledge graph. The <code>edge()</code> helper function marks fields as graph relationships and defines their labels. Well-designed edges create meaningful, queryable graph structures.</p> <p>In this guide: - Using the <code>edge()</code> function - Edge label conventions - Single vs list relationships - Common edge patterns - Relationship best practices</p>"},{"location":"fundamentals/schema-definition/relationships/#using-the-edge-function","title":"Using the edge() Function","text":""},{"location":"fundamentals/schema-definition/relationships/#basic-syntax","title":"Basic Syntax","text":"<pre><code>field_name: TargetType = edge(\n    label=\"EDGE_LABEL\",\n    description=\"Description of the relationship\",\n    # Additional Field parameters...\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#required-vs-optional-edges","title":"Required vs Optional Edges","text":"<pre><code># Required single relationship\nissued_by: Organization = edge(\n    label=\"ISSUED_BY\",\n    description=\"The organization that issued this document\"\n)\n\n# Optional single relationship\nverified_by: Optional[Person] = edge(\n    label=\"VERIFIED_BY\",\n    description=\"Person who verified this document, if applicable\"\n)\n\n# Required list relationship (one-to-many)\ncontains_items: List[LineItem] = edge(\n    label=\"CONTAINS_LINE\",\n    default_factory=list,  # REQUIRED for lists\n    description=\"Line items contained in this document\"\n)\n\n# Optional list relationship\naddresses: List[Address] = edge(\n    label=\"LOCATED_AT\",\n    default_factory=list,\n    description=\"Physical addresses for this entity\"\n)\n</code></pre> <p>Critical Rule: For list edges, you must provide <code>default_factory=list</code>.</p>"},{"location":"fundamentals/schema-definition/relationships/#edge-label-conventions","title":"Edge Label Conventions","text":""},{"location":"fundamentals/schema-definition/relationships/#naming-standards","title":"Naming Standards","text":"<p>\u2705 DO: - Use ALL_CAPS with underscores - Use verb phrases that describe the relationship - Choose descriptive, domain-appropriate verbs - Be consistent across your template</p> <p>\u274c DON'T: - Use camelCase, lowercase, or mixed case - Use vague labels like \"LINK\" or \"RELATED\" - Mix naming styles</p>"},{"location":"fundamentals/schema-definition/relationships/#good-vs-bad-labels","title":"Good vs Bad Labels","text":"<pre><code># \u2705 Good - Clear, descriptive, consistent\nissued_by: Organization = edge(label=\"ISSUED_BY\")\nsent_to: Client = edge(label=\"SENT_TO\")\ncontains_items: List[Item] = edge(label=\"CONTAINS_LINE\")\nlocated_at: Address = edge(label=\"LOCATED_AT\")\n\n# \u274c Bad - Inconsistent, vague\nissued_by: Organization = edge(label=\"issuedBy\")  # Wrong case\nsent_to: Client = edge(label=\"sent-to\")  # Wrong separator\ncontains_items: List[Item] = edge(label=\"has\")  # Too vague\nlocated_at: Address = edge(label=\"LINK\")  # Not descriptive\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#common-edge-labels-by-category","title":"Common Edge Labels by Category","text":""},{"location":"fundamentals/schema-definition/relationships/#authorship-ownership","title":"Authorship &amp; Ownership","text":"<pre><code># Document creation\nissued_by: Organization = edge(label=\"ISSUED_BY\")\ncreated_by: Person = edge(label=\"CREATED_BY\")\nauthored_by: Person = edge(label=\"AUTHORED_BY\")\nowned_by: Organization = edge(label=\"OWNED_BY\")\npublished_by: Organization = edge(label=\"PUBLISHED_BY\")\n\n# Verification &amp; approval\nverified_by: Person = edge(label=\"VERIFIED_BY\")\napproved_by: Person = edge(label=\"APPROVED_BY\")\nsigned_by: Person = edge(label=\"SIGNED_BY\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#recipients-targets","title":"Recipients &amp; Targets","text":"<pre><code># Document recipients\nsent_to: Client = edge(label=\"SENT_TO\")\naddressed_to: Person = edge(label=\"ADDRESSED_TO\")\ndelivered_to: Organization = edge(label=\"DELIVERED_TO\")\nbilled_to: Client = edge(label=\"BILLED_TO\")\n\n# Beneficiaries\ninsured_by: Person = edge(label=\"INSURED_BY\")\ncovered_by: InsurancePlan = edge(label=\"COVERED_BY\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#location-physical-presence","title":"Location &amp; Physical Presence","text":"<pre><code># Physical locations\nlocated_at: Address = edge(label=\"LOCATED_AT\")\nlives_at: Address = edge(label=\"LIVES_AT\")\nbased_at: Address = edge(label=\"BASED_AT\")\nmanufactured_at: Address = edge(label=\"MANUFACTURED_AT\")\n\n# Geographic relationships\noperates_in: Region = edge(label=\"OPERATES_IN\")\nships_to: Country = edge(label=\"SHIPS_TO\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#composition-containment","title":"Composition &amp; Containment","text":"<pre><code># Document structure\ncontains_item: List[LineItem] = edge(label=\"CONTAINS_LINE\")\nhas_component: List[Component] = edge(label=\"HAS_COMPONENT\")\nincludes_part: List[Part] = edge(label=\"INCLUDES_PART\")\ncomposed_of: List[Material] = edge(label=\"COMPOSED_OF\")\n\n# Hierarchical relationships\nhas_section: List[Section] = edge(label=\"HAS_SECTION\")\nhas_chapter: List[Chapter] = edge(label=\"HAS_CHAPTER\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#membership-association","title":"Membership &amp; Association","text":"<pre><code># Organizational relationships\nbelongs_to: Organization = edge(label=\"BELONGS_TO\")\npart_of: Group = edge(label=\"PART_OF\")\nmember_of: Organization = edge(label=\"MEMBER_OF\")\nemployed_by: Organization = edge(label=\"EMPLOYED_BY\")\n\n# Associations\naffiliated_with: Organization = edge(label=\"AFFILIATED_WITH\")\npartnered_with: Organization = edge(label=\"PARTNERED_WITH\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#services-offerings","title":"Services &amp; Offerings","text":"<pre><code># Insurance &amp; coverage\nhas_guarantee: List[Guarantee] = edge(label=\"HAS_GUARANTEE\")\noffers_plan: List[Plan] = edge(label=\"OFFERS_PLAN\")\nprovides_coverage: List[Coverage] = edge(label=\"PROVIDES_COVERAGE\")\n\n# Products &amp; services\noffers_product: List[Product] = edge(label=\"OFFERS_PRODUCT\")\nprovides_service: List[Service] = edge(label=\"PROVIDES_SERVICE\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#research-scientific","title":"Research &amp; Scientific","text":"<pre><code># Experiments &amp; studies\nhas_experiment: List[Experiment] = edge(label=\"HAS_EXPERIMENT\")\nuses_material: Material = edge(label=\"USES_MATERIAL\")\nhas_measurement: List[Measurement] = edge(label=\"HAS_MEASUREMENT\")\nhas_result: List[Result] = edge(label=\"HAS_RESULT\")\n\n# Processes &amp; methods\nhas_process_step: List[Step] = edge(label=\"HAS_PROCESS_STEP\")\nuses_method: Method = edge(label=\"USES_METHOD\")\nhas_evaluation: Evaluation = edge(label=\"HAS_EVALUATION\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#single-vs-list-relationships","title":"Single vs List Relationships","text":""},{"location":"fundamentals/schema-definition/relationships/#single-relationships-one-to-one","title":"Single Relationships (One-to-One)","text":"<p>Use when an entity has exactly one or at most one related entity:</p> <pre><code>class BillingDocument(BaseModel):\n    \"\"\"BillingDocument document.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_no\"])\n\n    document_no: str = Field(...)\n\n    # One invoice is issued by one organization\n    issued_by: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"The organization that issued this invoice\"\n    )\n\n    # One invoice is sent to one client\n    sent_to: Client = edge(\n        label=\"SENT_TO\",\n        description=\"The client receiving this invoice\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>BillingDocument-001 --ISSUED_BY--&gt; Acme Corp\nBillingDocument-001 --SENT_TO--&gt; Client A\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#list-relationships-one-to-many","title":"List Relationships (One-to-Many)","text":"<p>Use when an entity can have multiple related entities:</p> <pre><code>class BillingDocument(BaseModel):\n    \"\"\"BillingDocument document.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_no\"])\n\n    document_no: str = Field(...)\n\n    # One invoice contains many line items\n    contains_items: List[LineItem] = edge(\n        label=\"CONTAINS_LINE\",\n        default_factory=list,  # Required!\n        description=\"Line items in this invoice\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>BillingDocument-001 --CONTAINS_LINE--&gt; LineItem-1\nBillingDocument-001 --CONTAINS_LINE--&gt; LineItem-2\nBillingDocument-001 --CONTAINS_LINE--&gt; LineItem-3\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#optional-single-relationships","title":"Optional Single Relationships","text":"<p>Use <code>Optional[Type]</code> for relationships that may not exist:</p> <pre><code>class Document(BaseModel):\n    \"\"\"Document that may or may not have a verifier.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_id\"])\n\n    document_id: str = Field(...)\n\n    # Optional: document may not be verified\n    verified_by: Optional[Person] = edge(\n        label=\"VERIFIED_BY\",\n        description=\"Person who verified this document, if verified\"\n    )\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#edge-patterns-and-examples","title":"Edge Patterns and Examples","text":""},{"location":"fundamentals/schema-definition/relationships/#pattern-1-bidirectional-relationships","title":"Pattern 1: Bidirectional Relationships","text":"<p>Create meaningful relationships in both directions:</p> <pre><code>class Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n\n    # Organization has employees\n    employees: List[Person] = edge(\n        label=\"EMPLOYS\",\n        default_factory=list,\n        description=\"People employed by this organization\"\n    )\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\"])\n\n    first_name: str = Field(...)\n    last_name: str = Field(...)\n\n    # Person works for organization\n    employer: Optional[Organization] = edge(\n        label=\"EMPLOYED_BY\",\n        description=\"Organization employing this person\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>Organization --EMPLOYS--&gt; Person\nPerson --EMPLOYED_BY--&gt; Organization\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#pattern-2-shared-components","title":"Pattern 2: Shared Components","text":"<p>Multiple entities can reference the same component:</p> <pre><code>class Address(BaseModel):\n    \"\"\"Address component (shared).\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street: str = Field(...)\n    city: str = Field(...)\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\"])\n\n    first_name: str = Field(...)\n    last_name: str = Field(...)\n\n    addresses: List[Address] = edge(\n        label=\"LIVES_AT\",\n        default_factory=list,\n        description=\"Residential addresses\"\n    )\n\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n\n    addresses: List[Address] = edge(\n        label=\"LOCATED_AT\",\n        default_factory=list,\n        description=\"Business addresses\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>Person-1 --LIVES_AT--&gt; Address(123 Main St, Paris)\nPerson-2 --LIVES_AT--&gt; Address(123 Main St, Paris)  # Same address node\nOrganization-1 --LOCATED_AT--&gt; Address(123 Main St, Paris)  # Same address node\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#pattern-3-nested-relationships","title":"Pattern 3: Nested Relationships","text":"<p>Edges can point to entities that have their own edges:</p> <pre><code>class Material(BaseModel):\n    \"\"\"Material entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n\n    properties: List[MaterialProperty] = edge(\n        label=\"HAS_PROPERTY\",\n        default_factory=list,\n        description=\"Material properties\"\n    )\n\nclass Component(BaseModel):\n    \"\"\"Component entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"component_id\"])\n\n    component_id: str = Field(...)\n\n    material: Material = edge(\n        label=\"USES_MATERIAL\",\n        description=\"Material used in this component\"\n    )\n\nclass Assembly(BaseModel):\n    \"\"\"Assembly entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"assembly_id\"])\n\n    assembly_id: str = Field(...)\n\n    components: List[Component] = edge(\n        label=\"HAS_COMPONENT\",\n        default_factory=list,\n        description=\"Components in this assembly\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>Assembly --HAS_COMPONENT--&gt; Component --USES_MATERIAL--&gt; Material --HAS_PROPERTY--&gt; Property\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#pattern-4-multiple-edge-types-to-same-entity","title":"Pattern 4: Multiple Edge Types to Same Entity","text":"<p>An entity can have multiple types of relationships to the same target type:</p> <pre><code>class Document(BaseModel):\n    \"\"\"Document entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_id\"])\n\n    document_id: str = Field(...)\n\n    # Different relationship types to Person\n    created_by: Person = edge(\n        label=\"CREATED_BY\",\n        description=\"Person who created this document\"\n    )\n\n    reviewed_by: Optional[Person] = edge(\n        label=\"REVIEWED_BY\",\n        description=\"Person who reviewed this document\"\n    )\n\n    approved_by: Optional[Person] = edge(\n        label=\"APPROVED_BY\",\n        description=\"Person who approved this document\"\n    )\n</code></pre> <p>Graph Structure: <pre><code>Document --CREATED_BY--&gt; Person-A\nDocument --REVIEWED_BY--&gt; Person-B\nDocument --APPROVED_BY--&gt; Person-C\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#complete-example-billingdocument-template","title":"Complete Example: BillingDocument Template","text":"<p>Here's a complete example showing various edge patterns:</p> <pre><code>\"\"\"BillingDocument extraction template with comprehensive edge definitions.\"\"\"\n\nfrom typing import Any, List, Optional\nfrom pydantic import BaseModel, ConfigDict, Field\n\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- Components ---\n\nclass Address(BaseModel):\n    \"\"\"Physical address component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street: str = Field(...)\n    city: str = Field(...)\n    postal_code: str = Field(...)\n\nclass MonetaryAmount(BaseModel):\n    \"\"\"Monetary value component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    value: float = Field(...)\n    currency: str = Field(...)\n\n# --- Entities ---\n\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n    tax_id: Optional[str] = Field(None)\n\n    # Edge to Address component\n    addresses: List[Address] = edge(\n        label=\"LOCATED_AT\",\n        default_factory=list,\n        description=\"Business addresses\"\n    )\n\nclass Client(BaseModel):\n    \"\"\"Client entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(...)\n    email: Optional[str] = Field(None)\n\n    # Edge to Address component\n    addresses: List[Address] = edge(\n        label=\"LIVES_AT\",\n        default_factory=list,\n        description=\"Client addresses\"\n    )\n\nclass LineItem(BaseModel):\n    \"\"\"Line item entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"description\", \"unit_price\"])\n\n    description: str = Field(...)\n    quantity: float = Field(...)\n    unit_price: float = Field(...)\n\n    # Edge to MonetaryAmount component\n    total: MonetaryAmount = edge(\n        label=\"HAS_TOTAL\",\n        description=\"Total amount for this line item\"\n    )\n\n# --- Root Document ---\n\nclass BillingDocument(BaseModel):\n    \"\"\"BillingDocument document (root).\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_no\"])\n\n    document_no: str = Field(...)\n    date: str = Field(...)\n\n    # Single edges to entities\n    issued_by: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Organization that issued this invoice\"\n    )\n\n    sent_to: Client = edge(\n        label=\"SENT_TO\",\n        description=\"Client receiving this invoice\"\n    )\n\n    # List edge to entities\n    contains_items: List[LineItem] = edge(\n        label=\"CONTAINS_LINE\",\n        default_factory=list,\n        description=\"Line items in this invoice\"\n    )\n\n    # Edge to component\n    total_amount: MonetaryAmount = edge(\n        label=\"HAS_TOTAL\",\n        description=\"Total invoice amount\"\n    )\n</code></pre> <p>Resulting Graph: <pre><code>BillingDocument-001\n  \u251c\u2500 ISSUED_BY \u2192 Organization(Acme Corp)\n  \u2502               \u2514\u2500 LOCATED_AT \u2192 Address(123 Main St, Paris)\n  \u251c\u2500 SENT_TO \u2192 Client(John Doe)\n  \u2502             \u2514\u2500 LIVES_AT \u2192 Address(456 Oak Ave, London)\n  \u251c\u2500 CONTAINS_LINE \u2192 LineItem-1\n  \u2502                   \u2514\u2500 HAS_TOTAL \u2192 MonetaryAmount(100, EUR)\n  \u251c\u2500 CONTAINS_LINE \u2192 LineItem-2\n  \u2502                   \u2514\u2500 HAS_TOTAL \u2192 MonetaryAmount(200, EUR)\n  \u2514\u2500 HAS_TOTAL \u2192 MonetaryAmount(300, EUR)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/relationships/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/schema-definition/relationships/#use-descriptive-labels","title":"\ud83d\udc4d Use Descriptive Labels","text":"<pre><code># \u2705 Good - Clear and specific\nissued_by: Organization = edge(label=\"ISSUED_BY\")\ncontains_items: List[Item] = edge(label=\"CONTAINS_LINE\")\n\n# \u274c Bad - Vague\nissued_by: Organization = edge(label=\"HAS\")\ncontains_items: List[Item] = edge(label=\"RELATED_TO\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#be-consistent","title":"\ud83d\udc4d Be Consistent","text":"<pre><code># \u2705 Good - Consistent pattern\nlives_at: Address = edge(label=\"LIVES_AT\")\nworks_at: Address = edge(label=\"WORKS_AT\")\nlocated_at: Address = edge(label=\"LOCATED_AT\")\n\n# \u274c Bad - Inconsistent\nlives_at: Address = edge(label=\"LIVES_AT\")\nworks_at: Address = edge(label=\"WORKS_IN\")\nlocated_at: Address = edge(label=\"HAS_LOCATION\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#always-use-default_factory-for-lists","title":"\ud83d\udc4d Always Use default_factory for Lists","text":"<pre><code># \u2705 Good\nitems: List[Item] = edge(\n    label=\"CONTAINS_LINE\",\n    default_factory=list\n)\n\n# \u274c Bad - Missing default_factory\nitems: List[Item] = edge(label=\"CONTAINS_LINE\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#provide-clear-descriptions","title":"\ud83d\udc4d Provide Clear Descriptions","text":"<pre><code># \u2705 Good - Explains the relationship\nissued_by: Organization = edge(\n    label=\"ISSUED_BY\",\n    description=\"The organization that created and issued this document\"\n)\n\n# \u274c Bad - No description\nissued_by: Organization = edge(label=\"ISSUED_BY\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#common-mistakes","title":"Common Mistakes","text":""},{"location":"fundamentals/schema-definition/relationships/#missing-default_factory","title":"\u274c Missing default_factory","text":"<pre><code># Wrong\nitems: List[Item] = edge(label=\"CONTAINS_LINE\")\n\n# Correct\nitems: List[Item] = edge(\n    label=\"CONTAINS_LINE\",\n    default_factory=list\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#inconsistent-label-format","title":"\u274c Inconsistent Label Format","text":"<pre><code># Wrong - Mixed formats\nissued_by: Org = edge(label=\"issuedBy\")\nsent_to: Client = edge(label=\"SENT_TO\")\nhas_items: List[Item] = edge(label=\"contains-item\")\n\n# Correct - Consistent ALL_CAPS_WITH_UNDERSCORES\nissued_by: Org = edge(label=\"ISSUED_BY\")\nsent_to: Client = edge(label=\"SENT_TO\")\nhas_items: List[Item] = edge(label=\"CONTAINS_LINE\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#vague-labels","title":"\u274c Vague Labels","text":"<pre><code># Wrong - Too vague\norg: Organization = edge(label=\"HAS\")\nitems: List[Item] = edge(label=\"RELATED\")\n\n# Correct - Descriptive\norg: Organization = edge(label=\"ISSUED_BY\")\nitems: List[Item] = edge(label=\"CONTAINS_LINE\")\n</code></pre>"},{"location":"fundamentals/schema-definition/relationships/#next-steps","title":"Next Steps","text":"<p>Now that you understand relationships:</p> <ol> <li>Validation \u2192 - Add validators for data quality</li> <li>Advanced Patterns - Complex relationship patterns</li> <li>Best Practices - Complete template checklist</li> </ol>"},{"location":"fundamentals/schema-definition/staged-extraction-schema/","title":"Schema Design for Staged and Delta Extraction","text":"<p>This guide defines schema constraints for multi-pass extraction (staged and delta contracts use the same catalog and identity concepts).</p>"},{"location":"fundamentals/schema-definition/staged-extraction-schema/#identity-requirements","title":"Identity requirements","text":"<ul> <li>Root must expose reliable <code>graph_id_fields</code>.</li> <li>Entity models should define required, extractable identity fields.</li> <li>Identity examples are mandatory for robust ID discovery prompts.</li> <li>Avoid long free-text identifiers.</li> </ul> <p>Identity examples for list-entities can be provided in either (or both) of these ways; the catalog collects from both: - Parent field: list-of-dict examples on the field that contains the list (e.g. <code>studies = Field(examples=[{\"study_id\": \"3.1\", \"objective\": \"...\"}])</code>). - Child model's identity fields: scalar <code>examples</code> on the entity's <code>graph_id_fields</code> (e.g. <code>study_id = Field(examples=[\"3.1\", \"STUDY-BINDER-MW\"])</code>). These are included in the catalog so the LLM sees concrete valid-ID examples. Prefer short, document-derived ID examples (section numbers, figure/table labels, named items). Do not use section or chapter titles as entity identities.</p>"},{"location":"fundamentals/schema-definition/staged-extraction-schema/#parent-linkage-requirements","title":"Parent linkage requirements","text":"<ul> <li>Child paths must have resolvable parent paths.</li> <li>Parent identity must be discoverable before child attachment.</li> <li>Local child IDs should be disambiguated by parent context when needed.</li> </ul>"},{"location":"fundamentals/schema-definition/staged-extraction-schema/#components-and-edges","title":"Components and edges","text":"<ul> <li>Components use <code>is_entity=False</code>.</li> <li>Components participating in graph relationships should be attached via <code>edge(label=...)</code>.</li> <li>Keep component payloads concise and extraction-friendly.</li> </ul>"},{"location":"fundamentals/schema-definition/staged-extraction-schema/#complexity-limits","title":"Complexity limits","text":"<ul> <li>Prefer 2-4 depth levels.</li> <li>Reduce fan-out where possible.</li> <li>Split very broad domains into focused templates.</li> </ul>"},{"location":"fundamentals/schema-definition/staged-extraction-schema/#delta-specific-additions","title":"Delta-specific additions","text":"<ul> <li>Keep extracted properties flat.</li> <li>Enforce exact catalog path usage.</li> <li>Favor fields that stabilize cross-batch identity and reconciliation.</li> <li>Provide canonicalization instructions in field descriptions.</li> </ul>"},{"location":"fundamentals/schema-definition/staged-extraction-schema/#quality-readiness-checklist","title":"Quality-readiness checklist","text":"<ul> <li>Root identity present and stable.</li> <li>Entity IDs required and exemplified.</li> <li>Parent-child paths deterministic.</li> <li>No critical fields hidden only in deeply nested branches.</li> <li>Relationship-bearing fields have explicit edge labels.</li> </ul>"},{"location":"fundamentals/schema-definition/template-basics/","title":"Template Basics","text":""},{"location":"fundamentals/schema-definition/template-basics/#overview","title":"Overview","text":"<p>Every Pydantic template for Docling Graph follows a standard structure with required imports, helper functions, and organization patterns. This ensures consistency and compatibility with the extraction pipeline.</p> <p>In this guide: - Required imports and their purposes - The mandatory <code>edge()</code> helper function - Standard file organization - Docstring conventions</p>"},{"location":"fundamentals/schema-definition/template-basics/#required-imports","title":"Required Imports","text":""},{"location":"fundamentals/schema-definition/template-basics/#standard-import-block","title":"Standard Import Block","text":"<p>Every template must include this import structure:</p> <pre><code>\"\"\"\nBrief description of what this template extracts.\nMention the document type and key domain features.\n\"\"\"\n\nfrom typing import Any, List, Optional, Union, Self, Type\nfrom pydantic import BaseModel, ConfigDict, Field, field_validator, model_validator\nfrom datetime import date, datetime  # Include based on domain needs\nfrom enum import Enum  # Include if using enums\nimport re  # Include if using regex validators\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#import-breakdown","title":"Import Breakdown","text":"Import Purpose When to Use <code>Any, List, Optional, Union</code> Type hints for fields Always <code>Self, Type</code> Advanced type hints for validators When using validators <code>BaseModel</code> Base class for all models Always <code>ConfigDict</code> Model configuration (graph_id_fields, is_entity) Always <code>Field</code> Field definitions with metadata Always <code>field_validator</code> Single-field validation When validating individual fields <code>model_validator</code> Cross-field validation When validating multiple fields together <code>date, datetime</code> Date/time types For temporal data <code>Enum</code> Enumerated types For controlled vocabularies <code>re</code> Regular expressions For pattern matching in validators"},{"location":"fundamentals/schema-definition/template-basics/#example-minimal-template","title":"Example: Minimal Template","text":"<pre><code>\"\"\"\nInvoice extraction template.\nExtracts invoice data including issuer, client, and line items.\n\"\"\"\n\nfrom typing import Any, List, Optional\nfrom pydantic import BaseModel, ConfigDict, Field\n\n# This is the minimal import set for a basic template\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#example-full-featured-template","title":"Example: Full-Featured Template","text":"<pre><code>\"\"\"\nRheology research extraction template.\nExtracts scientific experiments, measurements, and materials.\n\"\"\"\n\nfrom typing import Any, List, Optional, Union, Self, Type\nfrom pydantic import BaseModel, ConfigDict, Field, field_validator, model_validator\nfrom datetime import date\nfrom enum import Enum\nimport re\n\n# This includes all common imports for complex templates\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#the-edge-helper-function","title":"The Edge Helper Function","text":""},{"location":"fundamentals/schema-definition/template-basics/#required-definition","title":"Required Definition","text":"<p>This function must be defined identically in every template:</p> <pre><code>def edge(label: str, **kwargs: Any) -&gt; Any:\n    \"\"\"\n    Helper function to create a Pydantic Field with edge metadata.\n    The 'edge_label' defines the type of relationship in the knowledge graph.\n    \"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#critical-rules","title":"Critical Rules","text":"<p>\u2705 DO: - Use lowercase <code>edge</code> (not <code>Edge</code> or <code>EDGE</code>) - Return <code>Field(...)</code> with <code>json_schema_extra={\"edge_label\": label}</code> - Accept <code>**kwargs</code> to pass through additional Field parameters - Include the docstring</p> <p>\u274c DON'T: - Change the function signature - Modify the <code>json_schema_extra</code> structure - Remove <code>**kwargs</code> support</p>"},{"location":"fundamentals/schema-definition/template-basics/#why-this-function","title":"Why This Function?","text":"<p>The <code>edge()</code> helper serves two purposes:</p> <ol> <li>Marks relationships - Tells the graph converter this field is an edge</li> <li>Provides metadata - The <code>edge_label</code> becomes the relationship type in the graph</li> </ol>"},{"location":"fundamentals/schema-definition/template-basics/#usage-examples","title":"Usage Examples","text":"<pre><code># Required single relationship\nissued_by: Organization = edge(\n    label=\"ISSUED_BY\",\n    description=\"The organization that issued this document\"\n)\n\n# Optional single relationship\nverified_by: Optional[Person] = edge(\n    label=\"VERIFIED_BY\",\n    description=\"Person who verified this document, if applicable\"\n)\n\n# Required list relationship (one-to-many)\ncontains_items: List[LineItem] = edge(\n    label=\"CONTAINS_LINE\",\n    default_factory=list,  # REQUIRED for lists\n    description=\"Line items contained in this document\"\n)\n\n# Optional list relationship\naddresses: List[Address] = edge(\n    label=\"LOCATED_AT\",\n    default_factory=list,\n    description=\"Physical addresses for this entity\"\n)\n</code></pre> <p>Important: For list edges, you must provide <code>default_factory=list</code> in the <code>edge()</code> call.</p>"},{"location":"fundamentals/schema-definition/template-basics/#standard-file-organization","title":"Standard File Organization","text":""},{"location":"fundamentals/schema-definition/template-basics/#recommended-structure","title":"Recommended Structure","text":"<p>Organize your template in this exact order:</p> <pre><code>\"\"\"\nTemplate docstring describing purpose and domain\n\"\"\"\n\n# --- 1. Required Imports ---\nfrom pydantic import BaseModel, ConfigDict, Field, field_validator\nfrom typing import Any, List, Optional\n# ... additional imports\n\n# --- 2. Edge Helper Function ---\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- 3. Helper Functions (if needed) ---\n# Normalization, parsing, or utility functions\n\n# --- 4. Reusable Components ---\n# Value objects with is_entity=False\n\n# --- 5. Reusable Entities ---\n# Common entities like Person, Organization, Address\n\n# --- 6. Domain-Specific Models ---\n# Models unique to this document type\n\n# --- 7. Root Document Model ---\n# The main entry point (last in file)\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#example-invoice-template-structure","title":"Example: Invoice Template Structure","text":"<pre><code>\"\"\"\nInvoice extraction template.\nExtracts structured data from invoice documents.\n\"\"\"\n\n# --- 1. Imports ---\nfrom typing import Any, List, Optional\nfrom pydantic import BaseModel, ConfigDict, Field\n\n# --- 2. Edge Helper ---\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- 3. Helper Functions ---\n# (none needed for this simple template)\n\n# --- 4. Components ---\nclass Address(BaseModel):\n    \"\"\"Physical address component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    # ... fields\n\nclass MonetaryAmount(BaseModel):\n    \"\"\"Monetary value component.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n    # ... fields\n\n# --- 5. Reusable Entities ---\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n    # ... fields\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"first_name\", \"last_name\"])\n    # ... fields\n\n# --- 6. Domain-Specific Models ---\nclass LineItem(BaseModel):\n    \"\"\"Invoice line item.\"\"\"\n    # ... fields\n\n# --- 7. Root Document ---\nclass Invoice(BaseModel):\n    \"\"\"Invoice document (root model).\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"invoice_number\"])\n    # ... fields\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#docstring-standards","title":"Docstring Standards","text":""},{"location":"fundamentals/schema-definition/template-basics/#module-docstring","title":"Module Docstring","text":"<p>Every template file should start with a clear module docstring:</p> <pre><code>\"\"\"\nPydantic templates for [Document Type] extraction.\n\nThese models extract [key information] from [document type] documents.\nThe schema is designed for automatic conversion to knowledge graphs.\n\nKey entities:\n- [Entity1]: [Description]\n- [Entity2]: [Description]\n\nKey relationships:\n- [Entity1] --[RELATIONSHIP]--&gt; [Entity2]\n\"\"\"\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#model-docstrings","title":"Model Docstrings","text":"<p>Each model should have a clear docstring:</p> <pre><code>class Person(BaseModel):\n    \"\"\"\n    A person entity.\n\n    Uniquely identified by first name, last name, and date of birth.\n    Represents individuals mentioned in documents.\n    \"\"\"\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#good-vs-bad-docstrings","title":"Good vs Bad Docstrings","text":"<p>\u2705 Good: <pre><code>class Address(BaseModel):\n    \"\"\"\n    Physical address component.\n\n    Deduplicated by content - identical addresses share the same node.\n    Used for both residential and business addresses.\n    \"\"\"\n</code></pre></p> <p>\u274c Bad: <pre><code>class Address(BaseModel):\n    \"\"\"Address.\"\"\"  # Too vague\n</code></pre></p>"},{"location":"fundamentals/schema-definition/template-basics/#complete-minimal-template","title":"Complete Minimal Template","text":"<p>Here's a complete, minimal template showing all required elements:</p> <pre><code>\"\"\"\nSimple document extraction template.\nExtracts basic document information.\n\"\"\"\n\nfrom typing import Any, List, Optional\nfrom pydantic import BaseModel, ConfigDict, Field\n\n# --- Edge Helper Function (REQUIRED) ---\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    \"\"\"Helper to create graph edges.\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- Component ---\nclass Address(BaseModel):\n    \"\"\"Physical address (value object).\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    street: str = Field(\n        description=\"Street name and number\",\n        examples=[\"123 Main St\", \"45 Rue de la Paix\"]\n    )\n    city: str = Field(\n        description=\"City name\",\n        examples=[\"Paris\", \"London\"]\n    )\n\n# --- Entity ---\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(\n        description=\"Legal organization name\",\n        examples=[\"Acme Corp\", \"Tech Solutions Ltd\"]\n    )\n\n    # Edge to Address\n    located_at: Address = edge(\n        label=\"LOCATED_AT\",\n        description=\"Organization's physical address\"\n    )\n\n# --- Root Document ---\nclass Document(BaseModel):\n    \"\"\"Document entity (root model).\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_id\"])\n\n    document_id: str = Field(\n        description=\"Unique document identifier\",\n        examples=[\"DOC-2024-001\", \"12345\"]\n    )\n\n    # Edge to Organization\n    issued_by: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Organization that issued this document\"\n    )\n</code></pre> <p>This template includes: \u2705 Module docstring \u2705 Required imports \u2705 <code>edge()</code> helper function \u2705 Component with <code>is_entity=False</code> \u2705 Entity with <code>graph_id_fields</code> \u2705 Root document model \u2705 Clear field descriptions and examples \u2705 Graph relationships via <code>edge()</code></p>"},{"location":"fundamentals/schema-definition/template-basics/#testing-your-template-structure","title":"Testing Your Template Structure","text":""},{"location":"fundamentals/schema-definition/template-basics/#quick-validation","title":"Quick Validation","text":"<p>Test that your template is properly structured:</p> <pre><code># test_template_structure.py\nfrom my_template import Document, Organization, Address\n\n# 1. Check imports work\nprint(\"\u2705 Imports successful\")\n\n# 2. Check edge function exists\nfrom my_template import edge\nprint(\"\u2705 edge() function defined\")\n\n# 3. Create test instance\ndoc = Document(\n    document_id=\"TEST-001\",\n    issued_by=Organization(\n        name=\"Test Corp\",\n        located_at=Address(\n            street=\"123 Test St\",\n            city=\"Paris\"\n        )\n    )\n)\nprint(\"\u2705 Model instantiation works\")\n\n# 4. Check serialization\njson_data = doc.model_dump_json(indent=2)\nprint(\"\u2705 JSON serialization works\")\nprint(json_data)\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#run-with-uv","title":"Run with uv","text":"<pre><code># Save test to file\nuv run python test_template_structure.py\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#common-mistakes","title":"Common Mistakes","text":""},{"location":"fundamentals/schema-definition/template-basics/#wrong-edge-definition","title":"\u274c Wrong edge() Definition","text":"<pre><code># WRONG - Missing **kwargs\ndef edge(label: str) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label})\n\n# WRONG - Wrong metadata key\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"label\": label}, **kwargs)\n\n# CORRECT\ndef edge(label: str, **kwargs: Any) -&gt; Any:\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#missing-default_factory-for-lists","title":"\u274c Missing default_factory for Lists","text":"<pre><code># WRONG - List edge without default_factory\nitems: List[Item] = edge(\n    label=\"CONTAINS_LINE\",\n    description=\"Items in document\"\n)\n\n# CORRECT\nitems: List[Item] = edge(\n    label=\"CONTAINS_LINE\",\n    default_factory=list,  # Required!\n    description=\"Items in document\"\n)\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#inconsistent-organization","title":"\u274c Inconsistent Organization","text":"<pre><code># WRONG - Root model at the top\nclass Document(BaseModel):\n    \"\"\"Root document.\"\"\"\n    # ...\n\nclass Address(BaseModel):\n    \"\"\"Component used by Document.\"\"\"\n    # ...\n\n# CORRECT - Components before entities, root at end\nclass Address(BaseModel):\n    \"\"\"Component.\"\"\"\n    # ...\n\nclass Document(BaseModel):\n    \"\"\"Root document.\"\"\"\n    # ...\n</code></pre>"},{"location":"fundamentals/schema-definition/template-basics/#next-steps","title":"Next Steps","text":"<p>Now that you understand template basics:</p> <ol> <li>Entities vs Components \u2192 - Learn the critical distinction</li> <li>Field Definitions - Master field descriptions and examples</li> <li>Example Templates - See complete working examples</li> </ol>"},{"location":"fundamentals/schema-definition/validation/","title":"Validation and Normalization","text":""},{"location":"fundamentals/schema-definition/validation/#overview","title":"Overview","text":"<p>Validators ensure data quality and consistency in your extracted data. Pydantic provides powerful validation mechanisms that can transform, normalize, and validate field values before they're stored in your knowledge graph.</p> <p>In this guide: - Field validators for single-field validation - Model validators for cross-field validation - Pre-validators for data transformation - Common validation patterns - Normalization helpers</p>"},{"location":"fundamentals/schema-definition/validation/#field-validators","title":"Field Validators","text":""},{"location":"fundamentals/schema-definition/validation/#basic-field-validator","title":"Basic Field Validator","text":"<p>Use <code>@field_validator</code> to validate individual fields:</p> <pre><code>from pydantic import BaseModel, Field, field_validator\nfrom typing import Any\n\nclass MonetaryAmount(BaseModel):\n    \"\"\"Monetary value with validation.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    value: float = Field(...)\n    currency: Optional[str] = Field(None)\n\n    @field_validator(\"value\")\n    @classmethod\n    def validate_positive(cls, v: Any) -&gt; Any:\n        \"\"\"Ensure value is non-negative.\"\"\"\n        if v &lt; 0:\n            raise ValueError(\"Monetary amount must be non-negative\")\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#validator-anatomy","title":"Validator Anatomy","text":"<pre><code>@field_validator(\"field_name\")  # Field to validate\n@classmethod  # Must be classmethod\ndef validator_name(cls, v: Any) -&gt; Any:  # Takes value, returns value\n    \"\"\"Docstring explaining validation.\"\"\"\n    # Validation logic\n    if not valid:\n        raise ValueError(\"Error message\")\n    return v  # Return (possibly modified) value\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#pre-validators-modebefore","title":"Pre-Validators (mode='before')","text":""},{"location":"fundamentals/schema-definition/validation/#when-to-use-pre-validators","title":"When to Use Pre-Validators","text":"<p>Use <code>mode='before'</code> to transform input before type coercion:</p> <pre><code>@field_validator(\"email\", mode=\"before\")\n@classmethod\ndef normalize_email(cls, v: Any) -&gt; Any:\n    \"\"\"Convert email to lowercase and strip whitespace.\"\"\"\n    if v:\n        return v.lower().strip()\n    return v\n</code></pre> <p>Use cases: - Normalizing strings (lowercase, strip whitespace) - Converting types (string to list) - Parsing complex formats - Cleaning input data</p>"},{"location":"fundamentals/schema-definition/validation/#pre-validator-examples","title":"Pre-Validator Examples","text":""},{"location":"fundamentals/schema-definition/validation/#email-normalization","title":"\ud83d\udccd Email Normalization","text":"<pre><code>class Person(BaseModel):\n    \"\"\"Person with normalized email.\"\"\"\n\n    email: Optional[str] = Field(None)\n\n    @field_validator(\"email\", mode=\"before\")\n    @classmethod\n    def normalize_email(cls, v: Any) -&gt; Any:\n        \"\"\"Convert email to lowercase and strip whitespace.\"\"\"\n        if v:\n            return v.lower().strip()\n        return v\n</code></pre> <p>Input/Output: <pre><code>Person(email=\"  John.Doe@EMAIL.COM  \")\n# Result: email=\"john.doe@email.com\"\n</code></pre></p>"},{"location":"fundamentals/schema-definition/validation/#string-to-list-conversion","title":"\ud83d\udccd String to List Conversion","text":"<pre><code>class Person(BaseModel):\n    \"\"\"Person with flexible name input.\"\"\"\n\n    given_names: List[str] = Field(default_factory=list)\n\n    @field_validator(\"given_names\", mode=\"before\")\n    @classmethod\n    def ensure_list(cls, v: Any) -&gt; Any:\n        \"\"\"Ensure given_names is always a list.\"\"\"\n        if isinstance(v, str):\n            # Handle comma-separated names\n            if \",\" in v:\n                return [name.strip() for name in v.split(\",\")]\n            return [v]\n        return v\n</code></pre> <p>Input/Output: <pre><code>Person(given_names=\"John, Paul, George\")\n# Result: given_names=[\"John\", \"Paul\", \"George\"]\n\nPerson(given_names=\"John\")\n# Result: given_names=[\"John\"]\n\nPerson(given_names=[\"John\", \"Paul\"])\n# Result: given_names=[\"John\", \"Paul\"]\n</code></pre></p>"},{"location":"fundamentals/schema-definition/validation/#phone-number-cleaning","title":"\ud83d\udccd Phone Number Cleaning","text":"<pre><code>class Contact(BaseModel):\n    \"\"\"Contact with cleaned phone number.\"\"\"\n\n    phone: Optional[str] = Field(None)\n\n    @field_validator(\"phone\", mode=\"before\")\n    @classmethod\n    def clean_phone(cls, v: Any) -&gt; Any:\n        \"\"\"Remove non-numeric characters except + and spaces.\"\"\"\n        if v:\n            # Keep only digits, +, and spaces\n            import re\n            return re.sub(r'[^\\d\\s+]', '', v)\n        return v\n</code></pre> <p>Input/Output: <pre><code>Contact(phone=\"+33 (0)1-23-45-67-89\")\n# Result: phone=\"+33 01 23 45 67 89\"\n</code></pre></p>"},{"location":"fundamentals/schema-definition/validation/#post-validators-default-mode","title":"Post-Validators (Default Mode)","text":""},{"location":"fundamentals/schema-definition/validation/#when-to-use-post-validators","title":"When to Use Post-Validators","text":"<p>Use default mode (or <code>mode='after'</code>) to validate after type coercion:</p> <pre><code>@field_validator(\"currency\")\n@classmethod\ndef validate_currency_format(cls, v: Any) -&gt; Any:\n    \"\"\"Ensure currency is 3 uppercase letters (ISO 4217).\"\"\"\n    if v and not (len(v) == 3 and v.isupper()):\n        raise ValueError(\"Currency must be 3 uppercase letters (ISO 4217)\")\n    return v\n</code></pre> <p>Use cases: - Validating format constraints - Checking value ranges - Enforcing business rules - Verifying data integrity</p>"},{"location":"fundamentals/schema-definition/validation/#post-validator-examples","title":"Post-Validator Examples","text":""},{"location":"fundamentals/schema-definition/validation/#currency-code-validation","title":"\ud83d\udccd Currency Code Validation","text":"<pre><code>class MonetaryAmount(BaseModel):\n    \"\"\"Monetary amount with validated currency.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    value: float = Field(...)\n    currency: Optional[str] = Field(None)\n\n    @field_validator(\"currency\")\n    @classmethod\n    def validate_currency_format(cls, v: Any) -&gt; Any:\n        \"\"\"Ensure currency is 3 uppercase letters.\"\"\"\n        if v and not (len(v) == 3 and v.isupper()):\n            raise ValueError(\"Currency must be 3 uppercase letters (ISO 4217)\")\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#range-validation","title":"\ud83d\udccd Range Validation","text":"<pre><code>class Product(BaseModel):\n    \"\"\"Product with validated quantity.\"\"\"\n\n    quantity: int = Field(...)\n\n    @field_validator(\"quantity\")\n    @classmethod\n    def validate_quantity_range(cls, v: Any) -&gt; Any:\n        \"\"\"Ensure quantity is between 1 and 10000.\"\"\"\n        if v &lt; 1:\n            raise ValueError(\"Quantity must be at least 1\")\n        if v &gt; 10000:\n            raise ValueError(\"Quantity cannot exceed 10000\")\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#email-format-validation","title":"\ud83d\udccd Email Format Validation","text":"<pre><code>class Contact(BaseModel):\n    \"\"\"Contact with validated email.\"\"\"\n\n    email: Optional[str] = Field(None)\n\n    @field_validator(\"email\")\n    @classmethod\n    def validate_email_format(cls, v: Any) -&gt; Any:\n        \"\"\"Basic email format validation.\"\"\"\n        if v and \"@\" not in v:\n            raise ValueError(\"Invalid email format\")\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#model-validators","title":"Model Validators","text":""},{"location":"fundamentals/schema-definition/validation/#when-to-use-model-validators","title":"When to Use Model Validators","text":"<p>Use <code>@model_validator</code> for cross-field validation - when validation depends on multiple fields:</p> <pre><code>from pydantic import model_validator\nfrom typing_extensions import Self\n\nclass Measurement(BaseModel):\n    \"\"\"Measurement with cross-field validation.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    numeric_value: Optional[float] = Field(None)\n    numeric_value_min: Optional[float] = Field(None)\n    numeric_value_max: Optional[float] = Field(None)\n\n    @model_validator(mode=\"after\")\n    def validate_value_consistency(self) -&gt; Self:\n        \"\"\"Ensure value fields are used consistently.\"\"\"\n        has_single = self.numeric_value is not None\n        has_min = self.numeric_value_min is not None\n        has_max = self.numeric_value_max is not None\n\n        if has_single and has_min and has_max:\n            raise ValueError(\n                \"Cannot specify numeric_value, numeric_value_min, \"\n                \"and numeric_value_max simultaneously\"\n            )\n\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#model-validator-examples","title":"Model Validator Examples","text":""},{"location":"fundamentals/schema-definition/validation/#date-range-validation","title":"\ud83d\udccd Date Range Validation","text":"<pre><code>from datetime import date\n\nclass Event(BaseModel):\n    \"\"\"Event with validated date range.\"\"\"\n\n    start_date: Optional[date] = Field(None)\n    end_date: Optional[date] = Field(None)\n\n    @model_validator(mode=\"after\")\n    def validate_date_range(self) -&gt; Self:\n        \"\"\"Ensure end_date is after start_date.\"\"\"\n        if self.start_date and self.end_date:\n            if self.end_date &lt; self.start_date:\n                raise ValueError(\"end_date must be after start_date\")\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#conditional-required-fields","title":"\ud83d\udccd Conditional Required Fields","text":"<pre><code>class Document(BaseModel):\n    \"\"\"Document with conditional validation.\"\"\"\n\n    document_type: str = Field(...)\n    document_no: Optional[str] = Field(None)\n    receipt_number: Optional[str] = Field(None)\n\n    @model_validator(mode=\"after\")\n    def validate_document_numbers(self) -&gt; Self:\n        \"\"\"Ensure appropriate number field is present.\"\"\"\n        if self.document_type == \"invoice\" and not self.document_no:\n            raise ValueError(\"document_no required for invoice documents\")\n        if self.document_type == \"receipt\" and not self.receipt_number:\n            raise ValueError(\"receipt_number required for receipt documents\")\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#mutual-exclusivity","title":"\ud83d\udccd Mutual Exclusivity","text":"<pre><code>class Payment(BaseModel):\n    \"\"\"Payment with mutually exclusive fields.\"\"\"\n\n    cash_amount: Optional[float] = Field(None)\n    card_amount: Optional[float] = Field(None)\n    check_amount: Optional[float] = Field(None)\n\n    @model_validator(mode=\"after\")\n    def validate_single_payment_method(self) -&gt; Self:\n        \"\"\"Ensure only one payment method is used.\"\"\"\n        methods = [\n            self.cash_amount is not None,\n            self.card_amount is not None,\n            self.check_amount is not None\n        ]\n        if sum(methods) &gt; 1:\n            raise ValueError(\"Only one payment method can be specified\")\n        if sum(methods) == 0:\n            raise ValueError(\"At least one payment method must be specified\")\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#semantic-sanity-clear-wrong-unitamount","title":"\ud83d\udccd Semantic sanity: clear wrong unit/amount","text":"<p>When a field pair has a clear semantic (e.g. amount + unit), use a model_validator to clear both if the unit indicates a different quantity type (e.g. temperature or viscosity mistaken for amount). Prefer clearing over raising so extraction still validates:</p> <pre><code>import re\nfrom typing_extensions import Self\n\nclass Component(BaseModel):\n    \"\"\"Component with amount; amount_unit must be a quantity unit, not a property unit.\"\"\"\n    amount_value: float | None = Field(None)\n    amount_unit: str | None = Field(None)\n    # ... other fields\n\n    @model_validator(mode=\"after\")\n    def clear_amount_if_property_unit(self) -&gt; Self:\n        \"\"\"Clear amount_value/amount_unit when unit indicates a property (temp, viscosity), not a quantity.\"\"\"\n        unit = self.amount_unit\n        if not unit or not isinstance(unit, str):\n            return self\n        normalized = re.sub(r\"[\\s\u00b7]\", \"\", unit.lower())\n        # Forbidden: temperature, viscosity, pressure\n        forbidden = (\"\u00b0c\", \"k\", \"pa.s\", \"pas\", \"mpa.s\", \"mpas\")\n        if any(f in normalized for f in forbidden) or normalized == \"pa\":\n            object.__setattr__(self, \"amount_value\", None)\n            object.__setattr__(self, \"amount_unit\", None)\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#deduplicate-root-level-list-by-key","title":"\ud83d\udccd Deduplicate root-level list by key","text":"<p>For root-level list fields that have no identity (e.g. authors), chunked extraction can append the same item multiple times. Use a model_validator to keep first occurrence per key:</p> <pre><code>from typing import List\nfrom typing_extensions import Self\n\nclass PersonIdentity(BaseModel):\n    full_name: str = Field(...)\n\nclass Document(BaseModel):\n    \"\"\"Root document.\"\"\"\n    authors: List[PersonIdentity] = Field(default_factory=list)\n    # ... other fields\n\n    @model_validator(mode=\"after\")\n    def deduplicate_authors_by_name(self) -&gt; Self:\n        \"\"\"Keep first occurrence of each author per full_name (removes duplicates from chunked extraction).\"\"\"\n        if not self.authors:\n            return self\n        seen: set[str] = set()\n        unique: list[PersonIdentity] = []\n        for a in self.authors:\n            key = (getattr(a, \"full_name\", None) or \"\").strip().lower()\n            if key not in seen:\n                seen.add(key)\n                unique.append(a)\n        object.__setattr__(self, \"authors\", unique)\n        return self\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#common-validation-patterns","title":"Common Validation Patterns","text":""},{"location":"fundamentals/schema-definition/validation/#pattern-1-positive-number-validation","title":"Pattern 1: Positive Number Validation","text":"<pre><code>@field_validator(\"amount\", \"quantity\", \"price\")\n@classmethod\ndef validate_positive(cls, v: Any) -&gt; Any:\n    \"\"\"Ensure value is positive.\"\"\"\n    if v is not None and v &lt; 0:\n        raise ValueError(f\"Value must be non-negative, got {v}\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#pattern-2-string-length-validation","title":"Pattern 2: String Length Validation","text":"<pre><code>@field_validator(\"postal_code\")\n@classmethod\ndef validate_postal_code_length(cls, v: Any) -&gt; Any:\n    \"\"\"Ensure postal code is 5 digits.\"\"\"\n    if v and len(v) != 5:\n        raise ValueError(\"Postal code must be 5 digits\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#pattern-3-enum-like-validation","title":"Pattern 3: Enum-like Validation","text":"<pre><code>@field_validator(\"status\")\n@classmethod\ndef validate_status(cls, v: Any) -&gt; Any:\n    \"\"\"Ensure status is one of allowed values.\"\"\"\n    allowed = [\"pending\", \"approved\", \"rejected\"]\n    if v and v not in allowed:\n        raise ValueError(f\"Status must be one of {allowed}\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#pattern-4-pattern-matching","title":"Pattern 4: Pattern Matching","text":"<pre><code>import re\n\n@field_validator(\"email\")\n@classmethod\ndef validate_email_pattern(cls, v: Any) -&gt; Any:\n    \"\"\"Validate email format using regex.\"\"\"\n    if v:\n        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n        if not re.match(pattern, v):\n            raise ValueError(\"Invalid email format\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#enum-normalization-helper","title":"Enum Normalization Helper","text":""},{"location":"fundamentals/schema-definition/validation/#the-problem","title":"The Problem","text":"<p>Enums can be tricky with LLM extraction - the model might return various formats:</p> <pre><code>from enum import Enum\n\nclass Status(str, Enum):\n    PENDING = \"Pending\"\n    APPROVED = \"Approved\"\n    REJECTED = \"Rejected\"\n\n# LLM might return: \"pending\", \"PENDING\", \"Pending\", \"approved\", etc.\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#the-solution","title":"The Solution","text":"<p>Use a normalization helper:</p> <pre><code>import re\nfrom enum import Enum\nfrom typing import Type, Any\n\ndef _normalize_enum(enum_cls: Type[Enum], v: Any) -&gt; Any:\n    \"\"\"\n    Accept enum instances, value strings, or member names.\n    Handles various formats: 'VALUE', 'value', 'Value', 'VALUE_NAME'.\n    Falls back to 'OTHER' member if present.\n    \"\"\"\n    if isinstance(v, enum_cls):\n        return v\n\n    if isinstance(v, str):\n        # Normalize to alphanumeric lowercase\n        key = re.sub(r\"[^A-Za-z0-9]+\", \"\", v).lower()\n\n        # Build mapping of normalized names/values to enum members\n        mapping = {}\n        for member in enum_cls:\n            normalized_name = re.sub(r\"[^A-Za-z0-9]+\", \"\", member.name).lower()\n            normalized_value = re.sub(r\"[^A-Za-z0-9]+\", \"\", member.value).lower()\n            mapping[normalized_name] = member\n            mapping[normalized_value] = member\n\n        if key in mapping:\n            return mapping[key]\n\n        # Last attempt: direct value match\n        try:\n            return enum_cls(v)\n        except Exception:\n            # Safe fallback to OTHER if present\n            if \"OTHER\" in enum_cls.__members__:\n                return enum_cls.OTHER\n            raise\n\n    raise ValueError(f\"Cannot normalize {v} to {enum_cls}\")\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#usage-example","title":"Usage Example","text":"<pre><code>class DocumentType(str, Enum):\n    INVOICE = \"Invoice\"\n    RECEIPT = \"Receipt\"\n    CREDIT_NOTE = \"Credit Note\"\n    DEBIT_NOTE = \"Debit Note\"\n    PRO_FORMA = \"Pro Forma\"\n    OTHER = \"Other\"\n\nclass Document(BaseModel):\n    \"\"\"Document with normalized enum.\"\"\"\n\n    document_type: DocumentType = Field(...)\n\n    @field_validator(\"document_type\", mode=\"before\")\n    @classmethod\n    def normalize_document_type(cls, v: Any) -&gt; Any:\n        return _normalize_enum(DocumentType, v)\n</code></pre> <p>Handles all these inputs: <pre><code>Document(document_type=\"invoice\")  # \u2192 DocumentType.INVOICE\nDocument(document_type=\"INVOICE\")  # \u2192 DocumentType.INVOICE\nDocument(document_type=\"Invoice\")  # \u2192 DocumentType.INVOICE\nDocument(document_type=\"credit note\")  # \u2192 DocumentType.CREDIT_NOTE\nDocument(document_type=\"unknown\")  # \u2192 DocumentType.OTHER (fallback)\n</code></pre></p>"},{"location":"fundamentals/schema-definition/validation/#measurement-parsing-helper","title":"Measurement Parsing Helper","text":""},{"location":"fundamentals/schema-definition/validation/#the-problem_1","title":"The Problem","text":"<p>LLMs might return measurements in various formats:</p> <pre><code>\"1.6 mPa.s\"\n\"2 mm\"\n\"80-90 \u00b0C\"\n\"High\"\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#the-solution_1","title":"The Solution","text":"<p>Use a parsing helper:</p> <pre><code>import re\nfrom typing import Any, Optional\n\ndef _parse_measurement_string(\n    s: str,\n    default_name: Optional[str] = None,\n    strict: bool = False\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Parse measurement strings into structured dict.\n\n    Examples:\n        \"1.6 mPa.s\" \u2192 {numeric_value: 1.6, unit: \"mPa.s\"}\n        \"80-90 \u00b0C\" \u2192 {numeric_value_min: 80, numeric_value_max: 90, unit: \"\u00b0C\"}\n        \"High\" \u2192 {text_value: \"High\"}\n    \"\"\"\n    if not isinstance(s, str):\n        return s\n\n    # Try to parse range (e.g., \"80-90 \u00b0C\")\n    range_match = re.match(\n        r\"^\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*-\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*([^\\d]+)?$\",\n        s\n    )\n    if range_match:\n        min_val = float(range_match.group(1))\n        max_val = float(range_match.group(2))\n        unit = (range_match.group(3) or \"\").strip() or None\n        return {\n            \"name\": default_name or \"Value\",\n            \"numeric_value\": None,\n            \"numeric_value_min\": min_val,\n            \"numeric_value_max\": max_val,\n            \"text_value\": None,\n            \"unit\": unit,\n        }\n\n    # Try to parse single value (e.g., \"1.6 mPa.s\")\n    single_match = re.match(r\"^\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*([^\\d]+)?$\", s)\n    if single_match:\n        num = float(single_match.group(1))\n        unit = (single_match.group(2) or \"\").strip() or None\n        return {\n            \"name\": default_name or \"Value\",\n            \"numeric_value\": num,\n            \"numeric_value_min\": None,\n            \"numeric_value_max\": None,\n            \"text_value\": None,\n            \"unit\": unit,\n        }\n\n    # No numeric part found\n    if strict:\n        raise ValueError(f\"Cannot parse '{s}' as measurement\")\n\n    # Fallback: keep raw as text\n    return {\n        \"name\": default_name or \"Value\",\n        \"numeric_value\": None,\n        \"numeric_value_min\": None,\n        \"numeric_value_max\": None,\n        \"text_value\": s.strip(),\n        \"unit\": None,\n    }\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#usage-example_1","title":"Usage Example","text":"<pre><code>class Measurement(BaseModel):\n    \"\"\"Flexible measurement model.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    name: str = Field(...)\n    numeric_value: Optional[float] = Field(None)\n    numeric_value_min: Optional[float] = Field(None)\n    numeric_value_max: Optional[float] = Field(None)\n    text_value: Optional[str] = Field(None)\n    unit: Optional[str] = Field(None)\n\n    @field_validator(\"numeric_value\", \"numeric_value_min\", \"numeric_value_max\", mode=\"before\")\n    @classmethod\n    def parse_if_string(cls, v: Any, info: ValidationInfo) -&gt; Any:\n        \"\"\"Parse measurement strings.\"\"\"\n        if isinstance(v, str):\n            field_name = info.field_name\n            parsed = _parse_measurement_string(v, default_name=field_name)\n            return parsed.get(field_name)\n        return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#best-practices","title":"Best Practices","text":""},{"location":"fundamentals/schema-definition/validation/#validate-early","title":"\ud83d\udc4d Validate Early","text":"<p>Use <code>mode='before'</code> for normalization, default mode for validation:</p> <pre><code>@field_validator(\"email\", mode=\"before\")\n@classmethod\ndef normalize_email(cls, v: Any) -&gt; Any:\n    \"\"\"Normalize before validation.\"\"\"\n    if v:\n        return v.lower().strip()\n    return v\n\n@field_validator(\"email\")\n@classmethod\ndef validate_email(cls, v: Any) -&gt; Any:\n    \"\"\"Validate after normalization.\"\"\"\n    if v and \"@\" not in v:\n        raise ValueError(\"Invalid email\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#provide-clear-error-messages","title":"\ud83d\udc4d Provide Clear Error Messages","text":"<pre><code># \u2705 Good - Specific error message\n@field_validator(\"quantity\")\n@classmethod\ndef validate_quantity(cls, v: Any) -&gt; Any:\n    if v &lt; 1:\n        raise ValueError(f\"Quantity must be at least 1, got {v}\")\n    return v\n\n# \u274c Bad - Vague error message\n@field_validator(\"quantity\")\n@classmethod\ndef validate_quantity(cls, v: Any) -&gt; Any:\n    if v &lt; 1:\n        raise ValueError(\"Invalid quantity\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#handle-none-values","title":"\ud83d\udc4d Handle None Values","text":"<pre><code>@field_validator(\"email\")\n@classmethod\ndef validate_email(cls, v: Any) -&gt; Any:\n    \"\"\"Validate email, allowing None.\"\"\"\n    if v is None:\n        return v  # Allow None for optional fields\n    if \"@\" not in v:\n        raise ValueError(\"Invalid email\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#use-type-guards","title":"\ud83d\udc4d Use Type Guards","text":"<pre><code>@field_validator(\"value\", mode=\"before\")\n@classmethod\ndef coerce_to_float(cls, v: Any) -&gt; Any:\n    \"\"\"Convert string to float if needed.\"\"\"\n    if isinstance(v, str):\n        try:\n            return float(v.replace(\",\", \"\"))\n        except ValueError:\n            raise ValueError(f\"Cannot convert '{v}' to float\")\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#graceful-error-handling","title":"Graceful Error Handling","text":""},{"location":"fundamentals/schema-definition/validation/#the-problem-with-strict-validators","title":"The Problem with Strict Validators","text":"<p>Strict validators that raise <code>ValueError</code> on invalid data can cause complete extraction failure:</p> <pre><code># \u274c Strict validator - causes extraction failure\n@field_validator(\"value\")\n@classmethod\ndef validate_positive(cls, v: Any) -&gt; Any:\n    \"\"\"Ensure amount is non-negative.\"\"\"\n    if v &lt; 0:\n        raise ValueError(f\"Monetary amount must be non-negative, got {v}\")\n    return v\n</code></pre> <p>What happens: - LLM extracts: <code>allowance_total: -258.12</code> (negative because it's a discount) - Validator rejects: \"Monetary amount must be non-negative\" - Result: Entire extraction fails, losing ALL extracted data</p>"},{"location":"fundamentals/schema-definition/validation/#the-solution-lenient-validators","title":"The Solution: Lenient Validators","text":"<p>Lenient validators coerce invalid values instead of rejecting them:</p> <pre><code># \u2705 Lenient validator - coerces instead of rejecting\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n@field_validator(\"value\", mode=\"before\")\n@classmethod\ndef coerce_positive(cls, v: Any) -&gt; Any:\n    \"\"\"\n    Coerce negative values to positive (use absolute value).\n\n    Allowances and discounts are often represented as negative in accounting,\n    but should be stored as positive amounts. The charge_indicator field\n    (in AllowanceCharge) indicates direction: false=allowance, true=charge.\n\n    This validator is lenient - it coerces instead of rejecting to prevent\n    extraction failures due to semantic differences in how amounts are represented.\n    \"\"\"\n    if isinstance(v, (int, float)) and v &lt; 0:\n        logger.warning(\n            f\"Negative monetary value {v} coerced to positive {abs(v)}. \"\n            \"Allowances/discounts should be positive amounts.\"\n        )\n        return abs(v)\n    return v\n</code></pre> <p>Benefits: - \u2705 Extraction succeeds even with \"invalid\" data - \u2705 Data quality issues are logged for review - \u2705 99% correct data is preserved instead of lost - \u2705 Semantic differences are handled gracefully</p>"},{"location":"fundamentals/schema-definition/validation/#when-to-use-lenient-validators","title":"When to Use Lenient Validators","text":"<p>Use lenient validators for:</p> <ol> <li>Semantic Variations</li> <li>Negative amounts for discounts/allowances</li> <li>Lowercase currency codes (normalize to uppercase)</li> <li> <p>Different date formats (parse and normalize)</p> </li> <li> <p>Common LLM Mistakes</p> </li> <li>Missing spaces in addresses</li> <li>Wrong case in enums</li> <li> <p>Currency symbols instead of codes</p> </li> <li> <p>Non-Critical Validation</p> </li> <li>Format preferences (3-letter currency codes)</li> <li>Range constraints (quantity &gt; 0)</li> <li>Pattern matching (email format)</li> </ol>"},{"location":"fundamentals/schema-definition/validation/#when-to-use-strict-validators","title":"When to Use Strict Validators","text":"<p>Use strict validators only for:</p> <ol> <li>Critical Data Integrity</li> <li>Required fields that must be present</li> <li>Type safety (must be a number, not a string)</li> <li> <p>Business rules that cannot be violated</p> </li> <li> <p>Security Concerns</p> </li> <li>SQL injection prevention</li> <li>Path traversal prevention</li> <li>XSS prevention</li> </ol>"},{"location":"fundamentals/schema-definition/validation/#lenient-validator-patterns","title":"Lenient Validator Patterns","text":""},{"location":"fundamentals/schema-definition/validation/#pattern-1-coerce-negative-to-positive","title":"Pattern 1: Coerce Negative to Positive","text":"<pre><code>@field_validator(\"value\", mode=\"before\")\n@classmethod\ndef coerce_positive(cls, v: Any) -&gt; Any:\n    \"\"\"Coerce negative values to positive.\"\"\"\n    if isinstance(v, (int, float)) and v &lt; 0:\n        logger.warning(f\"Negative value {v} coerced to {abs(v)}\")\n        return abs(v)\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#pattern-2-normalize-case","title":"Pattern 2: Normalize Case","text":"<pre><code>@field_validator(\"currency\", mode=\"before\")\n@classmethod\ndef normalize_currency(cls, v: Any) -&gt; Any:\n    \"\"\"Normalize currency to uppercase.\"\"\"\n    if v:\n        v_upper = str(v).strip().upper()\n        if len(v_upper) == 3 and v_upper.isalpha():\n            return v_upper\n        logger.warning(f\"Currency '{v}' normalized to '{v_upper}'\")\n        return v_upper\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#pattern-3-handle-zero-values","title":"Pattern 3: Handle Zero Values","text":"<pre><code>@field_validator(\"quantity\", mode=\"before\")\n@classmethod\ndef handle_zero(cls, v: Any) -&gt; Any:\n    \"\"\"Handle zero quantities by setting default.\"\"\"\n    if isinstance(v, (int, float)):\n        if v == 0:\n            logger.warning(\"Zero quantity detected, setting to 1 as default\")\n            return 1.0\n        elif v &lt; 0:\n            logger.warning(f\"Negative quantity {v} coerced to {abs(v)}\")\n            return abs(v)\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#pattern-4-symbol-to-code-conversion","title":"Pattern 4: Symbol to Code Conversion","text":"<pre><code>@field_validator(\"currency\", mode=\"before\")\n@classmethod\ndef convert_symbol(cls, v: Any) -&gt; Any:\n    \"\"\"Convert currency symbols to ISO codes.\"\"\"\n    symbol_map = {\n        \"\u20ac\": \"EUR\",\n        \"$\": \"USD\",\n        \"\u00a3\": \"GBP\",\n        \"\u00a5\": \"JPY\",\n    }\n\n    if v in symbol_map:\n        logger.info(f\"Currency symbol '{v}' converted to '{symbol_map[v]}'\")\n        return symbol_map[v]\n\n    return v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#logging-best-practices","title":"Logging Best Practices","text":"<p>Always log data quality issues:</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\n@field_validator(\"value\", mode=\"before\")\n@classmethod\ndef coerce_positive(cls, v: Any) -&gt; Any:\n    \"\"\"Coerce with logging.\"\"\"\n    if isinstance(v, (int, float)) and v &lt; 0:\n        # Log at WARNING level for data quality issues\n        logger.warning(\n            f\"Data quality issue: Negative value {v} coerced to {abs(v)}. \"\n            f\"Field: {cls.__name__}.value\"\n        )\n        return abs(v)\n    return v\n</code></pre> <p>Log Levels: - <code>logger.info()</code> - Normal coercion (e.g., lowercase \u2192 uppercase) - <code>logger.warning()</code> - Data quality issues (e.g., negative \u2192 positive) - <code>logger.error()</code> - Serious issues that couldn't be fixed</p>"},{"location":"fundamentals/schema-definition/validation/#complete-example-lenient-monetaryamount","title":"Complete Example: Lenient MonetaryAmount","text":"<pre><code>import logging\nfrom typing import Any\nfrom pydantic import BaseModel, ConfigDict, Field, field_validator\n\nlogger = logging.getLogger(__name__)\n\nclass MonetaryAmount(BaseModel):\n    \"\"\"Monetary amount with lenient validation.\"\"\"\n    model_config = ConfigDict(is_entity=False)\n\n    value: float = Field(\n        ...,\n        description=\"Monetary amount (always positive)\",\n        examples=[100.00, 1250.50, 89.99]\n    )\n\n    currency: str | None = Field(\n        None,\n        description=\"ISO 4217 currency code (3 uppercase letters)\",\n        examples=[\"EUR\", \"USD\", \"GBP\", \"CHF\"]\n    )\n\n    @field_validator(\"value\", mode=\"before\")\n    @classmethod\n    def coerce_positive(cls, v: Any) -&gt; Any:\n        \"\"\"Coerce negative values to positive.\"\"\"\n        if isinstance(v, (int, float)) and v &lt; 0:\n            logger.warning(\n                f\"Negative monetary value {v} coerced to positive {abs(v)}. \"\n                \"Allowances/discounts should be positive amounts.\"\n            )\n            return abs(v)\n        return v\n\n    @field_validator(\"currency\", mode=\"before\")\n    @classmethod\n    def normalize_currency(cls, v: Any) -&gt; Any:\n        \"\"\"Normalize currency to ISO 4217 format.\"\"\"\n        if not v:\n            return v\n\n        # Symbol to code mapping\n        symbol_map = {\n            \"\u20ac\": \"EUR\", \"$\": \"USD\", \"\u00a3\": \"GBP\", \"\u00a5\": \"JPY\",\n            \"\u20b9\": \"INR\", \"\u20bd\": \"RUB\", \"\u20a9\": \"KRW\", \"\u20aa\": \"ILS\",\n        }\n\n        v_str = str(v).strip()\n\n        # Convert symbol to code\n        if v_str in symbol_map:\n            return symbol_map[v_str]\n\n        # Normalize to uppercase\n        v_upper = v_str.upper()\n\n        # Validate format\n        if len(v_upper) == 3 and v_upper.isalpha():\n            return v_upper\n\n        # Log warning but don't fail\n        logger.warning(\n            f\"Currency '{v}' does not match ISO 4217 format. \"\n            f\"Normalized to '{v_upper}' but may be invalid.\"\n        )\n        return v_upper if len(v_upper) == 3 else v_str\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#migration-guide-strict-lenient","title":"Migration Guide: Strict \u2192 Lenient","text":"<p>Before (Strict): <pre><code>@field_validator(\"value\")\n@classmethod\ndef validate_positive(cls, v: Any) -&gt; Any:\n    if v &lt; 0:\n        raise ValueError(f\"Must be non-negative, got {v}\")\n    return v\n</code></pre></p> <p>After (Lenient): <pre><code>@field_validator(\"value\", mode=\"before\")\n@classmethod\ndef coerce_positive(cls, v: Any) -&gt; Any:\n    if isinstance(v, (int, float)) and v &lt; 0:\n        logger.warning(f\"Negative value {v} coerced to {abs(v)}\")\n        return abs(v)\n    return v\n</code></pre></p> <p>Changes: 1. Add <code>mode=\"before\"</code> to validator decorator 2. Replace <code>raise ValueError</code> with coercion logic 3. Add <code>logger.warning()</code> for data quality tracking 4. Add type guard (<code>isinstance</code>) for safety 5. Update docstring to explain lenient behavior</p>"},{"location":"fundamentals/schema-definition/validation/#testing-validators","title":"Testing Validators","text":""},{"location":"fundamentals/schema-definition/validation/#test-individual-validators","title":"Test Individual Validators","text":"<pre><code># test_validators.py\nfrom my_template import MonetaryAmount\nimport pytest\n\ndef test_positive_amount():\n    \"\"\"Test that negative amounts are rejected.\"\"\"\n    with pytest.raises(ValueError, match=\"non-negative\"):\n        MonetaryAmount(value=-100, currency=\"EUR\")\n\ndef test_valid_amount():\n    \"\"\"Test that positive amounts are accepted.\"\"\"\n    amount = MonetaryAmount(value=100, currency=\"EUR\")\n    assert amount.value == 100\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#test-with-uv","title":"Test with uv","text":"<pre><code>uv run pytest test_validators.py -v\n</code></pre>"},{"location":"fundamentals/schema-definition/validation/#next-steps","title":"Next Steps","text":"<p>Now that you understand validation:</p> <ol> <li>Advanced Patterns \u2192 - Complex validation patterns</li> <li>Best Practices - Complete template checklist</li> <li>Examples - See validators in action</li> </ol>"},{"location":"introduction/","title":"Introduction to Docling Graph","text":"<p>Welcome to Docling Graph! This section introduces the core concepts of knowledge graph extraction from documents.</p>"},{"location":"introduction/#what-is-docling-graph","title":"What is Docling Graph?","text":"<p>Docling Graph transforms unstructured documents into validated knowledge graphs with precise semantic relationships. Unlike traditional approaches that convert text to embeddings (losing exact relationships), Docling Graph preserves explicit entity connections.</p> <p>Key Advantage: Answer questions like \"who issued what to whom\" with exact relationships, not approximate embeddings.</p>"},{"location":"introduction/#why-knowledge-graphs","title":"Why Knowledge Graphs?","text":"<p>Knowledge graphs are essential for domains requiring exact entity connections:</p> <ul> <li>Chemistry: Track compounds, reactions, and measurements</li> <li>Finance/Legal: Map instruments, obligations, and dependencies</li> <li>Research: Connect authors, methodologies, and results</li> <li>Healthcare: Relate patients, treatments, and outcomes</li> </ul>"},{"location":"introduction/#how-it-works","title":"How It Works","text":"<p>Docling Graph follows a clear pipeline:</p> <ol> <li>Installation - Set up environment</li> <li>Schema Definition - Create Pydantic templates</li> <li>Pipeline Configuration - Configure backend and mode</li> <li>Extraction Process - Run extraction</li> <li>Graph Management - Export and visualize</li> </ol>"},{"location":"introduction/#quick-example","title":"Quick Example","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom pydantic import BaseModel, Field\n\nclass Person(BaseModel):\n    model_config = {'is_entity': True, 'graph_id_fields': ['name']}\n    name: str = Field(description=\"Person's full name\")\n    email: str = Field(description=\"Email address\")\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=Person,\n    backend=\"llm\",\n    inference=\"remote\"\n)\n\ncontext = run_pipeline(config)\nprint(f\"Extracted {context.knowledge_graph.number_of_nodes()} nodes\")\n</code></pre>"},{"location":"introduction/#learn-more","title":"Learn More","text":"<ul> <li>Key Concepts - Entities, components, nodes, edges</li> <li>Use Cases - Domain-specific examples</li> <li>Architecture - System design</li> <li>Quick Start - 5-minute tutorial</li> </ul> <p>Ready to start? Begin with installation or try the quick start.</p>"},{"location":"introduction/architecture/","title":"Architecture","text":""},{"location":"introduction/architecture/#system-architecture","title":"System Architecture","text":"<p>Docling Graph follows a modular, pipeline-based architecture with clear separation of concerns:</p> <p></p>"},{"location":"introduction/architecture/#core-components","title":"Core Components","text":""},{"location":"introduction/architecture/#document-processor","title":"Document Processor","text":"<p>Converts documents to structured format using Docling with OCR or Vision pipelines.</p> <p>Location: <code>docling_graph/core/extractors/document_processor.py</code></p>"},{"location":"introduction/architecture/#extraction-backends","title":"Extraction Backends","text":"<p>VLM Backend: Direct extraction from images using vision-language models (local only) LLM Backend: Text-based extraction supporting local (vLLM, Ollama) and remote APIs</p> <p>Location: <code>docling_graph/core/extractors/backends/</code></p>"},{"location":"introduction/architecture/#processing-strategies","title":"Processing Strategies","text":"<p>One-to-One: Each page produces a separate model (invoice batches, ID cards) Many-to-One: Multiple pages merged into single model (rheology researchs, reports)</p> <p>Location: <code>docling_graph/core/extractors/strategies/</code></p>"},{"location":"introduction/architecture/#document-chunker","title":"Document Chunker","text":"<p>Splits large documents while preserving semantic coherence and respecting structure.</p> <p>Location: <code>docling_graph/core/extractors/document_chunker.py</code></p>"},{"location":"introduction/architecture/#graph-converter","title":"Graph Converter","text":"<p>Transforms Pydantic models to NetworkX graphs with stable node IDs and automatic deduplication.</p> <p>Location: <code>docling_graph/core/converters/graph_converter.py</code></p>"},{"location":"introduction/architecture/#exporters-visualizers","title":"Exporters &amp; Visualizers","text":"<p>Export graphs in CSV, Cypher, JSON formats and generate interactive HTML visualizations.</p> <p>Location: <code>docling_graph/core/exporters/</code>, <code>docling_graph/core/visualizers/</code></p>"},{"location":"introduction/architecture/#complete-pipeline-flow","title":"Complete Pipeline Flow","text":"<pre><code>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%%\nflowchart TB\n    %% 1. Define Classes\n    classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1\n    classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037\n    classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20\n    classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100\n    classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0\n    classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A\n    classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238\n\n    %% 2. Define Nodes\n    A@{ shape: terminal, label: \"Input Source\" }\n    A1@{ shape: procs, label: \"1. Input Normalization&lt;br/&gt;Type Detection &amp; Validation\" }\n\n    A2{\"Input Type\"}\n\n    %% Ingestion Paths\n    B@{ shape: procs, label: \"2a. Docling Conversion&lt;br/&gt;Generates Images &amp; Markdown\" }\n    B2@{ shape: lin-proc, label: \"2b. Text Processing&lt;br/&gt;Direct to Markdown\" }\n    B3@{ shape: lin-proc, label: \"2c. Load DoclingDocument&lt;br/&gt;Pre-parsed Content\" }\n\n    %% Strategy Decision\n    C{\"3. Backend\"}\n\n    %% Extraction Paths\n    D@{ shape: lin-proc, label: \"4a. VLM Extraction&lt;br/&gt;Page-by-Page (Images)\" }\n    E@{ shape: lin-proc, label: \"4b. Markdown Prep&lt;br/&gt;Merge Text Content\" }\n\n    %% Chunking Logic (LLM Path)\n    F{\"5. Chunking\"}\n    G@{ shape: tag-proc, label: \"6a. Hybrid Chunking&lt;br/&gt;Semantic + Token-Aware\" }\n    H@{ shape: tag-proc, label: \"6b. Full Document&lt;br/&gt;Context Window Permitting\" }\n\n    I@{ shape: procs, label: \"7. Batch Extraction&lt;br/&gt;LLM Inference\" }\n\n    %% Convergence &amp; Validation\n    J@{ shape: tag-proc, label: \"8. Pydantic Validation&lt;br/&gt;Per-Chunk/Page Check\" }\n\n    K{\"9. Consolidation\"}\n\n    L@{ shape: lin-proc, label: \"10a. Smart Merge&lt;br/&gt;Programmatic/Reduce\" }\n    M@{ shape: lin-proc, label: \"10b. LLM Consolidation&lt;br/&gt;Refinement Loop\" }\n\n    %% Graph &amp; Export\n    N@{ shape: procs, label: \"11. Graph Conversion&lt;br/&gt;Pydantic \u2192 NetworkX\" }\n    O@{ shape: tag-proc, label: \"12. Node ID Generation&lt;br/&gt;Stable Hashing\" }\n\n    P@{ shape: tag-proc, label: \"13. Export&lt;br/&gt;CSV/Cypher/JSON\" }\n    Q@{ shape: tag-proc, label: \"14. Visualization&lt;br/&gt;HTML + Reports\" }\n\n    %% 3. Define Connections\n    A --&gt; A1\n    A1 --&gt; A2\n\n    %% Routing Inputs\n    A2 -- \"PDF/Image\" --&gt; B\n    A2 -- \"Text/MD\" --&gt; B2\n    A2 -- \"DoclingDoc\" --&gt; B3\n\n    %% Routing to Backend Strategy\n    B --&gt; C\n    B2 &amp; B3 --&gt; E\n\n    %% Backend Decisions\n    C -- VLM --&gt; D\n    C -- LLM --&gt; E\n\n    %% LLM Path: Markdown -&gt; Chunking -&gt; Extraction\n    E --&gt; F\n    F -- Yes --&gt; G\n    F -- No --&gt; H\n\n    G --&gt; I\n    H --&gt; I\n\n    %% VLM Path: Direct to Validation (Skips Chunking)\n    D --&gt; J\n\n    %% LLM Path: Join Validation\n    I --&gt; J\n\n    %% Consolidation\n    J --&gt; K\n    K -- \"Rule-Based\" --&gt; L\n    K -- \"AI-Based\" --&gt; M\n\n    %% Final Stages\n    L --&gt; N\n    M --&gt; N\n\n    N --&gt; O\n    O --&gt; P\n    P --&gt; Q\n\n    %% 4. Apply Classes\n    class A input\n    class A1,B,I,N process\n    class B2,B3,D,E,L,M process\n    class A2,C,F,K decision\n    class G,H,J,O operator\n    class P,Q output</code></pre>"},{"location":"introduction/architecture/#stage-by-stage-breakdown","title":"Stage-by-Stage Breakdown","text":""},{"location":"introduction/architecture/#stage-1-template-loading","title":"Stage 1: Template Loading","text":"<pre><code># Load Pydantic template\ntemplate = import_template(\"module.Template\")\n# Validate structure\nvalidate_template(template)\n</code></pre>"},{"location":"introduction/architecture/#stage-2-document-conversion","title":"Stage 2: Document Conversion","text":"<pre><code># Convert using Docling\ndoc = processor.convert_to_docling_doc(source)\n# Extract markdown\nmarkdown = processor.extract_full_markdown(doc)\n</code></pre>"},{"location":"introduction/architecture/#stage-3-extraction","title":"Stage 3: Extraction","text":"<pre><code># Choose backend\nif backend == \"vlm\":\n    models = vlm_backend.extract_from_document(source, template)\nelse:\n    models = llm_backend.extract_from_markdown(markdown, template)\n</code></pre>"},{"location":"introduction/architecture/#stage-4-consolidation-if-needed","title":"Stage 4: Consolidation (if needed)","text":"<pre><code>if len(models) &gt; 1:\n    final_model = programmatic_merge(models)\n</code></pre>"},{"location":"introduction/architecture/#stage-5-graph-conversion","title":"Stage 5: Graph Conversion","text":"<pre><code># Convert to graph\ngraph, metadata = converter.pydantic_list_to_graph([final_model])\n</code></pre>"},{"location":"introduction/architecture/#stage-6-export","title":"Stage 6: Export","text":"<pre><code># Export in multiple formats\ncsv_exporter.export(graph, output_dir)\ncypher_exporter.export(graph, output_dir)\njson_exporter.export(graph, output_dir)\n</code></pre>"},{"location":"introduction/architecture/#protocol-based-design","title":"Protocol-Based Design","text":"<p>Docling Graph uses Python Protocols for type-safe, flexible interfaces:</p> <pre><code>class ExtractionBackendProtocol(Protocol):\n    \"\"\"Protocol for extraction backends\"\"\"\n    def extract_from_document(self, source: str, template: Type[BaseModel]) -&gt; List[BaseModel]: ...\n</code></pre> <p>Benefits: Type safety, easy mocking, clear contracts, flexible implementations</p> <p>Location: <code>docling_graph/config.py</code></p> <p>Purpose: Type-safe configuration using Pydantic</p> <pre><code>class PipelineConfig(BaseModel):\n    \"\"\"Single source of truth for all defaults\"\"\"\n    source: str\n    template: Union[str, Type[BaseModel]]\n    backend: Literal[\"llm\", \"vlm\"] = \"llm\"\n    inference: Literal[\"local\", \"remote\"] = \"local\"\n    processing_mode: Literal[\"one-to-one\", \"many-to-one\"] = \"many-to-one\"\n    use_chunking: bool = True\n    export_format: Literal[\"csv\", \"cypher\"] = \"csv\"\n    output_dir: str = \"outputs\"\n    # ... additional settings\n</code></pre>"},{"location":"introduction/architecture/#error-handling","title":"Error Handling","text":"<p>Location: <code>docling_graph/exceptions.py</code></p> <p>Hierarchy: <pre><code>DoclingGraphError (base)\n\u251c\u2500\u2500 ConfigurationError\n\u251c\u2500\u2500 ClientError\n\u251c\u2500\u2500 ExtractionError\n\u251c\u2500\u2500 ValidationError\n\u251c\u2500\u2500 GraphError\n\u2514\u2500\u2500 PipelineError\n</code></pre></p> <p>Structured Errors: <pre><code>try:\n    run_pipeline(config)\nexcept ClientError as e:\n    print(f\"Error: {e.message}\")\n    print(f\"Details: {e.details}\")\n    print(f\"Cause: {e.cause}\")\n</code></pre></p>"},{"location":"introduction/architecture/#extensibility","title":"Extensibility","text":"<p>Docling Graph is designed for extension:</p> <ul> <li>LLM Providers: Implement <code>LLMClientProtocol</code></li> <li>Pipeline Stages: Implement <code>PipelineStage</code></li> <li>Export Formats: Extend <code>BaseExporter</code></li> </ul> <p>See Custom Backends for details.</p> <p>Now that you understand the architecture:</p> <ol> <li>Installation - Set up your environment</li> <li>Schema Definition - Create Pydantic templates</li> <li>Pipeline Configuration - Configure the pipeline</li> </ol>"},{"location":"introduction/key-concepts/","title":"Key Concepts","text":""},{"location":"introduction/key-concepts/#core-terminology","title":"Core Terminology","text":""},{"location":"introduction/key-concepts/#entity","title":"Entity","text":"<p>An entity is a unique, identifiable object that you want to track individually in your knowledge graph.</p> <p>Characteristics: - Has a stable identity (defined by <code>graph_id_fields</code>) - Represents real-world objects (people, organizations, documents) - Tracked individually even if properties are similar</p> <p>Example: <pre><code>class Person(BaseModel):\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['name', 'date_of_birth']\n    }\n    name: str\n    date_of_birth: str\n    email: str\n</code></pre></p> <p>Two persons with the same name but different birth dates are different entities.</p>"},{"location":"introduction/key-concepts/#component","title":"Component","text":"<p>A component is a value object that is deduplicated by its content.</p> <p>Characteristics: - No unique identity (set <code>is_entity=False</code>) - Represents shared values (addresses, amounts, measurements) - Identical components share the same graph node</p> <p>Example: <pre><code>class Address(BaseModel):\n    model_config = {'is_entity': False'}\n    street: str\n    city: str\n    postal_code: str\n</code></pre></p> <p>Two people at \"123 Main St, Boston, 02101\" share the same Address node.</p>"},{"location":"introduction/key-concepts/#node","title":"Node","text":"<p>A node is a vertex in the knowledge graph. Every Pydantic model instance becomes a node.</p> <p>Node Properties: - ID: Unique identifier (generated from <code>graph_id_fields</code> or content hash) - Type: The Pydantic class name (e.g., \"Person\", \"Organization\") - Attributes: All field values from the Pydantic model</p> <p>Example Node: <pre><code>ID: Person_JohnDoe_1990-01-15\nType: Person\nAttributes:\n  - name: \"John Doe\"\n  - date_of_birth: \"1990-01-15\"\n  - email: \"john@example.com\"\n</code></pre></p>"},{"location":"introduction/key-concepts/#edge","title":"Edge","text":"<p>An edge is a directed relationship between two nodes in the graph.</p> <p>Edge Properties: - Source: The node where the relationship starts - Target: The node where the relationship ends - Label: The relationship type (e.g., \"ISSUED_BY\", \"SENT_TO\") - Direction: Edges are directional (A \u2192 B is different from B \u2192 A)</p> <p>Example Edge: <pre><code>Source: Document_INV001\nLabel: ISSUED_BY\nTarget: Organization_AcmeCorp\n</code></pre></p> <p>This represents: \"Document INV001 was issued by Acme Corp\"</p>"},{"location":"introduction/key-concepts/#graph","title":"Graph","text":"<p>A graph is the complete network of nodes and edges representing your extracted knowledge.</p> <p>Graph Structure: <pre><code>Document_INV001\n  \u251c\u2500 ISSUED_BY \u2192 Organization_AcmeCorp\n  \u251c\u2500 SENT_TO \u2192 Person_JohnDoe\n  \u2514\u2500 CONTAINS_LINE \u2192 LineItem_001\n      \u2514\u2500 HAS_PRODUCT \u2192 Product_Widget\n</code></pre></p>"},{"location":"introduction/key-concepts/#pydantic-templates","title":"Pydantic Templates","text":""},{"location":"introduction/key-concepts/#what-is-a-template","title":"What is a Template?","text":"<p>A Pydantic template is a Python class that serves three purposes:</p> <ol> <li>Extraction Schema: Tells the LLM/VLM what data to extract</li> <li>Validation Rules: Ensures data quality and consistency</li> <li>Graph Structure: Defines how entities and relationships map to nodes and edges</li> </ol>"},{"location":"introduction/key-concepts/#template-example","title":"Template Example","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import List\n\ndef edge(label: str, **kwargs):\n    \"\"\"Helper to define graph relationships\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\nclass Organization(BaseModel):\n    \"\"\"An organization entity\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['name']\n    }\n\n    name: str = Field(\n        description=\"Legal name of the organization\",\n        examples=[\"Acme Corp\", \"Tech Solutions Ltd\"]\n    )\n\n    tax_id: str = Field(\n        description=\"Tax identification number\",\n        examples=[\"123456789\", \"FR12345678901\"]\n    )\n\nclass Invoice(BaseModel):\n    \"\"\"An invoice document\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['invoice_number']\n    }\n\n    invoice_number: str = Field(\n        description=\"Unique invoice identifier\",\n        examples=[\"INV-2024-001\", \"INV-123456\"]\n    )\n\n    # This creates an edge in the graph\n    issuer: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Organization that issued this invoice\"\n    )\n</code></pre> <p>Result: When extracted, this creates: - An <code>Invoice</code> node - An <code>Organization</code> node - An <code>ISSUED_BY</code> edge connecting them</p>"},{"location":"introduction/key-concepts/#extraction-backends","title":"Extraction Backends","text":""},{"location":"introduction/key-concepts/#vlm-vision-language-model","title":"VLM (Vision-Language Model)","text":"<p>What: Uses Docling's NuExtract models to extract data directly from document images.</p> <p>Best For: - Structured forms (invoices, ID cards, receipts) - Documents with clear key-value pairs - Small documents (1-3 pages)</p> <p>Characteristics: - Processes documents directly (no markdown conversion) - Local inference only - Fast for small documents - Excellent for forms</p>"},{"location":"introduction/key-concepts/#llm-large-language-model","title":"LLM (Large Language Model)","text":"<p>What: Uses language models to extract data from markdown/text representations.</p> <p>Best For: - Complex narratives (rheology researchs, reports) - Large documents (5+ pages) - Documents requiring deep understanding</p> <p>Characteristics: - Requires markdown conversion first - Local (vLLM, Ollama) or remote (OpenAI, Mistral, Gemini, WatsonX) - Supports chunking for large documents - Better for complex extraction</p>"},{"location":"introduction/key-concepts/#processing-modes","title":"Processing Modes","text":""},{"location":"introduction/key-concepts/#one-to-one","title":"One-to-One","text":"<p>What: Process each page independently, producing one Pydantic model per page.</p> <p>When to Use: - Each page contains independent information - Document is a batch of separate items (e.g., multiple invoices in one PDF) - You need page-level granularity</p> <p>Example: <pre><code>3-page PDF with 3 invoices\n\u2192 3 separate Invoice models\n\u2192 3 separate subgraphs\n</code></pre></p>"},{"location":"introduction/key-concepts/#many-to-one","title":"Many-to-One","text":"<p>What: Process all pages together, producing one merged Pydantic model for the entire document.</p> <p>When to Use: - Document spans multiple pages with related content - Information flows across pages - You want a document-level view</p> <p>Example: <pre><code>10-page rheology research\n\u2192 1 merged ResearchPaper model\n\u2192 1 unified graph\n</code></pre></p>"},{"location":"introduction/key-concepts/#chunking","title":"Chunking","text":""},{"location":"introduction/key-concepts/#why-chunking","title":"Why Chunking?","text":"<p>Large documents may exceed LLM context limits. Chunking splits the document into manageable pieces while preserving semantic coherence.</p>"},{"location":"introduction/key-concepts/#hybrid-chunking-strategy","title":"Hybrid Chunking Strategy","text":"<p>Docling Graph uses a sophisticated approach:</p> <ol> <li>Docling Segmentation: Respects document structure (sections, tables, lists)</li> <li>Semantic Boundaries: Groups related content together</li> <li>Token-Aware: Respects LLM context limits</li> <li>Context Preservation: Maintains coherence across chunks</li> </ol>"},{"location":"introduction/key-concepts/#consolidation","title":"Consolidation","text":"<p>After extracting from multiple chunks, results must be merged:</p> <p>Programmatic Merge (Fast): - Lists: Concatenate and deduplicate - Scalars: First non-null value wins - Objects: Recursive merge</p> <p>LLM Consolidation (Intelligent): - Uses LLM to intelligently merge results - Better handles semantic duplicates - Slower but more accurate</p>"},{"location":"introduction/key-concepts/#graph-construction","title":"Graph Construction","text":""},{"location":"introduction/key-concepts/#node-id-generation","title":"Node ID Generation","text":"<p>For Entities (with <code>graph_id_fields</code>): <pre><code># Person with graph_id_fields=['name', 'dob']\nPerson(name=\"John Doe\", dob=\"1990-01-15\")\n\u2192 Node ID: \"Person_JohnDoe_1990-01-15\"\n</code></pre></p> <p>For Components (content-based): <pre><code># Address with is_entity=False\nAddress(street=\"123 Main St\", city=\"Boston\")\n\u2192 Node ID: \"Address_{content_hash}\"\n</code></pre></p>"},{"location":"introduction/key-concepts/#deduplication","title":"Deduplication","text":"<p>Entities: Deduplicated by <code>graph_id_fields</code> - Same ID fields \u2192 Same node</p> <p>Components: Deduplicated by content - Same field values \u2192 Same node</p>"},{"location":"introduction/key-concepts/#example-graph","title":"Example Graph","text":"<p>Given these models:</p> <pre><code>author1 = Author(name=\"Dr. Smith\")\nauthor2 = Author(name=\"Dr. Jones\")\npaper = Paper(\n    title=\"Advanced AI\",\n    authors=[author1, author2]\n)\n</code></pre> <p>Resulting graph:</p> <pre><code>Paper_AdvancedAI\n  \u251c\u2500 HAS_AUTHOR \u2192 Author_DrSmith\n  \u2514\u2500 HAS_AUTHOR \u2192 Author_DrJones\n</code></pre>"},{"location":"introduction/key-concepts/#export-formats","title":"Export Formats","text":""},{"location":"introduction/key-concepts/#csv","title":"CSV","text":"<ul> <li>Purpose: Neo4j bulk import</li> <li>Files: <code>nodes.csv</code>, <code>edges.csv</code></li> <li>Best For: Production database loading</li> </ul>"},{"location":"introduction/key-concepts/#cypher","title":"Cypher","text":"<ul> <li>Purpose: Neo4j script execution</li> <li>Files: <code>document_graph.cypher</code></li> <li>Best For: Development and incremental updates</li> </ul>"},{"location":"introduction/key-concepts/#json","title":"JSON","text":"<ul> <li>Purpose: General-purpose data exchange</li> <li>Files: <code>graph.json</code></li> <li>Best For: API integration, archival</li> </ul>"},{"location":"introduction/key-concepts/#html","title":"HTML","text":"<ul> <li>Purpose: Interactive visualization</li> <li>Files: <code>graph.html</code></li> <li>Best For: Exploration and presentation</li> </ul>"},{"location":"introduction/key-concepts/#next-steps","title":"Next Steps","text":"<p>Now that you understand the core concepts:</p> <ol> <li>Use Cases - See domain-specific examples</li> <li>Architecture - Understand system design</li> <li>Installation - Set up your environment</li> </ol>"},{"location":"introduction/quickstart/","title":"Quickstart","text":""},{"location":"introduction/quickstart/#overview","title":"Overview","text":"<p>Get started with docling-graph in 5 minutes by extracting structured data from a simple billing document.</p> <p>What You'll Learn: - Basic template creation - Running your first extraction - Viewing results</p> <p>Prerequisites: - Python 3.10+ - A sample billing document (PDF or image)</p>"},{"location":"introduction/quickstart/#step-1-installation","title":"Step 1: Installation","text":"<pre><code>pip install docling-graph\n\n# Verify installation\ndocling-graph --version\n</code></pre>"},{"location":"introduction/quickstart/#step-2-create-a-template","title":"Step 2: Create a Template","text":"<p>Create a file <code>simple_billing_doc.py</code>:</p> <pre><code>\"\"\"Simple billing document template for quickstart.\"\"\"\n\nfrom pydantic import BaseModel, Field\n\nclass SimpleBillingDoc(BaseModel):\n    \"\"\"A simple billing document model.\"\"\"\n\n    document_no: str = Field(\n        description=\"The unique document identifier\",\n        examples=[\"INV-001\", \"2024-001\"]\n    )\n\n    date: str = Field(\n        description=\"Document date in any format\",\n        examples=[\"2024-01-15\", \"January 15, 2024\"]\n    )\n\n    total: float = Field(\n        description=\"Total amount to be paid\",\n        examples=[1234.56, 999.99]\n    )\n\n    currency: str = Field(\n        description=\"Currency code\",\n        examples=[\"USD\", \"EUR\", \"GBP\"]\n    )\n</code></pre>"},{"location":"introduction/quickstart/#step-3-run-extraction","title":"Step 3: Run Extraction","text":""},{"location":"introduction/quickstart/#option-a-using-cli","title":"Option A: Using CLI","text":"<pre><code># Process billing document\ndocling-graph convert billing_doc.pdf \\\n    --template \"simple_billing_doc.SimpleBillingDoc\" \\\n    --output-dir \"quickstart_output\"\n</code></pre>"},{"location":"introduction/quickstart/#option-b-using-python-api","title":"Option B: Using Python API","text":"<p>Create <code>run_quickstart.py</code>:</p> <pre><code>\"\"\"Quickstart extraction script.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\n\n# Configure pipeline\nconfig = PipelineConfig(\n    source=\"billing_doc.pdf\",\n    template=\"simple_billing_doc.SimpleBillingDoc\"\n)\n\n# Run extraction\nprint(\"Processing billing document...\")\ncontext = run_pipeline(config)\ngraph = context.knowledge_graph\nprint(f\"\u2705 Complete! Extracted {graph.number_of_nodes()} nodes\")\n</code></pre> <p>Run it:</p> <pre><code>python run_quickstart.py\n</code></pre>"},{"location":"introduction/quickstart/#troubleshooting","title":"Troubleshooting","text":"<p>Template Not Found: <pre><code># Ensure template is in current directory or use absolute path\ndocling-graph convert billing_doc.pdf --template \"$(pwd)/simple_billing_doc.SimpleBillingDoc\"\n</code></pre></p> <p>No Data Extracted: <pre><code># Use verbose logging to debug\ndocling-graph --verbose convert billing_doc.pdf --template simple_billing_doc.SimpleBillingDoc\n</code></pre></p> <p>API Key Error: <pre><code># Use local inference (default) or set API key\nexport MISTRAL_API_KEY='your-key'\n</code></pre></p>"},{"location":"introduction/quickstart/#improve-your-template","title":"Improve Your Template","text":"<p>Add more fields:</p> <pre><code>class ImprovedBillingDoc(BaseModel):\n    \"\"\"Improved billing document with more fields.\"\"\"\n\n    document_no: str = Field(description=\"Document number\")\n    date: str = Field(description=\"Document date\")\n    total: float = Field(description=\"Total amount\")\n    currency: str = Field(description=\"Currency\")\n\n    # New fields\n    issuer_name: str = Field(\n        description=\"Company that issued the document\",\n        examples=[\"Acme Corp\", \"ABC Company\"]\n    )\n\n    client_name: str = Field(\n        description=\"Client receiving the document\",\n        examples=[\"John Doe\", \"XYZ Inc\"]\n    )\n\n    subtotal: float = Field(\n        description=\"Amount before tax\",\n        examples=[1000.00]\n    )\n\n    tax_amount: float = Field(\n        description=\"Tax amount\",\n        examples=[234.56]\n    )\n</code></pre>"},{"location":"introduction/quickstart/#add-relationships","title":"Add Relationships","text":"<p>Create nested entities:</p> <pre><code>class Address(BaseModel):\n    \"\"\"Address component.\"\"\"\n    street: str\n    city: str\n    postal_code: str\n\nclass Organization(BaseModel):\n    \"\"\"Organization entity.\"\"\"\n    name: str\n    address: Address\n\ndef edge(label: str, **kwargs):\n    \"\"\"Helper for graph edges.\"\"\"\n    from pydantic import Field\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\nclass BillingDoc(BaseModel):\n    \"\"\"Billing document with relationships.\"\"\"\n    document_no: str\n    total: float\n    issued_by: Organization = edge(label=\"ISSUED_BY\")\n</code></pre>"},{"location":"introduction/quickstart/#try-different-backends","title":"Try Different Backends","text":"<pre><code># VLM for images (faster)\ndocling-graph convert billing_doc.jpg \\\n    --template \"simple_billing_doc.SimpleBillingDoc\" \\\n    --backend vlm\n\n# LLM for complex documents\ndocling-graph convert billing_doc.pdf \\\n    --template \"simple_billing_doc.SimpleBillingDoc\" \\\n    --backend llm \\\n    --inference remote\n</code></pre>"},{"location":"introduction/quickstart/#learn-more","title":"Learn More","text":"<ul> <li>Billing Document Extraction - Full billing document with relationships</li> <li>Schema Definition - Template creation guide</li> <li>CLI Reference - All CLI commands</li> </ul>"},{"location":"introduction/use-cases/","title":"Use Cases","text":""},{"location":"introduction/use-cases/#why-domain-specific-knowledge-graphs","title":"Why Domain-Specific Knowledge Graphs?","text":"<p>Different domains have unique requirements for knowledge representation:</p> <ul> <li>Chemistry: Track exact molecular structures and reaction conditions</li> <li>Finance: Map complex instrument dependencies and risk relationships</li> <li>Legal: Maintain precise contractual obligations and party relationships</li> <li>Research: Connect methodologies, results, and citations with full context</li> </ul> <p>Traditional text embeddings lose these precise relationships. Knowledge graphs preserve them.</p>"},{"location":"introduction/use-cases/#chemistry-materials-science","title":"Chemistry &amp; Materials Science","text":"<p>Extract materials, measurements, and experimental relationships from rheology researchs.</p> <p>Key Entities: Material, Measurement, Experiment Relationships: USES_MATERIAL, HAS_MEASUREMENT Use Case: Track exact material-property relationships and experimental conditions</p>"},{"location":"introduction/use-cases/#finance-legal","title":"Finance &amp; Legal","text":"<p>Extract parties, obligations, and contractual relationships from legal documents.</p> <p>Key Entities: Party, Obligation, Contract Relationships: OBLIGATED_BY, OBLIGATED_TO, HAS_PARTY Use Case: Track party-obligation relationships and contractual dependencies</p>"},{"location":"introduction/use-cases/#research-academia","title":"Research &amp; Academia","text":"<p>Extract authors, methodologies, and findings from academic papers.</p> <p>Key Entities: Author, Methodology, Result, ResearchPaper Relationships: HAS_AUTHOR, USES_METHODOLOGY, HAS_RESULT Use Case: Track author collaboration networks and research methodologies</p>"},{"location":"introduction/use-cases/#healthcare-medical","title":"Healthcare &amp; Medical","text":"<p>Extract patient information, diagnoses, and treatments from medical records.</p> <p>Key Entities: Patient, Diagnosis, Treatment, MedicalRecord Relationships: FOR_PATIENT, HAS_DIAGNOSIS, HAS_TREATMENT Use Case: Track patient-diagnosis-treatment relationships</p>"},{"location":"introduction/use-cases/#insurance-risk","title":"Insurance &amp; Risk","text":"<p>Extract coverage details, exclusions, and policy relationships.</p> <p>Key Entities: Coverage, Exclusion, InsurancePolicy Relationships: HELD_BY, PROVIDES_COVERAGE, HAS_EXCLUSION Use Case: Track policy-coverage relationships and risk exposure</p>"},{"location":"introduction/use-cases/#common-patterns","title":"Common Patterns","text":""},{"location":"introduction/use-cases/#document-entities-properties","title":"\ud83d\udccd Document \u2192 Entities \u2192 Properties","text":"<pre><code>Document\n  \u251c\u2500 HAS_ENTITY \u2192 Entity1\n  \u2502   \u251c\u2500 HAS_PROPERTY \u2192 Property1\n  \u2502   \u2514\u2500 HAS_PROPERTY \u2192 Property2\n  \u2514\u2500 HAS_ENTITY \u2192 Entity2\n      \u2514\u2500 HAS_PROPERTY \u2192 Property3\n</code></pre> <p>Used in: Rheology researchs, technical reports, specifications</p>"},{"location":"introduction/use-cases/#party-relationship-party","title":"\ud83d\udccd Party \u2192 Relationship \u2192 Party","text":"<pre><code>Party1 \u2500[RELATIONSHIP]\u2192 Party2\n</code></pre> <p>Used in: Contracts, agreements, organizational charts</p>"},{"location":"introduction/use-cases/#process-steps-outcomes","title":"\ud83d\udccd Process \u2192 Steps \u2192 Outcomes","text":"<pre><code>Process\n  \u251c\u2500 HAS_STEP \u2192 Step1\n  \u251c\u2500 HAS_STEP \u2192 Step2\n  \u2514\u2500 HAS_OUTCOME \u2192 Outcome\n</code></pre> <p>Used in: Procedures, experiments, workflows</p>"},{"location":"introduction/use-cases/#pattern-4-hierarchical-structures","title":"Pattern 4: Hierarchical Structures","text":"<pre><code>Parent\n  \u251c\u2500 HAS_CHILD \u2192 Child1\n  \u2502   \u2514\u2500 HAS_CHILD \u2192 Grandchild1\n  \u2514\u2500 HAS_CHILD \u2192 Child2\n</code></pre> <p>Used in: Organizational structures, document sections, taxonomies</p>"},{"location":"introduction/use-cases/#choosing-your-use-case","title":"Choosing Your Use Case","text":"<p>Questions to Ask:</p> <ol> <li>What entities do I need to track?</li> <li>What relationships matter?</li> <li>What queries will I run?</li> <li>What level of detail do I need?</li> </ol> <p>Ready to implement your use case?</p> <ol> <li>Schema Definition - Create your Pydantic templates</li> <li>Examples - See complete working examples</li> <li>Architecture - Understand the system design</li> </ol>"},{"location":"reference/","title":"API Reference","text":""},{"location":"reference/#overview","title":"Overview","text":"<p>Complete API reference for docling-graph modules, classes, and functions.</p> <p>What's Included: - Pipeline API - Configuration classes - Protocol definitions - Exception hierarchy - Converter classes - Extractor classes - Exporter classes - LLM client interfaces</p>"},{"location":"reference/#quick-links","title":"Quick Links","text":""},{"location":"reference/#core-apis","title":"Core APIs","text":"<p>Pipeline API Main entry point for document processing.</p> <ul> <li><code>run_pipeline()</code> - Execute the pipeline</li> <li>Pipeline stages and orchestration</li> </ul> <p>Configuration API Type-safe configuration classes.</p> <ul> <li><code>PipelineConfig</code> - Main configuration class</li> <li><code>ModelConfig</code> - Model configuration</li> <li><code>LLMConfig</code> / <code>VLMConfig</code> - Backend configs</li> </ul> <p>Protocols Protocol definitions for type-safe interfaces.</p> <ul> <li><code>ExtractionBackendProtocol</code> - VLM backends</li> <li><code>TextExtractionBackendProtocol</code> - LLM backends</li> <li><code>LLMClientProtocol</code> - LLM clients</li> <li><code>ExtractorProtocol</code> - Extraction strategies</li> </ul> <p>Exceptions Exception hierarchy and error handling.</p> <ul> <li><code>DoclingGraphError</code> - Base exception</li> <li><code>ConfigurationError</code> - Config errors</li> <li><code>ClientError</code> - API errors</li> <li><code>ExtractionError</code> - Extraction failures</li> <li><code>ValidationError</code> - Data validation</li> <li><code>GraphError</code> - Graph operations</li> <li><code>PipelineError</code> - Pipeline execution</li> </ul>"},{"location":"reference/#processing-apis","title":"Processing APIs","text":"<p>Converters Graph conversion from Pydantic models.</p> <ul> <li><code>GraphConverter</code> - Convert models to graphs</li> <li><code>NodeIDRegistry</code> - Stable node IDs</li> <li>Graph construction utilities</li> </ul> <p>Extractors Document extraction strategies.</p> <ul> <li><code>OneToOne</code> - Per-page extraction</li> <li><code>ManyToOne</code> - Consolidated extraction</li> <li>Backend implementations</li> <li>Chunking and batching</li> </ul> <p>Exporters Graph export formats.</p> <ul> <li><code>CSVExporter</code> - Neo4j-compatible CSV</li> <li><code>CypherExporter</code> - Cypher scripts</li> <li><code>JSONExporter</code> - JSON format</li> <li><code>DoclingExporter</code> - Docling documents</li> </ul> <p>LLM Clients LiteLLM-backed client for all LLM calls.</p> <ul> <li><code>LiteLLMClient</code> - Provider-agnostic client</li> </ul>"},{"location":"reference/#module-structure","title":"Module Structure","text":"<pre><code>docling_graph/\n\u251c\u2500\u2500 __init__.py              # Public API exports\n\u251c\u2500\u2500 pipeline.py              # run_pipeline()\n\u251c\u2500\u2500 config.py                # PipelineConfig\n\u251c\u2500\u2500 protocols.py             # Protocol definitions\n\u251c\u2500\u2500 exceptions.py            # Exception hierarchy\n\u2502\n\u251c\u2500\u2500 core/                    # Core processing\n\u2502   \u251c\u2500\u2500 converters/          # Graph conversion\n\u2502   \u251c\u2500\u2500 extractors/          # Extraction strategies\n\u2502   \u251c\u2500\u2500 exporters/           # Export formats\n\u2502   \u2514\u2500\u2500 visualizers/         # Visualization\n\u2502\n\u251c\u2500\u2500 llm_clients/             # LLM integrations\n\u2502   \u251c\u2500\u2500 base.py\n\u2502   \u251c\u2500\u2500 ollama.py\n\u2502   \u251c\u2500\u2500 mistral.py\n\u2502   \u251c\u2500\u2500 openai.py\n\u2502   \u251c\u2500\u2500 gemini.py\n\u2502   \u2514\u2500\u2500 vllm.py\n\u2502\n\u2514\u2500\u2500 pipeline/                # Pipeline orchestration\n    \u251c\u2500\u2500 context.py\n    \u251c\u2500\u2500 stages.py\n    \u2514\u2500\u2500 orchestrator.py\n</code></pre>"},{"location":"reference/#import-patterns","title":"Import Patterns","text":""},{"location":"reference/#basic-imports","title":"Basic Imports","text":"<pre><code># Main API\nfrom docling_graph import run_pipeline, PipelineConfig\n\n# Configuration classes\nfrom docling_graph import (\n    LLMConfig,\n    VLMConfig,\n    ModelConfig,\n    ModelsConfig\n)\n</code></pre>"},{"location":"reference/#advanced-imports","title":"Advanced Imports","text":"<pre><code># Protocols\nfrom docling_graph.protocols import (\n    ExtractionBackendProtocol,\n    TextExtractionBackendProtocol,\n    LLMClientProtocol\n)\n\n# Exceptions\nfrom docling_graph.exceptions import (\n    DoclingGraphError,\n    ConfigurationError,\n    ClientError,\n    ExtractionError,\n    ValidationError,\n    GraphError,\n    PipelineError\n)\n\n# Converters\nfrom docling_graph.core.converters import GraphConverter\n\n# Extractors\nfrom docling_graph.core.extractors import OneToOne, ManyToOne\n\n# Exporters\nfrom docling_graph.core.exporters import (\n    CSVExporter,\n    CypherExporter,\n    JSONExporter\n)\n</code></pre>"},{"location":"reference/#type-hints","title":"Type Hints","text":""},{"location":"reference/#common-types","title":"Common Types","text":"<pre><code>from typing import Any, Dict, List, Type, Union\nfrom pathlib import Path\nfrom pydantic import BaseModel\nimport networkx as nx\n\n# Configuration\nconfig: PipelineConfig\nconfig_dict: Dict[str, Any]\n\n# Templates\ntemplate: Type[BaseModel]\nmodel_instance: BaseModel\nmodels: List[BaseModel]\n\n# Graphs\ngraph: nx.MultiDiGraph\n\n# Paths\nsource: Union[str, Path]\noutput_dir: Path\n</code></pre>"},{"location":"reference/#version-information","title":"Version Information","text":"<pre><code>import docling_graph\n\n# Get version\nprint(docling_graph.__version__)  # e.g., \"v1.2.0\"\n\n# Check available exports\nprint(docling_graph.__all__)\n# ['run_pipeline', 'PipelineConfig', 'LLMConfig', ...]\n</code></pre>"},{"location":"reference/#api-stability","title":"API Stability","text":""},{"location":"reference/#stable-apis","title":"\ud83d\udfe2 Stable APIs","text":"<p>These APIs are stable and safe to use:</p> <ul> <li><code>run_pipeline()</code></li> <li><code>PipelineConfig</code></li> <li>All configuration classes</li> <li>Exception hierarchy</li> <li>Public protocols</li> </ul>"},{"location":"reference/#internal-apis","title":"\ud83d\udfe3 Internal APIs","text":"<p>These are internal and may change:</p> <ul> <li><code>pipeline.orchestrator</code> internals</li> <li><code>core.extractors.backends</code> internals</li> <li><code>core.utils</code> modules</li> </ul>"},{"location":"reference/#experimental","title":"\ud83d\udfe1 Experimental","text":"<p>These are experimental:</p> <ul> <li>Custom stage APIs</li> <li>Advanced pipeline customization</li> </ul>"},{"location":"reference/#deprecation-policy","title":"Deprecation Policy","text":"<p>Deprecated features will:</p> <ol> <li>Be marked with <code>@deprecated</code> decorator</li> <li>Emit <code>DeprecationWarning</code></li> <li>Be documented in CHANGELOG</li> <li>Be removed after 2 minor versions</li> </ol> <p>Example:</p> <pre><code>import warnings\n\n@deprecated(\"Use PipelineConfig instead\")\ndef old_function():\n    warnings.warn(\n        \"old_function is deprecated, use PipelineConfig\",\n        DeprecationWarning,\n        stacklevel=2\n    )\n</code></pre>"},{"location":"reference/#api-design-principles","title":"API Design Principles","text":""},{"location":"reference/#1-type-safety","title":"1. Type Safety","text":"<p>All public APIs use type hints:</p> <pre><code>def run_pipeline(config: Union[PipelineConfig, Dict[str, Any]]) -&gt; PipelineContext:\n    \"\"\"Type-safe function signature; returns pipeline context with graph and results.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#2-pydantic-validation","title":"2. Pydantic Validation","text":"<p>Configuration uses Pydantic for validation:</p> <pre><code>config = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\"  # Validated at runtime\n)\n</code></pre>"},{"location":"reference/#3-protocol-based","title":"3. Protocol-Based","text":"<p>Extensibility through protocols:</p> <pre><code>class MyBackend(TextExtractionBackendProtocol):\n    \"\"\"Custom backend implementing protocol.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#4-structured-exceptions","title":"4. Structured Exceptions","text":"<p>Clear error hierarchy:</p> <pre><code>try:\n    run_pipeline(config)\nexcept ConfigurationError as e:\n    print(f\"Config error: {e.message}\")\n    print(f\"Details: {e.details}\")\n</code></pre>"},{"location":"reference/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"local\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"reference/#advanced-usage","title":"Advanced Usage","text":"<pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import ExtractionError\n\nconfig = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"model_override\": \"mistral-small-latest\",\n    \"use_chunking\": True,\n    \"export_format\": \"cypher\"\n}\n\ntry:\n    run_pipeline(config)\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e}\")\n</code></pre>"},{"location":"reference/#api-documentation-sections","title":"API Documentation Sections","text":"<ol> <li>Pipeline API \u2192 - Main entry point</li> <li>Configuration API \u2192 - Configuration classes</li> <li>Protocols \u2192 - Protocol definitions</li> <li>Exceptions \u2192 - Exception hierarchy</li> <li>Converters \u2192 - Graph conversion</li> <li>Extractors \u2192 - Extraction strategies</li> <li>Exporters \u2192 - Export formats</li> <li>LLM Clients \u2192 - LLM integrations</li> </ol>"},{"location":"reference/#contributing","title":"Contributing","text":"<p>See Development Guide for:</p> <ul> <li>Adding new APIs</li> <li>API design guidelines</li> <li>Documentation standards</li> <li>Testing requirements</li> </ul>"},{"location":"reference/config/","title":"Configuration API","text":""},{"location":"reference/config/#overview","title":"Overview","text":"<p>Type-safe configuration classes for the docling-graph pipeline.</p> <p>Module: <code>docling_graph.config</code></p>"},{"location":"reference/config/#pipelineconfig","title":"PipelineConfig","text":"<p>Main configuration class for pipeline execution.</p> <pre><code>class PipelineConfig(BaseModel):\n    \"\"\"Type-safe configuration for the docling-graph pipeline.\"\"\"\n</code></pre>"},{"location":"reference/config/#constructor","title":"Constructor","text":"<pre><code>config = PipelineConfig(\n    source: Union[str, Path] = \"\",\n    template: Union[str, Type[BaseModel]] = \"\",\n    backend: Literal[\"llm\", \"vlm\"] = \"llm\",\n    inference: Literal[\"local\", \"remote\"] = \"local\",\n    processing_mode: Literal[\"one-to-one\", \"many-to-one\"] = \"many-to-one\",\n    extraction_contract: Literal[\"direct\", \"staged\", \"delta\"] = \"direct\",\n    docling_config: Literal[\"ocr\", \"vision\"] = \"ocr\",\n    model_override: str | None = None,\n    provider_override: str | None = None,\n    models: ModelsConfig = ModelsConfig(),\n    use_chunking: bool = True,\n    chunk_max_tokens: int | None = None,\n    debug: bool = False,\n    max_batch_size: int = 1,\n    dump_to_disk: bool | None = None,\n    export_format: Literal[\"csv\", \"cypher\"] = \"csv\",\n    export_docling: bool = True,\n    export_docling_json: bool = True,\n    export_markdown: bool = True,\n    export_per_page_markdown: bool = False,\n    reverse_edges: bool = False,\n    output_dir: Union[str, Path] = \"outputs\"\n)\n</code></pre>"},{"location":"reference/config/#fields","title":"Fields","text":""},{"location":"reference/config/#required-fields","title":"Required Fields","text":"Field Type Description <code>source</code> <code>str</code> or <code>Path</code> Path to source document <code>template</code> <code>str</code> or <code>Type[BaseModel]</code> Pydantic template class or dotted path"},{"location":"reference/config/#backend-configuration","title":"Backend Configuration","text":"Field Type Default Description <code>backend</code> <code>\"llm\"</code> or <code>\"vlm\"</code> <code>\"llm\"</code> Extraction backend type <code>inference</code> <code>\"local\"</code> or <code>\"remote\"</code> <code>\"local\"</code> Inference location <code>model_override</code> <code>str</code> or <code>None</code> <code>None</code> Override default model <code>provider_override</code> <code>str</code> or <code>None</code> <code>None</code> Override default provider <code>models</code> <code>ModelsConfig</code> <code>ModelsConfig()</code> Model configurations"},{"location":"reference/config/#processing-configuration","title":"Processing Configuration","text":"Field Type Default Description <code>processing_mode</code> <code>\"one-to-one\"</code> or <code>\"many-to-one\"</code> <code>\"many-to-one\"</code> Processing strategy <code>extraction_contract</code> <code>\"direct\"</code>, <code>\"staged\"</code>, or <code>\"delta\"</code> <code>\"direct\"</code> LLM extraction contract (<code>staged</code> is optimized for weaker models in many-to-one mode) <code>docling_config</code> <code>\"ocr\"</code> or <code>\"vision\"</code> <code>\"ocr\"</code> Docling pipeline type <code>use_chunking</code> <code>bool</code> <code>True</code> Enable document chunking <code>chunk_max_tokens</code> <code>int</code> or <code>None</code> <code>None</code> Max tokens per chunk (default 512 when chunking) <code>debug</code> <code>bool</code> <code>False</code> Enable debug artifacts <code>max_batch_size</code> <code>int</code> <code>1</code> Maximum batch size"},{"location":"reference/config/#staged-tuning-configuration","title":"Staged Tuning Configuration","text":"Field Type Default Description <code>staged_tuning_preset</code> <code>\"standard\"</code> or <code>\"advanced\"</code> <code>\"standard\"</code> Preset for staged extraction defaults <code>staged_pass_retries</code> <code>int</code> or <code>None</code> <code>None</code> Retries per staged pass (<code>None</code> uses preset) <code>parallel_workers</code> <code>int</code> or <code>None</code> <code>None</code> Parallel workers for extraction (staged fill pass and delta batch calls; <code>None</code> uses preset for staged) <code>staged_nodes_fill_cap</code> <code>int</code> or <code>None</code> <code>None</code> Max node instances per fill-pass call (<code>None</code> uses preset) <code>staged_id_shard_size</code> <code>int</code> or <code>None</code> <code>None</code> Max paths per ID-pass call (<code>0</code> = no sharding, <code>None</code> uses preset)"},{"location":"reference/config/#delta-configuration","title":"Delta Configuration","text":"<p>Delta extraction uses the same <code>parallel_workers</code> setting (see Staged Tuning above) for parallel batch calls.</p> Field Type Default Description <code>llm_batch_token_size</code> <code>int</code> <code>1024</code> Max input tokens per delta batch (new LLM call when exceeded) <code>delta_quality_require_root</code> <code>bool</code> <code>True</code> Require root instance in merged output <code>delta_quality_min_instances</code> <code>int</code> <code>1</code> Minimum node count threshold <code>delta_quality_max_parent_lookup_miss</code> <code>int</code> <code>4</code> Max parent-link misses before quality failure; <code>-1</code> disables this check <code>delta_quality_adaptive_parent_lookup</code> <code>bool</code> <code>True</code> Adaptive miss tolerance when root exists (e.g. up to half of instances, cap 300) <code>delta_quality_require_relationships</code> <code>bool</code> <code>False</code> Require at least one attached relationship/list linkage <code>delta_quality_require_structural_attachments</code> <code>bool</code> <code>False</code> Require structural attachments (avoid root-only outputs) <code>delta_normalizer_validate_paths</code> <code>bool</code> <code>True</code> Drop unknown/non-catalog paths <code>delta_normalizer_canonicalize_ids</code> <code>bool</code> <code>True</code> Normalize ID values for deterministic matching <code>delta_normalizer_strip_nested_properties</code> <code>bool</code> <code>True</code> Drop nested dict properties to keep flat graph payloads <code>delta_normalizer_attach_provenance</code> <code>bool</code> <code>True</code> Attach batch/chunk provenance to nodes/relationships <code>delta_resolvers_enabled</code> <code>bool</code> <code>True</code> Enable post-merge resolver pass <code>delta_resolvers_mode</code> <code>str</code> <code>\"semantic\"</code> Resolver mode: <code>off</code>, <code>fuzzy</code>, <code>semantic</code>, <code>chain</code> <code>delta_resolver_fuzzy_threshold</code> <code>float</code> <code>0.9</code> Fuzzy merge threshold <code>delta_resolver_semantic_threshold</code> <code>float</code> <code>0.92</code> Semantic merge threshold <code>delta_resolver_properties</code> <code>list[str]</code> <code>[]</code> Preferred properties used for resolver matching <code>delta_resolver_paths</code> <code>list[str]</code> <code>[]</code> Restrict resolver to selected catalog paths"},{"location":"reference/config/#gleaning-direct-and-delta","title":"Gleaning (direct and delta)","text":"<p>Optional second-pass extraction to improve recall. Applies to direct and delta contracts only (not staged).</p> Field Type Default Description <code>gleaning_enabled</code> <code>bool</code> <code>True</code> Run one extra extraction pass (\"what did you miss?\") and merge additional entities/relations. <code>gleaning_max_passes</code> <code>int</code> <code>1</code> Max number of gleaning passes when <code>gleaning_enabled</code> is True."},{"location":"reference/config/#export-configuration","title":"Export Configuration","text":"Field Type Default Description <code>dump_to_disk</code> <code>bool</code> or <code>None</code> <code>None</code> Control file exports. <code>None</code>=auto-detect (CLI=True, API=False), <code>True</code>=always export, <code>False</code>=never export <code>export_format</code> <code>\"csv\"</code> or <code>\"cypher\"</code> <code>\"csv\"</code> Graph export format <code>export_docling</code> <code>bool</code> <code>True</code> Export Docling outputs <code>export_docling_json</code> <code>bool</code> <code>True</code> Export Docling JSON <code>export_markdown</code> <code>bool</code> <code>True</code> Export markdown <code>export_per_page_markdown</code> <code>bool</code> <code>False</code> Export per-page markdown"},{"location":"reference/config/#graph-configuration","title":"Graph Configuration","text":"Field Type Default Description <code>reverse_edges</code> <code>bool</code> <code>False</code> Create reverse edges"},{"location":"reference/config/#output-configuration","title":"Output Configuration","text":"Field Type Default Description <code>output_dir</code> <code>str</code> or <code>Path</code> <code>\"outputs\"</code> Output directory path"},{"location":"reference/config/#methods","title":"Methods","text":""},{"location":"reference/config/#run","title":"run()","text":"<pre><code>def run(self) -&gt; None\n</code></pre> <p>Execute the pipeline with this configuration.</p> <p>Example:</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\"\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"reference/config/#to_dict","title":"to_dict()","text":"<pre><code>def to_dict(self) -&gt; Dict[str, Any]\n</code></pre> <p>Convert configuration to dictionary format.</p> <p>Returns: Dictionary with all configuration values</p> <p>Example:</p> <pre><code>config = PipelineConfig(source=\"doc.pdf\", template=\"templates.MyTemplate\")\nconfig_dict = config.to_dict()\nprint(config_dict[\"backend\"])  # \"llm\"\n</code></pre>"},{"location":"reference/config/#generate_yaml_dict","title":"generate_yaml_dict()","text":"<pre><code>@classmethod\ndef generate_yaml_dict(cls) -&gt; Dict[str, Any]\n</code></pre> <p>Generate YAML-compatible configuration dictionary with defaults.</p> <p>Returns: Dictionary suitable for YAML serialization</p>"},{"location":"reference/config/#modelsconfig","title":"ModelsConfig","text":"<p>Configuration for all model types.</p> <pre><code>class ModelsConfig(BaseModel):\n    \"\"\"Complete models configuration.\"\"\"\n\n    llm: LLMConfig = Field(default_factory=LLMConfig)\n    vlm: VLMConfig = Field(default_factory=VLMConfig)\n</code></pre>"},{"location":"reference/config/#fields_1","title":"Fields","text":"Field Type Description <code>llm</code> <code>LLMConfig</code> LLM model configuration <code>vlm</code> <code>VLMConfig</code> VLM model configuration"},{"location":"reference/config/#llmconfig","title":"LLMConfig","text":"<p>Configuration for LLM models.</p> <pre><code>class LLMConfig(BaseModel):\n    \"\"\"LLM model configurations for local and remote inference.\"\"\"\n\n    local: ModelConfig = Field(default_factory=lambda: ModelConfig(\n        model=\"ibm-granite/granite-4.0-1b\",\n        provider=\"vllm\"\n    ))\n    remote: ModelConfig = Field(default_factory=lambda: ModelConfig(\n        model=\"mistral-small-latest\",\n        provider=\"mistral\"\n    ))\n</code></pre>"},{"location":"reference/config/#fields_2","title":"Fields","text":"Field Type Default Model Default Provider <code>local</code> <code>ModelConfig</code> <code>ibm-granite/granite-4.0-1b</code> <code>vllm</code> <code>remote</code> <code>ModelConfig</code> <code>mistral-small-latest</code> <code>mistral</code>"},{"location":"reference/config/#vlmconfig","title":"VLMConfig","text":"<p>Configuration for VLM models.</p> <pre><code>class VLMConfig(BaseModel):\n    \"\"\"VLM model configuration.\"\"\"\n\n    local: ModelConfig = Field(default_factory=lambda: ModelConfig(\n        model=\"numind/NuExtract-2.0-8B\",\n        provider=\"docling\"\n    ))\n</code></pre>"},{"location":"reference/config/#fields_3","title":"Fields","text":"Field Type Default Model Default Provider <code>local</code> <code>ModelConfig</code> <code>numind/NuExtract-2.0-8B</code> <code>docling</code> <p>VLM inference</p> <p>VLM only supports local inference.</p>"},{"location":"reference/config/#modelconfig","title":"ModelConfig","text":"<p>Configuration for a specific model.</p> <pre><code>class ModelConfig(BaseModel):\n    \"\"\"Configuration for a specific model.\"\"\"\n\n    model: str = Field(..., description=\"Model name/path\")\n    provider: str = Field(..., description=\"Provider name\")\n</code></pre>"},{"location":"reference/config/#fields_4","title":"Fields","text":"Field Type Description <code>model</code> <code>str</code> Model name or path <code>provider</code> <code>str</code> Provider name (e.g., \"vllm\", \"mistral\")"},{"location":"reference/config/#backendconfig","title":"BackendConfig","text":"<p>Configuration for extraction backend (internal use).</p> <pre><code>class BackendConfig(BaseModel):\n    \"\"\"Configuration for an extraction backend.\"\"\"\n\n    provider: str = Field(..., description=\"Backend provider\")\n    model: str = Field(..., description=\"Model name or path\")\n    api_key: str | None = Field(None, description=\"API key\")\n    base_url: str | None = Field(None, description=\"Base URL\")\n</code></pre>"},{"location":"reference/config/#extractorconfig","title":"ExtractorConfig","text":"<p>Configuration for extraction strategy (internal use).</p> <pre><code>class ExtractorConfig(BaseModel):\n    \"\"\"Configuration for the extraction strategy.\"\"\"\n\n    strategy: Literal[\"many-to-one\", \"one-to-one\"] = Field(default=\"many-to-one\")\n    docling_config: Literal[\"ocr\", \"vision\"] = Field(default=\"ocr\")\n    use_chunking: bool = Field(default=True)\n    chunker_config: Dict[str, Any] | None = Field(default=None)\n</code></pre>"},{"location":"reference/config/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/config/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\"\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"reference/config/#custom-backend","title":"Custom Backend","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"remote\",\n    model_override=\"gpt-4-turbo\",\n    provider_override=\"openai\"\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"reference/config/#custom-processing","title":"Custom Processing","text":"<pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    processing_mode=\"one-to-one\",\n    use_chunking=False\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"reference/config/#custom-export","title":"Custom Export","text":"<pre><code>from docling_graph import run_pipeline\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    dump_to_disk=True,  # Enable file exports\n    export_format=\"cypher\",\n    export_docling_json=True,\n    export_markdown=True,\n    export_per_page_markdown=True,\n    output_dir=\"custom_outputs\"\n)\n\n# Returns data AND writes files\ncontext = run_pipeline(config)\n</code></pre>"},{"location":"reference/config/#api-mode-no-file-exports","title":"API Mode (No File Exports)","text":"<pre><code>from docling_graph import run_pipeline\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\"\n    # dump_to_disk defaults to None (auto-detects as False for API)\n    # debug defaults to False (no debug artifacts)\n)\n\n# Returns data only, no file exports, no debug artifacts\ncontext = run_pipeline(config)\ngraph = context.knowledge_graph\n</code></pre>"},{"location":"reference/config/#debug-mode","title":"Debug Mode","text":"<pre><code>from docling_graph import run_pipeline\nfrom pathlib import Path\n\n# Enable debug mode for troubleshooting\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    debug=True,  # Enable debug mode\n    dump_to_disk=True  # Also save final outputs\n)\n\ncontext = run_pipeline(config)\n\n# Debug artifacts saved to outputs/{document}_{timestamp}/debug/\ndebug_dir = Path(context.output_dir) / \"debug\"\nprint(f\"Debug artifacts saved to: {debug_dir}\")\n\n# Analyze staged debug artifacts\nimport json\n\n# Core staged artifacts\nfor name in [\n    \"node_catalog.json\",\n    \"id_pass.json\",\n    \"fill_pass.json\",\n    \"edges_pass.json\",\n    \"merged_output.json\",\n    \"staged_trace.json\",\n]:\n    p = debug_dir / name\n    print(name, \"exists\" if p.exists() else \"missing\")\n\n# Example: inspect staged trace timings\nwith open(debug_dir / \"staged_trace.json\") as f:\n    trace = json.load(f)\n    print(trace.get(\"timings_seconds\", {}))\n\n# When extraction_contract=\"delta\", debug may include: delta_trace.json, delta_merged_graph.json, delta_merged_output.json\n</code></pre>"},{"location":"reference/config/#explicit-control","title":"Explicit Control","text":"<pre><code>from docling_graph import run_pipeline\n\n# Force file exports in API mode\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    dump_to_disk=True,\n    output_dir=\"outputs\"\n)\ncontext = run_pipeline(config)\n\n# Force no file exports (even if output_dir is set)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    dump_to_disk=False,\n    output_dir=\"outputs\"  # Ignored\n)\ncontext = run_pipeline(config)\n</code></pre>"},{"location":"reference/config/#complete-configuration","title":"Complete Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig, LLMConfig, ModelConfig\n\nconfig = PipelineConfig(\n    # Source\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n\n    # Backend\n    backend=\"llm\",\n    inference=\"remote\",\n    model_override=\"mistral-small-latest\",\n    provider_override=\"mistral\",\n\n    # Processing\n    processing_mode=\"many-to-one\",\n    docling_config=\"ocr\",\n    use_chunking=True,\n    max_batch_size=5,\n\n    # Export\n    export_format=\"csv\",\n    export_docling=True,\n    export_docling_json=True,\n    export_markdown=True,\n    export_per_page_markdown=False,\n\n    # Graph\n    reverse_edges=False,\n\n    # Output\n    output_dir=\"outputs/custom\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"reference/config/#validation","title":"Validation","text":""},{"location":"reference/config/#automatic-validation","title":"Automatic Validation","text":"<p>Pydantic validates all fields automatically:</p> <pre><code># \u2705 Valid\nconfig = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\"\n)\n\n# \u274c Invalid - raises ValidationError\nconfig = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"invalid\"  # Not \"llm\" or \"vlm\"\n)\n</code></pre>"},{"location":"reference/config/#custom-validation","title":"Custom Validation","text":"<p>VLM backend validation:</p> <pre><code># \u274c Invalid - VLM doesn't support remote\nconfig = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"vlm\",\n    inference=\"remote\"  # Raises ValueError\n)\n\n# \u2705 Valid\nconfig = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"vlm\",\n    inference=\"local\"\n)\n</code></pre>"},{"location":"reference/config/#type-safety","title":"Type Safety","text":""},{"location":"reference/config/#type-hints","title":"Type Hints","text":"<p>All fields have proper type hints:</p> <pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom pathlib import Path\n\n# Type checker knows these are valid\nconfig = PipelineConfig(\n    source=\"doc.pdf\",  # str\n    template=\"templates.MyTemplate\",  # str\n    backend=\"llm\",  # Literal[\"llm\", \"vlm\"]\n    use_chunking=True  # bool\n)\n\n# Type checker knows output_dir is str\noutput: str = config.output_dir\n</code></pre>"},{"location":"reference/config/#ide-support","title":"IDE Support","text":"<p>IDEs provide autocomplete and type checking:</p> <pre><code>config = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"l\"  # IDE suggests \"llm\"\n)\n</code></pre>"},{"location":"reference/config/#default-values","title":"Default Values","text":"<p>All fields have sensible defaults:</p> <pre><code>config = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.MyTemplate\"\n    # All other fields use defaults\n)\n\nprint(config.backend)  # \"llm\"\nprint(config.inference)  # \"local\"\nprint(config.processing_mode)  # \"many-to-one\"\nprint(config.use_chunking)  # True\nprint(config.export_format)  # \"csv\"\n</code></pre>"},{"location":"reference/config/#related-apis","title":"Related APIs","text":"<ul> <li>Pipeline API - run_pipeline() function</li> <li>Protocols - Protocol definitions</li> <li>Exceptions - Validation errors</li> </ul>"},{"location":"reference/config/#see-also","title":"See Also","text":"<ul> <li>Configuration Guide - Configuration overview</li> <li>Python API - Usage guide</li> <li>Examples - Example configurations</li> </ul>"},{"location":"reference/converters/","title":"Converters API","text":""},{"location":"reference/converters/#overview","title":"Overview","text":"<p>Graph conversion from Pydantic models to NetworkX graphs.</p> <p>Module: <code>docling_graph.core.converters</code></p>"},{"location":"reference/converters/#graphconverter","title":"GraphConverter","text":"<p>Main class for converting Pydantic models to knowledge graphs.</p> <pre><code>class GraphConverter:\n    \"\"\"Convert Pydantic models to NetworkX graphs.\"\"\"\n\n    def __init__(\n        self,\n        config: Optional[GraphConverterConfig] = None,\n        node_id_registry: Optional[NodeIDRegistry] = None\n    ):\n        \"\"\"Initialize converter.\"\"\"\n</code></pre>"},{"location":"reference/converters/#methods","title":"Methods","text":""},{"location":"reference/converters/#convert","title":"convert()","text":"<pre><code>def convert(\n    self,\n    models: List[BaseModel],\n    reverse_edges: bool = False\n) -&gt; nx.MultiDiGraph:\n    \"\"\"\n    Convert Pydantic models to graph.\n\n    Args:\n        models: List of Pydantic model instances\n        reverse_edges: Create reverse edges\n\n    Returns:\n        NetworkX MultiDiGraph\n    \"\"\"\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.core.converters import GraphConverter\n\nconverter = GraphConverter()\ngraph = converter.convert(models, reverse_edges=False)\n\nprint(f\"Nodes: {graph.number_of_nodes()}\")\nprint(f\"Edges: {graph.number_of_edges()}\")\n</code></pre>"},{"location":"reference/converters/#nodeidregistry","title":"NodeIDRegistry","text":"<p>Registry for stable node ID generation.</p> <pre><code>class NodeIDRegistry:\n    \"\"\"Generate and track stable node IDs.\"\"\"\n\n    def get_or_create_id(\n        self,\n        model: BaseModel,\n        node_type: str\n    ) -&gt; str:\n        \"\"\"\n        Get or create stable ID for model.\n\n        Args:\n            model: Pydantic model instance\n            node_type: Type of node\n\n        Returns:\n            Stable node ID\n        \"\"\"\n</code></pre> <p>Features: - Deterministic ID generation - Collision detection - Cross-batch consistency - Graph ID field support</p> <p>Example:</p> <pre><code>from docling_graph.core.converters import NodeIDRegistry\n\nregistry = NodeIDRegistry()\nnode_id = registry.get_or_create_id(person_model, \"Person\")\n</code></pre>"},{"location":"reference/converters/#graphconverterconfig","title":"GraphConverterConfig","text":"<p>Configuration for graph conversion.</p> <pre><code>class GraphConverterConfig(BaseModel):\n    \"\"\"Configuration for graph converter.\"\"\"\n\n    reverse_edges: bool = False\n    include_metadata: bool = True\n</code></pre>"},{"location":"reference/converters/#related-apis","title":"Related APIs","text":"<ul> <li>Graph Management - Usage guide</li> <li>Exporters - Export graphs</li> </ul>"},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#overview","title":"Overview","text":"<p>Unified exception hierarchy for structured error handling in docling-graph.</p> <p>Module: <code>docling_graph.exceptions</code></p> <p>All exceptions inherit from <code>DoclingGraphError</code> and provide structured error information including message, details, and cause.</p>"},{"location":"reference/exceptions/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>DoclingGraphError (base)\n\u251c\u2500\u2500 ConfigurationError      # Invalid configuration\n\u251c\u2500\u2500 ClientError            # LLM/API client errors\n\u251c\u2500\u2500 ExtractionError        # Document extraction failures\n\u251c\u2500\u2500 ValidationError        # Data validation failures\n\u251c\u2500\u2500 GraphError            # Graph operation failures\n\u2514\u2500\u2500 PipelineError         # Pipeline execution failures\n</code></pre>"},{"location":"reference/exceptions/#base-exception","title":"Base Exception","text":""},{"location":"reference/exceptions/#doclinggrapherror","title":"DoclingGraphError","text":"<p>Base exception for all docling-graph errors.</p> <pre><code>class DoclingGraphError(Exception):\n    \"\"\"Base exception for all docling-graph errors.\"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        *,\n        details: dict[str, Any] | None = None,\n        cause: Exception | None = None\n    ) -&gt; None:\n        \"\"\"Initialize exception with structured information.\"\"\"\n</code></pre> <p>Attributes:</p> Attribute Type Description <code>message</code> <code>str</code> Human-readable error description <code>details</code> <code>dict[str, Any]</code> Additional context dictionary <code>cause</code> <code>Exception</code> or <code>None</code> Underlying exception that caused this error <p>Methods:</p>"},{"location":"reference/exceptions/#__str__","title":"__str__()","text":"<pre><code>def __str__(self) -&gt; str\n</code></pre> <p>Format exception with all available information.</p> <p>Returns: Formatted error message with details and cause</p>"},{"location":"reference/exceptions/#__repr__","title":"__repr__()","text":"<pre><code>def __repr__(self) -&gt; str\n</code></pre> <p>Detailed representation for debugging.</p> <p>Returns: Detailed string representation</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import DoclingGraphError\n\ntry:\n    # Some operation\n    raise DoclingGraphError(\n        \"Operation failed\",\n        details={\"file\": \"doc.pdf\", \"stage\": \"extraction\"},\n        cause=ValueError(\"Invalid input\")\n    )\nexcept DoclingGraphError as e:\n    print(e.message)  # \"Operation failed\"\n    print(e.details)  # {\"file\": \"doc.pdf\", \"stage\": \"extraction\"}\n    print(e.cause)    # ValueError(\"Invalid input\")\n</code></pre>"},{"location":"reference/exceptions/#specific-exceptions","title":"Specific Exceptions","text":""},{"location":"reference/exceptions/#configurationerror","title":"ConfigurationError","text":"<p>Raised when configuration is invalid or missing.</p> <pre><code>class ConfigurationError(DoclingGraphError):\n    \"\"\"Raised when configuration is invalid or missing.\"\"\"\n</code></pre> <p>Common Causes: - Missing required environment variables - Invalid configuration file - Unsupported model or provider - Missing required parameters - Invalid parameter combinations</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import ConfigurationError\n\nraise ConfigurationError(\n    \"API key not found\",\n    details={\"env_var\": \"MISTRAL_API_KEY\"}\n)\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import ConfigurationError\n\ntry:\n    config = PipelineConfig(\n        source=\"doc.pdf\",\n        template=\"templates.MyTemplate\",\n        backend=\"vlm\",\n        inference=\"remote\"  # VLM doesn't support remote!\n    )\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e.message}\")\n    print(f\"Details: {e.details}\")\n</code></pre>"},{"location":"reference/exceptions/#clienterror","title":"ClientError","text":"<p>Raised when LLM client operation fails.</p> <pre><code>class ClientError(DoclingGraphError):\n    \"\"\"Raised when LLM client operation fails.\"\"\"\n</code></pre> <p>Common Causes: - API authentication failure - Network timeout - Invalid API response - Rate limit exceeded - Model not available</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import ClientError\n\nraise ClientError(\n    \"API call failed\",\n    details={\n        \"provider\": \"mistral\",\n        \"model\": \"mistral-small-latest\",\n        \"status_code\": 429\n    },\n    cause=requests.exceptions.HTTPError(\"Rate limit exceeded\")\n)\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import ClientError\nimport time\n\ndef process_with_retry(config, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            run_pipeline(config)\n            return\n        except ClientError as e:\n            if \"rate limit\" in str(e).lower():\n                wait_time = 2 ** attempt\n                print(f\"Rate limited. Waiting {wait_time}s...\")\n                time.sleep(wait_time)\n            else:\n                raise\n</code></pre>"},{"location":"reference/exceptions/#extractionerror","title":"ExtractionError","text":"<p>Raised when document extraction fails.</p> <pre><code>class ExtractionError(DoclingGraphError):\n    \"\"\"Raised when document extraction fails.\"\"\"\n</code></pre> <p>Common Causes: - Document parsing failure - Empty extraction result - Invalid document format - Extraction timeout - Model inference failure</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import ExtractionError\n\nraise ExtractionError(\n    \"Failed to extract data from document\",\n    details={\n        \"source\": \"document.pdf\",\n        \"template\": \"MyTemplate\",\n        \"backend\": \"llm\"\n    },\n    cause=ValueError(\"Empty response from model\")\n)\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import ExtractionError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\"\n    })\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n\n    # Try fallback strategy\n    print(\"Trying with different backend...\")\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\",\n        \"backend\": \"vlm\"  # Fallback to VLM\n    })\n</code></pre>"},{"location":"reference/exceptions/#validationerror","title":"ValidationError","text":"<p>Raised when data validation fails.</p> <pre><code>class ValidationError(DoclingGraphError):\n    \"\"\"Raised when data validation fails.\"\"\"\n</code></pre> <p>Common Causes: - Pydantic validation error - Schema mismatch - Invalid data structure - Missing required fields - Type mismatch</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import ValidationError\nfrom pydantic import ValidationError as PydanticValidationError\n\ntry:\n    model = MyTemplate.model_validate(data)\nexcept PydanticValidationError as e:\n    raise ValidationError(\n        \"Data validation failed\",\n        details={\"errors\": e.errors()},\n        cause=e\n    )\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import ValidationError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.StrictTemplate\"\n    })\nexcept ValidationError as e:\n    print(f\"Validation failed: {e.message}\")\n\n    # Check Pydantic errors\n    if e.cause:\n        for error in e.cause.errors():\n            field = error['loc'][0]\n            msg = error['msg']\n            print(f\"  - {field}: {msg}\")\n</code></pre>"},{"location":"reference/exceptions/#grapherror","title":"GraphError","text":"<p>Raised when graph operation fails.</p> <pre><code>class GraphError(DoclingGraphError):\n    \"\"\"Raised when graph operation fails.\"\"\"\n</code></pre> <p>Common Causes: - Invalid graph structure - Node/edge creation failure - Graph validation error - Export failure - Circular dependencies</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import GraphError\n\nraise GraphError(\n    \"Failed to create graph edge\",\n    details={\n        \"source_node\": \"node_1\",\n        \"target_node\": \"node_2\",\n        \"edge_type\": \"RELATES_TO\"\n    }\n)\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import GraphError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\",\n        \"export_format\": \"cypher\"\n    })\nexcept GraphError as e:\n    print(f\"Graph error: {e.message}\")\n\n    # Try alternative export format\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\",\n        \"export_format\": \"csv\"  # Fallback to CSV\n    })\n</code></pre>"},{"location":"reference/exceptions/#pipelineerror","title":"PipelineError","text":"<p>Raised when pipeline execution fails.</p> <pre><code>class PipelineError(DoclingGraphError):\n    \"\"\"Raised when pipeline execution fails.\"\"\"\n</code></pre> <p>Common Causes: - Stage execution failure - Resource initialization error - Cleanup failure - Unexpected pipeline state</p> <p>Example:</p> <pre><code>from docling_graph.exceptions import PipelineError\n\nraise PipelineError(\n    \"Pipeline stage failed\",\n    details={\n        \"stage\": \"ExtractionStage\",\n        \"source\": \"document.pdf\"\n    },\n    cause=RuntimeError(\"Backend initialization failed\")\n)\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import PipelineError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\"\n    })\nexcept PipelineError as e:\n    print(f\"Pipeline failed: {e.message}\")\n    print(f\"Stage: {e.details.get('stage', 'unknown')}\")\n\n    if e.cause:\n        print(f\"Caused by: {e.cause}\")\n</code></pre>"},{"location":"reference/exceptions/#error-handling-patterns","title":"Error Handling Patterns","text":""},{"location":"reference/exceptions/#catch-specific-exceptions","title":"Catch Specific Exceptions","text":"<pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import (\n    ConfigurationError,\n    ClientError,\n    ExtractionError\n)\n\ntry:\n    run_pipeline(config)\n\nexcept ConfigurationError as e:\n    print(f\"Fix your configuration: {e.message}\")\n\nexcept ClientError as e:\n    print(f\"API error: {e.message}\")\n    # Maybe retry\n\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n    # Maybe try different backend\n</code></pre>"},{"location":"reference/exceptions/#catch-base-exception","title":"Catch Base Exception","text":"<pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import DoclingGraphError\n\ntry:\n    run_pipeline(config)\n\nexcept DoclingGraphError as e:\n    print(f\"Error: {e.message}\")\n    print(f\"Type: {type(e).__name__}\")\n    print(f\"Details: {e.details}\")\n\n    if e.cause:\n        print(f\"Caused by: {e.cause}\")\n</code></pre>"},{"location":"reference/exceptions/#access-error-details","title":"Access Error Details","text":"<pre><code>from docling_graph.exceptions import ExtractionError\n\ntry:\n    # Some operation\n    pass\nexcept ExtractionError as e:\n    # Access structured information\n    message = e.message\n    details = e.details\n    cause = e.cause\n\n    # Log details\n    print(f\"Error: {message}\")\n    for key, value in details.items():\n        print(f\"  {key}: {value}\")\n</code></pre>"},{"location":"reference/exceptions/#re-raise-with-context","title":"Re-raise with Context","text":"<pre><code>from docling_graph.exceptions import ExtractionError\n\ndef my_function():\n    try:\n        # Some operation\n        result = extract_data()\n    except ValueError as e:\n        # Wrap in docling-graph exception\n        raise ExtractionError(\n            \"Data extraction failed\",\n            details={\"function\": \"my_function\"},\n            cause=e\n        )\n</code></pre>"},{"location":"reference/exceptions/#best-practices","title":"Best Practices","text":""},{"location":"reference/exceptions/#use-specific-exceptions","title":"\ud83d\udc4d Use Specific Exceptions","text":"<pre><code># \u2705 Good - Specific exception\nfrom docling_graph.exceptions import ConfigurationError\n\nif not api_key:\n    raise ConfigurationError(\n        \"API key not found\",\n        details={\"env_var\": \"MISTRAL_API_KEY\"}\n    )\n\n# \u274c Avoid - Generic exception\nif not api_key:\n    raise Exception(\"API key not found\")\n</code></pre>"},{"location":"reference/exceptions/#provide-details","title":"\ud83d\udc4d Provide Details","text":"<pre><code># \u2705 Good - Detailed error\nfrom docling_graph.exceptions import ExtractionError\n\nraise ExtractionError(\n    \"Extraction failed\",\n    details={\n        \"source\": source,\n        \"template\": template.__name__,\n        \"backend\": \"llm\",\n        \"stage\": \"markdown_extraction\"\n    }\n)\n\n# \u274c Avoid - No details\nraise ExtractionError(\"Extraction failed\")\n</code></pre>"},{"location":"reference/exceptions/#chain-exceptions","title":"\ud83d\udc4d Chain Exceptions","text":"<pre><code># \u2705 Good - Chain exceptions\nfrom docling_graph.exceptions import ClientError\n\ntry:\n    response = api.call()\nexcept requests.HTTPError as e:\n    raise ClientError(\n        \"API call failed\",\n        details={\"status\": e.response.status_code},\n        cause=e  # Preserve original exception\n    )\n\n# \u274c Avoid - Lose original exception\ntry:\n    response = api.call()\nexcept requests.HTTPError:\n    raise ClientError(\"API call failed\")\n</code></pre>"},{"location":"reference/exceptions/#log-before-raising","title":"\ud83d\udc4d Log Before Raising","text":"<pre><code># \u2705 Good - Log then raise\nimport logging\nfrom docling_graph.exceptions import ExtractionError\n\nlogger = logging.getLogger(__name__)\n\ntry:\n    result = extract()\nexcept Exception as e:\n    logger.error(f\"Extraction failed: {e}\", exc_info=True)\n    raise ExtractionError(\n        \"Extraction failed\",\n        cause=e\n    )\n</code></pre>"},{"location":"reference/exceptions/#related-apis","title":"Related APIs","text":"<ul> <li>Error Handling Guide - Error handling patterns</li> <li>Pipeline API - Pipeline exceptions</li> <li>Configuration API - Configuration validation</li> </ul>"},{"location":"reference/exceptions/#see-also","title":"See Also","text":"<ul> <li>Python Exceptions - Python error handling</li> <li>Pydantic Validation - Pydantic errors</li> </ul>"},{"location":"reference/exporters/","title":"Exporters API","text":""},{"location":"reference/exporters/#overview","title":"Overview","text":"<p>Graph export formats for knowledge graphs.</p> <p>Module: <code>docling_graph.core.exporters</code></p>"},{"location":"reference/exporters/#base-exporter","title":"Base Exporter","text":""},{"location":"reference/exporters/#baseexporter","title":"BaseExporter","text":"<p>Base class for all exporters.</p> <pre><code>class BaseExporter:\n    \"\"\"Base class for graph exporters.\"\"\"\n\n    def __init__(\n        self,\n        graph: nx.MultiDiGraph,\n        output_dir: Path\n    ):\n        \"\"\"\n        Initialize exporter.\n\n        Args:\n            graph: NetworkX graph to export\n            output_dir: Output directory\n        \"\"\"\n        self.graph = graph\n        self.output_dir = output_dir\n\n    def export(self) -&gt; None:\n        \"\"\"Export graph to target format.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/exporters/#csv-exporter","title":"CSV Exporter","text":""},{"location":"reference/exporters/#csvexporter","title":"CSVExporter","text":"<p>Export graphs to Neo4j-compatible CSV format.</p> <pre><code>class CSVExporter(BaseExporter):\n    \"\"\"Export graph to CSV format.\"\"\"\n\n    def export(self) -&gt; None:\n        \"\"\"\n        Export to CSV files.\n\n        Creates:\n            - nodes.csv: Node data\n            - edges.csv: Edge data\n        \"\"\"\n</code></pre> <p>Output Format:</p> <p>nodes.csv: <pre><code>id,label,type,property1,property2,...\nnode_1,John Doe,Person,30,john@example.com\n</code></pre></p> <p>edges.csv: <pre><code>source,target,type\nnode_1,node_2,WORKS_AT\n</code></pre></p> <p>Example:</p> <pre><code>from docling_graph.core.exporters import CSVExporter\nfrom pathlib import Path\n\nexporter = CSVExporter(graph, Path(\"outputs\"))\nexporter.export()\n\n# Files created:\n# - outputs/nodes.csv\n# - outputs/edges.csv\n</code></pre>"},{"location":"reference/exporters/#cypher-exporter","title":"Cypher Exporter","text":""},{"location":"reference/exporters/#cypherexporter","title":"CypherExporter","text":"<p>Export graphs to Cypher script format.</p> <pre><code>class CypherExporter(BaseExporter):\n    \"\"\"Export graph to Cypher script.\"\"\"\n\n    def export(self) -&gt; None:\n        \"\"\"\n        Export to Cypher script.\n\n        Creates:\n            - graph.cypher: Cypher CREATE statements\n        \"\"\"\n</code></pre> <p>Output Format:</p> <pre><code>CREATE (n1:Person {name: \"John Doe\", age: 30})\nCREATE (n2:Organization {name: \"ACME Corp\"})\nCREATE (n1)-[:WORKS_AT]-&gt;(n2)\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.core.exporters import CypherExporter\nfrom pathlib import Path\n\nexporter = CypherExporter(graph, Path(\"outputs\"))\nexporter.export()\n\n# File created: outputs/graph.cypher\n</code></pre>"},{"location":"reference/exporters/#json-exporter","title":"JSON Exporter","text":""},{"location":"reference/exporters/#jsonexporter","title":"JSONExporter","text":"<p>Export graphs to JSON format.</p> <pre><code>class JSONExporter(BaseExporter):\n    \"\"\"Export graph to JSON format.\"\"\"\n\n    def export(self) -&gt; None:\n        \"\"\"\n        Export to JSON.\n\n        Creates:\n            - graph.json: NetworkX node-link format\n        \"\"\"\n</code></pre> <p>Output Format:</p> <pre><code>{\n  \"directed\": true,\n  \"multigraph\": true,\n  \"nodes\": [\n    {\"id\": \"node_1\", \"type\": \"Person\", \"name\": \"John\"}\n  ],\n  \"links\": [\n    {\"source\": \"node_1\", \"target\": \"node_2\", \"type\": \"WORKS_AT\"}\n  ]\n}\n</code></pre> <p>Example:</p> <pre><code>from docling_graph.core.exporters import JSONExporter\nfrom pathlib import Path\n\nexporter = JSONExporter(graph, Path(\"outputs\"))\nexporter.export()\n\n# File created: outputs/graph.json\n</code></pre>"},{"location":"reference/exporters/#docling-exporter","title":"Docling Exporter","text":""},{"location":"reference/exporters/#doclingexporter","title":"DoclingExporter","text":"<p>Export Docling document outputs.</p> <pre><code>class DoclingExporter:\n    \"\"\"Export Docling document outputs.\"\"\"\n\n    def export(\n        self,\n        document: Any,\n        output_dir: Path,\n        export_json: bool = True,\n        export_markdown: bool = True,\n        export_per_page: bool = False\n    ) -&gt; None:\n        \"\"\"\n        Export Docling outputs.\n\n        Args:\n            document: Docling document\n            output_dir: Output directory\n            export_json: Export JSON\n            export_markdown: Export markdown\n            export_per_page: Export per-page markdown\n        \"\"\"\n</code></pre> <p>Creates: - <code>docling_document.json</code> - Docling JSON - <code>markdown/full_document.md</code> - Full markdown - <code>markdown/pages/page_N.md</code> - Per-page markdown</p>"},{"location":"reference/exporters/#custom-exporters","title":"Custom Exporters","text":"<p>Create custom exporters by extending <code>BaseExporter</code>:</p> <pre><code>from docling_graph.core.exporters import BaseExporter\nfrom pathlib import Path\nimport networkx as nx\n\nclass MyExporter(BaseExporter):\n    \"\"\"Custom exporter.\"\"\"\n\n    def export(self) -&gt; None:\n        \"\"\"Export to custom format.\"\"\"\n        output_file = self.output_dir / \"custom.txt\"\n\n        with open(output_file, 'w') as f:\n            f.write(f\"Nodes: {self.graph.number_of_nodes()}\\n\")\n            f.write(f\"Edges: {self.graph.number_of_edges()}\\n\")\n</code></pre> <p>See Custom Exporters Guide for details.</p>"},{"location":"reference/exporters/#related-apis","title":"Related APIs","text":"<ul> <li>Export Formats - Usage guide</li> <li>Custom Exporters - Create exporters</li> <li>Converters - Graph conversion</li> </ul>"},{"location":"reference/extractors/","title":"Extractors API","text":""},{"location":"reference/extractors/#overview","title":"Overview","text":"<p>Document extraction strategies and backends.</p> <p>Module: <code>docling_graph.core.extractors</code></p> <p>Recent Improvements</p> <ul> <li>Model Capability Detection: Automatic tier detection and adaptive prompting</li> <li>Chain of Density: Multi-turn consolidation for ADVANCED tier models</li> <li>Zero Data Loss: Returns partial models instead of empty results on failures</li> <li>Real Tokenizers: Accurate token counting with 20% safety margins</li> <li>Enhanced GPU Cleanup: Better memory management for VLM backends</li> </ul>"},{"location":"reference/extractors/#extraction-strategies","title":"Extraction Strategies","text":""},{"location":"reference/extractors/#onetoone","title":"OneToOne","text":"<p>Per-page extraction strategy.</p> <pre><code>class OneToOne(ExtractorProtocol):\n    \"\"\"Extract data from each page separately.\"\"\"\n\n    def __init__(self, backend: Backend):\n        \"\"\"Initialize with backend.\"\"\"\n        self.backend = backend\n\n    def extract(\n        self,\n        source: str,\n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"\n        Extract from each page.\n\n        Returns:\n            List of models (one per page)\n        \"\"\"\n</code></pre> <p>Use Cases: - Multi-page documents with independent content - Page-level analysis - Parallel processing</p> <p>Example:</p> <pre><code>from docling_graph.core.extractors import OneToOne\nfrom docling_graph.core.extractors.backends import LLMBackend\n\nbackend = LLMBackend(model=\"llama-3.1-8b\")\nextractor = OneToOne(backend=backend)\n\nresults = extractor.extract(\"document.pdf\", MyTemplate)\nprint(f\"Extracted {len(results)} pages\")\n</code></pre>"},{"location":"reference/extractors/#manytoone","title":"ManyToOne","text":"<p>Consolidated extraction strategy with zero data loss.</p> <pre><code>class ManyToOne(ExtractorProtocol):\n    \"\"\"Extract and consolidate data from entire document.\"\"\"\n\n    def __init__(\n        self,\n        backend: Backend,\n        use_chunking: bool = True,\n    ):\n        \"\"\"Initialize with backend and options.\"\"\"\n        self.backend = backend\n        self.use_chunking = use_chunking\n\n    def extract(\n        self,\n        source: str,\n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"\n        Extract and consolidate.\n\n        Returns:\n            List with single consolidated model (success)\n            or multiple partial models (merge failure - zero data loss)\n        \"\"\"\n</code></pre> <p>Use Cases: - Single entity across document - Consolidated information - Summary extraction</p> <p>Features: - Zero Data Loss: Returns partial models if consolidation fails - Consolidation: Programmatic merge of chunk results - Schema-Aware Chunking: Dynamically adjusts chunk size based on schema</p> <p>Example:</p> <pre><code>from docling_graph.core.extractors import ManyToOne\nfrom docling_graph.core.extractors.backends import LLMBackend\n\nbackend = LLMBackend(model=\"llama-3.1-8b\")\nextractor = ManyToOne(\n    backend=backend,\n    use_chunking=True,\n)\n\nresults = extractor.extract(\"document.pdf\", MyTemplate)\n\n# Check if consolidation succeeded\nif len(results) == 1:\n    print(f\"\u2705 Consolidated model: {results[0]}\")\nelse:\n    print(f\"\u26a0 Got {len(results)} partial models (data preserved)\")\n</code></pre>"},{"location":"reference/extractors/#backends","title":"Backends","text":""},{"location":"reference/extractors/#llmbackend","title":"LLMBackend","text":"<p>LLM-based extraction backend with adaptive prompting.</p> <pre><code>class LLMBackend(TextExtractionBackendProtocol):\n    \"\"\"LLM backend for text extraction.\"\"\"\n\n    def __init__(\n        self,\n        client: LLMClientProtocol,\n        model: str,\n        provider: str\n    ):\n        \"\"\"Initialize LLM backend.\"\"\"\n        self.client = client\n        self.model_capability = self._detect_capability()  # Auto-detect tier\n</code></pre> <p>Methods:</p> <ul> <li><code>extract_from_markdown(markdown, template, context, is_partial)</code> - Extract from markdown with adaptive prompting</li> <li><code>consolidate_from_pydantic_models(raw_models, programmatic_model, template)</code> - Consolidate models (uses Chain of Density for ADVANCED tier)</li> <li><code>cleanup()</code> - Clean up resources</li> </ul> <p>Model Capability Tiers:</p> Tier Model Size Prompt Style Consolidation SIMPLE 1B-7B Minimal Single-turn STANDARD 7B-13B Balanced Single-turn ADVANCED 13B+ Detailed Chain of Density (3 turns) <p>Example:</p> <pre><code>from docling_graph.core.extractors.backends import LLMBackend\nfrom docling_graph.llm_clients import get_client\nfrom docling_graph.llm_clients.config import resolve_effective_model_config\n\n# STANDARD tier model (7B-13B)\neffective = resolve_effective_model_config(\"ollama\", \"llama3.1:8b\")\nclient = get_client(\"ollama\")(model_config=effective)\nbackend = LLMBackend(llm_client=client)\n\n# Automatically uses STANDARD tier prompts\nmodel = backend.extract_from_markdown(\n    markdown=markdown,\n    template=MyTemplate,\n    context=\"full document\",\n    is_partial=False\n)\n</code></pre>"},{"location":"reference/extractors/#vlmbackend","title":"VLMBackend","text":"<p>Vision-Language Model backend with enhanced GPU cleanup.</p> <pre><code>class VLMBackend(ExtractionBackendProtocol):\n    \"\"\"VLM backend for document extraction.\"\"\"\n\n    def __init__(self, model: str):\n        \"\"\"Initialize VLM backend.\"\"\"\n        self.model_name = model\n        self.model = None  # Loaded on first use\n</code></pre> <p>Methods:</p> <ul> <li><code>extract_from_document(source, template)</code> - Extract from document</li> <li><code>cleanup()</code> - Enhanced GPU memory cleanup</li> </ul> <p>Enhanced GPU Cleanup:</p> <p>The <code>cleanup()</code> method now includes: - Model-to-CPU transfer before deletion - Explicit CUDA cache clearing - Memory usage tracking and logging - Multi-GPU device support</p> <p>Example:</p> <pre><code>from docling_graph.core.extractors.backends import VLMBackend\n\nbackend = VLMBackend(model_name=\"numind/NuExtract-2.0-8B\")\n\ntry:\n    models = backend.extract_from_document(\"document.pdf\", MyTemplate)\nfinally:\n    backend.cleanup()  # Properly releases GPU memory\n</code></pre>"},{"location":"reference/extractors/#document-processing","title":"Document Processing","text":""},{"location":"reference/extractors/#documentprocessor","title":"DocumentProcessor","text":"<p>Handles document conversion and markdown extraction.</p> <pre><code>class DocumentProcessor(DocumentProcessorProtocol):\n    \"\"\"Process documents with Docling.\"\"\"\n\n    def convert_to_docling_doc(self, source: str) -&gt; Any:\n        \"\"\"Convert to Docling document.\"\"\"\n\n    def extract_full_markdown(self, document: Any) -&gt; str:\n        \"\"\"Extract full markdown.\"\"\"\n\n    def extract_page_markdowns(self, document: Any) -&gt; List[str]:\n        \"\"\"Extract per-page markdown.\"\"\"\n</code></pre>"},{"location":"reference/extractors/#chunking","title":"Chunking","text":""},{"location":"reference/extractors/#documentchunker","title":"DocumentChunker","text":"<p>Handles document chunking with real tokenizers and schema-aware sizing.</p> <pre><code>class DocumentChunker:\n    \"\"\"Chunk documents for processing.\"\"\"\n\n    def __init__(\n        self,\n        provider: str,\n        max_tokens: int = None,\n        tokenizer_name: str = None,\n        schema_json: str | None = None\n    ):\n        \"\"\"\n        Initialize chunker.\n\n        Args:\n            provider: LLM provider (for tokenizer selection)\n            max_tokens: Maximum tokens per chunk\n            tokenizer_name: Specific tokenizer to use\n            schema_json: Schema JSON string for dynamic adjustment\n        \"\"\"\n\n    def chunk_markdown(\n        self,\n        markdown: str,\n        max_tokens: int\n    ) -&gt; List[str]:\n        \"\"\"\n        Chunk markdown by tokens using real tokenizer.\n\n        Args:\n            markdown: Markdown content\n            max_tokens: Maximum tokens per chunk\n\n        Returns:\n            List of markdown chunks\n        \"\"\"\n\n    def update_schema_config(self, schema_json: str):\n        \"\"\"\n        Update schema configuration dynamically.\n\n        Args:\n            schema_json: New schema JSON string\n        \"\"\"\n</code></pre> <p>Features:</p> <ul> <li>Real Tokenizers: Uses provider-specific tokenizers for accurate token counting</li> <li>Safety Margins: Reserves a fixed 100-token buffer for protocol overhead</li> <li>Schema-Aware: Dynamically adjusts chunk size based on exact prompt tokens</li> <li>Provider-Specific: Optimized for each LLM provider</li> </ul> <p>Example:</p> <pre><code>import json\n\nfrom docling_graph.core.extractors import DocumentChunker\n\n# Create chunker with real tokenizer\nchunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096,\n    schema_json=json.dumps(MyTemplate.model_json_schema())\n)\n\n# Chunk with accurate token counting\nchunks = chunker.chunk_markdown(markdown, max_tokens=4096)\n\n# Update for different schema\nchunker.update_schema_config(schema_json=json.dumps(OtherTemplate.model_json_schema()))\n</code></pre>"},{"location":"reference/extractors/#factory","title":"Factory","text":""},{"location":"reference/extractors/#extractorfactorycreate_extractor","title":"ExtractorFactory.create_extractor()","text":"<p>Creates an extractor from pipeline configuration. Used internally by the pipeline; for programmatic use, import from <code>docling_graph.core.extractors</code>.</p> <pre><code>from docling_graph.core.extractors import ExtractorFactory\n\nextractor = ExtractorFactory.create_extractor(\n    processing_mode=\"many-to-one\",\n    backend_name=\"llm\",\n    extraction_contract=\"direct\",  # or \"staged\" / \"delta\" (LLM + many-to-one only)\n    staged_config=None,            # optional: pass_retries, parallel_workers, nodes_fill_cap, id_shard_size, delta_* for delta\n    llm_client=client,\n    docling_config=\"ocr\",\n)\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>processing_mode</code> <code>\"one-to-one\"</code> | <code>\"many-to-one\"</code> Extraction strategy <code>backend_name</code> <code>\"llm\"</code> | <code>\"vlm\"</code> Backend type <code>extraction_contract</code> <code>\"direct\"</code> | <code>\"staged\"</code> | <code>\"delta\"</code> LLM contract; <code>staged</code> and <code>delta</code> only apply to many-to-one <code>staged_config</code> <code>dict</code> | <code>None</code> Optional staged tuning (pass_retries, parallel_workers, etc.) <code>model_name</code> <code>str</code> | <code>None</code> Required for VLM <code>llm_client</code> <code>LLMClientProtocol</code> | <code>None</code> Required for LLM <code>docling_config</code> <code>str</code> <code>\"ocr\"</code> or <code>\"vision\"</code> <p>Returns: <code>BaseExtractor</code> instance.</p>"},{"location":"reference/extractors/#features","title":"Features","text":""},{"location":"reference/extractors/#zero-data-loss","title":"Zero Data Loss","text":"<p>Returns partial models instead of empty results:</p> <pre><code>results = extractor.extract(\"document.pdf\", MyTemplate)\n\nif len(results) == 1:\n    # Success: merged model\n    model = results[0]\nelse:\n    # Partial: multiple models (data preserved!)\n    for model in results:\n        process_partial(model)\n</code></pre>"},{"location":"reference/extractors/#real-tokenizer-integration","title":"Real Tokenizer Integration","text":"<p>Accurate token counting with safety margins:</p> <pre><code>chunker = DocumentChunker(\n    provider=\"mistral\",\n    max_tokens=4096  # Uses real Mistral tokenizer\n)\n# Applies 20% safety margin automatically\n</code></pre>"},{"location":"reference/extractors/#related-apis","title":"Related APIs","text":"<ul> <li>Staged Extraction - Multi-pass extraction</li> <li>Delta Extraction - Chunk-based graph extraction</li> <li>Extraction Process - Usage guide</li> <li>Model Merging - Zero data loss</li> <li>Protocols - Backend protocols</li> <li>Custom Backends - Create backends</li> </ul>"},{"location":"reference/llm-clients/","title":"LLM Clients API","text":"<p>Note</p> <p>LiteLLM is the default client path for LLM calls. You can also supply a custom client (see below).</p>"},{"location":"reference/llm-clients/#overview","title":"Overview","text":"<p>Module: <code>docling_graph.llm_clients</code></p> <p>All LLM calls go through <code>LiteLLMClient.get_json_response()</code> when using the default provider/model path. That method implements <code>LLMClientProtocol</code> directly. This preserves the extraction/consolidation pipeline while standardizing provider differences through LiteLLM.</p>"},{"location":"reference/llm-clients/#litellmclient-default","title":"LiteLLMClient (Default)","text":"<p><code>LiteLLMClient</code> wraps <code>litellm.completion()</code> and uses OpenAI-style parameters with <code>drop_params=True</code> to avoid provider-specific branching.</p>"},{"location":"reference/llm-clients/#example","title":"Example","text":"<pre><code>from docling_graph.llm_clients import get_client\nfrom docling_graph.llm_clients.config import resolve_effective_model_config\n\neffective = resolve_effective_model_config(\n    \"mistral\",\n    \"mistral-large-latest\",\n    overrides={\"generation\": {\"max_tokens\": 4096}},\n)\nclient_class = get_client(\"mistral\")\nclient = client_class(model_config=effective)\n\nresult = client.get_json_response(\n    prompt={\"system\": \"Extract data\", \"user\": \"Alice is a manager\"},\n    schema_json=\"{}\",\n)\n</code></pre>"},{"location":"reference/llm-clients/#json-mode","title":"JSON Mode","text":"<p>JSON/Structured Outputs are requested by default via <code>response_format</code>, with <code>ResponseHandler</code> providing a fallback if the model output is not strictly JSON.</p>"},{"location":"reference/llm-clients/#custom-llm-clients","title":"Custom LLM Clients","text":"<p>You can supply your own LLM client so the pipeline uses your inference URL, auth, or protocol while docling-graph still builds prompts, schemas, and runs the normal extraction flow.</p> <p>Contract: Your client must implement <code>LLMClientProtocol</code>: a single method</p> <ul> <li><code>get_json_response(self, prompt: str | Mapping[str, str], schema_json: str) -&gt; dict | list</code></li> </ul> <p>Pass it to the pipeline via <code>PipelineConfig(llm_client=your_client)</code> (or <code>run_pipeline({\"llm_client\": your_client, ...})</code>). When <code>llm_client</code> is set, the pipeline uses it and does not initialize a provider/model client from config.</p>"},{"location":"reference/llm-clients/#example-custom-litellm-backed-client-custom-url","title":"Example: custom LiteLLM-backed client (custom URL)","text":"<p>Use this pattern to point at an OpenAI-compatible or custom endpoint (e.g. on-prem WatsonX, vLLM, proxy) while reusing docling-graph\u2019s <code>ResponseHandler</code> for consistent JSON parsing:</p> <pre><code>from typing import Any, Dict, List, Mapping\n\nimport litellm\n\nfrom docling_graph.exceptions import ClientError\nfrom docling_graph.llm_clients.response_handler import ResponseHandler\nfrom docling_graph.protocols import LLMClientProtocol\n\n\nclass LiteLLMEndpointClient:\n    \"\"\"Custom client that calls a single endpoint via LiteLLM with your URL/auth.\"\"\"\n\n    def __init__(\n        self,\n        model: str,\n        base_url: str,\n        *,\n        api_key: str | None = None,\n        headers: dict[str, str] | None = None,\n        timeout_s: int = 120,\n        max_tokens: int = 4096,\n        temperature: float = 0.1,\n    ):\n        self.model = model\n        self.base_url = base_url.rstrip(\"/\")\n        self.api_key = api_key\n        self.headers = headers or {}\n        self.timeout_s = timeout_s\n        self.max_tokens = max_tokens\n        self.temperature = temperature\n\n    def get_json_response(\n        self, prompt: str | Mapping[str, str], schema_json: str\n    ) -&gt; Dict[str, Any] | List[Any]:\n        messages = self._messages(prompt)\n        request = {\n            \"model\": self.model,\n            \"messages\": messages,\n            \"api_base\": self.base_url,\n            \"temperature\": self.temperature,\n            \"max_tokens\": self.max_tokens,\n            \"timeout\": self.timeout_s,\n            \"response_format\": {\"type\": \"json_object\"},\n        }\n        if self.api_key:\n            request[\"api_key\"] = self.api_key\n        if self.headers:\n            request[\"headers\"] = dict(self.headers)\n\n        try:\n            response = litellm.completion(**request)\n        except Exception as e:\n            raise ClientError(\n                f\"LiteLLM call failed: {type(e).__name__}\",\n                details={\"model\": self.model, \"api_base\": self.base_url, \"error\": str(e)},\n                cause=e,\n            ) from e\n\n        choices = response.get(\"choices\", [])\n        if not choices:\n            raise ClientError(\"No choices in response\", details={\"model\": self.model})\n        content = choices[0].get(\"message\", {}).get(\"content\") or \"\"\n        finish_reason = choices[0].get(\"finish_reason\")\n        truncated = finish_reason == \"length\"\n\n        return ResponseHandler.parse_json_response(\n            content,\n            client_name=self.__class__.__name__,\n            aggressive_clean=False,\n            truncated=truncated,\n            max_tokens=self.max_tokens,\n        )\n\n    def _messages(self, prompt: str | Mapping[str, str]) -&gt; list[dict[str, str]]:\n        if isinstance(prompt, Mapping):\n            out = []\n            if prompt.get(\"system\"):\n                out.append({\"role\": \"system\", \"content\": prompt[\"system\"]})\n            if prompt.get(\"user\"):\n                out.append({\"role\": \"user\", \"content\": prompt[\"user\"]})\n            return out if out else [{\"role\": \"user\", \"content\": \"\"}]\n        return [{\"role\": \"user\", \"content\": prompt}]\n</code></pre> <p>Usage with the pipeline:</p> <pre><code>from docling_graph import PipelineConfig, run_pipeline\n\nclient = LiteLLMEndpointClient(\n    model=\"openai/your-model-name\",  # or e.g. hosted_vllm/...\n    base_url=\"https://your-inference.example.com/v1\",\n    api_key=\"optional-key\",\n)\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\",\n    llm_client=client,\n)\nrun_pipeline(config)\n# or: config.run()\n</code></pre> <p>For OpenAI-compatible endpoints, use a model string like <code>openai/&lt;model-name&gt;</code> so LiteLLM routes correctly. For other protocols, implement your own HTTP call inside <code>get_json_response()</code> and return a <code>dict</code> or <code>list</code>; you can still use <code>ResponseHandler.parse_json_response(raw_text, ...)</code> for the response body.</p>"},{"location":"reference/llm-clients/#see-also","title":"See Also","text":"<ul> <li>API Keys Setup - Configure API keys (including optional LM Studio API key and WatsonX)</li> <li>Model Configuration - Model setup (vLLM, Ollama, LM Studio, remote providers)</li> <li>Remote Inference - Backend selection</li> </ul>"},{"location":"reference/pipeline/","title":"Pipeline API","text":""},{"location":"reference/pipeline/#overview","title":"Overview","text":"<p>The Pipeline API provides the main entry point for document extraction and graph conversion.</p> <p>Module: <code>docling_graph.pipeline</code></p>"},{"location":"reference/pipeline/#functions","title":"Functions","text":""},{"location":"reference/pipeline/#run_pipeline","title":"run_pipeline()","text":"<pre><code>def run_pipeline(config: Union[PipelineConfig, Dict[str, Any]]) -&gt; PipelineContext\n</code></pre> <p>Run the extraction and graph conversion pipeline.</p> <p>Parameters:</p> Parameter Type Description <code>config</code> <code>PipelineConfig</code> or <code>dict</code> Pipeline configuration <p>Returns: <code>PipelineContext</code> with <code>knowledge_graph</code>, <code>extracted_models</code>, <code>graph_metadata</code>, and related results.</p> <p>Raises:</p> Exception When <code>PipelineError</code> Pipeline execution fails <code>ConfigurationError</code> Configuration is invalid <code>ExtractionError</code> Document extraction fails <p>Example:</p> <pre><code>from docling_graph import run_pipeline\n\n# Using dict\nconfig = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n    \"backend\": \"llm\",\n    \"inference\": \"local\",\n    \"output_dir\": \"outputs\"\n}\nrun_pipeline(config)\n\n# Using PipelineConfig\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\"\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"reference/pipeline/#pipeline-stages","title":"Pipeline Stages","text":"<p>The pipeline executes the following stages in order:</p>"},{"location":"reference/pipeline/#1-template-loading","title":"1. Template Loading","text":"<p>Purpose: Load and validate Pydantic templates</p> <p>Actions: - Import template module - Validate template structure - Check for required fields</p> <p>Errors: - <code>ConfigurationError</code> if template not found - <code>ValidationError</code> if template invalid</p>"},{"location":"reference/pipeline/#2-extraction","title":"2. Extraction","text":"<p>Purpose: Extract structured data from documents</p> <p>Actions: - Convert document with Docling - Extract using backend (VLM or LLM) - Validate extracted data</p> <p>Errors: - <code>ExtractionError</code> if extraction fails - <code>ValidationError</code> if data invalid</p>"},{"location":"reference/pipeline/#3-docling-export-optional","title":"3. Docling Export (Optional)","text":"<p>Purpose: Export Docling document outputs</p> <p>Actions: - Export Docling JSON - Export markdown - Export per-page markdown</p> <p>Controlled by: - <code>export_docling</code> - <code>export_docling_json</code> - <code>export_markdown</code> - <code>export_per_page_markdown</code></p>"},{"location":"reference/pipeline/#4-graph-conversion","title":"4. Graph Conversion","text":"<p>Purpose: Convert extracted data to knowledge graphs</p> <p>Actions: - Create NetworkX graph - Generate stable node IDs - Create edges from relationships</p> <p>Errors: - <code>GraphError</code> if conversion fails</p>"},{"location":"reference/pipeline/#5-export","title":"5. Export","text":"<p>Purpose: Export graphs in multiple formats</p> <p>Actions: - Export to CSV (nodes.csv, edges.csv) - Export to Cypher (graph.cypher) - Export to JSON (graph.json)</p> <p>Controlled by: - <code>export_format</code></p>"},{"location":"reference/pipeline/#6-visualization","title":"6. Visualization","text":"<p>Purpose: Generate reports and interactive visualizations</p> <p>Actions: - Create HTML visualization - Generate markdown report - Calculate statistics</p> <p>Outputs: - <code>graph_visualization.html</code> - <code>extraction_report.md</code></p>"},{"location":"reference/pipeline/#pipeline-context","title":"Pipeline Context","text":"<p>Internal context object passed between stages:</p> <pre><code>@dataclass\nclass PipelineContext:\n    \"\"\"Shared context for pipeline stages.\"\"\"\n\n    config: PipelineConfig\n    template: type[BaseModel] | None = None\n    extractor: BaseExtractor | None = None\n    extracted_models: list[BaseModel] | None = None\n    docling_document: Any = None\n    knowledge_graph: nx.DiGraph | None = None\n    graph_metadata: GraphMetadata | None = None\n    output_dir: Path | None = None\n    node_registry: Any | None = None\n\n    # Input normalization\n    normalized_source: Union[str, Path, Any] | None = None\n    input_metadata: Dict[str, Any] | None = None\n    input_type: Any | None = None\n\n    # Output and debug\n    output_manager: OutputDirectoryManager | None = None\n    trace_data: EventTrace | None = None  # Populated when config.debug is True\n</code></pre> <p>When <code>debug=True</code>, <code>trace_data</code> is populated as a chronological event log (<code>EventTrace</code>). When output is written to disk, it is saved as <code>debug/trace_data.json</code> in compact form with <code>summary</code> (including <code>runtime_seconds</code>), and ordered <code>steps</code> entries (<code>name</code>, <code>runtime_seconds</code>, <code>status</code>, <code>artifacts</code>). See Debug Mode for details.</p>"},{"location":"reference/pipeline/#configuration-options","title":"Configuration Options","text":""},{"location":"reference/pipeline/#required","title":"Required","text":"Option Type Description <code>source</code> <code>str</code> or <code>Path</code> Path to source document <code>template</code> <code>str</code> or <code>Type[BaseModel]</code> Pydantic template"},{"location":"reference/pipeline/#backend-selection","title":"Backend Selection","text":"Option Type Default Description <code>backend</code> <code>\"llm\"</code> or <code>\"vlm\"</code> <code>\"llm\"</code> Extraction backend <code>inference</code> <code>\"local\"</code> or <code>\"remote\"</code> <code>\"local\"</code> Inference location"},{"location":"reference/pipeline/#processing","title":"Processing","text":"Option Type Default Description <code>processing_mode</code> <code>\"one-to-one\"</code> or <code>\"many-to-one\"</code> <code>\"many-to-one\"</code> Processing strategy <code>extraction_contract</code> <code>\"direct\"</code>, <code>\"staged\"</code>, or <code>\"delta\"</code> <code>\"direct\"</code> LLM extraction contract for many-to-one mode <code>use_chunking</code> <code>bool</code> <code>True</code> Enable chunking <p>Contract behavior notes:</p> <ul> <li><code>direct</code>: one-pass structured extraction from full content.</li> <li><code>staged</code>: ID discovery + fill pass + merge assembly.</li> <li><code>delta</code>: chunk/batch graph extraction + normalization + merge + projection.</li> <li><code>delta</code> requires chunking-enabled many-to-one flow.</li> <li>Contract implementations are isolated by folder under <code>core/extractors/contracts/</code>.</li> </ul>"},{"location":"reference/pipeline/#export","title":"Export","text":"Option Type Default Description <code>export_format</code> <code>\"csv\"</code> or <code>\"cypher\"</code> <code>\"csv\"</code> Graph export format <code>output_dir</code> <code>str</code> or <code>Path</code> <code>\"outputs\"</code> Output directory <p>See Configuration API for complete options.</p>"},{"location":"reference/pipeline/#usage-patterns","title":"Usage Patterns","text":""},{"location":"reference/pipeline/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\"\n})\n</code></pre>"},{"location":"reference/pipeline/#with-error-handling","title":"With Error Handling","text":"<pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import (\n    ConfigurationError,\n    ExtractionError,\n    PipelineError\n)\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.MyTemplate\"\n    })\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e.message}\")\n    print(f\"Details: {e.details}\")\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\nexcept PipelineError as e:\n    print(f\"Pipeline error: {e.message}\")\n</code></pre>"},{"location":"reference/pipeline/#batch-processing","title":"Batch Processing","text":"<pre><code>from pathlib import Path\nfrom docling_graph import run_pipeline\n\ndocuments = Path(\"documents\").glob(\"*.pdf\")\n\nfor doc in documents:\n    print(f\"Processing {doc.name}...\")\n\n    run_pipeline({\n        \"source\": str(doc),\n        \"template\": \"templates.MyTemplate\",\n        \"output_dir\": f\"outputs/{doc.stem}\"\n    })\n\n    print(f\"\u2705 {doc.name} complete\")\n</code></pre>"},{"location":"reference/pipeline/#custom-configuration","title":"Custom Configuration","text":"<pre><code>from docling_graph import run_pipeline\n\nconfig = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n\n    # Backend\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"model_override\": \"mistral-small-latest\",\n    \"provider_override\": \"mistral\",\n\n    # Processing\n    \"processing_mode\": \"many-to-one\",\n    \"extraction_contract\": \"staged\",\n    \"use_chunking\": True,\n\n    # Export\n    \"export_format\": \"cypher\",\n    \"export_docling_json\": True,\n    \"export_markdown\": True,\n\n    # Output\n    \"output_dir\": \"outputs/custom\"\n}\n\nrun_pipeline(config)\n</code></pre>"},{"location":"reference/pipeline/#output-structure","title":"Output Structure","text":"<p>After successful execution with <code>dump_to_disk=True</code>, the output directory contains:</p> <pre><code>outputs/\n\u2514\u2500\u2500 document_name_timestamp/\n    \u251c\u2500\u2500 metadata.json                 # Pipeline metadata and performance metrics\n    \u2502\n    \u251c\u2500\u2500 docling/                      # Docling exports\n    \u2502   \u251c\u2500\u2500 document.json             # Docling JSON (if enabled)\n    \u2502   \u2514\u2500\u2500 document.md               # Markdown export (if enabled)\n    \u2502\n    \u251c\u2500\u2500 docling_graph/                # Docling-graph outputs\n    \u2502   \u251c\u2500\u2500 graph.json                # Graph JSON\n    \u2502   \u251c\u2500\u2500 nodes.csv                 # Graph nodes (if CSV export)\n    \u2502   \u251c\u2500\u2500 edges.csv                 # Graph edges (if CSV export)\n    \u2502   \u251c\u2500\u2500 graph.cypher              # Cypher script (if Cypher export)\n    \u2502   \u251c\u2500\u2500 graph.html                # Interactive visualization\n    \u2502   \u2514\u2500\u2500 report.md                 # Extraction report\n    \u2502\n    \u2514\u2500\u2500 debug/                        # Debug output (if debug=True)\n        \u2514\u2500\u2500 trace_data.json           # Compact summary + ordered steps with canonical artifacts\n</code></pre>"},{"location":"reference/pipeline/#metadatajson-structure","title":"metadata.json Structure","text":"<p>The <code>metadata.json</code> file contains pipeline configuration, results, and performance metrics:</p> <pre><code>{\n  \"pipeline_version\": \"1.1.0\",\n  \"timestamp\": \"2026-01-25T12:30:45.123456\",\n  \"input\": {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\"\n  },\n  \"config\": {\n    \"pipeline\": {\n      \"processing_mode\": \"many-to-one\",\n      \"debug\": true,\n      \"reverse_edges\": false,\n      \"docling\": \"ocr\"\n    },\n    \"extraction\": {\n      \"backend\": \"llm\",\n      \"inference\": \"remote\",\n      \"model\": \"mistral-small-latest\",\n      \"provider\": \"mistral\",\n      \"use_chunking\": true,\n      \"max_batch_size\": 1\n    }\n  },\n  \"processing_time_seconds\": 15.42,\n  \"results\": {\n    \"nodes\": 25,\n    \"edges\": 18,\n    \"extracted_models\": 4\n  }\n}\n</code></pre>"},{"location":"reference/pipeline/#output-directory-manager","title":"Output Directory Manager","text":"<p>The <code>OutputDirectoryManager</code> organizes all outputs into a structured hierarchy:</p> <pre><code>from docling_graph.core.utils.output_manager import OutputDirectoryManager\n\n# Create manager\nmanager = OutputDirectoryManager(\n    base_output_dir=Path(\"outputs\"),\n    source_filename=\"document.pdf\"\n)\n\n# Main output directories\ndocling_dir = manager.get_docling_dir()\ngraph_dir = manager.get_docling_graph_dir()\ndebug_dir = manager.get_debug_dir()\n\n# Optional debug subdirs (per-page / per-chunk)\nper_page_dir = manager.get_per_page_dir()\nper_chunk_dir = manager.get_per_chunk_dir()\n</code></pre>"},{"location":"reference/pipeline/#performance-considerations","title":"Performance Considerations","text":""},{"location":"reference/pipeline/#memory-usage","title":"Memory Usage","text":"<pre><code># For large documents, use chunking\nrun_pipeline({\n    \"source\": \"large_document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n    \"use_chunking\": True,  # Reduces memory usage\n    \"processing_mode\": \"one-to-one\"  # Process page by page\n})\n</code></pre>"},{"location":"reference/pipeline/#speed-optimization","title":"Speed Optimization","text":"<pre><code># For faster processing\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n    \"backend\": \"llm\",\n    \"inference\": \"local\",  # Faster than remote\n    \"use_chunking\": False  # Skip chunking for small docs\n})\n</code></pre>"},{"location":"reference/pipeline/#debugging","title":"Debugging","text":""},{"location":"reference/pipeline/#enable-logging","title":"Enable Logging","text":"<pre><code>import logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# Run pipeline\nfrom docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\"\n})\n</code></pre>"},{"location":"reference/pipeline/#inspect-outputs","title":"Inspect Outputs","text":"<pre><code>from pathlib import Path\nimport json\n\n# Run pipeline\nfrom docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.MyTemplate\",\n    \"output_dir\": \"outputs\"\n})\n\n# Inspect graph (path depends on output_dir and document name)\nfrom docling_graph.core.utils.output_manager import OutputDirectoryManager\nmanager = OutputDirectoryManager(Path(\"outputs\"), \"document.pdf\")\ngraph_path = manager.get_docling_graph_dir() / \"graph.json\"\nif graph_path.exists():\n    with open(graph_path) as f:\n        graph_data = json.load(f)\n        print(f\"Nodes: {len(graph_data.get('nodes', []))}\")\n        print(f\"Edges: {len(graph_data.get('links', []))}\")\n</code></pre>"},{"location":"reference/pipeline/#related-apis","title":"Related APIs","text":"<ul> <li>Configuration API - PipelineConfig class</li> <li>Exceptions - Exception hierarchy</li> <li>Extractors - Extraction strategies</li> </ul>"},{"location":"reference/pipeline/#see-also","title":"See Also","text":"<ul> <li>Python API Guide - Usage guide</li> <li>CLI Reference - CLI equivalent</li> <li>Examples - Example usage</li> </ul>"},{"location":"reference/protocols/","title":"Protocols","text":""},{"location":"reference/protocols/#overview","title":"Overview","text":"<p>Protocol definitions for type-safe interfaces in docling-graph.</p> <p>Module: <code>docling_graph.protocols</code></p> <p>Protocols define expected interfaces without requiring inheritance, enabling duck typing with type safety.</p>"},{"location":"reference/protocols/#backend-protocols","title":"Backend Protocols","text":""},{"location":"reference/protocols/#extractionbackendprotocol","title":"ExtractionBackendProtocol","text":"<p>Protocol for VLM backends that process documents directly.</p> <pre><code>@runtime_checkable\nclass ExtractionBackendProtocol(Protocol):\n    \"\"\"Protocol for extraction backends that process entire documents.\"\"\"\n\n    def extract_from_document(\n        self, \n        source: str, \n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"Extract structured data from a document.\"\"\"\n        ...\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up backend resources.\"\"\"\n        ...\n</code></pre> <p>Methods:</p>"},{"location":"reference/protocols/#extract_from_document","title":"extract_from_document()","text":"<pre><code>def extract_from_document(\n    source: str,\n    template: Type[BaseModel]\n) -&gt; List[BaseModel]\n</code></pre> <p>Extract structured data from a document.</p> <p>Parameters: - <code>source</code> (<code>str</code>): Path to source document - <code>template</code> (<code>Type[BaseModel]</code>): Pydantic model template</p> <p>Returns: List of extracted Pydantic model instances</p> <p>Example:</p> <pre><code>class MyVLMBackend(ExtractionBackendProtocol):\n    def extract_from_document(self, source, template):\n        # Process document directly\n        result = self.model.process(source)\n        return [template.model_validate(result)]\n\n    def cleanup(self):\n        del self.model\n</code></pre>"},{"location":"reference/protocols/#textextractionbackendprotocol","title":"TextExtractionBackendProtocol","text":"<p>Protocol for LLM backends that process markdown/text.</p> <pre><code>@runtime_checkable\nclass TextExtractionBackendProtocol(Protocol):\n    \"\"\"Protocol for extraction backends that process markdown/text.\"\"\"\n\n    client: Any  # LLM client instance\n\n    def extract_from_markdown(\n        self,\n        markdown: str,\n        template: Type[BaseModel],\n        context: str = \"document\",\n        is_partial: bool = False\n    ) -&gt; BaseModel | None:\n        \"\"\"Extract structured data from markdown.\"\"\"\n        ...\n\n    def consolidate_from_pydantic_models(\n        self,\n        raw_models: List[BaseModel],\n        programmatic_model: BaseModel,\n        template: Type[BaseModel]\n    ) -&gt; BaseModel | None:\n        \"\"\"Consolidate multiple models using LLM.\"\"\"\n        ...\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up backend resources.\"\"\"\n        ...\n</code></pre> <p>Attributes: - <code>client</code> (<code>Any</code>): LLM client instance</p> <p>Methods:</p>"},{"location":"reference/protocols/#extract_from_markdown","title":"extract_from_markdown()","text":"<pre><code>def extract_from_markdown(\n    markdown: str,\n    template: Type[BaseModel],\n    context: str = \"document\",\n    is_partial: bool = False\n) -&gt; BaseModel | None\n</code></pre> <p>Extract structured data from markdown content.</p> <p>Parameters: - <code>markdown</code> (<code>str</code>): Markdown content - <code>template</code> (<code>Type[BaseModel]</code>): Pydantic model template - <code>context</code> (<code>str</code>): Context description (e.g., \"page 1\") - <code>is_partial</code> (<code>bool</code>): Whether this is partial extraction</p> <p>Returns: Extracted model instance or None</p>"},{"location":"reference/protocols/#consolidate_from_pydantic_models","title":"consolidate_from_pydantic_models()","text":"<pre><code>def consolidate_from_pydantic_models(\n    raw_models: List[BaseModel],\n    programmatic_model: BaseModel,\n    template: Type[BaseModel]\n) -&gt; BaseModel | None\n</code></pre> <p>Consolidate multiple models using LLM.</p> <p>Parameters: - <code>raw_models</code> (<code>List[BaseModel]</code>): List of extracted models - <code>programmatic_model</code> (<code>BaseModel</code>): Programmatically merged model - <code>template</code> (<code>Type[BaseModel]</code>): Target template</p> <p>Returns: Consolidated model instance or None</p> <p>Example:</p> <pre><code>class MyLLMBackend(TextExtractionBackendProtocol):\n    def __init__(self, client):\n        self.client = client\n\n    def extract_from_markdown(self, markdown, template, context=\"\", is_partial=False):\n        prompt = f\"Extract from: {markdown}\"\n        response = self.client.get_json_response(prompt, template.model_json_schema())\n        return template.model_validate(response)\n\n    def consolidate_from_pydantic_models(self, raw_models, programmatic_model, template):\n        # Use LLM to merge models\n        return programmatic_model\n\n    def cleanup(self):\n        self.client.close()\n</code></pre>"},{"location":"reference/protocols/#llm-client-protocol","title":"LLM Client Protocol","text":""},{"location":"reference/protocols/#llmclientprotocol","title":"LLMClientProtocol","text":"<p>Protocol for LLM clients (Ollama, Mistral, OpenAI, etc.).</p> <pre><code>@runtime_checkable\nclass LLMClientProtocol(Protocol):\n    \"\"\"Protocol for LLM clients.\"\"\"\n\n    @property\n    def context_limit(self) -&gt; int:\n        \"\"\"Return effective context limit in tokens.\"\"\"\n        ...\n\n    def get_json_response(\n        self,\n        prompt: str | Mapping[str, str],\n        schema_json: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Execute LLM call and return parsed JSON.\"\"\"\n        ...\n</code></pre> <p>Properties:</p>"},{"location":"reference/protocols/#context_limit","title":"context_limit","text":"<pre><code>@property\ndef context_limit(self) -&gt; int\n</code></pre> <p>Return the effective context limit in tokens.</p> <p>Returns: Conservative token limit</p> <p>Methods:</p>"},{"location":"reference/protocols/#get_json_response","title":"get_json_response()","text":"<pre><code>def get_json_response(\n    prompt: str | Mapping[str, str],\n    schema_json: str\n) -&gt; Dict[str, Any]\n</code></pre> <p>Execute LLM call and return parsed JSON.</p> <p>Parameters: - <code>prompt</code> (<code>str</code> or <code>Mapping[str, str]</code>): Prompt (legacy string or dict with 'system' and 'user') - <code>schema_json</code> (<code>str</code>): Pydantic schema as JSON string</p> <p>Returns: Parsed JSON dictionary</p> <p>Example:</p> <pre><code>class MyLLMClient(LLMClientProtocol):\n    @property\n    def context_limit(self) -&gt; int:\n        return 8000  # Conservative limit\n\n    def get_json_response(self, prompt, schema_json):\n        # Handle both formats\n        if isinstance(prompt, dict):\n            system = prompt.get(\"system\", \"\")\n            user = prompt.get(\"user\", \"\")\n        else:\n            system = \"\"\n            user = prompt\n\n        # Call LLM API\n        response = self.api.chat(system=system, user=user)\n        return json.loads(response)\n</code></pre>"},{"location":"reference/protocols/#extractor-protocol","title":"Extractor Protocol","text":""},{"location":"reference/protocols/#extractorprotocol","title":"ExtractorProtocol","text":"<p>Protocol for extraction strategies.</p> <pre><code>@runtime_checkable\nclass ExtractorProtocol(Protocol):\n    \"\"\"Protocol for extraction strategies.\"\"\"\n\n    backend: Any  # Backend instance\n\n    def extract(\n        self,\n        source: str,\n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"Extract structured data from source document.\"\"\"\n        ...\n</code></pre> <p>Attributes: - <code>backend</code> (<code>Any</code>): Backend instance (VLM or LLM)</p> <p>Methods:</p>"},{"location":"reference/protocols/#extract","title":"extract()","text":"<pre><code>def extract(\n    source: str,\n    template: Type[BaseModel]\n) -&gt; List[BaseModel]\n</code></pre> <p>Extract structured data from source document.</p> <p>Parameters: - <code>source</code> (<code>str</code>): Path to source document - <code>template</code> (<code>Type[BaseModel]</code>): Pydantic model template</p> <p>Returns: List of extracted Pydantic model instances - OneToOne: May contain N models (one per page) - ManyToOne: Contains 1 merged model</p> <p>Example:</p> <pre><code>class MyExtractor(ExtractorProtocol):\n    def __init__(self, backend):\n        self.backend = backend\n\n    def extract(self, source, template):\n        # Use backend to extract\n        return self.backend.extract_from_document(source, template)\n</code></pre>"},{"location":"reference/protocols/#document-processor-protocol","title":"Document Processor Protocol","text":""},{"location":"reference/protocols/#documentprocessorprotocol","title":"DocumentProcessorProtocol","text":"<p>Protocol for document processing and conversion.</p> <pre><code>@runtime_checkable\nclass DocumentProcessorProtocol(Protocol):\n    \"\"\"Protocol for document processing and conversion.\"\"\"\n\n    def convert_to_docling_doc(self, source: str) -&gt; Any:\n        \"\"\"Convert document to Docling document object.\"\"\"\n        ...\n\n    def extract_full_markdown(self, document: Any) -&gt; str:\n        \"\"\"Extract complete markdown from document.\"\"\"\n        ...\n\n    def extract_page_markdowns(self, document: Any) -&gt; List[str]:\n        \"\"\"Extract markdown for each page separately.\"\"\"\n        ...\n</code></pre> <p>Methods:</p>"},{"location":"reference/protocols/#convert_to_docling_doc","title":"convert_to_docling_doc()","text":"<pre><code>def convert_to_docling_doc(source: str) -&gt; Any\n</code></pre> <p>Convert document to Docling document object.</p> <p>Parameters: - <code>source</code> (<code>str</code>): Path to source document</p> <p>Returns: Docling document object</p>"},{"location":"reference/protocols/#extract_full_markdown","title":"extract_full_markdown()","text":"<pre><code>def extract_full_markdown(document: Any) -&gt; str\n</code></pre> <p>Extract complete markdown from document.</p> <p>Parameters: - <code>document</code> (<code>Any</code>): Docling document object</p> <p>Returns: Full markdown content as string</p>"},{"location":"reference/protocols/#extract_page_markdowns","title":"extract_page_markdowns()","text":"<pre><code>def extract_page_markdowns(document: Any) -&gt; List[str]\n</code></pre> <p>Extract markdown for each page separately.</p> <p>Parameters: - <code>document</code> (<code>Any</code>): Docling document object</p> <p>Returns: List of markdown strings, one per page</p>"},{"location":"reference/protocols/#type-checking-utilities","title":"Type Checking Utilities","text":""},{"location":"reference/protocols/#is_vlm_backend","title":"is_vlm_backend()","text":"<pre><code>def is_vlm_backend(backend: Any) -&gt; TypeGuard[ExtractionBackendProtocol]\n</code></pre> <p>Check if backend behaves like a VLM backend.</p> <p>Parameters: - <code>backend</code> (<code>Any</code>): Backend instance to check</p> <p>Returns: True if backend provides document-level extraction</p> <p>Example:</p> <pre><code>from docling_graph.protocols import is_vlm_backend\n\nif is_vlm_backend(my_backend):\n    # Use VLM-specific features\n    result = my_backend.extract_from_document(source, template)\n</code></pre>"},{"location":"reference/protocols/#is_llm_backend","title":"is_llm_backend()","text":"<pre><code>def is_llm_backend(backend: Any) -&gt; TypeGuard[TextExtractionBackendProtocol]\n</code></pre> <p>Check if backend behaves like an LLM backend.</p> <p>Parameters: - <code>backend</code> (<code>Any</code>): Backend instance to check</p> <p>Returns: True if backend provides markdown/text extraction</p> <p>Example:</p> <pre><code>from docling_graph.protocols import is_llm_backend\n\nif is_llm_backend(my_backend):\n    # Use LLM-specific features\n    result = my_backend.extract_from_markdown(markdown, template)\n</code></pre>"},{"location":"reference/protocols/#get_backend_type","title":"get_backend_type()","text":"<pre><code>def get_backend_type(backend: Any) -&gt; str\n</code></pre> <p>Get the backend type as a string.</p> <p>Parameters: - <code>backend</code> (<code>Any</code>): Backend instance</p> <p>Returns: \"vlm\", \"llm\", or \"unknown\"</p> <p>Example:</p> <pre><code>from docling_graph.protocols import get_backend_type\n\nbackend_type = get_backend_type(my_backend)\nprint(f\"Backend type: {backend_type}\")\n</code></pre>"},{"location":"reference/protocols/#type-aliases","title":"Type Aliases","text":"<p>Convenient type aliases for clarity:</p> <pre><code># Backend can be either VLM or LLM\nBackend = ExtractionBackendProtocol | TextExtractionBackendProtocol\n\n# Extractor strategies\nExtractor = ExtractorProtocol\n\n# LLM client\nLLMClient = LLMClientProtocol\n\n# Document processor\nDocumentProcessor = DocumentProcessorProtocol\n</code></pre> <p>Usage:</p> <pre><code>from docling_graph.protocols import Backend, LLMClient\n\ndef process_with_backend(backend: Backend):\n    \"\"\"Process with any backend type.\"\"\"\n    pass\n\ndef create_client() -&gt; LLMClient:\n    \"\"\"Create an LLM client.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/protocols/#implementation-examples","title":"Implementation Examples","text":""},{"location":"reference/protocols/#custom-vlm-backend","title":"Custom VLM Backend","text":"<pre><code>from docling_graph.protocols import ExtractionBackendProtocol\nfrom typing import List, Type\nfrom pydantic import BaseModel\n\nclass CustomVLMBackend(ExtractionBackendProtocol):\n    \"\"\"Custom VLM backend implementation.\"\"\"\n\n    def __init__(self, model_name: str):\n        self.model = load_model(model_name)\n\n    def extract_from_document(\n        self,\n        source: str,\n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"Extract from document.\"\"\"\n        result = self.model.process(source)\n        return [template.model_validate(result)]\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        del self.model\n</code></pre>"},{"location":"reference/protocols/#custom-llm-backend","title":"Custom LLM Backend","text":"<pre><code>from docling_graph.protocols import TextExtractionBackendProtocol\nfrom typing import List, Type\nfrom pydantic import BaseModel\n\nclass CustomLLMBackend(TextExtractionBackendProtocol):\n    \"\"\"Custom LLM backend implementation.\"\"\"\n\n    def __init__(self, client):\n        self.client = client\n\n    def extract_from_markdown(\n        self,\n        markdown: str,\n        template: Type[BaseModel],\n        context: str = \"document\",\n        is_partial: bool = False\n    ) -&gt; BaseModel | None:\n        \"\"\"Extract from markdown.\"\"\"\n        schema = template.model_json_schema()\n        response = self.client.get_json_response(markdown, str(schema))\n        return template.model_validate(response)\n\n    def consolidate_from_pydantic_models(\n        self,\n        raw_models: List[BaseModel],\n        programmatic_model: BaseModel,\n        template: Type[BaseModel]\n    ) -&gt; BaseModel | None:\n        \"\"\"Consolidate models.\"\"\"\n        return programmatic_model\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        self.client.close()\n</code></pre>"},{"location":"reference/protocols/#runtime-checking","title":"Runtime Checking","text":"<p>All protocols are decorated with <code>@runtime_checkable</code>:</p> <pre><code>from docling_graph.protocols import ExtractionBackendProtocol\n\n# Check at runtime\nif isinstance(my_backend, ExtractionBackendProtocol):\n    print(\"Backend implements VLM protocol\")\n</code></pre>"},{"location":"reference/protocols/#related-apis","title":"Related APIs","text":"<ul> <li>Custom Backends - Implementation guide</li> <li>Extractors - Extractor implementations</li> <li>LLM Clients - Client implementations</li> </ul>"},{"location":"reference/protocols/#see-also","title":"See Also","text":"<ul> <li>Python Protocols - PEP 544</li> <li>Type Hints - Python typing</li> </ul>"},{"location":"usage/","title":"Usage","text":"<p>Practical guides for using Docling Graph through CLI, Python API, and advanced techniques.</p>"},{"location":"usage/#topics","title":"Topics","text":"<ol> <li>CLI Reference - Command-line interface</li> <li>Python API - Programmatic usage</li> <li>Examples - Working code examples</li> <li>Advanced Topics - Performance tuning and customization</li> </ol> <p>New users: Start with Examples CLI users: See CLI Reference Developers: Check Python API</p>"},{"location":"usage/advanced/","title":"Advanced Topics","text":""},{"location":"usage/advanced/#overview","title":"Overview","text":"<p>This section covers advanced topics for extending and optimizing docling-graph. These guides are for users who need to:</p> <ul> <li>Create custom extraction backends</li> <li>Build custom exporters</li> <li>Add pipeline stages</li> <li>Optimize performance</li> <li>Handle errors gracefully</li> <li>Test templates and pipelines</li> </ul>"},{"location":"usage/advanced/#topics","title":"Topics","text":""},{"location":"usage/advanced/#extensibility","title":"\ud83e\udde9 Extensibility","text":"<p>Custom Backends Create custom extraction backends for specialized models or APIs.</p> <ul> <li>Implement backend protocols</li> <li>VLM backend example</li> <li>LLM backend example</li> <li>Integration with pipeline</li> </ul> <p>Custom Exporters Build custom exporters for specialized output formats.</p> <ul> <li>Implement exporter protocol</li> <li>Graph data access</li> <li>Custom format generation</li> <li>Registration and usage</li> </ul> <p>Custom Stages Add custom stages to the pipeline for specialized processing.</p> <ul> <li>Pipeline stage protocol</li> <li>Stage implementation</li> <li>Context management</li> <li>Error handling</li> </ul>"},{"location":"usage/advanced/#optimization","title":"\ud83d\udcd0 Optimization","text":"<p>Performance Tuning Optimize extraction speed and resource usage.</p> <ul> <li>Model selection strategies</li> <li>Batch size optimization</li> <li>Memory management</li> <li>GPU utilization</li> <li>Caching strategies</li> </ul>"},{"location":"usage/advanced/#reliability","title":"\ud83d\udee1\ufe0f Reliability","text":"<p>Error Handling Handle errors gracefully and implement retry logic.</p> <ul> <li>Exception hierarchy</li> <li>Error recovery strategies</li> <li>Logging and debugging</li> <li>Retry mechanisms</li> </ul> <p>Testing Test templates, backends, and pipelines.</p> <ul> <li>Template validation</li> <li>Mock backends</li> <li>Integration testing</li> <li>CI/CD integration</li> </ul>"},{"location":"usage/advanced/#prerequisites","title":"Prerequisites","text":"<p>Before diving into advanced topics, ensure you understand:</p> <ol> <li>Schema Definition - Pydantic templates</li> <li>Pipeline Configuration - Configuration options</li> <li>Extraction Process - How extraction works</li> <li>Python API - Programmatic usage</li> </ol>"},{"location":"usage/advanced/#when-to-use-advanced-features","title":"When to Use Advanced Features","text":""},{"location":"usage/advanced/#custom-backends","title":"Custom Backends","text":"<p>Use when: \u2705 You have a specialized model not supported by default \u2705 You need to integrate with a proprietary API \u2705 You want to implement custom preprocessing \u2705 You need fine-grained control over extraction</p> <p>Don't use when: \u274c Default backends meet your needs \u274c You're just starting with docling-graph \u274c You don't need custom logic</p>"},{"location":"usage/advanced/#custom-exporters","title":"Custom Exporters","text":"<p>Use when: \u2705 You need a specialized output format \u2705 You're integrating with a specific database \u2705 You need custom data transformations \u2705 Default formats don't meet requirements</p> <p>Don't use when: \u274c CSV, Cypher, or JSON formats work \u274c You can post-process existing exports \u274c You're prototyping</p>"},{"location":"usage/advanced/#custom-stages","title":"Custom Stages","text":"<p>Use when: \u2705 You need custom preprocessing \u2705 You want to add validation steps \u2705 You need custom post-processing \u2705 You're building a specialized pipeline</p> <p>Don't use when: \u274c Default pipeline stages suffice \u274c You can achieve goals with configuration \u274c You're learning the system</p>"},{"location":"usage/advanced/#architecture","title":"Architecture","text":""},{"location":"usage/advanced/#extension-points","title":"Extension Points","text":"<p>%%{init: {'theme': 'redux-dark', 'look': 'default', 'layout': 'elk'}}%% flowchart TB     %% 1. Define Classes     classDef input fill:#E3F2FD,stroke:#90CAF9,color:#0D47A1     classDef config fill:#FFF8E1,stroke:#FFECB3,color:#5D4037     classDef output fill:#E8F5E9,stroke:#A5D6A7,color:#1B5E20     classDef decision fill:#FFE0B2,stroke:#FFB74D,color:#E65100     classDef data fill:#EDE7F6,stroke:#B39DDB,color:#4527A0     classDef operator fill:#F3E5F5,stroke:#CE93D8,color:#6A1B9A     classDef process fill:#ECEFF1,stroke:#B0BEC5,color:#263238</p> <pre><code>%% 2. Define Nodes\nA@{ shape: terminal, label: \"Input Source\" }\n\nB@{ shape: lin-proc, label: \"Custom Stage 1\" }\nC@{ shape: procs, label: \"Docling Conversion\" }\nD@{ shape: tag-proc, label: \"Custom Backend\" }\nE@{ shape: procs, label: \"Extraction\" }\nF@{ shape: lin-proc, label: \"Custom Stage 2\" }\nG@{ shape: procs, label: \"Graph Conversion\" }\nH@{ shape: tag-proc, label: \"Custom Exporter\" }\n\nI@{ shape: doc, label: \"Output\" }\n\n%% 3. Define Connections\nA --&gt; B\nB --&gt; C\nC --&gt; D\nD --&gt; E\nE --&gt; F\nF --&gt; G\nG --&gt; H\nH --&gt; I\n\n%% 4. Apply Classes\nclass A input\nclass B,F config\nclass C,E,G process\nclass D,H operator\nclass I output\n</code></pre> <p>```  Extension Points: - Custom Backends (blue): Replace extraction logic - Custom Exporters (blue): Replace export logic - Custom Stages (yellow): Add processing steps</p>"},{"location":"usage/advanced/#code-organization","title":"Code Organization","text":""},{"location":"usage/advanced/#project-structure-for-extensions","title":"Project Structure for Extensions","text":"<p><code>my_project/ \u251c\u2500\u2500 templates/              # Pydantic templates \u2502   \u2514\u2500\u2500 my_template.py \u251c\u2500\u2500 backends/               # Custom backends \u2502   \u251c\u2500\u2500 __init__.py \u2502   \u2514\u2500\u2500 my_backend.py \u251c\u2500\u2500 exporters/              # Custom exporters \u2502   \u251c\u2500\u2500 __init__.py \u2502   \u2514\u2500\u2500 my_exporter.py \u251c\u2500\u2500 stages/                 # Custom stages \u2502   \u251c\u2500\u2500 __init__.py \u2502   \u2514\u2500\u2500 my_stage.py \u251c\u2500\u2500 tests/                  # Tests \u2502   \u251c\u2500\u2500 test_backend.py \u2502   \u251c\u2500\u2500 test_exporter.py \u2502   \u2514\u2500\u2500 test_stage.py \u2514\u2500\u2500 main.py                 # Entry point</code></p>"},{"location":"usage/advanced/#development-workflow","title":"Development Workflow","text":""},{"location":"usage/advanced/#1-design","title":"1. Design","text":"<p>```python</p>"},{"location":"usage/advanced/#define-interface","title":"Define interface","text":"<p>from docling_graph.protocols import TextExtractionBackendProtocol  class MyBackend(TextExtractionBackendProtocol):     \"\"\"Custom backend implementation.\"\"\"     pass ```</p>"},{"location":"usage/advanced/#2-implement","title":"2. Implement","text":"<pre><code># Implement methods\ndef extract_from_markdown(self, markdown: str, template, context=\"\", is_partial=False):\n    \"\"\"Extract structured data.\"\"\"\n    # Your logic here\n    pass\n</code></pre>"},{"location":"usage/advanced/#3-test","title":"3. Test","text":"<pre><code># Write tests\ndef test_my_backend():\n    backend = MyBackend()\n    result = backend.extract_from_markdown(\"test\", MyTemplate)\n    assert result is not None\n</code></pre>"},{"location":"usage/advanced/#4-integrate","title":"4. Integrate","text":"<pre><code># Use in pipeline\nfrom docling_graph import PipelineConfig\nfrom my_backends import MyBackend\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    # Custom backend integration\n)\n</code></pre>"},{"location":"usage/advanced/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/#follow-protocols","title":"\ud83d\udc4d Follow Protocols","text":"<pre><code># \u2705 Good - Implement protocol\nfrom docling_graph.protocols import TextExtractionBackendProtocol\n\nclass MyBackend(TextExtractionBackendProtocol):\n    def extract_from_markdown(self, ...): ...\n    def consolidate_from_pydantic_models(self, ...): ...\n    def cleanup(self): ...\n\n# \u274c Avoid - Custom interface\nclass MyBackend:\n    def my_custom_method(self, ...): ...\n</code></pre>"},{"location":"usage/advanced/#handle-errors","title":"\ud83d\udc4d Handle Errors","text":"<pre><code># \u2705 Good - Use docling-graph exceptions\nfrom docling_graph.exceptions import ExtractionError\n\ndef extract(self, ...):\n    try:\n        result = self._process()\n        return result\n    except Exception as e:\n        raise ExtractionError(\n            \"Extraction failed\",\n            details={\"source\": source},\n            cause=e\n        )\n\n# \u274c Avoid - Generic exceptions\ndef extract(self, ...):\n    raise Exception(\"Something went wrong\")\n</code></pre>"},{"location":"usage/advanced/#write-tests","title":"\ud83d\udc4d Write Tests","text":"<pre><code># \u2705 Good - Comprehensive tests\ndef test_backend_success():\n    \"\"\"Test successful extraction.\"\"\"\n    pass\n\ndef test_backend_failure():\n    \"\"\"Test error handling.\"\"\"\n    pass\n\ndef test_backend_cleanup():\n    \"\"\"Test resource cleanup.\"\"\"\n    pass\n\n# \u274c Avoid - No tests\n# (No tests written)\n</code></pre>"},{"location":"usage/advanced/#document-code","title":"\ud83d\udc4d Document Code","text":"<pre><code># \u2705 Good - Clear documentation\nclass MyBackend:\n    \"\"\"\n    Custom backend for specialized extraction.\n\n    This backend uses a proprietary model to extract\n    structured data from documents.\n\n    Args:\n        api_key: API key for the service\n        model: Model name to use\n\n    Example:\n        &gt;&gt;&gt; backend = MyBackend(api_key=\"key\", model=\"model-v1\")\n        &gt;&gt;&gt; result = backend.extract_from_markdown(text, Template)\n    \"\"\"\n    pass\n\n# \u274c Avoid - No documentation\nclass MyBackend:\n    pass\n</code></pre>"},{"location":"usage/advanced/#performance-considerations","title":"Performance Considerations","text":""},{"location":"usage/advanced/#memory-management","title":"Memory Management","text":"<pre><code># \u2705 Good - Clean up resources\nclass MyBackend:\n    def cleanup(self):\n        \"\"\"Release resources.\"\"\"\n        if hasattr(self, 'model'):\n            del self.model\n        if hasattr(self, 'client'):\n            self.client.close()\n\n# \u274c Avoid - Memory leaks\nclass MyBackend:\n    def cleanup(self):\n        pass  # Resources not released\n</code></pre>"},{"location":"usage/advanced/#batch-processing","title":"Batch Processing","text":"<pre><code># \u2705 Good - Process in batches\ndef process_documents(docs):\n    batch_size = 10\n    for i in range(0, len(docs), batch_size):\n        batch = docs[i:i+batch_size]\n        process_batch(batch)\n\n# \u274c Avoid - Process all at once\ndef process_documents(docs):\n    process_all(docs)  # May run out of memory\n</code></pre>"},{"location":"usage/advanced/#security-considerations","title":"Security Considerations","text":""},{"location":"usage/advanced/#api-keys","title":"API Keys","text":"<pre><code># \u2705 Good - Use environment variables\nimport os\n\napi_key = os.getenv(\"MY_API_KEY\")\nif not api_key:\n    raise ValueError(\"MY_API_KEY not set\")\n\n# \u274c Avoid - Hardcoded keys\napi_key = \"sk-1234567890\"  # Never do this!\n</code></pre>"},{"location":"usage/advanced/#input-validation","title":"Input Validation","text":"<pre><code># \u2705 Good - Validate inputs\ndef extract(self, markdown: str, template):\n    if not markdown:\n        raise ValueError(\"Markdown cannot be empty\")\n    if not template:\n        raise ValueError(\"Template is required\")\n    # Process...\n\n# \u274c Avoid - No validation\ndef extract(self, markdown, template):\n    # Process without checks\n    pass\n</code></pre>"},{"location":"usage/advanced/#next-steps","title":"Next Steps","text":"<p>Choose a topic based on your needs:</p> <ol> <li>Custom Backends \u2192 - Extend extraction capabilities</li> <li>Custom Exporters \u2192 - Create custom output formats</li> <li>Custom Stages \u2192 - Add pipeline stages</li> <li>Performance Tuning \u2192 - Optimize performance</li> <li>Error Handling \u2192 - Handle errors gracefully</li> <li>Testing \u2192 - Test your extensions</li> </ol>"},{"location":"usage/advanced/custom-backends/","title":"Custom Backends","text":""},{"location":"usage/advanced/custom-backends/#overview","title":"Overview","text":"<p>Create custom extraction backends to integrate specialized models, APIs, or processing logic into the docling-graph pipeline.</p> <p>Prerequisites: - Understanding of Extraction Process - Familiarity with Python API - Knowledge of Pydantic models</p>"},{"location":"usage/advanced/custom-backends/#backend-types","title":"Backend Types","text":""},{"location":"usage/advanced/custom-backends/#vlm-backend-vision-language-model","title":"VLM Backend (Vision-Language Model)","text":"<p>Processes documents directly without markdown conversion.</p> <p>Protocol: <code>ExtractionBackendProtocol</code></p> <pre><code>from docling_graph.protocols import ExtractionBackendProtocol\n\nclass MyVLMBackend(ExtractionBackendProtocol):\n    def extract_from_document(self, source: str, template: Type[BaseModel]) -&gt; List[BaseModel]:\n        \"\"\"Extract from document directly.\"\"\"\n        pass\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        pass\n</code></pre>"},{"location":"usage/advanced/custom-backends/#llm-backend-language-model","title":"LLM Backend (Language Model)","text":"<p>Processes markdown/text content.</p> <p>Protocol: <code>TextExtractionBackendProtocol</code></p> <pre><code>from docling_graph.protocols import TextExtractionBackendProtocol\n\nclass MyLLMBackend(TextExtractionBackendProtocol):\n    client: Any  # LLM client instance\n\n    def extract_from_markdown(\n        self, \n        markdown: str, \n        template: Type[BaseModel],\n        context: str = \"document\",\n        is_partial: bool = False\n    ) -&gt; BaseModel | None:\n        \"\"\"Extract from markdown.\"\"\"\n        pass\n\n    def consolidate_from_pydantic_models(\n        self,\n        raw_models: List[BaseModel],\n        programmatic_model: BaseModel,\n        template: Type[BaseModel]\n    ) -&gt; BaseModel | None:\n        \"\"\"Consolidate multiple models.\"\"\"\n        pass\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        pass\n</code></pre>"},{"location":"usage/advanced/custom-backends/#complete-vlm-backend-example","title":"Complete VLM Backend Example","text":""},{"location":"usage/advanced/custom-backends/#implementation","title":"Implementation","text":"<pre><code>\"\"\"\nCustom VLM backend using a hypothetical vision model.\n\"\"\"\n\nfrom typing import Any, List, Type\nfrom pathlib import Path\nfrom pydantic import BaseModel\nfrom docling_graph.protocols import ExtractionBackendProtocol\nfrom docling_graph.exceptions import ExtractionError, ClientError\n\nclass CustomVLMBackend(ExtractionBackendProtocol):\n    \"\"\"\n    Custom VLM backend for specialized vision model.\n\n    Args:\n        model_name: Name of the vision model\n        api_key: API key for the service\n        base_url: Base URL for API (optional)\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name: str = \"vision-model-v1\",\n        api_key: str | None = None,\n        base_url: str | None = None\n    ):\n        self.model_name = model_name\n        self.api_key = api_key or self._get_api_key()\n        self.base_url = base_url or \"https://api.example.com/v1\"\n\n        # Initialize client\n        self.client = self._initialize_client()\n\n    def _get_api_key(self) -&gt; str:\n        \"\"\"Get API key from environment.\"\"\"\n        import os\n        api_key = os.getenv(\"CUSTOM_VLM_API_KEY\")\n        if not api_key:\n            raise ClientError(\n                \"API key not found\",\n                details={\"env_var\": \"CUSTOM_VLM_API_KEY\"}\n            )\n        return api_key\n\n    def _initialize_client(self) -&gt; Any:\n        \"\"\"Initialize the vision model client.\"\"\"\n        try:\n            # Your client initialization here\n            from my_vision_sdk import VisionClient\n            return VisionClient(\n                api_key=self.api_key,\n                base_url=self.base_url,\n                model=self.model_name\n            )\n        except Exception as e:\n            raise ClientError(\n                \"Failed to initialize client\",\n                details={\"model\": self.model_name},\n                cause=e\n            )\n\n    def extract_from_document(\n        self, \n        source: str, \n        template: Type[BaseModel]\n    ) -&gt; List[BaseModel]:\n        \"\"\"\n        Extract structured data from document.\n\n        Args:\n            source: Path to document (image or PDF)\n            template: Pydantic model template\n\n        Returns:\n            List of extracted model instances\n\n        Raises:\n            ExtractionError: If extraction fails\n        \"\"\"\n        try:\n            # Validate source\n            source_path = Path(source)\n            if not source_path.exists():\n                raise ExtractionError(\n                    \"Source file not found\",\n                    details={\"source\": source}\n                )\n\n            # Get schema\n            schema = template.model_json_schema()\n\n            # Call vision model\n            response = self.client.extract(\n                image_path=str(source_path),\n                schema=schema\n            )\n\n            # Parse response\n            extracted_data = response.get(\"data\", {})\n\n            # Validate with Pydantic\n            model_instance = template.model_validate(extracted_data)\n\n            return [model_instance]\n\n        except Exception as e:\n            raise ExtractionError(\n                \"Document extraction failed\",\n                details={\n                    \"source\": source,\n                    \"template\": template.__name__\n                },\n                cause=e\n            )\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        if hasattr(self, 'client') and self.client:\n            try:\n                self.client.close()\n            except Exception:\n                pass  # Best effort cleanup\n</code></pre>"},{"location":"usage/advanced/custom-backends/#usage","title":"Usage","text":"<pre><code>\"\"\"Use custom VLM backend.\"\"\"\n\nfrom docling_graph import PipelineConfig\nfrom my_backends import CustomVLMBackend\n\n# Create backend instance\nbackend = CustomVLMBackend(\n    model_name=\"vision-model-v1\",\n    api_key=\"your_api_key\"\n)\n\n# Note: Direct backend integration requires custom pipeline code\n# For now, use with extraction strategies directly\nfrom docling_graph.core.extractors.strategies import OneToOne\n\nextractor = OneToOne(backend=backend)\nresults = extractor.extract(\n    source=\"document.pdf\",\n    template=MyTemplate\n)\n</code></pre>"},{"location":"usage/advanced/custom-backends/#complete-llm-backend-example","title":"Complete LLM Backend Example","text":""},{"location":"usage/advanced/custom-backends/#implementation_1","title":"Implementation","text":"<pre><code>\"\"\"\nCustom LLM backend using a hypothetical language model.\n\"\"\"\n\nfrom typing import Any, Dict, List, Type\nfrom pydantic import BaseModel\nfrom docling_graph.protocols import TextExtractionBackendProtocol, LLMClientProtocol\nfrom docling_graph.exceptions import ExtractionError, ClientError\n\nclass CustomLLMClient(LLMClientProtocol):\n    \"\"\"Custom LLM client implementation.\"\"\"\n\n    def __init__(self, model: str, api_key: str):\n        self.model = model\n        self.api_key = api_key\n        self._context_limit = 8000  # Token limit\n\n    @property\n    def context_limit(self) -&gt; int:\n        \"\"\"Return context limit in tokens.\"\"\"\n        return self._context_limit\n\n    def get_json_response(\n        self, \n        prompt: str | Dict[str, str], \n        schema_json: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Execute LLM call and return parsed JSON.\n\n        Args:\n            prompt: System/user prompt or legacy string\n            schema_json: Pydantic schema as JSON string\n\n        Returns:\n            Parsed JSON dictionary\n        \"\"\"\n        try:\n            # Handle both formats\n            if isinstance(prompt, dict):\n                system_prompt = prompt.get(\"system\", \"\")\n                user_prompt = prompt.get(\"user\", \"\")\n            else:\n                system_prompt = \"\"\n                user_prompt = prompt\n\n            # Call your LLM API\n            from my_llm_sdk import LLMClient\n            client = LLMClient(api_key=self.api_key)\n\n            response = client.chat(\n                model=self.model,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_prompt},\n                    {\"role\": \"user\", \"content\": user_prompt}\n                ],\n                response_format={\"type\": \"json_object\"},\n                schema=schema_json\n            )\n\n            # Parse JSON response\n            import json\n            return json.loads(response.content)\n\n        except Exception as e:\n            raise ClientError(\n                \"LLM call failed\",\n                details={\"model\": self.model},\n                cause=e\n            )\n\n\n# Use a custom client in the pipeline\nfrom docling_graph import run_pipeline\n\nconfig = {\n    \"source\": \"doc.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"llm_client\": CustomLLMClient(model=\"custom-llm-v1\", api_key=\"...\"),\n}\nrun_pipeline(config)\n\n\nclass CustomLLMBackend(TextExtractionBackendProtocol):\n    \"\"\"\n    Custom LLM backend for text extraction.\n\n    Args:\n        model: Model name\n        api_key: API key\n    \"\"\"\n\n    def __init__(self, model: str = \"custom-llm-v1\", api_key: str | None = None):\n        import os\n        self.model = model\n        self.api_key = api_key or os.getenv(\"CUSTOM_LLM_API_KEY\")\n\n        if not self.api_key:\n            raise ClientError(\n                \"API key not found\",\n                details={\"env_var\": \"CUSTOM_LLM_API_KEY\"}\n            )\n\n        # Initialize client\n        self.client = CustomLLMClient(\n            model=self.model,\n            api_key=self.api_key\n        )\n\n    def extract_from_markdown(\n        self,\n        markdown: str,\n        template: Type[BaseModel],\n        context: str = \"document\",\n        is_partial: bool = False\n    ) -&gt; BaseModel | None:\n        \"\"\"\n        Extract structured data from markdown.\n\n        Args:\n            markdown: Markdown content\n            template: Pydantic model template\n            context: Context description\n            is_partial: Whether this is a partial extraction\n\n        Returns:\n            Extracted model instance or None\n        \"\"\"\n        try:\n            # Build prompt\n            schema_json = template.model_json_schema()\n\n            system_prompt = (\n                \"You are a data extraction expert. \"\n                \"Extract structured information from the provided text \"\n                \"according to the given schema.\"\n            )\n\n            user_prompt = f\"\"\"\nExtract information from this {context}:\n\n{markdown}\n\nReturn a JSON object matching this schema:\n{schema_json}\n\"\"\"\n\n            # Call LLM\n            response = self.client.get_json_response(\n                prompt={\"system\": system_prompt, \"user\": user_prompt},\n                schema_json=str(schema_json)\n            )\n\n            # Validate with Pydantic\n            model_instance = template.model_validate(response)\n            return model_instance\n\n        except Exception as e:\n            raise ExtractionError(\n                \"Markdown extraction failed\",\n                details={\n                    \"context\": context,\n                    \"template\": template.__name__\n                },\n                cause=e\n            )\n\n    def consolidate_from_pydantic_models(\n        self,\n        raw_models: List[BaseModel],\n        programmatic_model: BaseModel,\n        template: Type[BaseModel]\n    ) -&gt; BaseModel | None:\n        \"\"\"\n        Consolidate multiple models using LLM.\n\n        Args:\n            raw_models: List of extracted models\n            programmatic_model: Programmatically merged model\n            template: Target template\n\n        Returns:\n            Consolidated model instance\n        \"\"\"\n        try:\n            # Convert models to JSON\n            models_json = [m.model_dump() for m in raw_models]\n            programmatic_json = programmatic_model.model_dump()\n\n            system_prompt = (\n                \"You are a data consolidation expert. \"\n                \"Merge multiple extractions into a single coherent result.\"\n            )\n\n            user_prompt = f\"\"\"\nConsolidate these extractions:\n\nRaw extractions:\n{models_json}\n\nProgrammatic merge:\n{programmatic_json}\n\nReturn the best consolidated result as JSON.\n\"\"\"\n\n            schema_json = template.model_json_schema()\n\n            response = self.client.get_json_response(\n                prompt={\"system\": system_prompt, \"user\": user_prompt},\n                schema_json=str(schema_json)\n            )\n\n            return template.model_validate(response)\n\n        except Exception as e:\n            raise ExtractionError(\n                \"Consolidation failed\",\n                details={\"num_models\": len(raw_models)},\n                cause=e\n            )\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        # Close any open connections\n        pass\n</code></pre>"},{"location":"usage/advanced/custom-backends/#usage_1","title":"Usage","text":"<pre><code>\"\"\"Use custom LLM backend.\"\"\"\n\nfrom my_backends import CustomLLMBackend\nfrom docling_graph.core.extractors.strategies import ManyToOne\n\n# Create backend\nbackend = CustomLLMBackend(\n    model=\"custom-llm-v1\",\n    api_key=\"your_api_key\"\n)\n\n# Use with extractor\nextractor = ManyToOne(backend=backend)\nresults = extractor.extract(\n    source=\"document.pdf\",\n    template=MyTemplate\n)\n\n# Clean up\nbackend.cleanup()\n</code></pre>"},{"location":"usage/advanced/custom-backends/#testing-custom-backends","title":"Testing Custom Backends","text":""},{"location":"usage/advanced/custom-backends/#unit-tests","title":"Unit Tests","text":"<pre><code>\"\"\"Test custom backend.\"\"\"\n\nimport pytest\nfrom pydantic import BaseModel, Field\nfrom my_backends import CustomLLMBackend\n\nclass TestTemplate(BaseModel):\n    \"\"\"Simple test template.\"\"\"\n    name: str = Field(..., description=\"Name\")\n    value: int = Field(..., description=\"Value\")\n\ndef test_backend_initialization():\n    \"\"\"Test backend can be initialized.\"\"\"\n    backend = CustomLLMBackend(\n        model=\"test-model\",\n        api_key=\"test-key\"\n    )\n    assert backend.model == \"test-model\"\n    assert backend.client is not None\n\ndef test_extract_from_markdown():\n    \"\"\"Test markdown extraction.\"\"\"\n    backend = CustomLLMBackend(\n        model=\"test-model\",\n        api_key=\"test-key\"\n    )\n\n    markdown = \"Name: John, Value: 42\"\n    result = backend.extract_from_markdown(\n        markdown=markdown,\n        template=TestTemplate\n    )\n\n    assert result is not None\n    assert isinstance(result, TestTemplate)\n    assert result.name == \"John\"\n    assert result.value == 42\n\ndef test_cleanup():\n    \"\"\"Test cleanup doesn't raise errors.\"\"\"\n    backend = CustomLLMBackend(\n        model=\"test-model\",\n        api_key=\"test-key\"\n    )\n    backend.cleanup()  # Should not raise\n</code></pre>"},{"location":"usage/advanced/custom-backends/#integration-tests","title":"Integration Tests","text":"<pre><code>\"\"\"Integration test with pipeline.\"\"\"\n\nfrom docling_graph.core.extractors.strategies import ManyToOne\nfrom my_backends import CustomLLMBackend\n\ndef test_backend_with_extractor():\n    \"\"\"Test backend works with extractor.\"\"\"\n    backend = CustomLLMBackend(\n        model=\"test-model\",\n        api_key=\"test-key\"\n    )\n\n    extractor = ManyToOne(backend=backend)\n\n    results = extractor.extract(\n        source=\"test_document.pdf\",\n        template=TestTemplate\n    )\n\n    assert len(results) &gt; 0\n    assert all(isinstance(r, TestTemplate) for r in results)\n\n    backend.cleanup()\n</code></pre>"},{"location":"usage/advanced/custom-backends/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/custom-backends/#implement-all-protocol-methods","title":"\ud83d\udc4d Implement All Protocol Methods","text":"<pre><code># \u2705 Good - Complete implementation\nclass MyBackend(TextExtractionBackendProtocol):\n    client: Any\n\n    def extract_from_markdown(self, ...): ...\n    def consolidate_from_pydantic_models(self, ...): ...\n    def cleanup(self): ...\n\n# \u274c Avoid - Missing methods\nclass MyBackend:\n    def extract_from_markdown(self, ...): ...\n    # Missing other methods!\n</code></pre>"},{"location":"usage/advanced/custom-backends/#use-structured-exceptions","title":"\ud83d\udc4d Use Structured Exceptions","text":"<pre><code># \u2705 Good - Structured errors\nfrom docling_graph.exceptions import ExtractionError, ClientError\n\ndef extract(self, ...):\n    try:\n        result = self._process()\n        return result\n    except APIError as e:\n        raise ClientError(\"API call failed\", cause=e)\n    except ValidationError as e:\n        raise ExtractionError(\"Validation failed\", cause=e)\n\n# \u274c Avoid - Generic exceptions\ndef extract(self, ...):\n    raise Exception(\"Something went wrong\")\n</code></pre>"},{"location":"usage/advanced/custom-backends/#clean-up-resources","title":"\ud83d\udc4d Clean Up Resources","text":"<pre><code># \u2705 Good - Proper cleanup\nclass MyBackend:\n    def __init__(self):\n        self.client = initialize_client()\n        self.model = load_model()\n\n    def cleanup(self):\n        if hasattr(self, 'client'):\n            self.client.close()\n        if hasattr(self, 'model'):\n            del self.model\n            import gc\n            gc.collect()\n\n# \u274c Avoid - No cleanup\nclass MyBackend:\n    def cleanup(self):\n        pass  # Resources leak!\n</code></pre>"},{"location":"usage/advanced/custom-backends/#validate-inputs","title":"\ud83d\udc4d Validate Inputs","text":"<pre><code># \u2705 Good - Input validation\ndef extract_from_markdown(self, markdown: str, template, ...):\n    if not markdown or not markdown.strip():\n        raise ValueError(\"Markdown cannot be empty\")\n    if not template:\n        raise ValueError(\"Template is required\")\n    # Process...\n\n# \u274c Avoid - No validation\ndef extract_from_markdown(self, markdown, template, ...):\n    # Process without checks\n    pass\n</code></pre>"},{"location":"usage/advanced/custom-backends/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/advanced/custom-backends/#protocol-not-recognized","title":"\ud83d\udc1b Protocol Not Recognized","text":"<p>Backend not recognized by pipeline</p> <p>Solution: <pre><code># Ensure you implement the correct protocol\nfrom docling_graph.protocols import TextExtractionBackendProtocol\n\nclass MyBackend(TextExtractionBackendProtocol):\n    # Must have 'client' attribute for LLM backends\n    client: Any\n\n    # Must implement all required methods\n    def extract_from_markdown(self, ...): ...\n    def consolidate_from_pydantic_models(self, ...): ...\n    def cleanup(self): ...\n</code></pre></p>"},{"location":"usage/advanced/custom-backends/#memory-leaks","title":"\ud83d\udc1b Memory Leaks","text":"<p>Memory usage grows over time</p> <p>Solution: <pre><code># Implement proper cleanup\ndef cleanup(self):\n    # Close connections\n    if hasattr(self, 'client'):\n        self.client.close()\n\n    # Delete large objects\n    if hasattr(self, 'model'):\n        del self.model\n\n    # Force garbage collection\n    import gc\n    gc.collect()\n</code></pre></p>"},{"location":"usage/advanced/custom-backends/#api-rate-limits","title":"\ud83d\udc1b API Rate Limits","text":"<p>API calls fail due to rate limits</p> <p>Solution: <pre><code>import time\nfrom docling_graph.exceptions import ClientError\n\ndef _call_api_with_retry(self, *args, **kwargs):\n    \"\"\"Call API with exponential backoff.\"\"\"\n    max_retries = 3\n    base_delay = 1\n\n    for attempt in range(max_retries):\n        try:\n            return self.client.call(*args, **kwargs)\n        except RateLimitError as e:\n            if attempt == max_retries - 1:\n                raise ClientError(\"Rate limit exceeded\", cause=e)\n\n            delay = base_delay * (2 ** attempt)\n            time.sleep(delay)\n</code></pre></p>"},{"location":"usage/advanced/custom-backends/#next-steps","title":"Next Steps","text":"<ol> <li>Custom Exporters \u2192 - Create custom output formats</li> <li>Testing \u2192 - Test your backend</li> <li>Error Handling \u2192 - Handle errors gracefully</li> </ol>"},{"location":"usage/advanced/custom-exporters/","title":"Custom Exporters","text":""},{"location":"usage/advanced/custom-exporters/#overview","title":"Overview","text":"<p>Create custom exporters to output knowledge graphs in specialized formats for your specific use case or database system.</p> <p>Prerequisites: - Understanding of Graph Management - Familiarity with NetworkX graphs - Knowledge of target output format</p>"},{"location":"usage/advanced/custom-exporters/#exporter-protocol","title":"Exporter Protocol","text":"<p>All exporters must implement the <code>BaseExporter</code> protocol:</p> <pre><code>from pathlib import Path\nfrom typing import Any\nimport networkx as nx\n\nclass BaseExporter:\n    \"\"\"Base class for graph exporters.\"\"\"\n\n    def __init__(self, graph: nx.MultiDiGraph, output_dir: Path):\n        \"\"\"\n        Initialize exporter.\n\n        Args:\n            graph: NetworkX graph to export\n            output_dir: Directory for output files\n        \"\"\"\n        self.graph = graph\n        self.output_dir = output_dir\n\n    def export(self) -&gt; None:\n        \"\"\"Export the graph to the target format.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#complete-exporter-example","title":"Complete Exporter Example","text":""},{"location":"usage/advanced/custom-exporters/#graphml-exporter","title":"GraphML Exporter","text":"<pre><code>\"\"\"\nCustom exporter for GraphML format.\nGraphML is an XML-based format for graphs.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any\nimport networkx as nx\nfrom docling_graph.core.exporters.base import BaseExporter\nfrom docling_graph.exceptions import GraphError\n\nclass GraphMLExporter(BaseExporter):\n    \"\"\"\n    Export knowledge graph to GraphML format.\n\n    GraphML is widely supported by graph visualization tools\n    like Gephi, Cytoscape, and yEd.\n\n    Args:\n        graph: NetworkX graph to export\n        output_dir: Directory for output files\n        pretty_print: Whether to format XML with indentation\n    \"\"\"\n\n    def __init__(\n        self,\n        graph: nx.MultiDiGraph,\n        output_dir: Path,\n        pretty_print: bool = True\n    ):\n        super().__init__(graph, output_dir)\n        self.pretty_print = pretty_print\n\n    def export(self) -&gt; None:\n        \"\"\"\n        Export graph to GraphML format.\n\n        Creates a .graphml file in the output directory.\n\n        Raises:\n            GraphError: If export fails\n        \"\"\"\n        try:\n            # Ensure output directory exists\n            self.output_dir.mkdir(parents=True, exist_ok=True)\n\n            # Define output path\n            output_path = self.output_dir / \"graph.graphml\"\n\n            # Export using NetworkX\n            nx.write_graphml(\n                self.graph,\n                str(output_path),\n                prettyprint=self.pretty_print\n            )\n\n            print(f\"\u2705 GraphML exported to {output_path}\")\n\n        except Exception as e:\n            raise GraphError(\n                \"GraphML export failed\",\n                details={\"output_dir\": str(self.output_dir)},\n                cause=e\n            )\n\n    def get_statistics(self) -&gt; dict[str, Any]:\n        \"\"\"Get graph statistics for the export.\"\"\"\n        return {\n            \"num_nodes\": self.graph.number_of_nodes(),\n            \"num_edges\": self.graph.number_of_edges(),\n            \"node_types\": self._count_node_types(),\n            \"edge_types\": self._count_edge_types()\n        }\n\n    def _count_node_types(self) -&gt; dict[str, int]:\n        \"\"\"Count nodes by type.\"\"\"\n        type_counts: dict[str, int] = {}\n        for _, data in self.graph.nodes(data=True):\n            node_type = data.get(\"type\", \"Unknown\")\n            type_counts[node_type] = type_counts.get(node_type, 0) + 1\n        return type_counts\n\n    def _count_edge_types(self) -&gt; dict[str, int]:\n        \"\"\"Count edges by type.\"\"\"\n        type_counts: dict[str, int] = {}\n        for _, _, data in self.graph.edges(data=True):\n            edge_type = data.get(\"type\", \"Unknown\")\n            type_counts[edge_type] = type_counts.get(edge_type, 0) + 1\n        return type_counts\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#usage","title":"Usage","text":"<pre><code>\"\"\"Use custom GraphML exporter.\"\"\"\n\nfrom pathlib import Path\nimport networkx as nx\nfrom my_exporters import GraphMLExporter\n\n# Assume you have a graph from the pipeline\ngraph: nx.MultiDiGraph = ...  # From pipeline\n\n# Create exporter\nexporter = GraphMLExporter(\n    graph=graph,\n    output_dir=Path(\"outputs/graphml\"),\n    pretty_print=True\n)\n\n# Export\nexporter.export()\n\n# Get statistics\nstats = exporter.get_statistics()\nprint(f\"Exported {stats['num_nodes']} nodes and {stats['num_edges']} edges\")\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#advanced-exporter-example","title":"Advanced Exporter Example","text":""},{"location":"usage/advanced/custom-exporters/#rdfturtle-exporter","title":"RDF/Turtle Exporter","text":"<pre><code>\"\"\"\nExport knowledge graph to RDF Turtle format.\nUseful for semantic web applications and triple stores.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any\nimport networkx as nx\nfrom docling_graph.core.exporters.base import BaseExporter\nfrom docling_graph.exceptions import GraphError\n\nclass TurtleExporter(BaseExporter):\n    \"\"\"\n    Export knowledge graph to RDF Turtle format.\n\n    Args:\n        graph: NetworkX graph to export\n        output_dir: Directory for output files\n        namespace: Base namespace URI for entities\n        prefixes: Additional namespace prefixes\n    \"\"\"\n\n    def __init__(\n        self,\n        graph: nx.MultiDiGraph,\n        output_dir: Path,\n        namespace: str = \"http://example.org/kg/\",\n        prefixes: dict[str, str] | None = None\n    ):\n        super().__init__(graph, output_dir)\n        self.namespace = namespace\n        self.prefixes = prefixes or {\n            \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n            \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\",\n            \"xsd\": \"http://www.w3.org/2001/XMLSchema#\"\n        }\n\n    def export(self) -&gt; None:\n        \"\"\"Export graph to Turtle format.\"\"\"\n        try:\n            self.output_dir.mkdir(parents=True, exist_ok=True)\n            output_path = self.output_dir / \"graph.ttl\"\n\n            with open(output_path, 'w', encoding='utf-8') as f:\n                # Write prefixes\n                self._write_prefixes(f)\n                f.write(\"\\n\")\n\n                # Write nodes (entities)\n                self._write_nodes(f)\n                f.write(\"\\n\")\n\n                # Write edges (relationships)\n                self._write_edges(f)\n\n            print(f\"\u2705 Turtle RDF exported to {output_path}\")\n\n        except Exception as e:\n            raise GraphError(\n                \"Turtle export failed\",\n                details={\"output_dir\": str(self.output_dir)},\n                cause=e\n            )\n\n    def _write_prefixes(self, f: Any) -&gt; None:\n        \"\"\"Write namespace prefixes.\"\"\"\n        f.write(f\"@prefix : &lt;{self.namespace}&gt; .\\n\")\n        for prefix, uri in self.prefixes.items():\n            f.write(f\"@prefix {prefix}: &lt;{uri}&gt; .\\n\")\n\n    def _write_nodes(self, f: Any) -&gt; None:\n        \"\"\"Write node definitions.\"\"\"\n        for node_id, data in self.graph.nodes(data=True):\n            # Create URI for node\n            node_uri = self._create_uri(node_id)\n\n            # Write type\n            node_type = data.get(\"type\", \"Entity\")\n            f.write(f\"{node_uri} rdf:type :{node_type} ;\\n\")\n\n            # Write properties\n            properties = []\n            for key, value in data.items():\n                if key not in [\"type\", \"id\"]:\n                    prop_line = self._format_property(key, value)\n                    if prop_line:\n                        properties.append(prop_line)\n\n            # Write properties with proper punctuation\n            for i, prop in enumerate(properties):\n                if i &lt; len(properties) - 1:\n                    f.write(f\"    {prop} ;\\n\")\n                else:\n                    f.write(f\"    {prop} .\\n\")\n\n            f.write(\"\\n\")\n\n    def _write_edges(self, f: Any) -&gt; None:\n        \"\"\"Write edge definitions.\"\"\"\n        for source, target, data in self.graph.edges(data=True):\n            source_uri = self._create_uri(source)\n            target_uri = self._create_uri(target)\n            edge_type = data.get(\"type\", \"relatedTo\")\n\n            f.write(f\"{source_uri} :{edge_type} {target_uri} .\\n\")\n\n    def _create_uri(self, node_id: str) -&gt; str:\n        \"\"\"Create URI for a node.\"\"\"\n        # Clean node ID for URI\n        clean_id = node_id.replace(\" \", \"_\").replace(\"/\", \"_\")\n        return f\":{clean_id}\"\n\n    def _format_property(self, key: str, value: Any) -&gt; str | None:\n        \"\"\"Format a property for Turtle output.\"\"\"\n        if value is None:\n            return None\n\n        # Handle different value types\n        if isinstance(value, bool):\n            return f':{key} \"{str(value).lower()}\"^^xsd:boolean'\n        elif isinstance(value, int):\n            return f':{key} \"{value}\"^^xsd:integer'\n        elif isinstance(value, float):\n            return f':{key} \"{value}\"^^xsd:decimal'\n        elif isinstance(value, str):\n            # Escape quotes in strings\n            escaped = value.replace('\"', '\\\\\"')\n            return f':{key} \"{escaped}\"'\n        else:\n            # Convert to string for other types\n            return f':{key} \"{str(value)}\"'\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#integration-with-pipeline","title":"Integration with Pipeline","text":""},{"location":"usage/advanced/custom-exporters/#method-1-post-processing","title":"Method 1: Post-Processing","text":"<pre><code>\"\"\"Export after pipeline completes.\"\"\"\n\nfrom pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom my_exporters import GraphMLExporter, TurtleExporter\n\n# Run pipeline\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    output_dir=\"outputs\"\n)\nrun_pipeline(config)\n\n# Load the generated graph\nimport json\ngraph_path = Path(\"outputs/graph.json\")\nwith open(graph_path) as f:\n    graph_data = json.load(f)\n\n# Convert to NetworkX graph\nimport networkx as nx\ngraph = nx.node_link_graph(graph_data)\n\n# Export to custom formats\nGraphMLExporter(graph, Path(\"outputs/graphml\")).export()\nTurtleExporter(graph, Path(\"outputs/turtle\")).export()\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#method-2-custom-pipeline-stage","title":"Method 2: Custom Pipeline Stage","text":"<pre><code>\"\"\"Add custom export as pipeline stage.\"\"\"\n\nfrom docling_graph.pipeline.stages import PipelineStage\nfrom docling_graph.pipeline.context import PipelineContext\nfrom my_exporters import GraphMLExporter\n\nclass CustomExportStage(PipelineStage):\n    \"\"\"Custom export stage.\"\"\"\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"Execute custom export.\"\"\"\n        if context.graph is None:\n            return\n\n        # Export to GraphML\n        exporter = GraphMLExporter(\n            graph=context.graph,\n            output_dir=context.output_dir / \"graphml\"\n        )\n        exporter.export()\n\n        print(\"\u2705 Custom export complete\")\n\n# Use in custom pipeline orchestration\n# (Requires modifying pipeline code)\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#testing-custom-exporters","title":"Testing Custom Exporters","text":""},{"location":"usage/advanced/custom-exporters/#unit-tests","title":"Unit Tests","text":"<pre><code>\"\"\"Test custom exporter.\"\"\"\n\nimport pytest\nfrom pathlib import Path\nimport networkx as nx\nfrom my_exporters import GraphMLExporter\n\n@pytest.fixture\ndef sample_graph():\n    \"\"\"Create a sample graph for testing.\"\"\"\n    G = nx.MultiDiGraph()\n\n    # Add nodes\n    G.add_node(\"person_1\", type=\"Person\", name=\"John\", age=30)\n    G.add_node(\"org_1\", type=\"Organization\", name=\"ACME Corp\")\n\n    # Add edge\n    G.add_edge(\"person_1\", \"org_1\", type=\"WORKS_AT\")\n\n    return G\n\ndef test_exporter_initialization(sample_graph, tmp_path):\n    \"\"\"Test exporter can be initialized.\"\"\"\n    exporter = GraphMLExporter(\n        graph=sample_graph,\n        output_dir=tmp_path\n    )\n    assert exporter.graph == sample_graph\n    assert exporter.output_dir == tmp_path\n\ndef test_export_creates_file(sample_graph, tmp_path):\n    \"\"\"Test export creates output file.\"\"\"\n    exporter = GraphMLExporter(\n        graph=sample_graph,\n        output_dir=tmp_path\n    )\n    exporter.export()\n\n    output_file = tmp_path / \"graph.graphml\"\n    assert output_file.exists()\n    assert output_file.stat().st_size &gt; 0\n\ndef test_export_valid_format(sample_graph, tmp_path):\n    \"\"\"Test exported file is valid GraphML.\"\"\"\n    exporter = GraphMLExporter(\n        graph=sample_graph,\n        output_dir=tmp_path\n    )\n    exporter.export()\n\n    # Try to read it back\n    output_file = tmp_path / \"graph.graphml\"\n    loaded_graph = nx.read_graphml(str(output_file))\n\n    assert loaded_graph.number_of_nodes() == 2\n    assert loaded_graph.number_of_edges() == 1\n\ndef test_statistics(sample_graph, tmp_path):\n    \"\"\"Test statistics generation.\"\"\"\n    exporter = GraphMLExporter(\n        graph=sample_graph,\n        output_dir=tmp_path\n    )\n\n    stats = exporter.get_statistics()\n\n    assert stats[\"num_nodes\"] == 2\n    assert stats[\"num_edges\"] == 1\n    assert \"Person\" in stats[\"node_types\"]\n    assert \"Organization\" in stats[\"node_types\"]\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/custom-exporters/#handle-errors-gracefully","title":"\ud83d\udc4d Handle Errors Gracefully","text":"<pre><code># \u2705 Good - Structured error handling\nfrom docling_graph.exceptions import GraphError\n\ndef export(self):\n    try:\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        # Export logic...\n    except IOError as e:\n        raise GraphError(\"File write failed\", cause=e)\n    except Exception as e:\n        raise GraphError(\"Export failed\", cause=e)\n\n# \u274c Avoid - Silent failures\ndef export(self):\n    try:\n        # Export logic...\n        pass\n    except:\n        pass  # Error ignored!\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#validate-graph-data","title":"\ud83d\udc4d Validate Graph Data","text":"<pre><code># \u2705 Good - Validate before export\ndef export(self):\n    if self.graph.number_of_nodes() == 0:\n        raise GraphError(\"Cannot export empty graph\")\n\n    # Check for required attributes\n    for node_id, data in self.graph.nodes(data=True):\n        if \"type\" not in data:\n            raise GraphError(\n                f\"Node {node_id} missing 'type' attribute\"\n            )\n\n    # Proceed with export...\n\n# \u274c Avoid - No validation\ndef export(self):\n    # Export without checks\n    pass\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#provide-progress-feedback","title":"\ud83d\udc4d Provide Progress Feedback","text":"<pre><code># \u2705 Good - Progress updates\ndef export(self):\n    total_nodes = self.graph.number_of_nodes()\n    print(f\"Exporting {total_nodes} nodes...\")\n\n    # Export nodes\n    for i, (node_id, data) in enumerate(self.graph.nodes(data=True)):\n        self._export_node(node_id, data)\n        if (i + 1) % 100 == 0:\n            print(f\"  Processed {i + 1}/{total_nodes} nodes\")\n\n    print(\"\u2705 Export complete\")\n\n# \u274c Avoid - No feedback\ndef export(self):\n    # Silent export\n    pass\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#make-exporters-configurable","title":"\ud83d\udc4d Make Exporters Configurable","text":"<pre><code># \u2705 Good - Configurable options\nclass MyExporter(BaseExporter):\n    def __init__(\n        self,\n        graph: nx.MultiDiGraph,\n        output_dir: Path,\n        include_metadata: bool = True,\n        compress: bool = False,\n        encoding: str = \"utf-8\"\n    ):\n        super().__init__(graph, output_dir)\n        self.include_metadata = include_metadata\n        self.compress = compress\n        self.encoding = encoding\n\n# \u274c Avoid - Hardcoded behavior\nclass MyExporter(BaseExporter):\n    def __init__(self, graph, output_dir):\n        super().__init__(graph, output_dir)\n        # No configuration options\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#common-export-formats","title":"Common Export Formats","text":""},{"location":"usage/advanced/custom-exporters/#json-ld","title":"JSON-LD","text":"<pre><code>\"\"\"Export to JSON-LD for semantic web.\"\"\"\n\ndef export_jsonld(self) -&gt; None:\n    \"\"\"Export to JSON-LD format.\"\"\"\n    output = {\n        \"@context\": {\n            \"@vocab\": self.namespace,\n            \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n        },\n        \"@graph\": []\n    }\n\n    # Add nodes\n    for node_id, data in self.graph.nodes(data=True):\n        node_obj = {\n            \"@id\": node_id,\n            \"@type\": data.get(\"type\", \"Entity\")\n        }\n        # Add properties\n        for key, value in data.items():\n            if key not in [\"type\", \"id\"]:\n                node_obj[key] = value\n        output[\"@graph\"].append(node_obj)\n\n    # Write to file\n    import json\n    output_path = self.output_dir / \"graph.jsonld\"\n    with open(output_path, 'w') as f:\n        json.dump(output, f, indent=2)\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#dot-graphviz","title":"DOT (Graphviz)","text":"<pre><code>\"\"\"Export to DOT format for Graphviz.\"\"\"\n\ndef export_dot(self) -&gt; None:\n    \"\"\"Export to DOT format.\"\"\"\n    from networkx.drawing.nx_pydot import write_dot\n\n    output_path = self.output_dir / \"graph.dot\"\n    write_dot(self.graph, str(output_path))\n\n    print(f\"\u2705 DOT exported to {output_path}\")\n    print(\"  Visualize with: dot -Tpng graph.dot -o graph.png\")\n</code></pre>"},{"location":"usage/advanced/custom-exporters/#next-steps","title":"Next Steps","text":"<ol> <li>Custom Stages \u2192 - Add pipeline stages</li> <li>Testing \u2192 - Test your exporter</li> <li>Graph Management \u2192 - Learn about graphs</li> </ol>"},{"location":"usage/advanced/custom-stages/","title":"Custom Pipeline Stages","text":""},{"location":"usage/advanced/custom-stages/#overview","title":"Overview","text":"<p>Add custom stages to the docling-graph pipeline for specialized preprocessing, validation, or post-processing tasks.</p> <p>Prerequisites: - Understanding of Pipeline Architecture - Familiarity with Python API - Knowledge of pipeline context</p>"},{"location":"usage/advanced/custom-stages/#pipeline-stage-protocol","title":"Pipeline Stage Protocol","text":"<p>Custom stages should follow this pattern:</p> <pre><code>from docling_graph.pipeline.context import PipelineContext\n\nclass CustomStage:\n    \"\"\"Custom pipeline stage.\"\"\"\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"\n        Execute the stage.\n\n        Args:\n            context: Pipeline context with shared state\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"usage/advanced/custom-stages/#pipeline-context","title":"Pipeline Context","text":"<p>The <code>PipelineContext</code> provides access to pipeline state:</p> <pre><code>@dataclass\nclass PipelineContext:\n    \"\"\"Shared context for pipeline stages.\"\"\"\n\n    # Configuration\n    config: Dict[str, Any]\n\n    # Paths\n    source: Path\n    output_dir: Path\n\n    # Pipeline state\n    template: Type[BaseModel] | None = None\n    docling_doc: Any = None\n    extracted_models: List[BaseModel] | None = None\n    graph: nx.MultiDiGraph | None = None\n\n    # Metadata\n    metadata: Dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"usage/advanced/custom-stages/#complete-stage-examples","title":"Complete Stage Examples","text":""},{"location":"usage/advanced/custom-stages/#1-preprocessing-stage","title":"1. Preprocessing Stage","text":"<pre><code>\"\"\"\nPreprocessing stage to validate and prepare documents.\n\"\"\"\n\nfrom pathlib import Path\nfrom docling_graph.pipeline.context import PipelineContext\nfrom docling_graph.exceptions import PipelineError\n\nclass DocumentValidationStage:\n    \"\"\"\n    Validate document before processing.\n\n    Checks:\n    - File exists and is readable\n    - File size is within limits\n    - File format is supported\n    \"\"\"\n\n    def __init__(\n        self,\n        max_size_mb: int = 50,\n        allowed_formats: list[str] | None = None\n    ):\n        self.max_size_mb = max_size_mb\n        self.allowed_formats = allowed_formats or ['.pdf', '.png', '.jpg', '.jpeg']\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"Execute validation.\"\"\"\n        print(\"\ud83d\udd0d Validating document...\")\n\n        # Check file exists\n        if not context.source.exists():\n            raise PipelineError(\n                \"Source file not found\",\n                details={\"source\": str(context.source)}\n            )\n\n        # Check file size\n        size_mb = context.source.stat().st_size / (1024 * 1024)\n        if size_mb &gt; self.max_size_mb:\n            raise PipelineError(\n                f\"File too large: {size_mb:.1f}MB (max: {self.max_size_mb}MB)\",\n                details={\"source\": str(context.source), \"size_mb\": size_mb}\n            )\n\n        # Check format\n        if context.source.suffix.lower() not in self.allowed_formats:\n            raise PipelineError(\n                f\"Unsupported format: {context.source.suffix}\",\n                details={\n                    \"source\": str(context.source),\n                    \"allowed\": self.allowed_formats\n                }\n            )\n\n        # Store metadata\n        context.metadata[\"validation\"] = {\n            \"size_mb\": size_mb,\n            \"format\": context.source.suffix,\n            \"validated\": True\n        }\n\n        print(f\"\u2705 Document validated ({size_mb:.1f}MB)\")\n</code></pre>"},{"location":"usage/advanced/custom-stages/#2-post-processing-stage","title":"2. Post-Processing Stage","text":"<pre><code>\"\"\"\nPost-processing stage to enrich extracted data.\n\"\"\"\n\nfrom typing import List\nfrom pydantic import BaseModel\nfrom docling_graph.pipeline.context import PipelineContext\nfrom docling_graph.exceptions import PipelineError\n\nclass DataEnrichmentStage:\n    \"\"\"\n    Enrich extracted data with additional information.\n\n    Examples:\n    - Add timestamps\n    - Normalize values\n    - Add computed fields\n    - Validate business rules\n    \"\"\"\n\n    def __init__(self, add_timestamps: bool = True):\n        self.add_timestamps = add_timestamps\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"Execute enrichment.\"\"\"\n        if not context.extracted_models:\n            print(\"\u26a0\ufe0f  No models to enrich\")\n            return\n\n        print(\"\ud83d\udd27 Enriching extracted data...\")\n\n        enriched_count = 0\n        for model in context.extracted_models:\n            if self._enrich_model(model):\n                enriched_count += 1\n\n        context.metadata[\"enrichment\"] = {\n            \"models_processed\": len(context.extracted_models),\n            \"models_enriched\": enriched_count\n        }\n\n        print(f\"\u2705 Enriched {enriched_count} models\")\n\n    def _enrich_model(self, model: BaseModel) -&gt; bool:\n        \"\"\"Enrich a single model.\"\"\"\n        enriched = False\n\n        # Add timestamp if enabled\n        if self.add_timestamps:\n            from datetime import datetime\n            if hasattr(model, '__dict__'):\n                # Add as metadata (not modifying Pydantic model)\n                if not hasattr(model, '_metadata'):\n                    model._metadata = {}\n                model._metadata['processed_at'] = datetime.now().isoformat()\n                enriched = True\n\n        # Add more enrichment logic here\n\n        return enriched\n</code></pre>"},{"location":"usage/advanced/custom-stages/#3-validation-stage","title":"3. Validation Stage","text":"<pre><code>\"\"\"\nValidation stage to check extracted data quality.\n\"\"\"\n\nfrom typing import List\nfrom pydantic import BaseModel\nfrom docling_graph.pipeline.context import PipelineContext\nfrom docling_graph.exceptions import ValidationError\n\nclass QualityCheckStage:\n    \"\"\"\n    Validate extracted data quality.\n\n    Checks:\n    - Required fields are populated\n    - Data meets business rules\n    - Relationships are valid\n    \"\"\"\n\n    def __init__(\n        self,\n        min_confidence: float = 0.7,\n        require_relationships: bool = True\n    ):\n        self.min_confidence = min_confidence\n        self.require_relationships = require_relationships\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"Execute quality checks.\"\"\"\n        if not context.extracted_models:\n            raise ValidationError(\"No models to validate\")\n\n        print(\"\u2705 Running quality checks...\")\n\n        issues = []\n\n        for i, model in enumerate(context.extracted_models):\n            model_issues = self._check_model(model, i)\n            issues.extend(model_issues)\n\n        if issues:\n            print(f\"\u26a0\ufe0f  Found {len(issues)} quality issues:\")\n            for issue in issues[:5]:  # Show first 5\n                print(f\"  - {issue}\")\n            if len(issues) &gt; 5:\n                print(f\"  ... and {len(issues) - 5} more\")\n\n        context.metadata[\"quality_check\"] = {\n            \"models_checked\": len(context.extracted_models),\n            \"issues_found\": len(issues),\n            \"passed\": len(issues) == 0\n        }\n\n        if issues and self._is_critical():\n            raise ValidationError(\n                f\"Quality check failed with {len(issues)} issues\",\n                details={\"issues\": issues[:10]}\n            )\n\n        print(f\"\u2705 Quality check complete ({len(issues)} issues)\")\n\n    def _check_model(self, model: BaseModel, index: int) -&gt; List[str]:\n        \"\"\"Check a single model.\"\"\"\n        issues = []\n\n        # Check for empty required fields\n        for field_name, field_info in model.model_fields.items():\n            if field_info.is_required():\n                value = getattr(model, field_name, None)\n                if value is None or (isinstance(value, str) and not value.strip()):\n                    issues.append(\n                        f\"Model {index}: Required field '{field_name}' is empty\"\n                    )\n\n        # Check relationships if required\n        if self.require_relationships:\n            has_relationships = self._has_relationships(model)\n            if not has_relationships:\n                issues.append(\n                    f\"Model {index}: No relationships found\"\n                )\n\n        return issues\n\n    def _has_relationships(self, model: BaseModel) -&gt; bool:\n        \"\"\"Check if model has any relationships.\"\"\"\n        for field_name, field_info in model.model_fields.items():\n            json_schema_extra = field_info.json_schema_extra or {}\n            if \"edge_label\" in json_schema_extra:\n                value = getattr(model, field_name, None)\n                if value is not None:\n                    return True\n        return False\n\n    def _is_critical(self) -&gt; bool:\n        \"\"\"Determine if issues are critical.\"\"\"\n        # Could be configurable\n        return False\n</code></pre>"},{"location":"usage/advanced/custom-stages/#4-logging-stage","title":"4. Logging Stage","text":"<pre><code>\"\"\"\nLogging stage to track pipeline execution.\n\"\"\"\n\nimport json\nfrom datetime import datetime\nfrom pathlib import Path\nfrom docling_graph.pipeline.context import PipelineContext\n\nclass PipelineLoggingStage:\n    \"\"\"\n    Log pipeline execution details.\n\n    Creates a log file with:\n    - Execution timestamp\n    - Configuration used\n    - Processing statistics\n    - Any errors or warnings\n    \"\"\"\n\n    def __init__(self, log_level: str = \"INFO\"):\n        self.log_level = log_level\n        self.start_time = None\n\n    def execute(self, context: PipelineContext) -&gt; None:\n        \"\"\"Execute logging.\"\"\"\n        if self.start_time is None:\n            self.start_time = datetime.now()\n\n        log_entry = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"source\": str(context.source),\n            \"output_dir\": str(context.output_dir),\n            \"config\": self._sanitize_config(context.config),\n            \"metadata\": context.metadata,\n            \"statistics\": self._gather_statistics(context)\n        }\n\n        # Write log file\n        log_path = context.output_dir / \"pipeline.log.json\"\n        with open(log_path, 'w') as f:\n            json.dump(log_entry, f, indent=2)\n\n        print(f\"\ud83d\udcdd Log written to {log_path}\")\n\n    def _sanitize_config(self, config: dict) -&gt; dict:\n        \"\"\"Remove sensitive data from config.\"\"\"\n        sanitized = config.copy()\n        # Remove API keys\n        for key in list(sanitized.keys()):\n            if 'key' in key.lower() or 'token' in key.lower():\n                sanitized[key] = \"***REDACTED***\"\n        return sanitized\n\n    def _gather_statistics(self, context: PipelineContext) -&gt; dict:\n        \"\"\"Gather processing statistics.\"\"\"\n        stats = {}\n\n        if context.extracted_models:\n            stats[\"num_models\"] = len(context.extracted_models)\n\n        if context.graph:\n            stats[\"num_nodes\"] = context.graph.number_of_nodes()\n            stats[\"num_edges\"] = context.graph.number_of_edges()\n\n        if self.start_time:\n            duration = (datetime.now() - self.start_time).total_seconds()\n            stats[\"duration_seconds\"] = duration\n\n        return stats\n</code></pre>"},{"location":"usage/advanced/custom-stages/#integration-with-pipeline","title":"Integration with Pipeline","text":""},{"location":"usage/advanced/custom-stages/#method-1-wrapper-function","title":"Method 1: Wrapper Function","text":"<pre><code>\"\"\"\nWrap pipeline execution with custom stages.\n\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.pipeline.context import PipelineContext\nfrom my_stages import DocumentValidationStage, QualityCheckStage\n\ndef run_pipeline_with_stages(config: PipelineConfig):\n    \"\"\"Run pipeline with custom stages.\"\"\"\n\n    # Create context\n    context = PipelineContext(\n        config=config.to_dict(),\n        source=Path(config.source),\n        output_dir=Path(config.output_dir)\n    )\n\n    # Pre-processing stages\n    validation_stage = DocumentValidationStage(max_size_mb=100)\n    validation_stage.execute(context)\n\n    # Run main pipeline\n    run_pipeline(config)\n\n    # Post-processing stages\n    # (Would need to load results from output_dir)\n    quality_stage = QualityCheckStage()\n    # quality_stage.execute(context)\n\n    print(\"\u2705 Pipeline with custom stages complete\")\n\n# Usage\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\"\n)\nrun_pipeline_with_stages(config)\n</code></pre>"},{"location":"usage/advanced/custom-stages/#method-2-custom-orchestrator","title":"Method 2: Custom Orchestrator","text":"<pre><code>\"\"\"\nCreate custom pipeline orchestrator.\n\"\"\"\n\nfrom typing import List\nfrom docling_graph.pipeline.context import PipelineContext\nfrom docling_graph.pipeline.stages import (\n    TemplateLoadingStage,\n    ExtractionStage,\n    GraphConversionStage,\n    ExportStage\n)\nfrom my_stages import DocumentValidationStage, QualityCheckStage\n\nclass CustomPipelineOrchestrator:\n    \"\"\"Custom pipeline with additional stages.\"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config\n        self.stages = self._build_stages()\n\n    def _build_stages(self) -&gt; List:\n        \"\"\"Build pipeline stages.\"\"\"\n        return [\n            DocumentValidationStage(),      # Custom pre-processing\n            TemplateLoadingStage(),         # Built-in\n            ExtractionStage(),              # Built-in\n            QualityCheckStage(),            # Custom validation\n            GraphConversionStage(),         # Built-in\n            ExportStage(),                  # Built-in\n        ]\n\n    def run(self) -&gt; None:\n        \"\"\"Execute pipeline.\"\"\"\n        context = PipelineContext(\n            config=self.config,\n            source=Path(self.config[\"source\"]),\n            output_dir=Path(self.config[\"output_dir\"])\n        )\n\n        for stage in self.stages:\n            stage_name = stage.__class__.__name__\n            print(f\"\\n{'='*60}\")\n            print(f\"Stage: {stage_name}\")\n            print(f\"{'='*60}\")\n\n            try:\n                stage.execute(context)\n            except Exception as e:\n                print(f\"\u274c Stage {stage_name} failed: {e}\")\n                raise\n\n        print(\"\\n\u2705 All stages complete\")\n</code></pre>"},{"location":"usage/advanced/custom-stages/#testing-custom-stages","title":"Testing Custom Stages","text":"<pre><code>\"\"\"Test custom pipeline stage.\"\"\"\n\nimport pytest\nfrom pathlib import Path\nfrom docling_graph.pipeline.context import PipelineContext\nfrom my_stages import DocumentValidationStage\n\n@pytest.fixture\ndef sample_context(tmp_path):\n    \"\"\"Create sample context.\"\"\"\n    # Create a test file\n    test_file = tmp_path / \"test.pdf\"\n    test_file.write_bytes(b\"PDF content\")\n\n    return PipelineContext(\n        config={},\n        source=test_file,\n        output_dir=tmp_path / \"output\"\n    )\n\ndef test_stage_execution(sample_context):\n    \"\"\"Test stage executes successfully.\"\"\"\n    stage = DocumentValidationStage(max_size_mb=1)\n\n    # Should not raise\n    stage.execute(sample_context)\n\n    # Check metadata was added\n    assert \"validation\" in sample_context.metadata\n    assert sample_context.metadata[\"validation\"][\"validated\"]\n\ndef test_stage_file_not_found():\n    \"\"\"Test stage handles missing file.\"\"\"\n    context = PipelineContext(\n        config={},\n        source=Path(\"nonexistent.pdf\"),\n        output_dir=Path(\"output\")\n    )\n\n    stage = DocumentValidationStage()\n\n    with pytest.raises(Exception):\n        stage.execute(context)\n\ndef test_stage_file_too_large(tmp_path):\n    \"\"\"Test stage rejects large files.\"\"\"\n    # Create large file\n    large_file = tmp_path / \"large.pdf\"\n    large_file.write_bytes(b\"x\" * (100 * 1024 * 1024))  # 100MB\n\n    context = PipelineContext(\n        config={},\n        source=large_file,\n        output_dir=tmp_path / \"output\"\n    )\n\n    stage = DocumentValidationStage(max_size_mb=50)\n\n    with pytest.raises(Exception):\n        stage.execute(context)\n</code></pre>"},{"location":"usage/advanced/custom-stages/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/custom-stages/#keep-stages-focused","title":"\ud83d\udc4d Keep Stages Focused","text":"<pre><code># \u2705 Good - Single responsibility\nclass ValidationStage:\n    \"\"\"Validate document format and size.\"\"\"\n    def execute(self, context): ...\n\nclass EnrichmentStage:\n    \"\"\"Enrich extracted data.\"\"\"\n    def execute(self, context): ...\n\n# \u274c Avoid - Multiple responsibilities\nclass ProcessingStage:\n    \"\"\"Validate, enrich, and export.\"\"\"\n    def execute(self, context): ...\n</code></pre>"},{"location":"usage/advanced/custom-stages/#handle-errors-gracefully","title":"\ud83d\udc4d Handle Errors Gracefully","text":"<pre><code># \u2705 Good - Structured error handling\nfrom docling_graph.exceptions import PipelineError\n\ndef execute(self, context):\n    try:\n        self._process(context)\n    except ValueError as e:\n        raise PipelineError(\"Validation failed\", cause=e)\n    except Exception as e:\n        raise PipelineError(\"Stage execution failed\", cause=e)\n\n# \u274c Avoid - Silent failures\ndef execute(self, context):\n    try:\n        self._process(context)\n    except:\n        pass  # Error ignored!\n</code></pre>"},{"location":"usage/advanced/custom-stages/#update-context-metadata","title":"\ud83d\udc4d Update Context Metadata","text":"<pre><code># \u2705 Good - Track stage execution\ndef execute(self, context):\n    start_time = time.time()\n\n    # Process...\n\n    context.metadata[self.__class__.__name__] = {\n        \"executed\": True,\n        \"duration\": time.time() - start_time,\n        \"items_processed\": count\n    }\n\n# \u274c Avoid - No tracking\ndef execute(self, context):\n    # Process without tracking\n    pass\n</code></pre>"},{"location":"usage/advanced/custom-stages/#make-stages-configurable","title":"\ud83d\udc4d Make Stages Configurable","text":"<pre><code># \u2705 Good - Configurable behavior\nclass MyStage:\n    def __init__(self, threshold: float = 0.8, strict: bool = False):\n        self.threshold = threshold\n        self.strict = strict\n\n# \u274c Avoid - Hardcoded behavior\nclass MyStage:\n    def __init__(self):\n        self.threshold = 0.8  # Cannot be changed\n</code></pre>"},{"location":"usage/advanced/custom-stages/#next-steps","title":"Next Steps","text":"<ol> <li>Performance Tuning \u2192 - Optimize pipeline</li> <li>Error Handling \u2192 - Handle errors</li> <li>Testing \u2192 - Test your stages</li> </ol>"},{"location":"usage/advanced/error-handling/","title":"Error Handling","text":""},{"location":"usage/advanced/error-handling/#overview","title":"Overview","text":"<p>Handle errors gracefully in docling-graph pipelines with structured exception handling, retry logic, and debugging strategies.</p> <p>Prerequisites: - Understanding of Pipeline Architecture - Familiarity with Python API - Basic Python exception handling</p> <p>New: Zero Data Loss</p> <p>Docling Graph now implements zero data loss - extraction failures return partial models instead of empty results, ensuring you never lose successfully extracted data.</p>"},{"location":"usage/advanced/error-handling/#exception-hierarchy","title":"Exception Hierarchy","text":"<p>Docling-graph uses a structured exception hierarchy:</p> <pre><code>DoclingGraphError (base)\n\u251c\u2500\u2500 ConfigurationError      # Invalid configuration\n\u251c\u2500\u2500 ClientError            # LLM/API client errors\n\u251c\u2500\u2500 ExtractionError        # Document extraction failures\n\u251c\u2500\u2500 ValidationError        # Data validation failures\n\u251c\u2500\u2500 GraphError            # Graph operation failures\n\u2514\u2500\u2500 PipelineError         # Pipeline execution failures\n</code></pre>"},{"location":"usage/advanced/error-handling/#import-exceptions","title":"Import Exceptions","text":"<pre><code>from docling_graph.exceptions import (\n    DoclingGraphError,\n    ConfigurationError,\n    ClientError,\n    ExtractionError,\n    ValidationError,\n    GraphError,\n    PipelineError\n)\n</code></pre>"},{"location":"usage/advanced/error-handling/#common-error-scenarios","title":"Common Error Scenarios","text":""},{"location":"usage/advanced/error-handling/#1-configuration-errors","title":"1. Configuration Errors","text":"<pre><code>\"\"\"Handle configuration errors.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import ConfigurationError\n\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.MyTemplate\",\n        backend=\"vlm\",\n        inference=\"remote\"  # VLM doesn't support remote!\n    )\n    run_pipeline(config)\n\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e.message}\")\n    print(f\"Details: {e.details}\")\n    # Fix: Use local inference with VLM\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.MyTemplate\",\n        backend=\"vlm\",\n        inference=\"local\"  # Corrected\n    )\n    run_pipeline(config)\n</code></pre>"},{"location":"usage/advanced/error-handling/#2-client-errors-api","title":"2. Client Errors (API)","text":"<pre><code>\"\"\"Handle API client errors.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import ClientError\nimport time\n\ndef process_with_retry(source: str, max_retries: int = 3):\n    \"\"\"Process with retry on client errors.\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            config = PipelineConfig(\n                source=source,\n                template=\"templates.MyTemplate\",\n                backend=\"llm\",\n                inference=\"remote\"\n            )\n            run_pipeline(config)\n            print(\"\u2705 Processing successful\")\n            return\n\n        except ClientError as e:\n            print(f\"Attempt {attempt + 1} failed: {e.message}\")\n\n            if \"rate limit\" in str(e).lower():\n                # Rate limit - wait and retry\n                wait_time = 2 ** attempt  # Exponential backoff\n                print(f\"Rate limited. Waiting {wait_time}s...\")\n                time.sleep(wait_time)\n\n            elif \"authentication\" in str(e).lower():\n                # Auth error - don't retry\n                print(\"Authentication failed. Check API key.\")\n                raise\n\n            elif attempt == max_retries - 1:\n                # Last attempt failed\n                print(\"Max retries reached\")\n                raise\n            else:\n                # Other error - retry\n                time.sleep(1)\n\n# Usage\nprocess_with_retry(\"document.pdf\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#3-extraction-errors","title":"3. Extraction Errors","text":"<pre><code>\"\"\"Handle extraction errors.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import ExtractionError\n\ndef process_with_fallback(source: str):\n    \"\"\"Process with fallback strategy.\"\"\"\n\n    # Try VLM first (faster)\n    try:\n        print(\"Trying VLM extraction...\")\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\",\n            backend=\"vlm\",\n            inference=\"local\"\n        )\n        run_pipeline(config)\n        print(\"\u2705 VLM extraction successful\")\n        return\n\n    except ExtractionError as e:\n        print(f\"VLM failed: {e.message}\")\n        print(\"Falling back to LLM...\")\n\n    # Fallback to LLM\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\",\n            backend=\"llm\",\n            inference=\"local\"\n        )\n        run_pipeline(config)\n        print(\"\u2705 LLM extraction successful\")\n\n    except ExtractionError as e:\n        print(f\"Both methods failed: {e.message}\")\n        print(f\"Details: {e.details}\")\n        raise\n\n# Usage\nprocess_with_fallback(\"document.pdf\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#4-validation-errors","title":"4. Validation Errors","text":"<pre><code>\"\"\"Handle validation errors.\"\"\"\n\nfrom pydantic import BaseModel, Field, ValidationError as PydanticValidationError\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import ValidationError\n\nclass StrictTemplate(BaseModel):\n    \"\"\"Template with strict validation.\"\"\"\n    name: str = Field(..., min_length=1)\n    age: int = Field(..., ge=0, le=150)\n    email: str = Field(..., pattern=r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$')\n\ndef process_with_validation_handling(source: str):\n    \"\"\"Process with validation error handling.\"\"\"\n\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.StrictTemplate\"\n        )\n        run_pipeline(config)\n\n    except ValidationError as e:\n        print(f\"Validation failed: {e.message}\")\n\n        # Check if it's a Pydantic validation error\n        if e.cause and isinstance(e.cause, PydanticValidationError):\n            print(\"\\nValidation errors:\")\n            for error in e.cause.errors():\n                field = error['loc'][0]\n                msg = error['msg']\n                print(f\"  - {field}: {msg}\")\n\n        # Option 1: Use more lenient template\n        print(\"\\nRetrying with lenient template...\")\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.LenientTemplate\"\n        )\n        run_pipeline(config)\n\n# Usage\nprocess_with_validation_handling(\"document.pdf\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#5-graph-errors","title":"5. Graph Errors","text":"<pre><code>\"\"\"Handle graph construction errors.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import GraphError\n\ndef process_with_graph_validation(source: str):\n    \"\"\"Process with graph validation.\"\"\"\n\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\",\n            export_format=\"cypher\"\n        )\n        run_pipeline(config)\n\n    except GraphError as e:\n        print(f\"Graph error: {e.message}\")\n        print(f\"Details: {e.details}\")\n\n        # Try alternative export format\n        print(\"Trying CSV export instead...\")\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\",\n            export_format=\"csv\"  # Fallback format\n        )\n        run_pipeline(config)\n\n# Usage\nprocess_with_graph_validation(\"document.pdf\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#retry-strategies","title":"Retry Strategies","text":""},{"location":"usage/advanced/error-handling/#exponential-backoff","title":"Exponential Backoff","text":"<pre><code>\"\"\"Implement exponential backoff for retries.\"\"\"\n\nimport time\nfrom typing import Callable, Any\nfrom docling_graph.exceptions import ClientError\n\ndef retry_with_backoff(\n    func: Callable,\n    max_retries: int = 3,\n    base_delay: float = 1.0,\n    max_delay: float = 60.0,\n    backoff_factor: float = 2.0\n) -&gt; Any:\n    \"\"\"\n    Retry function with exponential backoff.\n\n    Args:\n        func: Function to retry\n        max_retries: Maximum number of retries\n        base_delay: Initial delay in seconds\n        max_delay: Maximum delay in seconds\n        backoff_factor: Multiplier for delay\n\n    Returns:\n        Function result\n\n    Raises:\n        Exception from last attempt\n    \"\"\"\n    last_exception = None\n\n    for attempt in range(max_retries):\n        try:\n            return func()\n\n        except ClientError as e:\n            last_exception = e\n\n            if attempt == max_retries - 1:\n                # Last attempt\n                break\n\n            # Calculate delay\n            delay = min(base_delay * (backoff_factor ** attempt), max_delay)\n\n            print(f\"Attempt {attempt + 1} failed. Retrying in {delay:.1f}s...\")\n            time.sleep(delay)\n\n    # All retries failed\n    raise last_exception\n\n# Usage\ndef process_document():\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.MyTemplate\",\n        backend=\"llm\",\n        inference=\"remote\"\n    )\n    run_pipeline(config)\n\nretry_with_backoff(process_document, max_retries=3)\n</code></pre>"},{"location":"usage/advanced/error-handling/#conditional-retry","title":"Conditional Retry","text":"<pre><code>\"\"\"Retry only for specific errors.\"\"\"\n\nfrom docling_graph.exceptions import ClientError, ConfigurationError\n\ndef should_retry(exception: Exception) -&gt; bool:\n    \"\"\"Determine if error is retryable.\"\"\"\n\n    # Don't retry configuration errors\n    if isinstance(exception, ConfigurationError):\n        return False\n\n    # Retry client errors\n    if isinstance(exception, ClientError):\n        error_msg = str(exception).lower()\n\n        # Don't retry auth errors\n        if \"authentication\" in error_msg or \"unauthorized\" in error_msg:\n            return False\n\n        # Retry rate limits and timeouts\n        if \"rate limit\" in error_msg or \"timeout\" in error_msg:\n            return True\n\n    # Default: don't retry\n    return False\n\ndef process_with_conditional_retry(source: str, max_retries: int = 3):\n    \"\"\"Process with conditional retry.\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            config = PipelineConfig(\n                source=source,\n                template=\"templates.MyTemplate\"\n            )\n            run_pipeline(config)\n            return\n\n        except Exception as e:\n            if not should_retry(e) or attempt == max_retries - 1:\n                raise\n\n            print(f\"Retryable error. Attempt {attempt + 2}...\")\n            time.sleep(2 ** attempt)\n</code></pre>"},{"location":"usage/advanced/error-handling/#logging-and-debugging","title":"Logging and Debugging","text":""},{"location":"usage/advanced/error-handling/#enable-detailed-logging","title":"Enable Detailed Logging","text":"<pre><code>\"\"\"Configure logging for debugging.\"\"\"\n\nimport logging\nfrom docling_graph import run_pipeline, PipelineConfig\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('pipeline.log'),\n        logging.StreamHandler()\n    ]\n)\n\nlogger = logging.getLogger('docling_graph')\n\n# Run pipeline with logging\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.MyTemplate\"\n    )\n    run_pipeline(config)\n\nexcept Exception as e:\n    logger.error(f\"Pipeline failed: {e}\", exc_info=True)\n    raise\n</code></pre>"},{"location":"usage/advanced/error-handling/#debug-mode","title":"Debug Mode","text":"<pre><code>\"\"\"Run pipeline in debug mode.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import DoclingGraphError\n\ndef debug_pipeline(source: str):\n    \"\"\"Run pipeline with detailed error information.\"\"\"\n\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\"\n        )\n        run_pipeline(config)\n\n    except DoclingGraphError as e:\n        print(\"\\n\" + \"=\"*60)\n        print(\"ERROR DETAILS\")\n        print(\"=\"*60)\n        print(f\"Type: {type(e).__name__}\")\n        print(f\"Message: {e.message}\")\n\n        if e.details:\n            print(\"\\nDetails:\")\n            for key, value in e.details.items():\n                print(f\"  {key}: {value}\")\n\n        if e.cause:\n            print(f\"\\nCaused by: {type(e.cause).__name__}\")\n            print(f\"  {e.cause}\")\n\n        print(\"=\"*60)\n        raise\n\n# Usage\ndebug_pipeline(\"document.pdf\")\n\n### Trace Data for Debugging\n\n**Trace data** provides visibility into pipeline internals for debugging extraction issues:\n\n```python\n\"\"\"Use trace data to debug extraction failures.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\n\ndef debug_with_trace(source: str):\n    \"\"\"Debug extraction using trace data.\"\"\"\n\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.ComplexTemplate\",\n        debug=True,  # Enable debug mode\n        dump_to_disk=True,   # Export for analysis\n        output_dir=\"debug_output\"\n    )\n\n    context = run_pipeline(config)\n\n    # Analyze debug artifacts\n    from pathlib import Path\n    import json\n\n    debug_dir = Path(context.output_dir) / \"debug\"\n\n    if debug_dir.exists():\n        expected = [\n            \"node_catalog.json\",\n            \"id_pass.json\",\n            \"fill_pass.json\",\n            \"edges_pass.json\",\n            \"merged_output.json\",\n            \"staged_trace.json\",\n            \"trace_data.json\",\n        ]\n        print(\"Debug artifacts:\")\n        for name in expected:\n            p = debug_dir / name\n            print(f\"  - {name}: {'ok' if p.exists() else 'missing'}\")\n\n        staged_trace_path = debug_dir / \"staged_trace.json\"\n        if staged_trace_path.exists():\n            with open(staged_trace_path) as f:\n                staged_trace = json.load(f)\n            print(\"\\nStaged timings:\", staged_trace.get(\"timings_seconds\", {}))\n            print(\"Per-path counts:\", staged_trace.get(\"per_path_counts\", {}))\n            print(\"Merge stats:\", staged_trace.get(\"merge_stats\", {}))\n\n    return context\n\n# Usage\ncontext = debug_with_trace(\"problematic_document.pdf\")\n</code></pre> <p>See Also: Trace Data Debugging Guide for comprehensive examples.</p> <pre><code>### Automatic Cleanup on Failure\n\nWhen `dump_to_disk=True`, the pipeline automatically cleans up empty output directories if processing fails:\n\n```python\n\"\"\"Automatic cleanup of empty directories on failure.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import PipelineError\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    dump_to_disk=True,\n    output_dir=\"outputs\"\n)\n\ntry:\n    context = run_pipeline(config)\nexcept PipelineError as e:\n    # If the pipeline fails before writing any files,\n    # the empty output directory is automatically removed\n    print(f\"Pipeline failed: {e.message}\")\n    # No empty artifact directories left in outputs/\n</code></pre> <p>Cleanup Behavior:</p> <ul> <li>Empty directories are removed - If the pipeline fails before writing any files, the output directory is automatically deleted</li> <li>Partial results are preserved - If any files were written before the failure, the directory is kept</li> <li>Only when dump_to_disk=True - Cleanup only runs when file exports are enabled</li> <li>Logged for transparency - Cleanup actions are logged for visibility</li> </ul> <p>Example Scenarios:</p> <pre><code># Scenario 1: Failure during template loading (before any files)\n# \u2192 Output directory is removed (empty)\n\n# Scenario 2: Failure during extraction (after docling conversion)\n# \u2192 Output directory is kept (contains docling/ files)\n\n# Scenario 3: dump_to_disk=False\n# \u2192 No cleanup needed (no directory created)\n</code></pre> <p>This ensures your <code>outputs/</code> folder stays clean without manual intervention.</p>"},{"location":"usage/advanced/error-handling/#error-recovery-patterns","title":"Error Recovery Patterns","text":""},{"location":"usage/advanced/error-handling/#zero-data-loss","title":"Zero Data Loss","text":"<p>Zero data loss ensures extraction failures never result in completely empty results:</p> <pre><code>\"\"\"Handle extraction with zero data loss.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom pathlib import Path\nimport json\n\ndef process_with_zero_data_loss(source: str):\n    \"\"\"Process document with zero data loss guarantee.\"\"\"\n\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.BillingDocument\",\n        processing_mode=\"many-to-one\",\n        output_dir=\"outputs\"\n    )\n\n    try:\n        results = run_pipeline(config)\n\n        # Check result type\n        if len(results) == 1:\n            print(\"\u2705 Successfully merged into single model\")\n            return {\"status\": \"complete\", \"models\": results}\n        else:\n            print(f\"\u26a0 Got {len(results)} partial models (merge failed)\")\n            print(\"  But data is preserved!\")\n            return {\"status\": \"partial\", \"models\": results}\n\n    except Exception as e:\n        print(f\"Pipeline failed: {e}\")\n\n        # Even on failure, check for partial results\n        output_dir = Path(\"outputs\")\n        if output_dir.exists():\n            # Look for partial model files\n            model_files = list(output_dir.glob(\"*.json\"))\n            if model_files:\n                print(f\"\u2705 Found {len(model_files)} partial model files\")\n\n                # Load partial models\n                partial_models = []\n                for file in model_files:\n                    with open(file) as f:\n                        partial_models.append(json.load(f))\n\n                return {\"status\": \"recovered\", \"models\": partial_models}\n\n        return {\"status\": \"failed\", \"models\": []}\n\n# Usage\nresult = process_with_zero_data_loss(\"invoice.pdf\")\n\nif result[\"status\"] == \"complete\":\n    # Use merged model\n    model = result[\"models\"][0]\n    print(f\"Invoice: {model.get('document_no')}\")\n\nelif result[\"status\"] == \"partial\":\n    # Use partial models\n    print(\"Working with partial models:\")\n    for i, model in enumerate(result[\"models\"], 1):\n        print(f\"  Model {i}: {model.get('document_no', 'N/A')}\")\n\nelif result[\"status\"] == \"recovered\":\n    # Recovered from files\n    print(\"Recovered partial data from files\")\n\nelse:\n    print(\"No data available\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#partial-model-handling","title":"Partial Model Handling","text":"<pre><code>\"\"\"Work with partial models when merging fails.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom typing import List, Dict, Any\n\ndef extract_with_partial_handling(source: str) -&gt; Dict[str, Any]:\n    \"\"\"Extract and handle partial models intelligently.\"\"\"\n\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.BillingDocument\",\n        processing_mode=\"many-to-one\",\n    )\n\n    results = run_pipeline(config)\n\n    if len(results) == 1:\n        # Success: single merged model\n        return {\n            \"status\": \"merged\",\n            \"document_no\": results[0].document_no,\n            \"total\": results[0].total,\n            \"line_items\": len(results[0].line_items or []),\n            \"completeness\": 100\n        }\n    else:\n        # Partial: multiple models\n        print(f\"\u26a0 Merge failed, got {len(results)} partial models\")\n\n        # Combine data from partial models\n        combined = {\n            \"status\": \"partial\",\n            \"document_no\": None,\n            \"total\": None,\n            \"line_items\": 0,\n            \"completeness\": 0\n        }\n\n        # Extract what we can\n        for model in results:\n            if model.document_no and not combined[\"document_no\"]:\n                combined[\"document_no\"] = model.document_no\n            if model.total and not combined[\"total\"]:\n                combined[\"total\"] = model.total\n            if model.line_items:\n                combined[\"line_items\"] += len(model.line_items)\n\n        # Calculate completeness\n        fields_found = sum([\n            bool(combined[\"document_no\"]),\n            bool(combined[\"total\"]),\n            bool(combined[\"line_items\"] &gt; 0)\n        ])\n        combined[\"completeness\"] = int((fields_found / 3) * 100)\n\n        return combined\n\n# Usage\nresult = extract_with_partial_handling(\"invoice.pdf\")\n\nprint(f\"Status: {result['status']}\")\nprint(f\"Invoice: {result['document_no'] or 'N/A'}\")\nprint(f\"Total: ${result['total'] or 0}\")\nprint(f\"Line items: {result['line_items']}\")\nprint(f\"Completeness: {result['completeness']}%\")\n\nif result['completeness'] &lt; 100:\n    print(\"\u26a0 Incomplete extraction - consider manual review\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>\"\"\"Degrade gracefully on errors.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import ExtractionError\n\ndef process_with_degradation(source: str):\n    \"\"\"Process with graceful degradation.\"\"\"\n\n    results = {\n        \"success\": False,\n        \"method\": None,\n        \"output_dir\": None,\n        \"models\": []\n    }\n\n    # Try best method first\n    methods = [\n        (\"VLM Local\", {\"backend\": \"vlm\", \"inference\": \"local\"}),\n        (\"LLM Local\", {\"backend\": \"llm\", \"inference\": \"local\"}),\n        (\"LLM Remote\", {\"backend\": \"llm\", \"inference\": \"remote\"})\n    ]\n\n    for method_name, config_overrides in methods:\n        try:\n            print(f\"Trying {method_name}...\")\n\n            config = PipelineConfig(\n                source=source,\n                template=\"templates.MyTemplate\",\n                **config_overrides\n            )\n            models = run_pipeline(config)\n\n            results[\"success\"] = True\n            results[\"method\"] = method_name\n            results[\"output_dir\"] = config.output_dir\n            results[\"models\"] = models\n\n            print(f\"\u2705 Success with {method_name}\")\n            print(f\"  Extracted {len(models)} model(s)\")\n            break\n\n        except ExtractionError as e:\n            print(f\"\u274c {method_name} failed: {e.message}\")\n            continue\n\n    if not results[\"success\"]:\n        print(\"\u274c All methods failed\")\n\n    return results\n</code></pre>"},{"location":"usage/advanced/error-handling/#partial-success-handling","title":"Partial Success Handling","text":"<pre><code>\"\"\"Handle partial extraction success.\"\"\"\n\nfrom pathlib import Path\nimport json\nfrom docling_graph import run_pipeline, PipelineConfig\n\ndef process_with_partial_success(source: str):\n    \"\"\"Process and handle partial results.\"\"\"\n\n    try:\n        config = PipelineConfig(\n            source=source,\n            template=\"templates.MyTemplate\",\n            output_dir=\"outputs\"\n        )\n        models = run_pipeline(config)\n\n        # Check completeness\n        if len(models) == 1:\n            return {\n                \"status\": \"complete\",\n                \"models\": models,\n                \"output_dir\": config.output_dir\n            }\n        else:\n            return {\n                \"status\": \"partial\",\n                \"models\": models,\n                \"output_dir\": config.output_dir,\n                \"warning\": f\"Got {len(models)} partial models instead of 1\"\n            }\n\n    except Exception as e:\n        print(f\"Pipeline failed: {e}\")\n\n        # Check if partial results exist\n        output_dir = Path(\"outputs\")\n        if output_dir.exists():\n            # Check for extracted data\n            nodes_file = output_dir / \"nodes.csv\"\n            if nodes_file.exists():\n                print(\"\u2705 Partial results available in files\")\n                print(f\"  Nodes: {nodes_file}\")\n\n                # Use partial results\n                return {\n                    \"status\": \"recovered\",\n                    \"models\": [],\n                    \"output_dir\": output_dir\n                }\n\n        return {\"status\": \"failed\", \"models\": [], \"output_dir\": None}\n</code></pre>"},{"location":"usage/advanced/error-handling/#validation-strategies","title":"Validation Strategies","text":""},{"location":"usage/advanced/error-handling/#pre-validation","title":"Pre-Validation","text":"<pre><code>\"\"\"Validate before processing.\"\"\"\n\nfrom pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import ConfigurationError\n\ndef validate_and_process(source: str, template: str):\n    \"\"\"Validate configuration before processing.\"\"\"\n\n    # Validate source\n    source_path = Path(source)\n    if not source_path.exists():\n        raise ConfigurationError(\n            \"Source file not found\",\n            details={\"source\": source}\n        )\n\n    # Validate template\n    try:\n        # Try to import template\n        module_path, class_name = template.rsplit(\".\", 1)\n        import importlib\n        module = importlib.import_module(module_path)\n        template_class = getattr(module, class_name)\n    except Exception as e:\n        raise ConfigurationError(\n            \"Invalid template\",\n            details={\"template\": template},\n            cause=e\n        )\n\n    # Validate file size\n    size_mb = source_path.stat().st_size / (1024 * 1024)\n    if size_mb &gt; 100:\n        print(f\"\u26a0\ufe0f  Large file: {size_mb:.1f}MB\")\n\n    # Process\n    config = PipelineConfig(\n        source=source,\n        template=template\n    )\n    run_pipeline(config)\n</code></pre>"},{"location":"usage/advanced/error-handling/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/error-handling/#use-specific-exceptions","title":"\ud83d\udc4d Use Specific Exceptions","text":"<pre><code># \u2705 Good - Catch specific exceptions\ntry:\n    run_pipeline(config)\nexcept ClientError as e:\n    # Handle API errors\n    pass\nexcept ExtractionError as e:\n    # Handle extraction errors\n    pass\n\n# \u274c Avoid - Catch all exceptions\ntry:\n    run_pipeline(config)\nexcept Exception:\n    pass  # What went wrong?\n</code></pre>"},{"location":"usage/advanced/error-handling/#provide-context","title":"\ud83d\udc4d Provide Context","text":"<pre><code># \u2705 Good - Detailed error context\nfrom docling_graph.exceptions import ExtractionError\n\ntry:\n    result = extract_data(source)\nexcept Exception as e:\n    raise ExtractionError(\n        \"Failed to extract data\",\n        details={\n            \"source\": source,\n            \"template\": template.__name__,\n            \"stage\": \"extraction\"\n        },\n        cause=e\n    )\n\n# \u274c Avoid - Generic errors\ntry:\n    result = extract_data(source)\nexcept Exception as e:\n    raise Exception(\"Extraction failed\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#log-before-raising","title":"\ud83d\udc4d Log Before Raising","text":"<pre><code># \u2705 Good - Log then raise\nimport logging\nlogger = logging.getLogger(__name__)\n\ntry:\n    run_pipeline(config)\nexcept ExtractionError as e:\n    logger.error(f\"Extraction failed: {e}\", exc_info=True)\n    raise\n\n# \u274c Avoid - Silent failures\ntry:\n    run_pipeline(config)\nexcept ExtractionError:\n    pass  # Error lost!\n</code></pre>"},{"location":"usage/advanced/error-handling/#clean-up-resources","title":"\ud83d\udc4d Clean Up Resources","text":"<pre><code># \u2705 Good - Always clean up\ntry:\n    run_pipeline(config)\nfinally:\n    # Clean up even if error occurs\n    cleanup_resources()\n\n# \u274c Avoid - No cleanup on error\ntry:\n    run_pipeline(config)\n    cleanup_resources()  # Not called if error!\nexcept:\n    pass\n</code></pre>"},{"location":"usage/advanced/error-handling/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"usage/advanced/error-handling/#common-errors","title":"Common Errors","text":"Error Cause Solution <code>ConfigurationError: VLM backend only supports local inference</code> VLM with remote Use <code>inference=\"local\"</code> <code>ClientError: API key not found</code> Missing API key Set environment variable <code>ExtractionError: Empty extraction result</code> Poor template Improve field descriptions <code>ValidationError: Field required</code> Missing data Make field optional <code>GraphError: Invalid graph structure</code> Bad relationships Check edge definitions"},{"location":"usage/advanced/error-handling/#zero-data-loss-best-practices","title":"Zero Data Loss Best Practices","text":""},{"location":"usage/advanced/error-handling/#1-always-check-result-count","title":"1. Always Check Result Count","text":"<pre><code># \u2705 Good - Check if merge succeeded\nresults = run_pipeline(config)\n\nif len(results) == 1:\n    # Merged successfully\n    process_merged_model(results[0])\nelse:\n    # Got partial models\n    process_partial_models(results)\n</code></pre>"},{"location":"usage/advanced/error-handling/#2-handle-partial-models-gracefully","title":"2. Handle Partial Models Gracefully","text":"<pre><code># \u2705 Good - Extract what you can from partial models\ndef get_document_no(models: List) -&gt; str:\n    \"\"\"Get invoice number from any model that has it.\"\"\"\n    for model in models:\n        if model.document_no:\n            return model.document_no\n    return \"N/A\"\n</code></pre>"},{"location":"usage/advanced/error-handling/#3-log-partial-results","title":"3. Log Partial Results","text":"<pre><code># \u2705 Good - Log when you get partial results\nimport logging\nlogger = logging.getLogger(__name__)\n\nresults = run_pipeline(config)\nif len(results) &gt; 1:\n    logger.warning(f\"Got {len(results)} partial models instead of 1\")\n    logger.info(\"Data preserved despite merge failure\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#4-provide-user-feedback","title":"4. Provide User Feedback","text":"<pre><code># \u2705 Good - Inform users about partial results\nresults = run_pipeline(config)\n\nif len(results) == 1:\n    print(\"\u2705 Extraction complete\")\nelse:\n    print(f\"\u26a0 Extraction partially complete ({len(results)} fragments)\")\n    print(\"  All data preserved - manual review recommended\")\n</code></pre>"},{"location":"usage/advanced/error-handling/#next-steps","title":"Next Steps","text":"<ol> <li>Model Merging \u2192 - Learn about zero data loss</li> <li>Testing \u2192 - Test error handling</li> <li>Exceptions Reference \u2192 - Full exception API</li> <li>Extraction Process \u2192 - Extraction guide</li> </ol>"},{"location":"usage/advanced/performance-tuning/","title":"Performance Tuning","text":""},{"location":"usage/advanced/performance-tuning/#overview","title":"Overview","text":"<p>Optimize docling-graph pipeline performance for speed, memory efficiency, and resource utilization.</p> <p>Prerequisites: - Understanding of Pipeline Configuration - Familiarity with Extraction Process - Basic knowledge of system resources</p> <p>New Performance Features</p> <p>Recent improvements include:</p> <ul> <li>Provider-Specific Batching: Optimized merge thresholds per provider</li> <li>Real Tokenizer Integration: Accurate token counting with safety margins</li> <li>Enhanced GPU Cleanup: Better memory management for VLM backends</li> <li>Model Capability Detection: Automatic prompt adaptation based on model size</li> </ul>"},{"location":"usage/advanced/performance-tuning/#performance-factors","title":"Performance Factors","text":""},{"location":"usage/advanced/performance-tuning/#key-metrics","title":"Key Metrics","text":"<ol> <li>Throughput: Documents processed per hour</li> <li>Latency: Time per document</li> <li>Memory Usage: RAM and VRAM consumption</li> <li>Cost: API costs for remote inference</li> </ol>"},{"location":"usage/advanced/performance-tuning/#staged-extraction-tuning","title":"Staged Extraction Tuning","text":"<p>When using <code>extraction_contract=\\\"staged\\\"</code>, tune these parameters first:</p> <ul> <li><code>staged_id_shard_size</code>: paths per ID-pass call (<code>0</code> = no sharding, single call).</li> <li><code>staged_nodes_fill_cap</code>: instances per fill-pass call.</li> <li><code>parallel_workers</code>: parallel workers for extraction (staged fill pass and delta batch calls).</li> </ul> <pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    processing_mode=\"many-to-one\",\n    extraction_contract=\"staged\",\n    staged_id_shard_size=2,      # reduce ID payload size\n    staged_nodes_fill_cap=10,    # balance quality vs throughput\n    parallel_workers=4,         # parallel fill/delta calls\n)\n</code></pre> <p>Tuning guidance: - If ID-pass responses truncate, reduce <code>staged_id_shard_size</code>. - If fill calls are too slow, increase <code>parallel_workers</code> (within system limits). - If fill quality drops, reduce <code>staged_nodes_fill_cap</code>.</p>"},{"location":"usage/advanced/performance-tuning/#delta-extraction-tuning","title":"Delta Extraction Tuning","text":"<p>When using <code>extraction_contract=\"delta\"</code>, tune these first:</p> <ul> <li><code>llm_batch_token_size</code>: max input tokens per LLM batch (default 2048). Larger batches = fewer calls but higher token usage per call.</li> <li><code>parallel_workers</code>: parallel workers for delta batch LLM calls.</li> </ul> <p>Delta runs chunk \u2192 batch plan \u2192 per-batch LLM (DeltaGraph) \u2192 IR normalize \u2192 merge \u2192 optional resolvers \u2192 projection \u2192 quality gate. See Delta Extraction.</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    processing_mode=\"many-to-one\",\n    extraction_contract=\"delta\",\n    use_chunking=True,\n    llm_batch_token_size=2048,\n    parallel_workers=2,\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#model-selection","title":"Model Selection","text":""},{"location":"usage/advanced/performance-tuning/#local-vs-remote","title":"Local vs Remote","text":"<pre><code># \u2705 Fast - Local inference (no network latency)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"local\",  # Faster for small documents\n    model_override=\"ibm-granite/granite-4.0-1b\"  # Smaller = faster\n)\n\n# \u26a0\ufe0f Slower - Remote inference (network overhead)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"remote\",  # Better for complex documents\n    model_override=\"gpt-4-turbo\"  # More accurate but slower\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#model-size-trade-offs","title":"Model Size Trade-offs","text":"Model Size Speed Accuracy Memory Use Case 1B params \u26a1 Very Fast \ud83d\udfe1 Moderate Accuracy 2-4 GB Simple forms, fast processing 7-8B params \u26a1 Fast \ud83d\udfe2 Acceptable Accuracy 8-16 GB General documents 13B+ params \ud83d\udc22 Slow \ud83d\udc8e High Accuracy 16-32 GB Complex documents <p>Recommendation:</p> <pre><code># Simple documents (forms, invoices)\nmodel_override=\"ibm-granite/granite-4.0-1b\"  # Fast\n\n# General documents\nmodel_override=\"llama-3.1-8b\"  # Balanced\n\n# Complex documents (rheology researchs, legal)\nmodel_override=\"mistral-small-latest\"  # Accurate (remote)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#batch-processing","title":"Batch Processing","text":""},{"location":"usage/advanced/performance-tuning/#provider-specific-batching","title":"Provider-Specific Batching","text":"<p>Different providers have different optimal batching strategies:</p> <pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# OpenAI - Aggressive batching (90% merge threshold)\n# Best for: High-volume processing with reliable API\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",\n    use_chunking=True  # Automatically uses threshold\n)\n\n# Ollama/Local - Conservative batching (75% threshold)\n# Best for: Variable performance local models\nconfig = PipelineConfig(\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n    use_chunking=True  # Automatically uses threshold\n)\n</code></pre> <p>Default Threshold:</p> <p>All providers now use a 95% threshold by default. This provides an optimal balance between: - Efficiency: Fewer API calls, faster processing - Reliability: Adequate safety margin for context limits - Consistency: Same behavior across all providers</p> <p>Performance Impact: - Higher threshold (0.95-0.98) = Fewer API calls = Faster processing - Lower threshold (0.80-0.90) = More aggressive merging = Fewer batches but less optimal fit</p> <p>Note: You can override the threshold programmatically if needed (see Batch Processing).</p>"},{"location":"usage/advanced/performance-tuning/#batch-size-staged-and-delta-extraction","title":"Batch size, staged and delta extraction","text":"<p><code>max_batch_size</code> is available in the config for metadata and future use. For many-to-one LLM extraction, batching is controlled by:</p> <ul> <li>Chunking and delta extraction when <code>extraction_contract=\"delta\"</code>: token-bounded batches (<code>llm_batch_token_size</code>), then merge. See Delta Extraction.</li> <li>Staged extraction when <code>extraction_contract=\"staged\"</code>: <code>staged_nodes_fill_cap</code>, <code>parallel_workers</code>, etc. See Staged Extraction.</li> </ul>"},{"location":"usage/advanced/performance-tuning/#memory-management","title":"Memory Management","text":""},{"location":"usage/advanced/performance-tuning/#monitor-memory-usage","title":"Monitor Memory Usage","text":"<pre><code>\"\"\"Monitor memory during processing.\"\"\"\n\nimport psutil\nimport GPUtil\n\ndef log_memory_usage():\n    \"\"\"Log current memory usage.\"\"\"\n    # RAM\n    ram = psutil.virtual_memory()\n    print(f\"RAM: {ram.percent}% ({ram.used / 1e9:.1f}GB / {ram.total / 1e9:.1f}GB)\")\n\n    # GPU\n    try:\n        gpus = GPUtil.getGPUs()\n        for gpu in gpus:\n            print(f\"GPU {gpu.id}: {gpu.memoryUtil*100:.1f}% ({gpu.memoryUsed}MB / {gpu.memoryTotal}MB)\")\n    except:\n        print(\"No GPU detected\")\n\n# Use during pipeline\nfrom docling_graph import run_pipeline, PipelineConfig\n\nlog_memory_usage()  # Before\nconfig = PipelineConfig(...)\nrun_pipeline(config)\nlog_memory_usage()  # After\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#reduce-memory-usage","title":"Reduce Memory Usage","text":"<pre><code># \u2705 Good - Process in smaller chunks\nconfig = PipelineConfig(\n    source=\"large_document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=True,  # Enable chunking\n    processing_mode=\"one-to-one\"  # Process page by page\n)\n\n# \u274c Avoid - Load entire document\nconfig = PipelineConfig(\n    source=\"large_document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=False,  # Load all at once\n    processing_mode=\"many-to-one\"\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#clean-up-resources","title":"Clean Up Resources","text":"<pre><code>\"\"\"Properly clean up after processing.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\nimport gc\nimport torch\n\ndef process_with_cleanup(source: str):\n    \"\"\"Process document with proper cleanup.\"\"\"\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.MyTemplate\"\n    )\n\n    try:\n        run_pipeline(config)\n    finally:\n        # Force garbage collection\n        gc.collect()\n\n        # Clear GPU cache if using PyTorch\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n# Process multiple documents\nfor doc in documents:\n    process_with_cleanup(doc)\n    # Memory is freed between documents\n</code></pre> <p>Enhanced GPU Cleanup for VLM</p> <p>VLM backends now include enhanced GPU memory management:</p> <pre><code>from docling_graph.core.extractors.backends import VlmBackend\n\nbackend = VlmBackend(model_name=\"numind/NuExtract-2.0-8B\")\ntry:\n    models = backend.extract_from_document(source, template)\nfinally:\n    backend.cleanup()  # Enhanced cleanup:\n    # 1. Moves model to CPU before deletion\n    # 2. Explicitly clears CUDA cache\n    # 3. Logs memory usage before/after\n    # 4. Handles multiple GPU devices\n</code></pre> <p>Memory Savings: Up to 8GB VRAM freed per cleanup cycle</p>"},{"location":"usage/advanced/performance-tuning/#gpu-utilization","title":"GPU Utilization","text":""},{"location":"usage/advanced/performance-tuning/#enable-gpu-acceleration","title":"Enable GPU Acceleration","text":"<pre><code># Install with GPU support\nuv sync\n\n# Verify GPU is available\nuv run python -c \"import torch; print(torch.cuda.is_available())\"\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#optimize-gpu-usage","title":"Optimize GPU Usage","text":"<pre><code># \u2705 Good - Use GPU for local inference\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"local\",  # Will use GPU if available\n    provider_override=\"vllm\"  # Optimized for GPU\n)\n\n# Monitor GPU utilization\nimport torch\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#multi-gpu-support","title":"Multi-GPU Support","text":"<pre><code>\"\"\"Use multiple GPUs for parallel processing.\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\n\ndef process_on_gpu(source: str, gpu_id: int):\n    \"\"\"Process document on specific GPU.\"\"\"\n    # Set GPU device\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.MyTemplate\",\n        output_dir=f\"outputs/gpu_{gpu_id}\"\n    )\n    run_pipeline(config)\n\n# Process documents in parallel on different GPUs\nfrom concurrent.futures import ThreadPoolExecutor\n\ndocuments = [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\", \"doc4.pdf\"]\nwith ThreadPoolExecutor(max_workers=2) as executor:\n    # GPU 0 processes doc1 and doc3\n    # GPU 1 processes doc2 and doc4\n    futures = [\n        executor.submit(process_on_gpu, doc, i % 2)\n        for i, doc in enumerate(documents)\n    ]\n\n    for future in futures:\n        future.result()\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#real-tokenizer-integration","title":"Real Tokenizer Integration","text":""},{"location":"usage/advanced/performance-tuning/#accurate-token-counting","title":"Accurate Token Counting","text":"<p>Docling Graph now uses real tokenizers for accurate token counting:</p> <pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# \u2705 Good - Real tokenizer with safety margin\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3.1:8b\",\n    use_chunking=True  # Uses real tokenizer + 20% safety margin\n)\n</code></pre> <p>Benefits:</p> <ol> <li>Prevents Context Overflows: Accurate token counting prevents exceeding context limits</li> <li>Better Chunk Packing: More efficient use of context window</li> <li>Reduced API Calls: Optimal chunk sizes reduce number of requests</li> <li>Cost Savings: Fewer API calls = lower costs</li> </ol> <p>Performance Comparison:</p> Method Accuracy Context Overflows Chunk Efficiency Character Heuristic ~70% Occasional 60-70% Real Tokenizer 95%+ Rare 80-90%"},{"location":"usage/advanced/performance-tuning/#safety-margins","title":"Safety Margins","text":"<pre><code># Default: 20% safety margin\n# If model has 8192 token context:\n# - Effective limit: 6553 tokens (80% of 8192)\n# - Prevents edge cases and ensures reliability\n\n# For aggressive batching (not recommended):\n# Modify ChunkBatcher.batch_chunks merge_threshold\n# But this may cause context overflows\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#chunking-strategies","title":"Chunking Strategies","text":""},{"location":"usage/advanced/performance-tuning/#disable-chunking-for-small-documents","title":"Disable Chunking for Small Documents","text":"<pre><code># \u2705 Good - No chunking for small docs (&lt; 5 pages)\nconfig = PipelineConfig(\n    source=\"short_document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=False  # Faster for small docs\n)\n\n# \u2705 Good - Enable chunking for large docs (&gt; 5 pages)\nconfig = PipelineConfig(\n    source=\"long_document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=True  # Necessary for large docs\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#optimize-chunk-size","title":"Optimize Chunk Size","text":"<pre><code>\"\"\"Configure chunking for optimal performance.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\n\n# For fast processing (may sacrifice accuracy)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=True,\n    # Larger chunks = fewer API calls but more memory\n)\n\n# For accurate processing (slower)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    use_chunking=True,\n    # Smaller chunks = more API calls but better accuracy\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#consolidation-strategies","title":"Consolidation Strategies","text":""},{"location":"usage/advanced/performance-tuning/#programmatic-vs-llm-consolidation","title":"Programmatic vs LLM Consolidation","text":"<pre><code># \u2705 Fast - Programmatic merge (no LLM call)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    processing_mode=\"many-to-one\",\n)\n\n# \u26a0\ufe0f Slow - LLM consolidation (extra API call)\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    processing_mode=\"many-to-one\",\n)\n</code></pre> <p>When to Use Each:</p> Strategy Speed Accuracy Use Case Programmatic \u26a1 Very Fast \ud83d\udfe1 Moderate Accuracy Simple merging, lists LLM (Standard) \ud83d\udc22 Slow \ud83d\udfe2 High Accuracy Complex conflicts LLM (Chain of Density) \ud83d\udc0c Very Slow \ud83d\udc8e Highest Accuracy Critical documents"},{"location":"usage/advanced/performance-tuning/#chain-of-density-consolidation","title":"Chain of Density Consolidation","text":"<p>For ADVANCED tier models (13B+), consolidation uses a multi-turn approach:</p> <pre><code># Automatically enabled for large models\nconfig = PipelineConfig(\n    source=\"complex_document.pdf\",\n    template=\"templates.Contract\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",  # ADVANCED tier\n    processing_mode=\"many-to-one\",\n)\n</code></pre> <p>Process: 1. Initial Merge (Turn 1): Create first consolidated version 2. Refinement (Turn 2): Identify and resolve conflicts 3. Final Polish (Turn 3): Ensure completeness and accuracy</p> <p>Performance Impact: - Token Usage: 3x more tokens than standard consolidation - Time: 3x longer processing time - Quality: Significantly better for complex documents - Cost: 3x API costs</p> <p>When to Use:</p> <ul> <li>\u2705 Critical documents requiring highest accuracy</li> <li>\u2705 Complex contracts or legal documents</li> <li>\u2705 Documents with many conflicts</li> <li>\u274c Simple forms or invoices (overkill)</li> <li>\u274c High-volume batch processing (too slow)</li> </ul>"},{"location":"usage/advanced/performance-tuning/#profiling","title":"Profiling","text":""},{"location":"usage/advanced/performance-tuning/#profile-pipeline-execution","title":"Profile Pipeline Execution","text":"<pre><code>\"\"\"Profile pipeline to identify bottlenecks.\"\"\"\n\nimport time\nfrom docling_graph import run_pipeline, PipelineConfig\n\ndef profile_pipeline(source: str):\n    \"\"\"Profile pipeline execution.\"\"\"\n    stages = {}\n\n    # Overall timing\n    start = time.time()\n\n    # Would need to instrument pipeline stages\n    # This is a simplified example\n\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.MyTemplate\"\n    )\n\n    run_pipeline(config)\n\n    total_time = time.time() - start\n\n    print(f\"\\nProfiling Results:\")\n    print(f\"Total time: {total_time:.2f}s\")\n    print(f\"Throughput: {1/total_time:.2f} docs/sec\")\n\n# Profile\nprofile_pipeline(\"document.pdf\")\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#use-python-profiler","title":"Use Python Profiler","text":"<pre><code># Profile with cProfile\nuv run python -m cProfile -o profile.stats my_script.py\n\n# Analyze results\nuv run python -m pstats profile.stats\n# Then: sort cumtime, stats 20\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#optimization-checklist","title":"Optimization Checklist","text":""},{"location":"usage/advanced/performance-tuning/#before-processing","title":"Before Processing","text":"<ul> <li> Choose appropriate model size for task</li> <li> Enable GPU if available</li> <li> Set optimal batch size for hardware</li> <li> Disable chunking for small documents</li> <li> Use programmatic merge when possible</li> </ul>"},{"location":"usage/advanced/performance-tuning/#during-processing","title":"During Processing","text":"<ul> <li> Monitor memory usage</li> <li> Watch for GPU utilization</li> <li> Check for bottlenecks</li> <li> Log processing times</li> </ul>"},{"location":"usage/advanced/performance-tuning/#after-processing","title":"After Processing","text":"<ul> <li> Clean up GPU memory</li> <li> Force garbage collection</li> <li> Review performance metrics</li> <li> Identify optimization opportunities</li> </ul>"},{"location":"usage/advanced/performance-tuning/#performance-benchmarks","title":"Performance Benchmarks","text":""},{"location":"usage/advanced/performance-tuning/#typical-processing-times","title":"Typical Processing Times","text":"<p>Small Document (1-5 pages): - VLM Local: 5-15 seconds - LLM Local: 10-30 seconds - LLM Remote: 15-45 seconds</p> <p>Medium Document (10-20 pages): - VLM Local: 30-60 seconds - LLM Local: 1-3 minutes - LLM Remote: 2-5 minutes</p> <p>Large Document (50+ pages): - VLM Local: 2-5 minutes - LLM Local: 5-15 minutes - LLM Remote: 10-30 minutes</p> <p>Times vary based on hardware, model, and document complexity</p>"},{"location":"usage/advanced/performance-tuning/#cost-optimization","title":"Cost Optimization","text":""},{"location":"usage/advanced/performance-tuning/#reduce-api-costs","title":"Reduce API Costs","text":"<pre><code># \u2705 Good - Use local inference when possible\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"local\"  # No API costs\n)\n\n# \u2705 Good - Use smaller remote models\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n    backend=\"llm\",\n    inference=\"remote\",\n    model_override=\"mistral-small-latest\"  # Cheaper than large models\n)\n\n# \u274c Avoid - Unnecessary LLM consolidation\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.MyTemplate\",\n)\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#estimate-costs","title":"Estimate Costs","text":"<pre><code>\"\"\"Estimate API costs before processing.\"\"\"\n\ndef estimate_cost(num_pages: int, model: str = \"mistral-small-latest\"):\n    \"\"\"Estimate processing cost.\"\"\"\n    # Rough estimates (check provider pricing)\n    costs_per_page = {\n        \"mistral-small-latest\": 0.01,\n        \"gpt-4-turbo\": 0.05,\n        \"gemini-2.5-flash\": 0.005\n    }\n\n    cost_per_page = costs_per_page.get(model, 0.02)\n    total_cost = num_pages * cost_per_page\n\n    print(f\"Estimated cost: ${total_cost:.2f}\")\n    print(f\"Model: {model}\")\n    print(f\"Pages: {num_pages}\")\n\n    return total_cost\n\n# Estimate before processing\nestimate_cost(num_pages=100, model=\"mistral-small-latest\")\n</code></pre>"},{"location":"usage/advanced/performance-tuning/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/advanced/performance-tuning/#slow-processing","title":"\ud83d\udc1b Slow Processing","text":"<p>Solutions: 1. Use smaller model 2. Enable GPU acceleration 3. Disable chunking for small docs 4. Use local inference 5. Increase batch size</p>"},{"location":"usage/advanced/performance-tuning/#out-of-memory","title":"\ud83d\udc1b Out of Memory","text":"<p>Solutions: 1. Reduce batch size 2. Enable chunking 3. Use smaller model 4. Process one-to-one instead of many-to-one 5. Clean up between documents</p>"},{"location":"usage/advanced/performance-tuning/#gpu-not-utilized","title":"\ud83d\udc1b GPU Not Utilized","text":"<p>Solutions: 1. Verify GPU installation: <code>torch.cuda.is_available()</code> 2. Install GPU dependencies: <code>uv sync</code> 3. Check CUDA version compatibility 4. Use vLLM provider for GPU optimization</p>"},{"location":"usage/advanced/performance-tuning/#performance-optimization-summary","title":"Performance Optimization Summary","text":""},{"location":"usage/advanced/performance-tuning/#quick-wins","title":"Quick Wins","text":"<ol> <li>Use Provider-Specific Batching: Automatic optimization per provider</li> <li>Enable Real Tokenizers: Accurate token counting prevents overflows</li> <li>Choose Right Model Tier: Match model size to task complexity</li> <li>Clean Up GPU Memory: Use enhanced cleanup for VLM backends</li> <li>Disable Chunking for Small Docs: Faster processing for &lt; 5 pages</li> </ol>"},{"location":"usage/advanced/performance-tuning/#advanced-optimizations","title":"Advanced Optimizations","text":"<ol> <li>Multi-GPU Processing: Parallel document processing</li> <li>Staged Extraction: Use <code>extraction_contract=\"staged\"</code> for complex nested templates</li> <li>Delta Extraction: Use <code>extraction_contract=\"delta\"</code> for long documents (chunk-based graph extraction)</li> <li>Memory Profiling: Monitor and optimize resource usage</li> <li>Chunking: Tune <code>chunk_max_tokens</code> and <code>use_chunking</code> for your docs</li> </ol>"},{"location":"usage/advanced/performance-tuning/#next-steps","title":"Next Steps","text":"<ol> <li>Staged Extraction \u2192 - Multi-pass extraction tuning</li> <li>Delta Extraction \u2192 - Chunk-based graph extraction tuning</li> <li>Error Handling \u2192 - Handle errors gracefully</li> <li>Testing \u2192 - Test performance optimizations</li> <li>GPU Setup \u2192 - Configure GPU</li> </ol>"},{"location":"usage/advanced/testing/","title":"Testing","text":""},{"location":"usage/advanced/testing/#overview","title":"Overview","text":"<p>Test Pydantic templates, custom backends, and pipeline configurations to ensure reliable extraction and graph generation.</p> <p>Prerequisites: - Understanding of Schema Definition - Familiarity with Python API - Basic pytest knowledge</p>"},{"location":"usage/advanced/testing/#setup","title":"Setup","text":""},{"location":"usage/advanced/testing/#install-test-dependencies","title":"Install Test Dependencies","text":"<pre><code># Install with test dependencies\nuv sync --extra dev\n\n# Or install pytest separately\nuv add --dev pytest pytest-cov pytest-mock\n</code></pre>"},{"location":"usage/advanced/testing/#project-structure","title":"Project Structure","text":"<pre><code>my_project/\n\u251c\u2500\u2500 templates/\n\u2502   \u2514\u2500\u2500 my_template.py\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py              # Shared fixtures\n\u2502   \u251c\u2500\u2500 test_templates.py        # Template tests\n\u2502   \u251c\u2500\u2500 test_extraction.py       # Extraction tests\n\u2502   \u2514\u2500\u2500 test_integration.py      # End-to-end tests\n\u251c\u2500\u2500 pyproject.toml\n\u2514\u2500\u2500 pytest.ini\n</code></pre>"},{"location":"usage/advanced/testing/#template-testing","title":"Template Testing","text":""},{"location":"usage/advanced/testing/#basic-template-validation","title":"Basic Template Validation","text":"<pre><code>\"\"\"Test Pydantic template validation.\"\"\"\n\nimport pytest\nfrom pydantic import ValidationError\nfrom templates.my_template import Person, Organization\n\ndef test_person_valid():\n    \"\"\"Test valid person creation.\"\"\"\n    person = Person(\n        name=\"John Doe\",\n        age=30,\n        email=\"john@example.com\"\n    )\n\n    assert person.name == \"John Doe\"\n    assert person.age == 30\n    assert person.email == \"john@example.com\"\n\ndef test_person_invalid_age():\n    \"\"\"Test person with invalid age.\"\"\"\n    with pytest.raises(ValidationError) as exc_info:\n        Person(\n            name=\"John Doe\",\n            age=-5,  # Invalid\n            email=\"john@example.com\"\n        )\n\n    errors = exc_info.value.errors()\n    assert any(e['loc'] == ('age',) for e in errors)\n\ndef test_person_invalid_email():\n    \"\"\"Test person with invalid email.\"\"\"\n    with pytest.raises(ValidationError):\n        Person(\n            name=\"John Doe\",\n            age=30,\n            email=\"not-an-email\"  # Invalid\n        )\n\ndef test_person_optional_fields():\n    \"\"\"Test person with optional fields.\"\"\"\n    person = Person(\n        name=\"John Doe\",\n        age=30\n        # email is optional\n    )\n\n    assert person.email is None\n</code></pre>"},{"location":"usage/advanced/testing/#test-field-validators","title":"Test Field Validators","text":"<pre><code>\"\"\"Test custom field validators.\"\"\"\n\nfrom pydantic import BaseModel, Field, field_validator\n\nclass EmailTemplate(BaseModel):\n    \"\"\"Template with email validation.\"\"\"\n\n    email: str = Field(..., description=\"Email address\")\n\n    @field_validator(\"email\")\n    @classmethod\n    def validate_email(cls, v):\n        \"\"\"Validate email format.\"\"\"\n        if \"@\" not in v:\n            raise ValueError(\"Invalid email format\")\n        return v.lower()\n\ndef test_email_validator_valid():\n    \"\"\"Test valid email.\"\"\"\n    template = EmailTemplate(email=\"John@Example.com\")\n    assert template.email == \"john@example.com\"  # Lowercased\n\ndef test_email_validator_invalid():\n    \"\"\"Test invalid email.\"\"\"\n    with pytest.raises(ValidationError) as exc_info:\n        EmailTemplate(email=\"not-an-email\")\n\n    errors = exc_info.value.errors()\n    assert \"Invalid email format\" in str(errors)\n</code></pre>"},{"location":"usage/advanced/testing/#test-relationships","title":"Test Relationships","text":"<pre><code>\"\"\"Test entity relationships.\"\"\"\n\nfrom pydantic import BaseModel, Field, ConfigDict\n\ndef edge(label: str, **kwargs):\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\nclass Address(BaseModel):\n    model_config = ConfigDict(is_entity=False)\n    street: str\n    city: str\n\nclass Person(BaseModel):\n    name: str\n    address: Address = edge(label=\"LIVES_AT\")\n\ndef test_relationship_structure():\n    \"\"\"Test relationship is properly defined.\"\"\"\n    person = Person(\n        name=\"John\",\n        address=Address(street=\"123 Main St\", city=\"NYC\")\n    )\n\n    assert person.name == \"John\"\n    assert person.address.street == \"123 Main St\"\n    assert person.address.city == \"NYC\"\n\ndef test_relationship_metadata():\n    \"\"\"Test edge metadata is present.\"\"\"\n    field_info = Person.model_fields[\"address\"]\n    assert field_info.json_schema_extra is not None\n    assert field_info.json_schema_extra.get(\"edge_label\") == \"LIVES_AT\"\n</code></pre>"},{"location":"usage/advanced/testing/#mock-backends","title":"Mock Backends","text":""},{"location":"usage/advanced/testing/#create-mock-backend","title":"Create Mock Backend","text":"<pre><code>\"\"\"Mock backend for testing.\"\"\"\n\nfrom typing import List, Type\nfrom pydantic import BaseModel\n\nclass MockLLMBackend:\n    \"\"\"Mock LLM backend for testing.\"\"\"\n\n    def __init__(self, mock_response: dict | None = None):\n        self.mock_response = mock_response or {}\n        self.call_count = 0\n        self.last_markdown = None\n        self.last_template = None\n\n    def extract_from_markdown(\n        self,\n        markdown: str,\n        template: Type[BaseModel],\n        context: str = \"document\",\n        is_partial: bool = False\n    ) -&gt; BaseModel | None:\n        \"\"\"Mock extraction.\"\"\"\n        self.call_count += 1\n        self.last_markdown = markdown\n        self.last_template = template\n\n        # Return mock response\n        if self.mock_response:\n            return template.model_validate(self.mock_response)\n\n        return None\n\n    def consolidate_from_pydantic_models(\n        self,\n        raw_models: List[BaseModel],\n        programmatic_model: BaseModel,\n        template: Type[BaseModel]\n    ) -&gt; BaseModel | None:\n        \"\"\"Mock consolidation.\"\"\"\n        return programmatic_model\n\n    def cleanup(self) -&gt; None:\n        \"\"\"Mock cleanup.\"\"\"\n        pass\n</code></pre>"},{"location":"usage/advanced/testing/#use-mock-backend","title":"Use Mock Backend","text":"<pre><code>\"\"\"Test extraction with mock backend.\"\"\"\n\nimport pytest\nfrom templates.my_template import Person\n\ndef test_extraction_with_mock():\n    \"\"\"Test extraction using mock backend.\"\"\"\n    # Create mock backend\n    mock_backend = MockLLMBackend(\n        mock_response={\n            \"name\": \"John Doe\",\n            \"age\": 30,\n            \"email\": \"john@example.com\"\n        }\n    )\n\n    # Use mock backend\n    result = mock_backend.extract_from_markdown(\n        markdown=\"Name: John Doe, Age: 30\",\n        template=Person\n    )\n\n    # Verify\n    assert result is not None\n    assert result.name == \"John Doe\"\n    assert result.age == 30\n    assert mock_backend.call_count == 1\n\ndef test_extraction_tracks_calls():\n    \"\"\"Test mock tracks method calls.\"\"\"\n    mock_backend = MockLLMBackend()\n\n    mock_backend.extract_from_markdown(\"test\", Person)\n    mock_backend.extract_from_markdown(\"test2\", Person)\n\n    assert mock_backend.call_count == 2\n    assert mock_backend.last_markdown == \"test2\"\n</code></pre>"},{"location":"usage/advanced/testing/#integration-testing","title":"Integration Testing","text":""},{"location":"usage/advanced/testing/#test-complete-pipeline","title":"Test Complete Pipeline","text":"<pre><code>\"\"\"Integration test for complete pipeline.\"\"\"\n\nimport pytest\nfrom pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\n\n@pytest.fixture\ndef sample_document(tmp_path):\n    \"\"\"Create sample document for testing.\"\"\"\n    doc_path = tmp_path / \"test.pdf\"\n    # Create minimal PDF (or use existing test file)\n    doc_path.write_bytes(b\"%PDF-1.4\\n%Test PDF\")\n    return doc_path\n\n@pytest.fixture\ndef output_dir(tmp_path):\n    \"\"\"Create output directory.\"\"\"\n    output = tmp_path / \"outputs\"\n    output.mkdir()\n    return output\n\ndef test_pipeline_execution(sample_document, output_dir):\n    \"\"\"Test pipeline executes successfully.\"\"\"\n    config = PipelineConfig(\n        source=str(sample_document),\n        template=\"templates.my_template.Person\",\n        output_dir=str(output_dir)\n    )\n\n    # Should not raise\n    run_pipeline(config)\n\n    # Verify outputs exist\n    assert (output_dir / \"nodes.csv\").exists()\n    assert (output_dir / \"edges.csv\").exists()\n\ndef test_pipeline_with_invalid_source():\n    \"\"\"Test pipeline handles invalid source.\"\"\"\n    config = PipelineConfig(\n        source=\"nonexistent.pdf\",\n        template=\"templates.my_template.Person\"\n    )\n\n    with pytest.raises(Exception):\n        run_pipeline(config)\n</code></pre>"},{"location":"usage/advanced/testing/#test-with-real-documents","title":"Test with Real Documents","text":"<pre><code>\"\"\"Test with real document samples.\"\"\"\n\nimport pytest\nfrom pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\n\n@pytest.fixture\ndef invoice_pdf():\n    \"\"\"Path to sample invoice.\"\"\"\n    return Path(\"tests/fixtures/sample_invoice.pdf\")\n\n@pytest.fixture\ndef research_paper_pdf():\n    \"\"\"Path to sample rheology research.\"\"\"\n    return Path(\"tests/fixtures/sample_paper.pdf\")\n\ndef test_invoice_extraction(invoice_pdf, tmp_path):\n    \"\"\"Test invoice extraction.\"\"\"\n    if not invoice_pdf.exists():\n        pytest.skip(\"Sample invoice not available\")\n\n    config = PipelineConfig(\n        source=str(invoice_pdf),\n        template=\"templates.billing_document.BillingDocument\",\n        output_dir=str(tmp_path)\n    )\n\n    run_pipeline(config)\n\n    # Verify invoice-specific outputs\n    nodes_file = tmp_path / \"nodes.csv\"\n    assert nodes_file.exists()\n\n    # Check for expected node types\n    content = nodes_file.read_text()\n    assert \"Invoice\" in content\n    assert \"LineItem\" in content\n\ndef test_research_paper_extraction(research_paper_pdf, tmp_path):\n    \"\"\"Test rheology research extraction.\"\"\"\n    if not research_paper_pdf.exists():\n        pytest.skip(\"Sample paper not available\")\n\n    config = PipelineConfig(\n        source=str(research_paper_pdf),\n        template=\"templates.rheology_research.ScholarlyRheologyPaperPaper\",\n        output_dir=str(tmp_path),\n        use_chunking=True  # Large document\n    )\n\n    run_pipeline(config)\n\n    # Verify outputs\n    assert (tmp_path / \"nodes.csv\").exists()\n    assert (tmp_path / \"edges.csv\").exists()\n</code></pre>"},{"location":"usage/advanced/testing/#test-fixtures","title":"Test Fixtures","text":""},{"location":"usage/advanced/testing/#shared-fixtures","title":"Shared Fixtures","text":"<pre><code>\"\"\"Shared test fixtures in conftest.py.\"\"\"\n\nimport pytest\nfrom pathlib import Path\nfrom pydantic import BaseModel, Field\n\n@pytest.fixture\ndef sample_template():\n    \"\"\"Sample template for testing.\"\"\"\n    class TestTemplate(BaseModel):\n        name: str = Field(..., description=\"Name\")\n        value: int = Field(..., description=\"Value\")\n\n    return TestTemplate\n\n@pytest.fixture\ndef sample_data():\n    \"\"\"Sample data for testing.\"\"\"\n    return {\n        \"name\": \"Test\",\n        \"value\": 42\n    }\n\n@pytest.fixture\ndef temp_output_dir(tmp_path):\n    \"\"\"Temporary output directory.\"\"\"\n    output_dir = tmp_path / \"outputs\"\n    output_dir.mkdir()\n    return output_dir\n\n@pytest.fixture\ndef mock_backend():\n    \"\"\"Mock backend for testing.\"\"\"\n    from tests.mocks import MockLLMBackend\n    return MockLLMBackend()\n</code></pre>"},{"location":"usage/advanced/testing/#use-fixtures","title":"Use Fixtures","text":"<pre><code>\"\"\"Use shared fixtures in tests.\"\"\"\n\ndef test_with_fixtures(sample_template, sample_data):\n    \"\"\"Test using fixtures.\"\"\"\n    instance = sample_template.model_validate(sample_data)\n\n    assert instance.name == \"Test\"\n    assert instance.value == 42\n\ndef test_with_output_dir(temp_output_dir):\n    \"\"\"Test with temporary output directory.\"\"\"\n    test_file = temp_output_dir / \"test.txt\"\n    test_file.write_text(\"test\")\n\n    assert test_file.exists()\n</code></pre>"},{"location":"usage/advanced/testing/#parametrized-tests","title":"Parametrized Tests","text":""},{"location":"usage/advanced/testing/#test-multiple-inputs","title":"Test Multiple Inputs","text":"<pre><code>\"\"\"Test with multiple parameter sets.\"\"\"\n\nimport pytest\nfrom templates.my_template import Person\n\n@pytest.mark.parametrize(\"name,age,valid\", [\n    (\"John\", 30, True),\n    (\"Jane\", 25, True),\n    (\"Bob\", -5, False),  # Invalid age\n    (\"\", 30, False),     # Empty name\n])\ndef test_person_validation(name, age, valid):\n    \"\"\"Test person validation with various inputs.\"\"\"\n    if valid:\n        person = Person(name=name, age=age)\n        assert person.name == name\n        assert person.age == age\n    else:\n        with pytest.raises(Exception):\n            Person(name=name, age=age)\n\n@pytest.mark.parametrize(\"backend,inference\", [\n    (\"llm\", \"local\"),\n    (\"llm\", \"remote\"),\n    (\"vlm\", \"local\"),\n])\ndef test_pipeline_configurations(backend, inference, tmp_path):\n    \"\"\"Test different pipeline configurations.\"\"\"\n    from docling_graph import run_pipeline, PipelineConfig\n\n    config = PipelineConfig(\n        source=\"test.pdf\",\n        template=\"templates.my_template.Person\",\n        backend=backend,\n        inference=inference,\n        output_dir=str(tmp_path)\n    )\n\n    # Verify configuration\n    assert config.backend == backend\n    assert config.inference == inference\n</code></pre>"},{"location":"usage/advanced/testing/#coverage-testing","title":"Coverage Testing","text":""},{"location":"usage/advanced/testing/#run-with-coverage","title":"Run with Coverage","text":"<pre><code># Run tests with coverage\nuv run pytest --cov=templates --cov=my_module --cov-report=html\n\n# View coverage report\nopen htmlcov/index.html\n</code></pre>"},{"location":"usage/advanced/testing/#coverage-configuration","title":"Coverage Configuration","text":"<pre><code># pytest.ini\n[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\n\n# Coverage settings\n[coverage:run]\nsource = templates,my_module\nomit = tests/*,*/__pycache__/*\n\n[coverage:report]\nexclude_lines =\n    pragma: no cover\n    def __repr__\n    raise AssertionError\n    raise NotImplementedError\n    if __name__ == .__main__.:\n</code></pre>"},{"location":"usage/advanced/testing/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"usage/advanced/testing/#github-actions","title":"GitHub Actions","text":"<pre><code># .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Install uv\n      run: curl -LsSf https://astral.sh/uv/install.sh | sh\n\n    - name: Install dependencies\n      run: uv sync --extra dev\n\n    - name: Run tests\n      run: uv run pytest --cov --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\n</code></pre>"},{"location":"usage/advanced/testing/#best-practices","title":"Best Practices","text":""},{"location":"usage/advanced/testing/#test-edge-cases","title":"\ud83d\udc4d Test Edge Cases","text":"<pre><code># \u2705 Good - Test edge cases\ndef test_empty_string():\n    \"\"\"Test with empty string.\"\"\"\n    with pytest.raises(ValidationError):\n        Person(name=\"\", age=30)\n\ndef test_boundary_values():\n    \"\"\"Test boundary values.\"\"\"\n    Person(name=\"A\", age=0)    # Minimum\n    Person(name=\"A\"*100, age=150)  # Maximum\n\n# \u274c Avoid - Only happy path\ndef test_person():\n    \"\"\"Test person.\"\"\"\n    person = Person(name=\"John\", age=30)\n    assert person.name == \"John\"\n</code></pre>"},{"location":"usage/advanced/testing/#use-descriptive-names","title":"\ud83d\udc4d Use Descriptive Names","text":"<pre><code># \u2705 Good - Descriptive test names\ndef test_person_validation_rejects_negative_age():\n    \"\"\"Test that negative ages are rejected.\"\"\"\n    pass\n\ndef test_invoice_extraction_handles_multiple_line_items():\n    \"\"\"Test extraction of invoices with multiple items.\"\"\"\n    pass\n\n# \u274c Avoid - Vague names\ndef test_person():\n    pass\n\ndef test_extraction():\n    pass\n</code></pre>"},{"location":"usage/advanced/testing/#keep-tests-independent","title":"\ud83d\udc4d Keep Tests Independent","text":"<pre><code># \u2705 Good - Independent tests\ndef test_create_person():\n    \"\"\"Test person creation.\"\"\"\n    person = Person(name=\"John\", age=30)\n    assert person.name == \"John\"\n\ndef test_validate_person():\n    \"\"\"Test person validation.\"\"\"\n    with pytest.raises(ValidationError):\n        Person(name=\"\", age=30)\n\n# \u274c Avoid - Dependent tests\nperson = None\n\ndef test_create():\n    global person\n    person = Person(name=\"John\", age=30)\n\ndef test_validate():\n    # Depends on test_create!\n    assert person.name == \"John\"\n</code></pre>"},{"location":"usage/advanced/testing/#mock-external-dependencies","title":"\ud83d\udc4d Mock External Dependencies","text":"<pre><code># \u2705 Good - Mock external APIs\n@pytest.fixture\ndef mock_api(monkeypatch):\n    \"\"\"Mock external API.\"\"\"\n    def mock_call(*args, **kwargs):\n        return {\"result\": \"success\"}\n\n    monkeypatch.setattr(\"my_module.api.call\", mock_call)\n\ndef test_with_mock_api(mock_api):\n    \"\"\"Test using mocked API.\"\"\"\n    result = my_function()\n    assert result == \"success\"\n\n# \u274c Avoid - Real API calls in tests\ndef test_with_real_api():\n    \"\"\"Test with real API.\"\"\"\n    result = api.call()  # Slow, unreliable, costs money\n    assert result\n</code></pre>"},{"location":"usage/advanced/testing/#troubleshooting-tests","title":"Troubleshooting Tests","text":""},{"location":"usage/advanced/testing/#tests-fail-locally-but-pass-in-ci","title":"\ud83d\udc1b Tests Fail Locally But Pass in CI","text":"<p>Solution: <pre><code># Use tmp_path fixture for file operations\ndef test_file_operations(tmp_path):\n    \"\"\"Test file operations.\"\"\"\n    test_file = tmp_path / \"test.txt\"\n    test_file.write_text(\"test\")\n    assert test_file.exists()\n\n# Don't use hardcoded paths\n# \u274c test_file = Path(\"/tmp/test.txt\")\n</code></pre></p>"},{"location":"usage/advanced/testing/#slow-tests","title":"\ud83d\udc1b Slow Tests","text":"<p>Solution: <pre><code># Mark slow tests\n@pytest.mark.slow\ndef test_large_document():\n    \"\"\"Test with large document.\"\"\"\n    pass\n\n# Run fast tests only\n# pytest -m \"not slow\"\n</code></pre></p>"},{"location":"usage/advanced/testing/#flaky-tests","title":"\ud83d\udc1b Flaky Tests","text":"<p>Solution: <pre><code># Add retries for flaky tests\n@pytest.mark.flaky(reruns=3)\ndef test_api_call():\n    \"\"\"Test API call (may be flaky).\"\"\"\n    pass\n</code></pre></p>"},{"location":"usage/advanced/testing/#next-steps","title":"Next Steps","text":"<ol> <li>Advanced Topics Index - Back to overview</li> <li>Custom Backends \u2192 - Test custom backends</li> <li>Error Handling \u2192 - Test error scenarios</li> </ol>"},{"location":"usage/advanced/trace-data-debugging/","title":"Trace Data Debugging","text":"<p>When <code>debug=True</code>, Docling Graph writes <code>debug/trace_data.json</code> as a compact, step-oriented payload.</p>"},{"location":"usage/advanced/trace-data-debugging/#trace-shape","title":"Trace Shape","text":"<p>Top-level structure:</p> <pre><code>{\n  \"summary\": {\n    \"runtime_seconds\": 1.237,\n    \"page_count\": 1,\n    \"extraction_success\": true,\n    \"fallback_used\": false,\n    \"node_count\": 7,\n    \"edge_count\": 6\n  },\n  \"steps\": [\n    {\n      \"name\": \"pipeline\",\n      \"runtime_seconds\": 1.237,\n      \"status\": \"success\",\n      \"artifacts\": { \"...\": \"...\" }\n    },\n    {\n      \"name\": \"docling_conversion\",\n      \"runtime_seconds\": 0.312,\n      \"status\": \"success\",\n      \"artifacts\": { \"...\": \"...\" }\n    }\n  ]\n}\n</code></pre> <p>Each step object includes only: - <code>name</code> - <code>runtime_seconds</code> (duration in seconds, 4 decimal places) - <code>status</code> - <code>artifacts</code> (single canonical payload; no mirrored <code>events</code>)</p>"},{"location":"usage/advanced/trace-data-debugging/#typical-step-artifacts","title":"Typical Step Artifacts","text":"<ul> <li><code>docling_conversion.artifacts.pages</code></li> <li><code>data_extraction.artifacts.extractions</code></li> <li><code>data_extraction.artifacts.fallbacks</code></li> <li><code>data_extraction.artifacts.staged_traces</code> (when extraction_contract=\"staged\")</li> <li><code>data_extraction.artifacts.delta_trace</code> / delta debug artifacts (when extraction_contract=\"delta\")</li> <li><code>graph_mapping.artifacts.graph</code></li> <li><code>pipeline.artifacts.start|finish|failure</code></li> </ul>"},{"location":"usage/advanced/trace-data-debugging/#structured-output-diagnostics","title":"Structured Output Diagnostics","text":"<p>Look at <code>data_extraction</code> step artifacts for structured-output behavior.</p> <p>Example payload keys: - <code>structured_attempted</code> - <code>structured_failed</code> - <code>fallback_used</code> - <code>fallback_error_class</code> - <code>structured_primary_attempt_parsed_json</code> - <code>structured_primary_attempt_raw</code></p>"},{"location":"usage/advanced/trace-data-debugging/#quick-inspection","title":"Quick Inspection","text":""},{"location":"usage/advanced/trace-data-debugging/#jq","title":"jq","text":"<pre><code>jq '.steps[] | {name, runtime_seconds, status}' debug/trace_data.json\n</code></pre> <pre><code>jq '.steps[] | select(.name == \"data_extraction\") | .artifacts.fallbacks' debug/trace_data.json\n</code></pre>"},{"location":"usage/advanced/trace-data-debugging/#python","title":"Python","text":"<pre><code>import json\nfrom pathlib import Path\n\ndata = json.loads(Path(\"debug/trace_data.json\").read_text())\nprint(data[\"summary\"])\nfor step in data[\"steps\"]:\n    print(step[\"name\"], step[\"runtime_seconds\"], step[\"status\"])\n</code></pre>"},{"location":"usage/advanced/trace-data-debugging/#notes","title":"Notes","text":"<ul> <li>Large strings are truncated during JSON export to keep debug files manageable.</li> <li><code>trace_data.json</code> intentionally exports compact step artifacts only (no mirrored raw events).</li> <li><code>trace_data.json</code> no longer uses legacy buckets like <code>extractions</code>, <code>intermediate_graphs</code>, or <code>consolidation</code>.</li> </ul>"},{"location":"usage/api/","title":"Python API","text":""},{"location":"usage/api/#overview","title":"Overview","text":"<p>The docling-graph Python API provides programmatic access to the document-to-graph pipeline, enabling integration into Python applications, notebooks, and workflows.</p> <p>Key Components: - <code>run_pipeline()</code> - Main pipeline function - <code>PipelineConfig</code> - Type-safe configuration - Direct module imports for advanced usage</p>"},{"location":"usage/api/#quick-start","title":"Quick Start","text":""},{"location":"usage/api/#basic-usage-api-mode-no-file-exports","title":"Basic Usage (API Mode - No File Exports)","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Configure pipeline\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\n\n# Run pipeline - returns data directly\ncontext = run_pipeline(config)\n\n# Access results in memory\ngraph = context.knowledge_graph\nmodel = context.pydantic_model\nprint(f\"Extracted {graph.number_of_nodes()} nodes\")\n</code></pre>"},{"location":"usage/api/#installation","title":"Installation","text":"<pre><code>pip install docling-graph\n</code></pre> <p>The package includes LiteLLM and supports both remote and local inference out of the box.</p>"},{"location":"usage/api/#api-components","title":"API Components","text":""},{"location":"usage/api/#1-pipelineconfig","title":"1. PipelineConfig","text":"<p>Type-safe configuration class with validation.</p> <pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\n</code></pre> <p>Learn more: PipelineConfig \u2192</p>"},{"location":"usage/api/#2-run_pipeline","title":"2. run_pipeline()","text":"<p>Main pipeline execution function.</p> <pre><code>from docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\"\n})\n</code></pre> <p>Learn more: run_pipeline() \u2192</p>"},{"location":"usage/api/#3-direct-module-access","title":"3. Direct Module Access","text":"<p>For advanced usage, import modules directly.</p> <pre><code>from docling_graph.core.converters import GraphConverter\nfrom docling_graph.core.exporters import CSVExporter\nfrom docling_graph.core.visualizers import InteractiveVisualizer\n</code></pre> <p>Learn more: API Reference \u2192</p>"},{"location":"usage/api/#common-patterns","title":"Common Patterns","text":""},{"location":"usage/api/#pattern-1-simple-conversion-memory-efficient","title":"Pattern 1: Simple Conversion (Memory-Efficient)","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\n# Returns data directly - no file exports\ncontext = run_pipeline(config)\ngraph = context.knowledge_graph\ninvoice = context.pydantic_model\n</code></pre>"},{"location":"usage/api/#pattern-2-custom-configuration","title":"Pattern 2: Custom Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"research.pdf\",\n    template=\"templates.ScholarlyRheologyPaper\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    # Use extraction_contract=\"delta\" for chunk-based graph extraction on long docs\n)\n\n# Access results in memory\ncontext = run_pipeline(config)\ngraph = context.knowledge_graph\nprint(f\"Research: {graph.number_of_nodes()} nodes, {graph.number_of_edges()} edges\")\n</code></pre>"},{"location":"usage/api/#pattern-3-batch-processing-memory-efficient","title":"Pattern 3: Batch Processing (Memory-Efficient)","text":"<pre><code>from pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\n\ndocuments = Path(\"documents\").glob(\"*.pdf\")\nall_graphs = []\n\nfor doc in documents:\n    config = PipelineConfig(\n        source=str(doc),\n        template=\"templates.BillingDocument\"\n    )\n\n    try:\n        # Process without file exports\n        context = run_pipeline(config)\n        all_graphs.append({\n            \"filename\": doc.name,\n            \"graph\": context.knowledge_graph,\n            \"model\": context.pydantic_model\n        })\n        print(f\"\u2705 Processed: {doc.name}\")\n    except Exception as e:\n        print(f\"\u274c Failed: {doc.name} - {e}\")\n\n# Aggregate results\ntotal_nodes = sum(g[\"graph\"].number_of_nodes() for g in all_graphs)\nprint(f\"\\nTotal entities: {total_nodes}\")\n</code></pre>"},{"location":"usage/api/#pattern-4-error-handling","title":"Pattern 4: Error Handling","text":"<pre><code>from docling_graph import PipelineConfig\nfrom docling_graph.exceptions import (\n    ConfigurationError,\n    ExtractionError,\n    PipelineError\n)\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\ntry:\n    run_pipeline(config)\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e.message}\")\n    print(f\"Details: {e.details}\")\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\nexcept PipelineError as e:\n    print(f\"Pipeline error: {e.message}\")\n</code></pre>"},{"location":"usage/api/#comparison-cli-vs-python-api","title":"Comparison: CLI vs Python API","text":"Feature CLI Python API Ease of Use Simple commands Requires Python code Flexibility Limited to options Full programmatic control Integration Shell scripts Python applications File Exports Always exports files No exports by default (memory-efficient) Return Values N/A Returns <code>PipelineContext</code> with graph and model Batch Processing Shell loops Python loops with error handling Configuration YAML + flags PipelineConfig objects Best For Quick tasks, scripts Applications, notebooks, workflows <p>Python API export behavior</p> <p>Python API defaults to dump_to_disk=False for memory efficiency. Set dump_to_disk=True to enable file exports.</p>"},{"location":"usage/api/#environment-setup","title":"Environment Setup","text":""},{"location":"usage/api/#api-keys","title":"API Keys","text":"<pre><code>import os\n\n# Set API keys programmatically\nos.environ[\"MISTRAL_API_KEY\"] = \"your-key\"\nos.environ[\"OPENAI_API_KEY\"] = \"your-key\"\n\n# Or use python-dotenv\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    inference=\"remote\"\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/api/#python-path","title":"Python Path","text":"<pre><code>import sys\nfrom pathlib import Path\n\n# Add project root to path\nproject_root = Path(__file__).parent.parent\nsys.path.append(str(project_root))\n\n# Now you can import templates\nfrom templates.billing_document import BillingDocument\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=Invoice  # Pass class directly\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/api/#integration-examples","title":"Integration Examples","text":""},{"location":"usage/api/#flask-web-application","title":"Flask Web Application","text":"<pre><code>from flask import Flask, request, jsonify\nfrom docling_graph import PipelineConfig\nfrom pathlib import Path\nimport uuid\n\napp = Flask(__name__)\n\n@app.route('/convert', methods=['POST'])\ndef convert_document():\n    # Get uploaded file\n    file = request.files['document']\n    template = request.form.get('template', 'templates.BillingDocument')\n\n    # Save temporarily\n    temp_id = str(uuid.uuid4())\n    temp_path = f\"temp/{temp_id}_{file.filename}\"\n    file.save(temp_path)\n\n    # Process\n    try:\n        config = PipelineConfig(\n            source=temp_path,\n            template=template,\n        )\n        context = run_pipeline(config)\n\n        return jsonify({\n            \"status\": \"success\",\n            \"model\": context.pydantic_model.model_dump()\n        })\n    except Exception as e:\n        return jsonify({\n            \"status\": \"error\",\n            \"message\": str(e)\n        }), 500\n    finally:\n        # Cleanup\n        Path(temp_path).unlink(missing_ok=True)\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"usage/api/#jupyter-notebook","title":"Jupyter Notebook","text":"<pre><code># Cell 1: Setup\nfrom docling_graph import PipelineConfig\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Cell 2: Process document\nconfig = PipelineConfig(\n    source=\"research.pdf\",\n    template=\"templates.ScholarlyRheologyPaper\"\n)\ncontext = run_pipeline(config)\n\n# Cell 3: Analyze results\ngraph = context.knowledge_graph\n\nprint(f\"Total nodes: {graph.number_of_nodes()}\")\nprint(f\"Total edges: {graph.number_of_edges()}\")\n\n# Cell 4: Visualize\nnode_types = nodes['type'].value_counts()\nnode_types.plot(kind='bar', title='Node Types')\nplt.show()\n</code></pre>"},{"location":"usage/api/#airflow-dag","title":"Airflow DAG","text":"<pre><code>from airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom datetime import datetime\nfrom docling_graph import PipelineConfig\n\ndef process_document(**context):\n    config = PipelineConfig(\n        source=context['params']['source'],\n        template=context['params']['template']\n    )\n    run_pipeline(config)\n\nwith DAG(\n    'document_processing',\n    start_date=datetime(2024, 1, 1),\n    schedule_interval='@daily'\n) as dag:\n\n    process_task = PythonOperator(\n        task_id='process_document',\n        python_callable=process_document,\n        params={\n            'source': 'documents/daily.pdf',\n            'template': 'templates.BillingDocument'\n        }\n    )\n</code></pre>"},{"location":"usage/api/#best-practices","title":"Best Practices","text":""},{"location":"usage/api/#use-type-safe-configuration","title":"\ud83d\udc4d Use Type-Safe Configuration","text":"<pre><code># \u2705 Good - Type-safe with validation\nfrom docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\"  # Validated\n)\n\n# \u274c Avoid - Dictionary without validation\nconfig = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"backend\": \"invalid\"  # No validation\n}\n</code></pre>"},{"location":"usage/api/#handle-errors-gracefully","title":"\ud83d\udc4d Handle Errors Gracefully","text":"<pre><code># \u2705 Good - Specific error handling\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import ExtractionError\n\ntry:\n    run_pipeline(config)\nexcept ExtractionError as e:\n    logger.error(f\"Extraction failed: {e.message}\")\n    # Implement retry logic or fallback\n\n# \u274c Avoid - Catching all exceptions\ntry:\n    run_pipeline(config)\nexcept Exception:\n    pass  # Silent failure\n</code></pre>"},{"location":"usage/api/#next-steps","title":"Next Steps","text":"<p>Explore the Python API in detail:</p> <ol> <li>run_pipeline() \u2192 - Pipeline function</li> <li>PipelineConfig \u2192 - Configuration class</li> <li>Programmatic Examples \u2192 - Code examples</li> <li>Batch Processing \u2192 - Batch patterns</li> </ol> <p>Or continue to: - Examples \u2192 - Real-world examples - API Reference \u2192 - Complete API docs</p>"},{"location":"usage/api/batch-processing/","title":"Batch Processing","text":""},{"location":"usage/api/batch-processing/#overview","title":"Overview","text":"<p>Batch processing enables efficient processing of multiple documents with progress tracking, error handling, and result aggregation.</p> <p>Key Features: - Memory-efficient processing (no file exports by default) - Parallel processing - Progress tracking - Error recovery - Result aggregation - Resource management</p>"},{"location":"usage/api/batch-processing/#basic-batch-processing","title":"Basic Batch Processing","text":""},{"location":"usage/api/batch-processing/#simple-loop-memory-efficient","title":"Simple Loop (Memory-Efficient)","text":"<pre><code>from pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\n\ndocuments = Path(\"documents\").glob(\"*.pdf\")\nresults = []\n\nfor doc in documents:\n    config = PipelineConfig(\n        source=str(doc),\n        template=\"templates.BillingDocument\"\n    )\n\n    try:\n        # Process without file exports - memory efficient\n        context = run_pipeline(config)\n        results.append({\n            \"filename\": doc.name,\n            \"nodes\": context.knowledge_graph.number_of_nodes(),\n            \"edges\": context.knowledge_graph.number_of_edges()\n        })\n        print(f\"\u2705 {doc.name}: {results[-1]['nodes']} nodes\")\n    except Exception as e:\n        print(f\"\u274c {doc.name}: {e}\")\n\n# Summary\nprint(f\"\\nTotal documents: {len(results)}\")\nprint(f\"Total nodes: {sum(r['nodes'] for r in results)}\")\n</code></pre>"},{"location":"usage/api/batch-processing/#with-file-exports","title":"With File Exports","text":"<pre><code>from pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\n\ndocuments = Path(\"documents\").glob(\"*.pdf\")\n\nfor doc in documents:\n    config = PipelineConfig(\n        source=str(doc),\n        template=\"templates.BillingDocument\",\n        dump_to_disk=True,  # Enable file exports\n        output_dir=f\"outputs/{doc.stem}\"\n    )\n\n    try:\n        context = run_pipeline(config)\n        print(f\"\u2705 {doc.name}\")\n    except Exception as e:\n        print(f\"\u274c {doc.name}: {e}\")\n</code></pre>"},{"location":"usage/api/batch-processing/#progress-tracking","title":"Progress Tracking","text":""},{"location":"usage/api/batch-processing/#using-tqdm","title":"Using tqdm","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\nfrom tqdm import tqdm\n\ndocuments = list(Path(\"documents\").glob(\"*.pdf\"))\n\nfor doc in tqdm(documents, desc=\"Processing\"):\n    config = PipelineConfig(\n        source=str(doc),\n        template=\"templates.BillingDocument\"\n    )\n\n    try:\n        run_pipeline(config)\n    except Exception as e:\n        tqdm.write(f\"\u274c {doc.name}: {e}\")\n</code></pre> <p>Install tqdm: <pre><code>uv add tqdm\n</code></pre></p>"},{"location":"usage/api/batch-processing/#error-handling","title":"Error Handling","text":""},{"location":"usage/api/batch-processing/#comprehensive-error-tracking-memory-efficient","title":"Comprehensive Error Tracking (Memory-Efficient)","text":"<pre><code>from pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import DoclingGraphError\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef batch_process(input_dir: str, template: str):\n    \"\"\"Process documents with error tracking - no file exports.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    results = {\n        \"success\": [],\n        \"failed\": [],\n        \"graphs\": []\n    }\n\n    for doc in documents:\n        try:\n            config = PipelineConfig(\n                source=str(doc),\n                template=template\n            )\n\n            # Process without file exports\n            context = run_pipeline(config)\n\n            # Store results in memory\n            results[\"success\"].append(doc.name)\n            results[\"graphs\"].append({\n                \"filename\": doc.name,\n                \"graph\": context.knowledge_graph,\n                \"model\": context.pydantic_model\n            })\n            logger.info(f\"\u2705 Success: {doc.name} ({context.knowledge_graph.number_of_nodes()} nodes)\")\n\n        except DoclingGraphError as e:\n            results[\"failed\"].append({\n                \"document\": doc.name,\n                \"error\": e.message,\n                \"details\": e.details\n            })\n            logger.error(f\"\u274c Failed: {doc.name} - {e.message}\")\n\n        except Exception as e:\n            results[\"failed\"].append({\n                \"document\": doc.name,\n                \"error\": str(e),\n                \"details\": None\n            })\n            logger.exception(f\"\u274c Unexpected error: {doc.name}\")\n\n    # Summary\n    total = len(documents)\n    logger.info(f\"\\n{'='*50}\")\n    logger.info(f\"Total: {total}\")\n    logger.info(f\"Success: {len(results['success'])}\")\n    logger.info(f\"Failed: {len(results['failed'])}\")\n    logger.info(f\"Total nodes: {sum(g['graph'].number_of_nodes() for g in results['graphs'])}\")\n\n    return results\n\n# Run batch processing\nresults = batch_process(\n    input_dir=\"documents/invoices\",\n    template=\"templates.billing_document.BillingDocument\"\n)\n</code></pre>"},{"location":"usage/api/batch-processing/#parallel-processing","title":"Parallel Processing","text":""},{"location":"usage/api/batch-processing/#using-threadpoolexecutor-memory-efficient","title":"Using ThreadPoolExecutor (Memory-Efficient)","text":"<pre><code>from pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom tqdm import tqdm\n\ndef process_document(doc_path: Path, template: str):\n    \"\"\"Process single document without file exports.\"\"\"\n    try:\n        config = PipelineConfig(\n            source=str(doc_path),\n            template=template\n        )\n        context = run_pipeline(config)\n        return {\n            \"status\": \"success\",\n            \"document\": doc_path.name,\n            \"nodes\": context.knowledge_graph.number_of_nodes(),\n            \"edges\": context.knowledge_graph.number_of_edges(),\n            \"graph\": context.knowledge_graph,\n            \"model\": context.pydantic_model\n        }\n    except Exception as e:\n        return {\"status\": \"error\", \"document\": doc_path.name, \"error\": str(e)}\n\ndef parallel_batch_process(\n    input_dir: str,\n    template: str,\n    max_workers: int = 4\n):\n    \"\"\"Process documents in parallel - memory efficient.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    results = {\"success\": [], \"failed\": [], \"graphs\": []}\n\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        # Submit all tasks\n        futures = {\n            executor.submit(process_document, doc, template): doc\n            for doc in documents\n        }\n\n        # Process results as they complete\n        for future in tqdm(as_completed(futures), total=len(documents), desc=\"Processing\"):\n            result = future.result()\n\n            if result[\"status\"] == \"success\":\n                results[\"success\"].append(result[\"document\"])\n                results[\"graphs\"].append({\n                    \"filename\": result[\"document\"],\n                    \"graph\": result[\"graph\"],\n                    \"model\": result[\"model\"],\n                    \"nodes\": result[\"nodes\"],\n                    \"edges\": result[\"edges\"]\n                })\n            else:\n                results[\"failed\"].append({\n                    \"document\": result[\"document\"],\n                    \"error\": result[\"error\"]\n                })\n\n    # Summary\n    total_nodes = sum(g[\"nodes\"] for g in results[\"graphs\"])\n    total_edges = sum(g[\"edges\"] for g in results[\"graphs\"])\n    print(f\"\\nCompleted: {len(results['success'])} succeeded, {len(results['failed'])} failed\")\n    print(f\"Total entities: {total_nodes} nodes, {total_edges} edges\")\n    return results\n\n# Run parallel processing\nresults = parallel_batch_process(\n    input_dir=\"documents/invoices\",\n    template=\"templates.billing_document.BillingDocument\",\n    max_workers=4\n)\n</code></pre>"},{"location":"usage/api/batch-processing/#result-aggregation","title":"Result Aggregation","text":""},{"location":"usage/api/batch-processing/#collecting-statistics","title":"Collecting Statistics","text":"<pre><code>from pathlib import Path\nimport json\nimport pandas as pd\nfrom docling_graph import PipelineConfig\n\ndef batch_with_stats(input_dir: str, template: str):\n    \"\"\"Process documents and collect statistics.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    all_stats = []\n\n    for doc in documents:\n        try:\n            # Process document\n            config = PipelineConfig(\n                source=str(doc),\n                template=template\n            )\n            context = run_pipeline(config)\n            graph = context.knowledge_graph\n            stats = {\n                \"document\": doc.name,\n                \"status\": \"success\",\n                \"node_count\": graph.number_of_nodes(),\n                \"edge_count\": graph.number_of_edges(),\n            }\n            all_stats.append(stats)\n\n        except Exception as e:\n            all_stats.append({\n                \"document\": doc.name,\n                \"status\": \"error\",\n                \"error\": str(e)\n            })\n\n    # Create summary DataFrame\n    df = pd.DataFrame(all_stats)\n\n    # Print statistics\n    print(\"\\n=== Batch Statistics ===\")\n    print(f\"Total documents: {len(df)}\")\n    print(f\"Successful: {(df['status'] == 'success').sum()}\")\n    print(f\"Failed: {(df['status'] == 'error').sum()}\")\n\n    if 'node_count' in df.columns:\n        successful = df[df['status'] == 'success']\n        print(f\"\\nAverage nodes: {successful['node_count'].mean():.1f}\")\n        print(f\"Average edges: {successful['edge_count'].mean():.1f}\")\n        print(f\"Average density: {successful['density'].mean():.3f}\")\n\n    return df\n\n# Run with statistics\ndf = batch_with_stats(\n    input_dir=\"documents/invoices\",\n    template=\"templates.billing_document.BillingDocument\"\n)\n\n# Analyze results\nprint(\"\\nTop 5 documents by node count:\")\nprint(df.nlargest(5, 'node_count')[['document', 'node_count', 'edge_count']])\n</code></pre>"},{"location":"usage/api/batch-processing/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"usage/api/batch-processing/#pattern-1-conditional-processing","title":"Pattern 1: Conditional Processing","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\n\ndef smart_batch_process(input_dir: str):\n    \"\"\"Process documents with template selection.\"\"\"\n    documents = Path(input_dir).glob(\"*\")\n\n    for doc in documents:\n        # Determine template based on filename\n        if \"invoice\" in doc.name.lower():\n            template = \"templates.billing_document.BillingDocument\"\n            backend = \"vlm\"\n        elif \"research\" in doc.name.lower():\n            template = \"templates.rheology_research.ScholarlyRheologyPaper\"\n            backend = \"llm\"\n        else:\n            print(f\"\u2298 Skipped (unknown type): {doc.name}\")\n            continue\n\n        # Process with appropriate config\n        config = PipelineConfig(\n            source=str(doc),\n            template=template,\n            backend=backend\n        )\n\n        try:\n            run_pipeline(config)\n            print(f\"\u2705 {doc.name}\")\n        except Exception as e:\n            print(f\"\u274c {doc.name}: {e}\")\n\nsmart_batch_process(\"documents/mixed\")\n</code></pre>"},{"location":"usage/api/batch-processing/#pattern-2-retry-logic","title":"Pattern 2: Retry Logic","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\nimport time\n\ndef process_with_retry(\n    doc_path: Path,\n    template: str,\n    max_retries: int = 3,\n    delay: int = 5\n):\n    \"\"\"Process document with retry logic.\"\"\"\n    for attempt in range(1, max_retries + 1):\n        try:\n            config = PipelineConfig(\n                source=str(doc_path),\n                template=template\n            )\n            run_pipeline(config)\n            return {\"status\": \"success\", \"attempts\": attempt}\n\n        except Exception as e:\n            if attempt &lt; max_retries:\n                print(f\"Attempt {attempt} failed, retrying in {delay}s...\")\n                time.sleep(delay)\n            else:\n                return {\n                    \"status\": \"error\",\n                    \"attempts\": attempt,\n                    \"error\": str(e)\n                }\n\ndef batch_with_retry(input_dir: str, template: str):\n    \"\"\"Batch process with retry logic.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    results = []\n\n    for doc in documents:\n        result = process_with_retry(\n            doc_path=doc,\n            template=template,\n            max_retries=3\n        )\n        result[\"document\"] = doc.name\n        results.append(result)\n\n        status = \"\u2705\" if result[\"status\"] == \"success\" else \"\u274c\"\n        print(f\"{status} {doc.name} (attempts: {result['attempts']})\")\n\n    return results\n\nresults = batch_with_retry(\n    input_dir=\"documents/invoices\",\n    template=\"templates.billing_document.BillingDocument\"\n)\n</code></pre>"},{"location":"usage/api/batch-processing/#pattern-3-checkpoint-and-resume","title":"Pattern 3: Checkpoint and Resume","text":"<pre><code>from pathlib import Path\nimport json\nfrom docling_graph import PipelineConfig\n\ndef batch_with_checkpoint(\n    input_dir: str,\n    template: str,\n    checkpoint_file: str = \"checkpoint.json\"\n):\n    \"\"\"Batch process with checkpoint support.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    checkpoint_path = Path(checkpoint_file)\n\n    # Load checkpoint\n    if checkpoint_path.exists():\n        with open(checkpoint_path) as f:\n            checkpoint = json.load(f)\n        processed = set(checkpoint.get(\"processed\", []))\n        print(f\"Resuming from checkpoint: {len(processed)} already processed\")\n    else:\n        processed = set()\n        checkpoint = {\"processed\": [], \"failed\": []}\n\n    # Process remaining documents\n    for doc in documents:\n        if doc.name in processed:\n            print(f\"\u2298 Skipped (already processed): {doc.name}\")\n            continue\n\n        try:\n            config = PipelineConfig(\n                source=str(doc),\n                template=template\n            )\n            run_pipeline(config)\n\n            # Update checkpoint\n            checkpoint[\"processed\"].append(doc.name)\n            print(f\"\u2705 {doc.name}\")\n\n        except Exception as e:\n            checkpoint[\"failed\"].append({\n                \"document\": doc.name,\n                \"error\": str(e)\n            })\n            print(f\"\u274c {doc.name}: {e}\")\n\n        # Save checkpoint after each document\n        with open(checkpoint_path, 'w') as f:\n            json.dump(checkpoint, f, indent=2)\n\n    print(f\"\\nProcessed: {len(checkpoint['processed'])}\")\n    print(f\"Failed: {len(checkpoint['failed'])}\")\n\n    return checkpoint\n\n# Run with checkpoint\ncheckpoint = batch_with_checkpoint(\n    input_dir=\"documents/invoices\",\n    template=\"templates.billing_document.BillingDocument\"\n)\n</code></pre>"},{"location":"usage/api/batch-processing/#resource-management","title":"Resource Management","text":""},{"location":"usage/api/batch-processing/#memory-management","title":"Memory Management","text":"<pre><code>from pathlib import Path\nfrom docling_graph import PipelineConfig\nimport gc\n\ndef batch_with_memory_management(\n    input_dir: str,\n    template: str,\n    cleanup_interval: int = 10\n):\n    \"\"\"Batch process with memory cleanup.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n\n    for i, doc in enumerate(documents, 1):\n        config = PipelineConfig(\n            source=str(doc),\n            template=template\n        )\n\n        try:\n            run_pipeline(config)\n            print(f\"\u2705 {doc.name}\")\n        except Exception as e:\n            print(f\"\u274c {doc.name}: {e}\")\n\n        # Periodic cleanup\n        if i % cleanup_interval == 0:\n            gc.collect()\n            print(f\"[Cleanup after {i} documents]\")\n\nbatch_with_memory_management(\n    input_dir=\"documents/large_batch\",\n    template=\"templates.billing_document.BillingDocument\",\n    cleanup_interval=10\n)\n</code></pre>"},{"location":"usage/api/batch-processing/#complete-example","title":"Complete Example","text":""},{"location":"usage/api/batch-processing/#production-ready-batch-processor","title":"Production-Ready Batch Processor","text":"<pre><code>\"\"\"\nProduction-ready batch processor with all features.\n\"\"\"\n\nfrom pathlib import Path\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom docling_graph import PipelineConfig\nfrom docling_graph.exceptions import DoclingGraphError\nimport json\nimport logging\nfrom datetime import datetime\nfrom tqdm import tqdm\nimport pandas as pd\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\nclass BatchProcessor:\n    \"\"\"Production-ready batch document processor.\"\"\"\n\n    def __init__(\n        self,\n        input_dir: str,\n        template: str,\n        output_base: str,\n        max_workers: int = 4,\n        max_retries: int = 3\n    ):\n        self.input_dir = Path(input_dir)\n        self.template = template\n        self.output_base = Path(output_base)\n        self.max_workers = max_workers\n        self.max_retries = max_retries\n\n        # Create output directory\n        self.output_base.mkdir(parents=True, exist_ok=True)\n\n        # Initialize checkpoint\n        self.checkpoint_file = self.output_base / \"checkpoint.json\"\n        self.load_checkpoint()\n\n    def load_checkpoint(self):\n        \"\"\"Load processing checkpoint.\"\"\"\n        if self.checkpoint_file.exists():\n            with open(self.checkpoint_file) as f:\n                self.checkpoint = json.load(f)\n            logger.info(f\"Loaded checkpoint: {len(self.checkpoint['processed'])} processed\")\n        else:\n            self.checkpoint = {\n                \"processed\": [],\n                \"failed\": [],\n                \"started_at\": datetime.now().isoformat()\n            }\n\n    def save_checkpoint(self):\n        \"\"\"Save processing checkpoint.\"\"\"\n        with open(self.checkpoint_file, 'w') as f:\n            json.dump(self.checkpoint, f, indent=2)\n\n    def process_document(self, doc_path: Path):\n        \"\"\"Process single document with retry logic.\"\"\"\n        # Skip if already processed\n        if doc_path.name in self.checkpoint[\"processed\"]:\n            return {\"status\": \"skipped\", \"document\": doc_path.name}\n\n        # Retry loop\n        for attempt in range(1, self.max_retries + 1):\n            try:\n                config = PipelineConfig(\n                    source=str(doc_path),\n                    template=self.template\n                )\n\n                context = run_pipeline(config)\n                graph = context.knowledge_graph\n                stats = {\n                    \"node_count\": graph.number_of_nodes(),\n                    \"edge_count\": graph.number_of_edges(),\n                }\n\n                return {\n                    \"status\": \"success\",\n                    \"document\": doc_path.name,\n                    \"attempts\": attempt,\n                    **stats\n                }\n\n            except DoclingGraphError as e:\n                if attempt &lt; self.max_retries:\n                    logger.warning(f\"Attempt {attempt} failed for {doc_path.name}, retrying...\")\n                    continue\n                else:\n                    return {\n                        \"status\": \"error\",\n                        \"document\": doc_path.name,\n                        \"attempts\": attempt,\n                        \"error\": e.message\n                    }\n            except Exception as e:\n                return {\n                    \"status\": \"error\",\n                    \"document\": doc_path.name,\n                    \"attempts\": attempt,\n                    \"error\": str(e)\n                }\n\n    def process_batch(self):\n        \"\"\"Process all documents in batch.\"\"\"\n        documents = list(self.input_dir.glob(\"*.pdf\"))\n        logger.info(f\"Found {len(documents)} documents to process\")\n\n        results = []\n\n        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n            futures = {\n                executor.submit(self.process_document, doc): doc\n                for doc in documents\n            }\n\n            for future in tqdm(as_completed(futures), total=len(documents), desc=\"Processing\"):\n                result = future.result()\n                results.append(result)\n\n                # Update checkpoint\n                if result[\"status\"] == \"success\":\n                    self.checkpoint[\"processed\"].append(result[\"document\"])\n                elif result[\"status\"] == \"error\":\n                    self.checkpoint[\"failed\"].append({\n                        \"document\": result[\"document\"],\n                        \"error\": result[\"error\"]\n                    })\n\n                self.save_checkpoint()\n\n        # Generate summary\n        self.generate_summary(results)\n\n        return results\n\n    def generate_summary(self, results):\n        \"\"\"Generate processing summary.\"\"\"\n        df = pd.DataFrame(results)\n\n        # Save detailed results\n        summary_file = self.output_base / \"batch_results.csv\"\n        df.to_csv(summary_file, index=False)\n\n        # Print summary\n        logger.info(\"\\n\" + \"=\"*50)\n        logger.info(\"BATCH PROCESSING SUMMARY\")\n        logger.info(\"=\"*50)\n        logger.info(f\"Total documents: {len(df)}\")\n        logger.info(f\"Successful: {(df['status'] == 'success').sum()}\")\n        logger.info(f\"Failed: {(df['status'] == 'error').sum()}\")\n        logger.info(f\"Skipped: {(df['status'] == 'skipped').sum()}\")\n\n        if 'node_count' in df.columns:\n            successful = df[df['status'] == 'success']\n            if len(successful) &gt; 0:\n                logger.info(f\"\\nAverage nodes: {successful['node_count'].mean():.1f}\")\n                logger.info(f\"Average edges: {successful['edge_count'].mean():.1f}\")\n                logger.info(f\"Average density: {successful['density'].mean():.3f}\")\n\n        logger.info(f\"\\nResults saved to: {summary_file}\")\n\n# Usage\nif __name__ == \"__main__\":\n    processor = BatchProcessor(\n        input_dir=\"documents/invoices\",\n        template=\"templates.billing_document.BillingDocument\",\n        output_base=\"outputs/production_batch\",\n        max_workers=4,\n        max_retries=3\n    )\n\n    results = processor.process_batch()\n</code></pre> <p>Run: <pre><code>uv run python batch_processor.py\n</code></pre></p>"},{"location":"usage/api/batch-processing/#best-practices","title":"Best Practices","text":""},{"location":"usage/api/batch-processing/#use-progress-tracking","title":"\ud83d\udc4d Use Progress Tracking","text":"<pre><code># \u2705 Good - Visual progress\nfrom tqdm import tqdm\n\nfor doc in tqdm(documents, desc=\"Processing\"):\n    run_pipeline(config)\n\n# \u274c Avoid - No feedback\nfor doc in documents:\n    run_pipeline(config)\n</code></pre>"},{"location":"usage/api/batch-processing/#implement-error-recovery","title":"\ud83d\udc4d Implement Error Recovery","text":"<pre><code># \u2705 Good - Checkpoint and resume\ncheckpoint = load_checkpoint()\nfor doc in documents:\n    if doc.name not in checkpoint[\"processed\"]:\n        process(doc)\n        checkpoint[\"processed\"].append(doc.name)\n        save_checkpoint(checkpoint)\n\n# \u274c Avoid - Start from scratch on failure\nfor doc in documents:\n    process(doc)\n</code></pre>"},{"location":"usage/api/batch-processing/#aggregate-results","title":"\ud83d\udc4d Aggregate Results","text":"<pre><code># \u2705 Good - Collect statistics\nresults = []\nfor doc in documents:\n    result = process(doc)\n    results.append(result)\n\ndf = pd.DataFrame(results)\ndf.to_csv(\"summary.csv\")\n\n# \u274c Avoid - No summary\nfor doc in documents:\n    process(doc)\n</code></pre>"},{"location":"usage/api/batch-processing/#next-steps","title":"Next Steps","text":"<ol> <li>Examples \u2192 - Real-world examples</li> <li>Advanced Topics \u2192 - Custom backends</li> <li>API Reference \u2192 - Complete API docs</li> </ol>"},{"location":"usage/api/llm-model-config/","title":"LLM Model Configuration","text":"<p>This guide explains how to define models, override settings, and inspect the resolved (effective) LLM configuration at runtime.</p>"},{"location":"usage/api/llm-model-config/#select-a-model-and-provider","title":"Select a Model and Provider","text":"<p>Model context windows and output limits are resolved dynamically via LiteLLM. To use a new model, simply specify the provider and model name in your config or via CLI overrides.</p>"},{"location":"usage/api/llm-model-config/#override-via-python-api","title":"Override via Python (API)","text":"<p>You can override generation, reliability, connection settings, and model limits at runtime:</p> <pre><code>from docling_graph import PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"doc.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\",\n    model_override=\"gpt-4o\",\n    provider_override=\"openai\",\n    structured_output=True,  # default; set False for legacy prompt-schema mode\n    structured_sparse_check=True,  # default; set False to disable sparse-result fallback guard\n    llm_overrides={\n        \"generation\": {\"temperature\": 0.2, \"max_tokens\": 2048},\n        \"reliability\": {\"timeout_s\": 120, \"max_retries\": 1},\n        \"context_limit\": 128000,           # Override context window size\n        \"max_output_tokens\": 4096,        # Override max output tokens\n    },\n)\n</code></pre>"},{"location":"usage/api/llm-model-config/#override-via-config-file","title":"Override via Config File","text":"<p>In <code>config.yaml</code>, use the same <code>llm_overrides</code> shape:</p> <pre><code>models:\n  llm:\n    remote:\n      provider: openai\n      model: gpt-4o\n\nllm_overrides:\n  generation:\n    temperature: 0.2\n    max_tokens: 512\n  reliability:\n    timeout_s: 120\n  context_limit: 128000        # Override context window size\n  max_output_tokens: 4096      # Override max output tokens\n</code></pre>"},{"location":"usage/api/llm-model-config/#override-via-cli","title":"Override via CLI","text":"<p>Common overrides:</p> <pre><code>docling-graph convert doc.pdf --template templates.BillingDocument \\\n  --provider openai --model gpt-4o \\\n  --llm-temperature 0.2 \\\n  --llm-max-tokens 2048 \\\n  --llm-timeout 120 \\\n  --schema-enforced-llm \\\n  --llm-context-limit 128000 \\\n  --llm-max-output-tokens 4096\n</code></pre>"},{"location":"usage/api/llm-model-config/#available-cli-overrides","title":"Available CLI Overrides","text":"<ul> <li><code>--llm-temperature</code>: Generation temperature (0.0-2.0)</li> <li><code>--llm-max-tokens</code>: Maximum tokens in response</li> <li><code>--llm-top-p</code>: Top-p sampling parameter</li> <li><code>--llm-timeout</code>: Request timeout in seconds</li> <li><code>--llm-retries</code>: Maximum retry attempts</li> <li><code>--llm-base-url</code>: Custom API base URL (e.g. for on-prem OpenAI-compatible servers)</li> <li><code>--llm-context-limit</code>: Total context window size in tokens</li> <li><code>--llm-max-output-tokens</code>: Maximum tokens the model can generate</li> <li><code>--schema-enforced-llm/--no-schema-enforced-llm</code>: Enable/disable API-enforced JSON schema mode</li> <li><code>--structured-sparse-check/--no-structured-sparse-check</code>: Enable/disable sparse structured-result fallback guard</li> </ul> <p>Runtime behavior: - With <code>structured_output=True</code>, Docling Graph attempts API-level <code>json_schema</code> first. - If that request fails, it logs diagnostics and retries once with legacy prompt-schema mode. - If schema mode succeeds but the returned JSON is clearly sparse for the schema, it performs   the same one-time legacy retry to prevent silent quality regressions.</p> <p>API keys are not passed via CLI; use environment variables or <code>llm_overrides.connection.api_key</code> in config. For on-prem OpenAI-compatible servers: use <code>provider=openai</code>, <code>--llm-base-url</code>, and set <code>CUSTOM_LLM_BASE_URL</code> / <code>CUSTOM_LLM_API_KEY</code>. For LM Studio (<code>provider=lmstudio</code>): use optional <code>LM_STUDIO_API_BASE</code> and <code>LM_STUDIO_API_KEY</code> (or <code>llm_overrides.connection</code>) when needed.</p>"},{"location":"usage/api/llm-model-config/#recommended-quality-metrics","title":"Recommended Quality Metrics","text":"<p>When validating structured output rollouts, track:</p> <ul> <li>schema conformance rate before salvage/repair,</li> <li>salvage invocation rate (how often repair/coercion is needed),</li> <li>strict-mode failure rate by model/provider,</li> <li>latency and token deltas versus legacy prompt-schema mode.</li> </ul> <p>This allows you to compare quality and cost impact between: <code>structured_output=True</code> (default) and <code>structured_output=False</code> (fallback).</p>"},{"location":"usage/api/llm-model-config/#model-limits-and-defaults","title":"Model Limits and Defaults","text":""},{"location":"usage/api/llm-model-config/#context-limit-and-max-output-tokens","title":"Context Limit and Max Output Tokens","text":"<p>By default, these values are resolved from LiteLLM metadata. If LiteLLM doesn't have information about your model, the system falls back to defaults:</p> <ul> <li>Default context limit: 8,192 tokens</li> <li>Default max output tokens: 2,048 tokens</li> </ul> <p>Important: If you see warnings about falling back to defaults, provide explicit values via CLI flags or <code>llm_overrides</code> to optimize extraction performance.</p>"},{"location":"usage/api/llm-model-config/#merge-threshold","title":"Merge Threshold","text":"<p>The <code>merge_threshold</code> controls when chunks are merged into batches (default: 95%). This is provider-specific and can be overridden programmatically:</p> <pre><code>from docling_graph.core.extractors import ChunkBatcher\n\nbatcher = ChunkBatcher(\n    context_limit=128000,\n    schema_json='{\"title\": \"Schema\"}',\n    tokenizer=tokenizer,\n    merge_threshold=0.90,  # Override default 95%\n    provider=\"openai\",\n)\n</code></pre> <p>Note: Merge threshold is not currently available as a CLI option. Use the Python API for advanced control.</p>"},{"location":"usage/api/llm-model-config/#view-the-resolved-config","title":"View the Resolved Config","text":"<p>CLI:</p> <pre><code>docling-graph convert doc.pdf --template templates.BillingDocument --show-llm-config\n</code></pre> <p>Python:</p> <pre><code>from docling_graph.llm_clients.config import resolve_effective_model_config\n\neffective = resolve_effective_model_config(\"openai\", \"gpt-4o\")\nprint(effective.model_dump())\n</code></pre>"},{"location":"usage/api/pipeline-config/","title":"PipelineConfig","text":""},{"location":"usage/api/pipeline-config/#overview","title":"Overview","text":"<p><code>PipelineConfig</code> is a type-safe configuration class built with Pydantic that provides validation, defaults, and IDE autocomplete for pipeline configuration.</p> <p>Key Features: - Type validation - Default values - IDE autocomplete - Validation errors - Convenience methods</p>"},{"location":"usage/api/pipeline-config/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Create configuration\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\n\n# Run pipeline\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/api/pipeline-config/#constructor-parameters","title":"Constructor Parameters","text":""},{"location":"usage/api/pipeline-config/#required-parameters","title":"Required Parameters","text":"Parameter Type Description <code>source</code> <code>str | Path</code> Path to source document <code>template</code> <code>str | Type[BaseModel]</code> Pydantic template (dotted path or class)"},{"location":"usage/api/pipeline-config/#core-settings","title":"Core Settings","text":"Parameter Type Default Description <code>backend</code> <code>Literal[\"llm\", \"vlm\"]</code> <code>\"llm\"</code> Backend type <code>inference</code> <code>Literal[\"local\", \"remote\"]</code> <code>\"local\"</code> Inference mode <code>processing_mode</code> <code>Literal[\"one-to-one\", \"many-to-one\"]</code> <code>\"many-to-one\"</code> Processing strategy <code>extraction_contract</code> <code>Literal[\"direct\", \"staged\", \"delta\"]</code> <code>\"direct\"</code> LLM extraction contract: <code>direct</code> (single-pass), <code>staged</code> (multi-pass ID\u2192fill\u2192merge), <code>delta</code> (chunk-based graph IR\u2192merge\u2192projection). See Delta Extraction."},{"location":"usage/api/pipeline-config/#docling-settings","title":"Docling Settings","text":"Parameter Type Default Description <code>docling_config</code> <code>Literal[\"ocr\", \"vision\"]</code> <code>\"ocr\"</code> Docling pipeline type"},{"location":"usage/api/pipeline-config/#model-overrides","title":"Model Overrides","text":"Parameter Type Default Description <code>model_override</code> <code>str | None</code> <code>None</code> Override model name <code>provider_override</code> <code>str | None</code> <code>None</code> Override provider name"},{"location":"usage/api/pipeline-config/#custom-llm-client","title":"Custom LLM Client","text":"Parameter Type Default Description <code>llm_client</code> <code>LLMClientProtocol \\| None</code> <code>None</code> Custom LLM client instance. When set, the pipeline uses this client for all LLM calls and does not initialize a provider/model from config. Use this to target a custom inference URL, on-prem endpoint, or any client implementing <code>get_json_response(prompt, schema_json) -&gt; dict | list</code>. <p>Usage: Pass any object that implements <code>LLMClientProtocol</code> (e.g. a LiteLLM-backed client with a custom <code>base_url</code>). See LLM Clients \u2014 Custom LLM Clients for a full example.</p> <pre><code>from docling_graph import PipelineConfig, run_pipeline\n\n# Your custom client (must implement get_json_response(prompt, schema_json))\ncustom_client = MyLiteLLMEndpointClient(base_url=\"https://...\", model=\"openai/...\")\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    llm_client=custom_client,\n)\nrun_pipeline(config)  # or config.run()\n</code></pre>"},{"location":"usage/api/pipeline-config/#extraction-settings","title":"Extraction Settings","text":"Parameter Type Default Description <code>use_chunking</code> <code>bool</code> <code>True</code> Enable document chunking <code>max_batch_size</code> <code>int</code> <code>1</code> Maximum batch size <code>gleaning_enabled</code> <code>bool</code> <code>True</code> Run optional second-pass extraction (\"what did you miss?\") to improve recall. Applies to direct and delta contracts only (not staged). See Gleaning. <code>gleaning_max_passes</code> <code>int</code> <code>1</code> Max number of gleaning passes when <code>gleaning_enabled</code> is True (1 = one extra pass). <p>For delta extraction, additional options (e.g. <code>llm_batch_token_size</code>, <code>parallel_workers</code>, <code>delta_resolvers_enabled</code>, <code>delta_resolvers_mode</code>, <code>delta_quality_max_parent_lookup_miss</code>) can be set via a config dict or YAML <code>defaults</code>; see Delta Extraction and Configuration reference.</p>"},{"location":"usage/api/pipeline-config/#debug-settings","title":"Debug Settings","text":"Parameter Type Default Description <code>debug</code> <code>bool</code> <code>False</code> Enable debug mode to save all intermediate extraction artifacts"},{"location":"usage/api/pipeline-config/#export-settings","title":"Export Settings","text":"Parameter Type Default Description <code>dump_to_disk</code> <code>bool | None</code> <code>None</code> Control file exports. <code>None</code>=auto (CLI=True, API=False), <code>True</code>=always, <code>False</code>=never <code>export_format</code> <code>Literal[\"csv\", \"cypher\"]</code> <code>\"csv\"</code> Export format <code>export_docling</code> <code>bool</code> <code>True</code> Export Docling outputs <code>export_docling_json</code> <code>bool</code> <code>True</code> Export Docling JSON <code>export_markdown</code> <code>bool</code> <code>True</code> Export markdown <code>export_per_page_markdown</code> <code>bool</code> <code>False</code> Export per-page markdown"},{"location":"usage/api/pipeline-config/#graph-settings","title":"Graph Settings","text":"Parameter Type Default Description <code>reverse_edges</code> <code>bool</code> <code>False</code> Create bidirectional edges"},{"location":"usage/api/pipeline-config/#output-settings","title":"Output Settings","text":"Parameter Type Default Description <code>output_dir</code> <code>str | Path</code> <code>\"outputs\"</code> Output directory path"},{"location":"usage/api/pipeline-config/#models-configuration","title":"Models Configuration","text":"Parameter Type Default Description <code>models</code> <code>ModelsConfig</code> Default models Models configuration"},{"location":"usage/api/pipeline-config/#methods","title":"Methods","text":""},{"location":"usage/api/pipeline-config/#run","title":"run()","text":"<p>Execute the pipeline with this configuration.</p> <pre><code>from docling_graph import run_pipeline\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\n# Returns PipelineContext with results\ncontext = run_pipeline(config)\ngraph = context.knowledge_graph\n</code></pre> <p>Returns: <code>PipelineContext</code> - Contains knowledge graph, Pydantic model, and other results</p> <p>Raises: <code>PipelineError</code>, <code>ConfigurationError</code>, <code>ExtractionError</code></p> <p>Accessing pipeline return values</p> <p>Use run_pipeline(config) instead of config.run() to access return values.</p>"},{"location":"usage/api/pipeline-config/#to_dict","title":"to_dict()","text":"<p>Convert configuration to dictionary format.</p> <pre><code>config = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\nconfig_dict = config.to_dict()\nprint(config_dict)\n# {\n#     \"source\": \"document.pdf\",\n#     \"template\": \"templates.BillingDocument\",\n#     \"backend\": \"llm\",\n#     ...\n# }\n</code></pre> <p>Returns: <code>Dict[str, Any]</code></p>"},{"location":"usage/api/pipeline-config/#complete-examples","title":"Complete Examples","text":""},{"location":"usage/api/pipeline-config/#minimal-config-api-mode","title":"\ud83d\udccd Minimal Config (API Mode)","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Only required parameters - no file exports by default\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.BillingDocument\"\n)\n\n# Returns data in memory\ncontext = run_pipeline(config)\ngraph = context.knowledge_graph\ninvoice = context.pydantic_model\n</code></pre>"},{"location":"usage/api/pipeline-config/#debug-mode-enabled","title":"\ud83d\udccd Debug Mode Enabled","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Enable debug mode for troubleshooting\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    debug=True,  # Save all intermediate artifacts\n    dump_to_disk=True,  # Also save final outputs\n    output_dir=\"outputs/debug_run\"\n)\n\ncontext = run_pipeline(config)\n\n# Debug artifacts available at:\n# outputs/debug_run/document_pdf_20260206_094500/debug/\nprint(f\"Debug artifacts saved to: {context.output_dir}/debug/\")\n</code></pre>"},{"location":"usage/api/pipeline-config/#output-settings_1","title":"Output Settings","text":"Parameter Type Default Description <code>output_dir</code> <code>str | Path</code> <code>\"outputs\"</code> Output directory path"},{"location":"usage/api/pipeline-config/#minimal-config-with-file-exports","title":"\ud83d\udccd Minimal Config With File Exports","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Enable file exports\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=\"templates.BillingDocument\",\n    dump_to_disk=True,\n    output_dir=\"outputs/invoice\"\n)\n\n# Returns data AND writes files\ncontext = run_pipeline(config)\n</code></pre>"},{"location":"usage/api/pipeline-config/#remote-llm","title":"\ud83d\udccd Remote LLM","text":"<pre><code>import os\nfrom docling_graph import run_pipeline, PipelineConfig\n\n# Set API key\nos.environ[\"MISTRAL_API_KEY\"] = \"your-key\"\n\n# Configure for remote inference\nconfig = PipelineConfig(\n    source=\"research.pdf\",\n    template=\"templates.ScholarlyRheologyPaper\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/api/pipeline-config/#delta-extraction-long-documents","title":"\ud83d\udccd Delta extraction (long documents)","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Delta: chunk \u2192 batches \u2192 flat graph IR \u2192 merge \u2192 projection\nconfig = PipelineConfig(\n    source=\"long_document.pdf\",\n    template=\"templates.ScholarlyRheologyPaper\",\n    backend=\"llm\",\n    processing_mode=\"many-to-one\",\n    extraction_contract=\"delta\",\n    use_chunking=True,\n    llm_batch_token_size=2048,\n    parallel_workers=2,\n    delta_resolvers_enabled=True,\n    delta_resolvers_mode=\"semantic\",\n    gleaning_enabled=True,  # Set False to disable optional second-pass recall boost\n    gleaning_max_passes=1,\n)\n\nrun_pipeline(config)\n</code></pre> <p>See Delta Extraction for all delta options, quality gates, and Gleaning (direct and delta).</p>"},{"location":"usage/api/pipeline-config/#local-vlm","title":"\ud83d\udccd Local VLM","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# VLM for form extraction\nconfig = PipelineConfig(\n    source=\"form.jpg\",\n    template=\"templates.IDCard\",\n    backend=\"vlm\",\n    inference=\"local\",  # VLM only supports local\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\"\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/api/pipeline-config/#template-as-class","title":"\ud83d\udccd Template as Class","text":"<pre><code>from pydantic import BaseModel, Field\nfrom docling_graph import run_pipeline, PipelineConfig\n\n# Define template inline\nclass Invoice(BaseModel):\n    \"\"\"Invoice template.\"\"\"\n    invoice_number: str = Field(description=\"Invoice number\")\n    total: float = Field(description=\"Total amount\")\n\n# Pass class directly\nconfig = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=Invoice  # Class instead of string\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/api/pipeline-config/#custom-models-configuration","title":"\ud83d\udccd Custom Models Configuration","text":"<pre><code>from docling_graph import LLMConfig, ModelConfig, ModelsConfig, PipelineConfig, run_pipeline\n\n# Custom models configuration\nmodels = ModelsConfig(\n    llm=LLMConfig(\n        remote=ModelConfig(\n            model=\"gpt-4o\",\n            provider=\"openai\"\n        )\n    )\n)\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\",\n    models=models\n)\n\nrun_pipeline(config)\n</code></pre> <p>For full registry and override details, see <code>docs/usage/api/llm-model-config.md</code>.</p>"},{"location":"usage/api/pipeline-config/#validation","title":"Validation","text":""},{"location":"usage/api/pipeline-config/#automatic-validation","title":"Automatic Validation","text":"<p>PipelineConfig validates parameters at creation:</p> <pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# This raises ValidationError\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.BillingDocument\",\n        backend=\"invalid\"  # Invalid value\n    )\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")\n</code></pre>"},{"location":"usage/api/pipeline-config/#vlm-constraints","title":"VLM Constraints","text":"<p>VLM backend only supports local inference:</p> <pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# This raises ValidationError\ntry:\n    config = PipelineConfig(\n        source=\"document.pdf\",\n        template=\"templates.BillingDocument\",\n        backend=\"vlm\",\n        inference=\"remote\"  # Not allowed for VLM\n    )\nexcept ValueError as e:\n    print(f\"VLM only supports local inference: {e}\")\n</code></pre>"},{"location":"usage/api/pipeline-config/#type-safety-benefits","title":"Type Safety Benefits","text":""},{"location":"usage/api/pipeline-config/#ide-autocomplete","title":"IDE Autocomplete","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",  # IDE suggests: \"llm\" | \"vlm\"\n    inference=\"remote\",  # IDE suggests: \"local\" | \"remote\"\n    processing_mode=\"many-to-one\"  # IDE suggests valid options\n)\n</code></pre>"},{"location":"usage/api/pipeline-config/#type-checking","title":"Type Checking","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# mypy will catch this error\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    use_chunking=\"yes\"  # Error: expected bool, got str\n)\n</code></pre>"},{"location":"usage/api/pipeline-config/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/api/pipeline-config/#programmatic-configuration","title":"Programmatic Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom pathlib import Path\n\ndef create_config(source: str, template: str, use_remote: bool = False):\n    \"\"\"Factory function for creating configurations.\"\"\"\n    return PipelineConfig(\n        source=source,\n        template=template,\n        backend=\"llm\",\n        inference=\"remote\" if use_remote else \"local\",\n        provider_override=\"mistral\" if use_remote else \"ollama\"\n    )\n\n# Use factory\nconfig = create_config(\"document.pdf\", \"templates.BillingDocument\", use_remote=True)\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/api/pipeline-config/#configuration-templates","title":"Configuration Templates","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\n# Base configuration\nBASE_CONFIG = {\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"provider_override\": \"mistral\",\n    \"use_chunking\": True,\n}\n\n# Create specific configurations\ndef process_invoice(source: str):\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.BillingDocument\",\n        **BASE_CONFIG\n    )\n    run_pipeline(config)\n\ndef process_research(source: str):\n    config = PipelineConfig(\n        source=source,\n        template=\"templates.ScholarlyRheologyPaper\",\n        **BASE_CONFIG,\n    )\n    run_pipeline(config)\n</code></pre>"},{"location":"usage/api/pipeline-config/#dynamic-configuration","title":"Dynamic Configuration","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom pathlib import Path\n\ndef smart_config(source: str) -&gt; PipelineConfig:\n    \"\"\"Create configuration based on document characteristics.\"\"\"\n    path = Path(source)\n    file_size = path.stat().st_size\n\n    # Choose settings based on file size\n    if file_size &lt; 1_000_000:  # &lt; 1MB\n        use_chunking = False\n        processing = \"one-to-one\"\n    else:\n        use_chunking = True\n        processing = \"many-to-one\"\n\n    # Choose backend based on extension\n    if path.suffix.lower() in ['.jpg', '.png']:\n        backend = \"vlm\"\n    else:\n        backend = \"llm\"\n\n    return PipelineConfig(\n        source=source,\n        template=\"templates.BillingDocument\",\n        backend=backend,\n        processing_mode=processing,\n        use_chunking=use_chunking\n    )\n\n# Use smart configuration\nconfig = smart_config(\"document.pdf\")\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/api/pipeline-config/#configuration-patterns","title":"Configuration Patterns","text":""},{"location":"usage/api/pipeline-config/#pattern-1-environment-based-configuration","title":"Pattern 1: Environment-Based Configuration","text":"<pre><code>import os\nfrom docling_graph import run_pipeline, PipelineConfig\n\ndef get_config(source: str, template: str) -&gt; PipelineConfig:\n    \"\"\"Get configuration based on environment.\"\"\"\n    env = os.getenv(\"ENVIRONMENT\", \"development\")\n\n    if env == \"production\":\n        return PipelineConfig(\n            source=source,\n            template=template,\n            backend=\"llm\",\n            inference=\"remote\",\n            provider_override=\"mistral\",\n            model_override=\"mistral-large-latest\",\n        )\n    else:\n        return PipelineConfig(\n            source=source,\n            template=template,\n            backend=\"llm\",\n            inference=\"local\",\n            provider_override=\"ollama\",\n        )\n\nconfig = get_config(\"document.pdf\", \"templates.BillingDocument\")\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/api/pipeline-config/#pattern-2-configuration-builder","title":"Pattern 2: Configuration Builder","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\n\nclass ConfigBuilder:\n    \"\"\"Builder pattern for PipelineConfig.\"\"\"\n\n    def __init__(self, source: str, template: str):\n        self.config_dict = {\n            \"source\": source,\n            \"template\": template\n        }\n\n    def with_remote_llm(self, provider: str, model: str):\n        self.config_dict.update({\n            \"backend\": \"llm\",\n            \"inference\": \"remote\",\n            \"provider_override\": provider,\n            \"model_override\": model\n        })\n        return self\n\n    def with_chunking(self, enabled: bool = True):\n        self.config_dict[\"use_chunking\"] = enabled\n        return self\n\n    def build(self) -&gt; PipelineConfig:\n        return PipelineConfig(**self.config_dict)\n\n# Use builder\nconfig = (ConfigBuilder(\"document.pdf\", \"templates.BillingDocument\")\n    .with_remote_llm(\"mistral\", \"mistral-large-latest\")\n    .with_chunking(True)\n    .build())\n\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/api/pipeline-config/#best-practices","title":"Best Practices","text":""},{"location":"usage/api/pipeline-config/#use-type-safe-configuration","title":"\ud83d\udc4d Use Type-Safe Configuration","text":"<pre><code># \u2705 Good - Type-safe with validation\nfrom docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\"  # Validated at creation\n)\n\n# \u274c Avoid - Dictionary without validation\nconfig = {\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"backend\": \"invalid\"  # No validation\n}\n</code></pre>"},{"location":"usage/api/pipeline-config/#use-defaults-when-possible","title":"\ud83d\udc4d Use Defaults When Possible","text":"<pre><code># \u2705 Good - Rely on sensible defaults\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\"\n    # Uses default backend, inference, etc.\n)\n\n# \u274c Avoid - Specifying every parameter\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"local\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    # ... all defaults\n)\n</code></pre>"},{"location":"usage/api/pipeline-config/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/api/pipeline-config/#validation-error","title":"\ud83d\udc1b Validation Error","text":"<p>Error: <pre><code>ValidationError: 1 validation error for PipelineConfig\nbackend\n  Input should be 'llm' or 'vlm'\n</code></pre></p> <p>Solution: <pre><code># Use valid values\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\"  # Valid: \"llm\" or \"vlm\"\n)\n</code></pre></p>"},{"location":"usage/api/pipeline-config/#vlm-remote-inference","title":"\ud83d\udc1b VLM Remote Inference","text":"<p>Error: <pre><code>ValueError: VLM backend currently only supports local inference\n</code></pre></p> <p>Solution: <pre><code># VLM only supports local\nconfig = PipelineConfig(\n    source=\"form.jpg\",\n    template=\"templates.IDCard\",\n    backend=\"vlm\",\n    inference=\"local\"  # Must be local for VLM\n)\n</code></pre></p>"},{"location":"usage/api/pipeline-config/#next-steps","title":"Next Steps","text":"<ol> <li>Programmatic Examples \u2192 - More code examples</li> <li>Batch Processing \u2192 - Batch patterns</li> <li>API Reference \u2192 - Complete API docs</li> </ol>"},{"location":"usage/api/programmatic-examples/","title":"Programmatic Examples","text":""},{"location":"usage/api/programmatic-examples/#overview","title":"Overview","text":"<p>This guide provides complete, ready-to-run Python examples for common document processing scenarios using the docling-graph API.</p> <p>All examples use <code>uv run python</code> for execution.</p>"},{"location":"usage/api/programmatic-examples/#quick-reference","title":"Quick Reference","text":"Example Use Case Backend Simple Invoice Basic extraction LLM (Remote) Local Processing Offline processing LLM (Local) VLM Form Extraction Image forms VLM (Local) Rheology Research Complex documents LLM (Remote) Batch Processing Multiple documents Any Error Handling Production code Any Flask Integration Web application Any Jupyter Notebook Interactive analysis Any"},{"location":"usage/api/programmatic-examples/#example-1-simple-invoice-extraction","title":"Example 1: Simple Invoice Extraction","text":"<p>Use Case: Extract structured data from an invoice using remote LLM.</p> <p>File: <code>examples/simple_billing_document.py</code></p> <pre><code>\"\"\"\nSimple invoice extraction using remote LLM.\n\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\n\n# Set API key\nos.environ[\"MISTRAL_API_KEY\"] = \"your-api-key\"\n\n# Configure pipeline\nconfig = PipelineConfig(\n    source=\"documents/invoice.pdf\",\n    template=\"templates.billing_document.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-small-latest\"\n)\n\n# Run pipeline\nprint(\"Processing invoice...\")\ncontext = run_pipeline(config)\ngraph = context.knowledge_graph\nprint(f\"\u2705 Complete! Extracted {graph.number_of_nodes()} nodes\")\n</code></pre> <p>Run: <pre><code>uv run python examples/simple_billing_document.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-2-local-processing-with-ollama","title":"Example 2: Local Processing with Ollama","text":"<p>Use Case: Process documents locally without API costs.</p> <p>File: <code>examples/local_ollama.py</code></p> <pre><code>\"\"\"\nLocal document processing using Ollama.\n\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\n\n# Ensure Ollama is running:\n# ollama serve\n# ollama pull llama3:8b\n\nconfig = PipelineConfig(\n    source=\"documents/research.pdf\",\n    template=\"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\",\n    backend=\"llm\",\n    inference=\"local\",\n    provider_override=\"ollama\",\n    model_override=\"llama3:8b\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n)\n\nprint(\"Processing with Ollama...\")\ntry:\n    run_pipeline(config)\n    print(\"\u2705 Complete!\")\nexcept Exception as e:\n    print(f\"\u274c Error: {e}\")\n    print(\"Hint: Is Ollama running? (ollama serve)\")\n</code></pre> <p>Run: <pre><code># Start Ollama first\nollama serve\n\n# In another terminal\nuv run python examples/local_ollama.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-3-vlm-form-extraction","title":"Example 3: VLM Form Extraction","text":"<p>Use Case: Extract data from image forms using vision model.</p> <p>File: <code>examples/vlm_form.py</code></p> <pre><code>\"\"\"\nVLM extraction from image forms.\n\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"documents/id_card.jpg\",\n    template=\"templates.id_card.IDCard\",\n    backend=\"vlm\",\n    inference=\"local\",  # VLM only supports local\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\"\n)\n\nprint(\"Extracting from image...\")\ncontext = run_pipeline(config)\nprint(\"\u2705 Complete!\")\n\n# Display results\ngraph = context.knowledge_graph\nprint(f\"\\nExtracted {graph.number_of_nodes()} nodes\")\nfor node_id, node_data in list(graph.nodes(data=True))[:5]:\n    print(f\"  - {node_id}: {node_data}\")\n</code></pre> <p>Run: <pre><code>uv run python examples/vlm_form.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-4-rheology-research-with-consolidation","title":"Example 4: Rheology Research with Consolidation","text":"<p>Use Case: High-accuracy extraction from complex documents.</p> <p>File: <code>examples/research_consolidation.py</code></p> <pre><code>\"\"\"\nRheology research extraction with LLM consolidation.\n\"\"\"\n\nimport os\nfrom docling_graph import run_pipeline, PipelineConfig\n\nos.environ[\"MISTRAL_API_KEY\"] = \"your-api-key\"\n\nconfig = PipelineConfig(\n    source=\"documents/research_paper.pdf\",\n    template=\"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    docling_config=\"vision\"  # Better for complex layouts\n)\n\nprint(\"Processing rheology research (this may take a few minutes)...\")\ncontext = run_pipeline(config)\nprint(\"\u2705 Complete!\")\n\n# Analyze results\ngraph = context.knowledge_graph\nprint(f\"\\nGraph Statistics:\")\nprint(f\"  Nodes: {graph.number_of_nodes()}\")\nprint(f\"  Edges: {graph.number_of_edges()}\")\n</code></pre> <p>Run: <pre><code>uv run python examples/research_consolidation.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-5-batch-processing","title":"Example 5: Batch Processing","text":"<p>Use Case: Process multiple documents with progress tracking.</p> <p>File: <code>examples/batch_process.py</code></p> <pre><code>\"\"\"\nBatch process multiple documents.\n\"\"\"\n\nfrom pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom tqdm import tqdm\n\ndef process_batch(input_dir: str, template: str):\n    \"\"\"Process all PDFs in a directory.\"\"\"\n    documents = list(Path(input_dir).glob(\"*.pdf\"))\n    results = {\"success\": [], \"failed\": []}\n\n    print(f\"Processing {len(documents)} documents...\")\n\n    for doc in tqdm(documents, desc=\"Processing\"):\n        try:\n            config = PipelineConfig(\n                source=str(doc),\n                template=template\n            )\n            run_pipeline(config)\n            results[\"success\"].append(doc.name)\n\n        except Exception as e:\n            results[\"failed\"].append((doc.name, str(e)))\n            tqdm.write(f\"\u274c {doc.name}: {e}\")\n\n    # Summary\n    print(f\"\\n{'='*50}\")\n    print(f\"Completed: {len(results['success'])} succeeded\")\n    print(f\"Failed: {len(results['failed'])}\")\n\n    if results[\"failed\"]:\n        print(\"\\nFailed documents:\")\n        for name, error in results[\"failed\"]:\n            print(f\"  - {name}: {error}\")\n\n    return results\n\nif __name__ == \"__main__\":\n    results = process_batch(\n        input_dir=\"documents/invoices\",\n        template=\"templates.billing_document.BillingDocument\"\n    )\n</code></pre> <p>Run: <pre><code>uv run python examples/batch_process.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-6-robust-error-handling","title":"Example 6: Robust Error Handling","text":"<p>Use Case: Production-ready code with comprehensive error handling.</p> <p>File: <code>examples/robust_processing.py</code></p> <pre><code>\"\"\"\nProduction-ready document processing with error handling.\n\"\"\"\n\nimport logging\nfrom pathlib import Path\nfrom typing import Optional\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import (\n    ConfigurationError,\n    ExtractionError,\n    PipelineError,\n    DoclingGraphError\n)\n\n# Setup logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\ndef process_document(\n    source: str,\n    template: str,\n    max_retries: int = 3\n) -&gt; bool:\n    \"\"\"\n    Process document with retry logic and error handling.\n\n    Args:\n        source: Path to source document\n        template: Pydantic template path\n        max_retries: Maximum retry attempts\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    for attempt in range(1, max_retries + 1):\n        try:\n            logger.info(f\"Processing {source} (attempt {attempt}/{max_retries})\")\n\n            config = PipelineConfig(\n                source=source,\n                template=template\n            )\n\n            run_pipeline(config)\n            logger.info(f\"\u2705 Successfully processed: {source}\")\n            return True\n\n        except ConfigurationError as e:\n            logger.error(f\"Configuration error: {e.message}\")\n            if e.details:\n                logger.error(f\"Details: {e.details}\")\n            return False  # Don't retry configuration errors\n\n        except ExtractionError as e:\n            logger.error(f\"Extraction failed: {e.message}\")\n            if attempt &lt; max_retries:\n                logger.info(f\"Retrying... ({attempt}/{max_retries})\")\n                continue\n            return False\n\n        except PipelineError as e:\n            logger.error(f\"Pipeline error: {e.message}\")\n            if attempt &lt; max_retries:\n                logger.info(f\"Retrying... ({attempt}/{max_retries})\")\n                continue\n            return False\n\n        except DoclingGraphError as e:\n            logger.error(f\"Docling-graph error: {e.message}\")\n            return False\n\n        except Exception as e:\n            logger.exception(f\"Unexpected error: {e}\")\n            return False\n\n    return False\n\nif __name__ == \"__main__\":\n    # Process single document\n    success = process_document(\n        source=\"documents/invoice.pdf\",\n        template=\"templates.billing_document.BillingDocument\"\n    )\n\n    if success:\n        print(\"Processing completed successfully\")\n    else:\n        print(\"Processing failed\")\n        exit(1)\n</code></pre> <p>Run: <pre><code>uv run python examples/robust_processing.py\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-7-flask-api-integration","title":"Example 7: Flask API Integration","text":"<p>Use Case: Web API for document processing.</p> <p>File: <code>examples/flask_api.py</code></p> <pre><code>\"\"\"\nFlask API for document processing.\n\"\"\"\n\nfrom flask import Flask, request, jsonify, send_file\nfrom werkzeug.utils import secure_filename\nfrom pathlib import Path\nimport uuid\nimport os\n\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import DoclingGraphError\n\napp = Flask(__name__)\napp.config['UPLOAD_FOLDER'] = 'temp'\napp.config['OUTPUT_FOLDER'] = 'outputs'\napp.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max\n\n# Ensure directories exist\nPath(app.config['UPLOAD_FOLDER']).mkdir(exist_ok=True)\nPath(app.config['OUTPUT_FOLDER']).mkdir(exist_ok=True)\n\n@app.route('/health', methods=['GET'])\ndef health():\n    \"\"\"Health check endpoint.\"\"\"\n    return jsonify({\"status\": \"healthy\"})\n\n@app.route('/process', methods=['POST'])\ndef process_document():\n    \"\"\"Process uploaded document.\"\"\"\n    # Validate request\n    if 'document' not in request.files:\n        return jsonify({\"error\": \"No document provided\"}), 400\n\n    file = request.files['document']\n    if file.filename == '':\n        return jsonify({\"error\": \"Empty filename\"}), 400\n\n    template = request.form.get('template', 'templates.billing_document.BillingDocument')\n\n    # Save file\n    job_id = str(uuid.uuid4())\n    filename = secure_filename(file.filename)\n    temp_path = Path(app.config['UPLOAD_FOLDER']) / f\"{job_id}_{filename}\"\n    file.save(temp_path)\n\n    try:\n        # Process document\n        config = PipelineConfig(\n            source=str(temp_path),\n            template=template\n        )\n\n        context = run_pipeline(config)\n\n        return jsonify({\n            \"status\": \"success\",\n            \"job_id\": job_id,\n            \"model\": context.pydantic_model.model_dump()\n        })\n\n    except DoclingGraphError as e:\n        return jsonify({\n            \"status\": \"error\",\n            \"message\": e.message,\n            \"details\": e.details\n        }), 500\n\n    except Exception as e:\n        return jsonify({\n            \"status\": \"error\",\n            \"message\": str(e)\n        }), 500\n\n    finally:\n        # Cleanup temp file\n        temp_path.unlink(missing_ok=True)\n\nif __name__ == '__main__':\n    app.run(debug=True, port=5000)\n</code></pre> <p>Run: <pre><code>uv run python examples/flask_api.py\n</code></pre></p> <p>Test: <pre><code># Upload and process document\ncurl -X POST http://localhost:5000/process \\\n    -F \"document=@invoice.pdf\" \\\n    -F \"template=templates.billing_document.BillingDocument\"\n\n# Download results\ncurl -O http://localhost:5000/download/{job_id}/nodes.csv\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#example-8-jupyter-notebook-analysis","title":"Example 8: Jupyter Notebook Analysis","text":"<p>Use Case: Interactive document analysis in Jupyter.</p> <p>File: <code>examples/notebook_analysis.ipynb</code></p> <pre><code># Cell 1: Setup\nfrom docling_graph import run_pipeline, PipelineConfig\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\n# Cell 2: Process Document\nconfig = PipelineConfig(\n    source=\"documents/research.pdf\",\n    template=\"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\"\n)\n\nprint(\"Processing document...\")\ncontext = run_pipeline(config)\nprint(\"\u2705 Complete!\")\n\n# Cell 3: Load Results\ngraph = context.knowledge_graph\nnodes = pd.DataFrame([{\"id\": node_id, **attrs} for node_id, attrs in graph.nodes(data=True)])\nedges = pd.DataFrame(\n    [{\"source\": u, \"target\": v, **attrs} for u, v, attrs in graph.edges(data=True)]\n)\n\nprint(f\"Nodes: {len(nodes)}\")\nprint(f\"Edges: {len(edges)}\")\n\n# Cell 4: Analyze Node Types\nnode_counts = nodes['type'].value_counts()\nprint(\"\\nNode Type Distribution:\")\nprint(node_counts)\n\n# Visualize\nplt.figure(figsize=(10, 6))\nnode_counts.plot(kind='bar')\nplt.title('Node Types Distribution')\nplt.xlabel('Node Type')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# Cell 5: Analyze Relationships\nedge_counts = edges['type'].value_counts()\nprint(\"\\nRelationship Distribution:\")\nprint(edge_counts)\n\n# Visualize\nplt.figure(figsize=(10, 6))\nedge_counts.plot(kind='bar', color='coral')\nplt.title('Relationship Types Distribution')\nplt.xlabel('Relationship Type')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# Cell 6: Network Analysis\nimport networkx as nx\n\n# Create graph\nG = nx.DiGraph()\nfor _, edge in edges.iterrows():\n    G.add_edge(edge['source'], edge['target'], type=edge['type'])\n\nprint(f\"\\nNetwork Statistics:\")\nprint(f\"  Nodes: {G.number_of_nodes()}\")\nprint(f\"  Edges: {G.number_of_edges()}\")\nprint(f\"  Density: {nx.density(G):.3f}\")\nprint(f\"  Is connected: {nx.is_weakly_connected(G)}\")\n\n# Cell 7: Visualize Network\nplt.figure(figsize=(12, 8))\npos = nx.spring_layout(G, k=0.5, iterations=50)\nnx.draw(G, pos, \n        node_color='lightblue',\n        node_size=500,\n        with_labels=True,\n        font_size=8,\n        arrows=True,\n        edge_color='gray',\n        alpha=0.7)\nplt.title('Knowledge Graph Visualization')\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Run: <pre><code>jupyter notebook examples/notebook_analysis.ipynb\n</code></pre></p>"},{"location":"usage/api/programmatic-examples/#best-practices","title":"Best Practices","text":""},{"location":"usage/api/programmatic-examples/#use-environment-variables-for-secrets","title":"\ud83d\udc4d Use Environment Variables for Secrets","text":"<pre><code># \u2705 Good - Environment variables\nimport os\nos.environ[\"MISTRAL_API_KEY\"] = os.getenv(\"MISTRAL_API_KEY\")\n\n# \u274c Avoid - Hardcoded secrets\nos.environ[\"MISTRAL_API_KEY\"] = \"sk-1234...\"  # Don't commit!\n</code></pre>"},{"location":"usage/api/programmatic-examples/#handle-errors-gracefully","title":"\ud83d\udc4d Handle Errors Gracefully","text":"<pre><code># \u2705 Good - Specific error handling\nfrom docling_graph.exceptions import ExtractionError\n\ntry:\n    run_pipeline(config)\nexcept ExtractionError as e:\n    logger.error(f\"Extraction failed: {e.message}\")\n    # Implement fallback\n\n# \u274c Avoid - Silent failures\ntry:\n    run_pipeline(config)\nexcept:\n    pass\n</code></pre>"},{"location":"usage/api/programmatic-examples/#next-steps","title":"Next Steps","text":"<ol> <li>Batch Processing \u2192 - Advanced batch patterns</li> <li>Examples \u2192 - Real-world examples</li> <li>Advanced Topics \u2192 - Custom backends</li> </ol>"},{"location":"usage/api/run-pipeline/","title":"run_pipeline()","text":""},{"location":"usage/api/run-pipeline/#overview","title":"Overview","text":"<p>The <code>run_pipeline()</code> function is the main entry point for executing the document-to-graph pipeline programmatically.</p> <p>Function Signature: <pre><code>def run_pipeline(config: Union[PipelineConfig, Dict[str, Any]]) -&gt; PipelineContext\n</code></pre></p> <p>Returns: <code>PipelineContext</code> object containing the knowledge graph, Pydantic model, and other pipeline results.</p>"},{"location":"usage/api/run-pipeline/#basic-usage","title":"Basic Usage","text":""},{"location":"usage/api/run-pipeline/#default-behavior-no-file-exports","title":"Default Behavior (No File Exports)","text":"<pre><code>from docling_graph import run_pipeline\n\n# Returns data directly - no file exports by default\ncontext = run_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\"\n})\n\n# Access results\ngraph = context.knowledge_graph\nmodels = context.extracted_models or []\nprint(f\"Extracted {graph.number_of_nodes()} nodes, {len(models)} model(s)\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#with-file-exports","title":"With File Exports","text":"<pre><code>from docling_graph import run_pipeline\n\n# Enable file exports with dump_to_disk\ncontext = run_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"dump_to_disk\": True,\n    \"output_dir\": \"outputs\"\n})\n\n# Results available both in memory and on disk\ngraph = context.knowledge_graph\n# Files also written to outputs/\n</code></pre>"},{"location":"usage/api/run-pipeline/#with-pipelineconfig","title":"With PipelineConfig","text":"<pre><code>from docling_graph import PipelineConfig, run_pipeline\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\",\n    inference=\"remote\"\n)\n\n# Returns PipelineContext\ncontext = run_pipeline(config)\n</code></pre>"},{"location":"usage/api/run-pipeline/#parameters","title":"Parameters","text":""},{"location":"usage/api/run-pipeline/#config","title":"config","text":"<p>Type: <code>PipelineConfig | Dict[str, Any]</code></p> <p>Required: Yes</p> <p>Description: Pipeline configuration as either: - <code>PipelineConfig</code> object (recommended) - Dictionary with configuration keys</p>"},{"location":"usage/api/run-pipeline/#configuration-keys","title":"Configuration Keys","text":""},{"location":"usage/api/run-pipeline/#required-keys","title":"Required Keys","text":"Key Type Description <code>source</code> <code>str</code> Path to source document <code>template</code> <code>str | Type[BaseModel]</code> Pydantic template (dotted path or class)"},{"location":"usage/api/run-pipeline/#optional-keys","title":"Optional Keys","text":"Key Type Default Description <code>backend</code> <code>str</code> <code>\"llm\"</code> Backend type: <code>\"llm\"</code> or <code>\"vlm\"</code> <code>inference</code> <code>str</code> <code>\"local\"</code> Inference mode: <code>\"local\"</code> or <code>\"remote\"</code> <code>processing_mode</code> <code>str</code> <code>\"many-to-one\"</code> Processing strategy <code>extraction_contract</code> <code>str</code> <code>\"direct\"</code> Extraction contract: <code>\"direct\"</code>, <code>\"staged\"</code>, or <code>\"delta\"</code> (see Delta Extraction) <code>docling_config</code> <code>str</code> <code>\"ocr\"</code> Docling pipeline: <code>\"ocr\"</code> or <code>\"vision\"</code> <code>use_chunking</code> <code>bool</code> <code>True</code> Enable document chunking <code>gleaning_enabled</code> <code>bool</code> <code>True</code> Run optional second-pass extraction to improve recall (direct and delta only). <code>gleaning_max_passes</code> <code>int</code> <code>1</code> Max gleaning passes when gleaning is enabled. <code>dump_to_disk</code> <code>bool</code> or <code>None</code> <code>None</code> Control file exports (None=auto: CLI=True, API=False) <code>export_format</code> <code>str</code> <code>\"csv\"</code> Export format: <code>\"csv\"</code> or <code>\"cypher\"</code> <code>model_override</code> <code>str</code> <code>None</code> Override model name <code>provider_override</code> <code>str</code> <code>None</code> Override provider name <p>See PipelineConfig for complete list.</p>"},{"location":"usage/api/run-pipeline/#return-value","title":"Return Value","text":"<p>Type: <code>PipelineContext</code></p> <p>Returns a <code>PipelineContext</code> object containing:</p> Attribute Type Description <code>knowledge_graph</code> <code>nx.DiGraph</code> NetworkX directed graph with extracted entities and relationships <code>extracted_models</code> <code>list[BaseModel]</code> List of validated Pydantic model instances (one or more) <code>graph_metadata</code> <code>GraphMetadata</code> Graph statistics (node/edge counts, etc.) <code>docling_document</code> <code>DoclingDocument</code> or <code>None</code> Original Docling document (if available) <code>config</code> <code>PipelineConfig</code> Pipeline configuration used <p>Example: <pre><code>context = run_pipeline(config)\n\n# Access the knowledge graph\ngraph = context.knowledge_graph\nprint(f\"Nodes: {graph.number_of_nodes()}\")\nprint(f\"Edges: {graph.number_of_edges()}\")\n\n# Access extracted Pydantic models\nfor model in context.extracted_models or []:\n    print(f\"Model type: {type(model).__name__}\")\n</code></pre></p>"},{"location":"usage/api/run-pipeline/#exceptions","title":"Exceptions","text":""},{"location":"usage/api/run-pipeline/#configurationerror","title":"ConfigurationError","text":"<p>Raised when configuration is invalid.</p> <pre><code>from docling_graph import run_pipeline\nfrom docling_graph.exceptions import ConfigurationError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.BillingDocument\",\n        \"backend\": \"invalid\"  # Invalid backend\n    })\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e.message}\")\n    print(f\"Details: {e.details}\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#extractionerror","title":"ExtractionError","text":"<p>Raised when document extraction fails.</p> <pre><code>from docling_graph.exceptions import ExtractionError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.Missing\"  # Template not found\n    })\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#pipelineerror","title":"PipelineError","text":"<p>Raised when pipeline execution fails.</p> <pre><code>from docling_graph.exceptions import PipelineError\n\ntry:\n    run_pipeline({\n        \"source\": \"document.pdf\",\n        \"template\": \"templates.BillingDocument\"\n    })\nexcept PipelineError as e:\n    print(f\"Pipeline error: {e.message}\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#complete-examples","title":"Complete Examples","text":""},{"location":"usage/api/run-pipeline/#minimal-configuration-api-mode","title":"\ud83d\udccd Minimal Configuration (API Mode)","text":"<pre><code>from docling_graph import run_pipeline\n\n# Minimal required configuration - returns data, no file exports\ncontext = run_pipeline({\n    \"source\": \"invoice.pdf\",\n    \"template\": \"templates.BillingDocument\"\n})\n\n# Access results in memory\ngraph = context.knowledge_graph\ninvoice = (context.extracted_models or [None])[0]\nprint(f\"Extracted invoice with {graph.number_of_nodes()} entities\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#remote-llm","title":"\ud83d\udccd Remote LLM","text":"<pre><code>import os\nfrom docling_graph import run_pipeline\n\n# Set API key\nos.environ[\"MISTRAL_API_KEY\"] = \"your-key\"\n\n# Configure for remote inference\ncontext = run_pipeline({\n    \"source\": \"research.pdf\",\n    \"template\": \"templates.ScholarlyRheologyPaper\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"provider_override\": \"mistral\",\n    \"model_override\": \"mistral-large-latest\",\n    \"processing_mode\": \"many-to-one\",\n    \"use_chunking\": True\n})\n\n# Access the knowledge graph\ngraph = context.knowledge_graph\nprint(f\"Rheology research: {graph.number_of_nodes()} nodes, {graph.number_of_edges()} edges\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#local-vlm","title":"\ud83d\udccd Local VLM","text":"<pre><code>from docling_graph import run_pipeline\n\n# VLM for form extraction\ncontext = run_pipeline({\n    \"source\": \"form.jpg\",\n    \"template\": \"templates.IDCard\",\n    \"backend\": \"vlm\",\n    \"inference\": \"local\",\n    \"processing_mode\": \"one-to-one\",\n    \"docling_config\": \"vision\"\n})\n\n# Access extracted data (one-to-one returns one model per page; take first)\nid_card = (context.extracted_models or [None])[0]\nif id_card:\n    print(f\"Name: {id_card.first_name} {id_card.last_name}\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#with-error-handling","title":"\ud83d\udccd With Error Handling","text":"<pre><code>from docling_graph import run_pipeline, PipelineContext\nfrom docling_graph.exceptions import (\n    ConfigurationError,\n    ExtractionError,\n    PipelineError\n)\nimport logging\nfrom pathlib import Path\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef process_document(source: str, template: str) -&gt; PipelineContext | None:\n    \"\"\"Process document with comprehensive error handling.\"\"\"\n    try:\n        context = run_pipeline({\n            \"source\": source,\n            \"template\": template,\n            \"backend\": \"llm\",\n            \"inference\": \"remote\"\n        })\n        logger.info(f\"\u2705 Successfully processed: {source}\")\n        logger.info(f\"  Nodes: {context.knowledge_graph.number_of_nodes()}\")\n        return context\n\n    except ConfigurationError as e:\n        logger.error(f\"Configuration error for {source}: {e.message}\")\n        if e.details:\n            logger.error(f\"Details: {e.details}\")\n        return None\n\n    except ExtractionError as e:\n        logger.error(f\"Extraction failed for {source}: {e.message}\")\n        return None\n\n    except PipelineError as e:\n        logger.error(f\"Pipeline error for {source}: {e.message}\")\n        return None\n\n    except Exception as e:\n        logger.exception(f\"Unexpected error for {source}: {e}\")\n        return None\n\n# Use the function\ncontext = process_document(\"invoice.pdf\", \"templates.BillingDocument\")\nif context:\n    print(f\"Graph has {context.knowledge_graph.number_of_nodes()} nodes\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#batch-processing-memory-efficient","title":"\ud83d\udccd Batch Processing (Memory-Efficient)","text":"<pre><code>from pathlib import Path\nfrom docling_graph import run_pipeline\n\ndef batch_process(input_dir: str, template: str):\n    \"\"\"Process all PDFs in a directory without disk writes.\"\"\"\n    documents = Path(input_dir).glob(\"*.pdf\")\n    results = {\"success\": [], \"failed\": []}\n    all_graphs = []\n\n    for doc in documents:\n        try:\n            # Process without file exports\n            context = run_pipeline({\n                \"source\": str(doc),\n                \"template\": template\n            })\n\n            # Store graph in memory\n            all_graphs.append({\n                \"filename\": doc.name,\n                \"graph\": context.knowledge_graph,\n                \"models\": context.extracted_models\n            })\n\n            results[\"success\"].append(doc.name)\n            print(f\"\u2705 {doc.name}: {context.knowledge_graph.number_of_nodes()} nodes\")\n\n        except Exception as e:\n            results[\"failed\"].append((doc.name, str(e)))\n            print(f\"\u274c {doc.name}: {e}\")\n\n    # Summary\n    print(f\"\\nProcessed: {len(results['success'])} succeeded, {len(results['failed'])} failed\")\n    return results, all_graphs\n\n# Run batch processing\nresults, graphs = batch_process(\"documents/\", \"templates.BillingDocument\")\n\n# Optionally export combined results\nif graphs:\n    print(f\"\\nTotal entities across all documents: {sum(g['graph'].number_of_nodes() for g in graphs)}\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/api/run-pipeline/#dump_to_disk-behavior","title":"dump_to_disk Behavior","text":"<p>The <code>dump_to_disk</code> parameter controls file exports:</p> <pre><code>from docling_graph import run_pipeline\n\n# Default: No file exports (API mode)\ncontext = run_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\"\n})\n# Returns data in memory only\n\n# Explicit: Disable file exports\ncontext = run_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"dump_to_disk\": False\n})\n# Returns data only\n</code></pre> <p>CLI vs API defaults</p> <p>CLI mode defaults to dump_to_disk=True, API mode defaults to dump_to_disk=False.</p>"},{"location":"usage/api/run-pipeline/#custom-models-configuration","title":"Custom Models Configuration","text":"<pre><code>from docling_graph import run_pipeline\n\n# Override models from config\ncontext = run_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"backend\": \"llm\",\n    \"inference\": \"remote\",\n    \"models\": {\n        \"llm\": {\n            \"remote\": {\n                \"model\": \"gpt-4o\",\n                \"provider\": \"openai\"\n            }\n        }\n    }\n})\n\n# Access results\ngraph = context.knowledge_graph\n</code></pre>"},{"location":"usage/api/run-pipeline/#conditional-processing","title":"Conditional Processing","text":"<pre><code>from pathlib import Path\nfrom docling_graph import run_pipeline\n\ndef smart_process(source: str):\n    \"\"\"Choose configuration based on document type.\"\"\"\n    path = Path(source)\n\n    # Determine template and config\n    if \"invoice\" in path.name.lower():\n        template = \"templates.BillingDocument\"\n        backend = \"vlm\"\n        processing = \"one-to-one\"\n    elif \"research\" in path.name.lower():\n        template = \"templates.ScholarlyRheologyPaper\"\n        backend = \"llm\"\n        processing = \"many-to-one\"\n    else:\n        raise ValueError(f\"Unknown document type: {path.name}\")\n\n    # Process and return results\n    context = run_pipeline({\n        \"source\": source,\n        \"template\": template,\n        \"backend\": backend,\n        \"processing_mode\": processing\n    })\n\n    return context\n\n# Use smart processing\ninvoice_context = smart_process(\"invoice_001.pdf\")\nresearch_context = smart_process(\"research_paper.pdf\")\n\nprint(f\"Invoice nodes: {invoice_context.knowledge_graph.number_of_nodes()}\")\nprint(f\"Research nodes: {research_context.knowledge_graph.number_of_nodes()}\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#integration-patterns","title":"Integration Patterns","text":""},{"location":"usage/api/run-pipeline/#flask-api-memory-efficient","title":"Flask API (Memory-Efficient)","text":"<pre><code>from flask import Flask, request, jsonify\nfrom docling_graph import run_pipeline\nfrom pathlib import Path\nimport uuid\n\napp = Flask(__name__)\n\n@app.route('/process', methods=['POST'])\ndef process_endpoint():\n    \"\"\"API endpoint for document processing - returns data without disk writes.\"\"\"\n    file = request.files.get('document')\n    template = request.form.get('template', 'templates.BillingDocument')\n\n    if not file:\n        return jsonify({\"error\": \"No file provided\"}), 400\n\n    # Save temporarily\n    temp_id = str(uuid.uuid4())\n    temp_path = f\"temp/{temp_id}_{file.filename}\"\n    Path(\"temp\").mkdir(exist_ok=True)\n    file.save(temp_path)\n\n    try:\n        # Process without file exports (memory-efficient)\n        context = run_pipeline({\n            \"source\": temp_path,\n            \"template\": template\n        })\n\n        # Extract data from context\n        graph = context.knowledge_graph\n        models = context.extracted_models or []\n\n        return jsonify({\n            \"status\": \"success\",\n            \"id\": temp_id,\n            \"nodes\": graph.number_of_nodes(),\n            \"edges\": graph.number_of_edges(),\n            \"data\": models[0].model_dump() if models else None\n        })\n\n    except Exception as e:\n        return jsonify({\n            \"status\": \"error\",\n            \"message\": str(e)\n        }), 500\n\n    finally:\n        # Cleanup\n        Path(temp_path).unlink(missing_ok=True)\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"usage/api/run-pipeline/#celery-task-with-return-data","title":"Celery Task (With Return Data)","text":"<pre><code>from celery import Celery\nfrom docling_graph import run_pipeline\nfrom pathlib import Path\n\napp = Celery('tasks', broker='redis://localhost:6379')\n\n@app.task\ndef process_document_task(source: str, template: str):\n    \"\"\"Async document processing task - returns graph statistics.\"\"\"\n    try:\n        context = run_pipeline({\n            \"source\": source,\n            \"template\": template\n        })\n\n        graph = context.knowledge_graph\n        return {\n            \"status\": \"success\",\n            \"nodes\": graph.number_of_nodes(),\n            \"edges\": graph.number_of_edges(),\n            \"node_types\": list(set(data.get('type') for _, data in graph.nodes(data=True)))\n        }\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": str(e)}\n\n# Usage\nresult = process_document_task.delay(\n    \"document.pdf\",\n    \"templates.BillingDocument\"\n)\n# Get result\ndata = result.get(timeout=300)\nprint(f\"Processed: {data['nodes']} nodes, {data['edges']} edges\")\n</code></pre>"},{"location":"usage/api/run-pipeline/#airflow-operator-with-xcom","title":"Airflow Operator (With XCom)","text":"<pre><code>from airflow.operators.python import PythonOperator\nfrom docling_graph import run_pipeline\n\ndef process_document(**context):\n    \"\"\"Airflow task for document processing - pushes results to XCom.\"\"\"\n    params = context['params']\n\n    # Process and get results\n    pipeline_context = run_pipeline({\n        \"source\": params['source'],\n        \"template\": params['template']\n    })\n\n    # Push graph statistics to XCom\n    graph = pipeline_context.knowledge_graph\n    context['task_instance'].xcom_push(\n        key='graph_stats',\n        value={\n            'nodes': graph.number_of_nodes(),\n            'edges': graph.number_of_edges()\n        }\n    )\n\n    return \"Processing complete\"\n\n# In DAG definition\nprocess_task = PythonOperator(\n    task_id='process_document',\n    python_callable=process_document,\n    params={\n        'source': 'documents/daily.pdf',\n        'template': 'templates.BillingDocument'\n    }\n)\n</code></pre>"},{"location":"usage/api/run-pipeline/#best-practices","title":"Best Practices","text":""},{"location":"usage/api/run-pipeline/#use-pipelineconfig-for-type-safety","title":"\ud83d\udc4d Use PipelineConfig for Type Safety","text":"<pre><code># \u2705 Good - Type-safe with validation\nfrom docling_graph import PipelineConfig, run_pipeline\n\nconfig = PipelineConfig(\n    source=\"document.pdf\",\n    template=\"templates.BillingDocument\",\n    backend=\"llm\"  # Validated at creation\n)\nrun_pipeline(config)\n\n# \u274c Avoid - No validation until runtime\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"backend\": \"invalid\"  # Error at runtime\n})\n</code></pre>"},{"location":"usage/api/run-pipeline/#handle-errors-explicitly","title":"\ud83d\udc4d Handle Errors Explicitly","text":"<pre><code># \u2705 Good - Specific error handling\nfrom docling_graph.exceptions import ExtractionError\n\ntry:\n    run_pipeline(config)\nexcept ExtractionError as e:\n    logger.error(f\"Extraction failed: {e.message}\")\n    # Implement retry or fallback\n\n# \u274c Avoid - Silent failures\ntry:\n    run_pipeline(config)\nexcept:\n    pass\n</code></pre>"},{"location":"usage/api/run-pipeline/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/api/run-pipeline/#template-not-found","title":"\ud83d\udc1b Template Not Found","text":"<p>Error: <pre><code>ModuleNotFoundError: No module named 'templates'\n</code></pre></p> <p>Solution: <pre><code>import sys\nfrom pathlib import Path\n\n# Add project root to path\nsys.path.append(str(Path.cwd()))\n\n# Now import works\nfrom docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\"\n})\n</code></pre></p>"},{"location":"usage/api/run-pipeline/#api-key-not-found","title":"\ud83d\udc1b API Key Not Found","text":"<p>Error: <pre><code>ConfigurationError: API key not found for provider: mistral\n</code></pre></p> <p>Solution: <pre><code>import os\n\n# Set API key before running\nos.environ[\"MISTRAL_API_KEY\"] = \"your-key\"\n\nfrom docling_graph import run_pipeline\n\nrun_pipeline({\n    \"source\": \"document.pdf\",\n    \"template\": \"templates.BillingDocument\",\n    \"inference\": \"remote\"\n})\n</code></pre></p>"},{"location":"usage/api/run-pipeline/#next-steps","title":"Next Steps","text":"<ol> <li>PipelineConfig \u2192 - Configuration class</li> <li>Programmatic Examples \u2192 - More examples</li> <li>Batch Processing \u2192 - Batch patterns</li> </ol>"},{"location":"usage/cli/","title":"CLI Reference","text":""},{"location":"usage/cli/#overview","title":"Overview","text":"<p>The docling-graph CLI provides command-line tools for document-to-graph conversion, configuration management, and graph visualization.</p> <p>Available Commands: - <code>init</code> - Create configuration files - <code>convert</code> - Convert documents to graphs - <code>inspect</code> - Visualize graphs in browser</p>"},{"location":"usage/cli/#quick-start","title":"Quick Start","text":""},{"location":"usage/cli/#installation","title":"Installation","text":"<pre><code>pip install docling-graph\n\n# Verify installation\ndocling-graph --version\n</code></pre> <p>(If you installed from source with uv, use <code>uv run docling-graph</code> instead of <code>docling-graph</code>.)</p>"},{"location":"usage/cli/#basic-usage","title":"Basic Usage","text":"<pre><code># 1. Initialize configuration\ndocling-graph init\n\n# 2. Convert a document\ndocling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\"\n\n# 3. Visualize the graph\ndocling-graph inspect outputs/\n</code></pre>"},{"location":"usage/cli/#global-options","title":"Global Options","text":"<p>Available with all commands:</p> Option Short Description <code>--verbose</code> <code>-v</code> Enable detailed logging <code>--version</code> Show version and exit <code>--help</code> <code>-h</code> Show help message"},{"location":"usage/cli/#examples","title":"Examples","text":"<pre><code># Show version\ndocling-graph --version\n\n# Enable verbose logging\ndocling-graph --verbose convert document.pdf -t \"templates.BillingDocument\"\n\n# Show help\ndocling-graph --help\ndocling-graph convert --help\n</code></pre>"},{"location":"usage/cli/#command-overview","title":"Command Overview","text":""},{"location":"usage/cli/#init","title":"init","text":"<p>Create a configuration file with interactive prompts.</p> <pre><code>docling-graph init\n</code></pre> <p>Features: - Interactive configuration builder (processing mode, extraction contract, backend, inference, provider/model, export, output) - When you select delta as extraction contract, prompts for delta resolvers and quality gate tuning - Dependency validation - Provider/model identifiers use LiteLLM routing - API key guidance</p> <p>Learn more: init Command \u2192</p>"},{"location":"usage/cli/#convert","title":"convert","text":"<p>Convert documents to knowledge graphs.</p> <pre><code>docling-graph convert SOURCE --template TEMPLATE [OPTIONS]\n</code></pre> <p>Features: - Multiple backend support (LLM/VLM) - Flexible processing modes - Configurable chunking - Multiple export formats</p> <p>Learn more: convert Command \u2192</p>"},{"location":"usage/cli/#inspect","title":"inspect","text":"<p>Visualize graphs in your browser.</p> <pre><code>docling-graph inspect PATH [OPTIONS]\n</code></pre> <p>Features: - Interactive HTML visualization - CSV and JSON import - Node/edge exploration - Self-contained output</p> <p>Learn more: inspect Command \u2192</p>"},{"location":"usage/cli/#common-workflows","title":"Common Workflows","text":""},{"location":"usage/cli/#workflow-1-first-time-setup","title":"Workflow 1: First-Time Setup","text":"<pre><code># 1. Initialize configuration\ndocling-graph init\n\n# 2. Install dependencies (if prompted)\nuv sync\n\n# 3. Set API key (if using remote)\nexport MISTRAL_API_KEY=\"your-key\"\n\n# 4. Convert first document\ndocling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\"\n</code></pre>"},{"location":"usage/cli/#workflow-2-batch-processing","title":"Workflow 2: Batch Processing","text":"<pre><code># Process multiple documents\nfor pdf in documents/*.pdf; do\n    docling-graph convert \"$pdf\" \\\n        --template \"templates.BillingDocument\" \\\n        --output-dir \"outputs/$(basename $pdf .pdf)\"\ndone\n\n# Visualize results\nfor dir in outputs/*/; do\n    docling-graph inspect \"$dir\" \\\n        --output \"${dir}/visualization.html\" \\\n        --no-open\ndone\n</code></pre>"},{"location":"usage/cli/#workflow-3-development-iteration","title":"Workflow 3: Development Iteration","text":"<pre><code># 1. Convert with verbose logging\ndocling-graph --verbose convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --output-dir \"test_output\"\n\n# 2. Inspect results\ndocling-graph inspect test_output/\n\n# 3. Iterate on template\n# Edit templates/billing_document.py\n\n# 4. Re-run conversion\ndocling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --output-dir \"test_output\"\n</code></pre>"},{"location":"usage/cli/#configuration-priority","title":"Configuration Priority","text":"<p>The CLI uses the following priority order (highest to lowest):</p> <ol> <li>Command-line arguments (e.g., <code>--backend llm</code>)</li> <li>config.yaml (created by <code>init</code>)</li> <li>Built-in defaults (from PipelineConfig)</li> </ol>"},{"location":"usage/cli/#example","title":"Example","text":"<pre><code># config.yaml\ndefaults:\n  backend: llm\n  inference: local\n</code></pre> <pre><code># This uses remote inference (CLI overrides config)\ndocling-graph convert doc.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --inference remote\n</code></pre>"},{"location":"usage/cli/#environment-variables","title":"Environment Variables","text":""},{"location":"usage/cli/#api-keys","title":"API Keys","text":"<pre><code># Remote providers\nexport MISTRAL_API_KEY=\"your-key\"\nexport OPENAI_API_KEY=\"your-key\"\nexport GEMINI_API_KEY=\"your-key\"\nexport WATSONX_API_KEY=\"your-key\"\n</code></pre>"},{"location":"usage/cli/#local-providers","title":"Local Providers","text":"<pre><code># vLLM base URL (default: http://localhost:8000/v1)\nexport VLLM_BASE_URL=\"http://custom-host:8000/v1\"\n\n# Ollama base URL (default: http://localhost:11434)\nexport OLLAMA_BASE_URL=\"http://custom-host:11434\"\n</code></pre>"},{"location":"usage/cli/#output-structure","title":"Output Structure","text":"<p>Default output directory structure:</p> <pre><code>outputs/\n\u251c\u2500\u2500 metadata.json          # Pipeline metadata\n\u251c\u2500\u2500 docling/               # Docling conversion output\n\u2502   \u251c\u2500\u2500 document.json      # Docling format\n\u2502   \u2514\u2500\u2500 document.md        # Markdown export\n\u2514\u2500\u2500 docling_graph/         # Graph outputs\n    \u251c\u2500\u2500 graph.json         # Complete graph\n    \u251c\u2500\u2500 nodes.csv          # Node data\n    \u251c\u2500\u2500 edges.csv          # Edge data\n    \u251c\u2500\u2500 graph.html         # Interactive visualization\n    \u2514\u2500\u2500 report.md          # Summary report\n</code></pre>"},{"location":"usage/cli/#error-handling","title":"Error Handling","text":""},{"location":"usage/cli/#common-errors","title":"Common Errors","text":"<p>Configuration Error: <pre><code>[red]Configuration Error:[/red] Invalid backend type: 'invalid'\n</code></pre> Solution: Use <code>llm</code> or <code>vlm</code></p> <p>Extraction Error: <pre><code>[red]Extraction Error:[/red] Template not found: 'templates.Missing'\n</code></pre> Solution: Check template path and ensure it's importable</p> <p>Pipeline Error: <pre><code>[red]Pipeline Error:[/red] API key not found for provider: mistral\n</code></pre> Solution: Set <code>MISTRAL_API_KEY</code> environment variable</p>"},{"location":"usage/cli/#verbose-mode","title":"Verbose Mode","text":"<p>Enable verbose logging for debugging:</p> <pre><code>docling-graph --verbose convert document.pdf \\\n    --template \"templates.BillingDocument\"\n</code></pre>"},{"location":"usage/cli/#best-practices","title":"Best Practices","text":""},{"location":"usage/cli/#use-configuration-files","title":"\ud83d\udc4d Use Configuration Files","text":"<pre><code># \u2705 Good - Reusable configuration\ndocling-graph init\ndocling-graph convert document.pdf -t \"templates.BillingDocument\"\n\n# \u274c Avoid - Repeating options\ndocling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider mistral \\\n    --model mistral-large-latest\n</code></pre>"},{"location":"usage/cli/#organize-output","title":"\ud83d\udc4d Organize Output","text":"<pre><code># \u2705 Good - Organized by document\ndocling-graph convert invoice_001.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --output-dir \"outputs/invoice_001\"\n\n# \u274c Avoid - Overwriting outputs\ndocling-graph convert invoice_001.pdf \\\n    --template \"templates.BillingDocument\"\n</code></pre>"},{"location":"usage/cli/#use-verbose-for-development","title":"\ud83d\udc4d Use Verbose for Development","text":"<pre><code># \u2705 Good - Debug during development\ndocling-graph --verbose convert document.pdf \\\n    --template \"templates.BillingDocument\"\n\n# \u2705 Good - Silent in production\ndocling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\"\n</code></pre>"},{"location":"usage/cli/#next-steps","title":"Next Steps","text":"<p>Explore each command in detail:</p> <ol> <li>init Command \u2192 - Configuration setup</li> <li>convert Command \u2192 - Document conversion</li> <li>inspect Command \u2192 - Graph visualization</li> <li>CLI Recipes \u2192 - Common patterns</li> </ol> <p>Or continue to: - Python API \u2192 - Programmatic usage - Examples \u2192 - Real-world examples</p>"},{"location":"usage/cli/cli-recipes/","title":"CLI Recipes","text":"<p>This guide provides ready-to-use CLI commands for all example scripts. Run these from your project root directory.</p>"},{"location":"usage/cli/cli-recipes/#quick-reference","title":"Quick Reference","text":"Recipe Script Backend Use Case 01: VLM from Image <code>01_quickstart_vlm_image.py</code> VLM Forms, invoices, ID cards 02: LLM from PDF <code>02_quickstart_llm_pdf.py</code> LLM (Remote) Rheology researchs, reports 03: URL Processing <code>03_url_processing.py</code> LLM (Remote) Remote documents 04: Input Formats <code>04_input_formats.py</code> LLM Text, Markdown, JSON 05: Processing Modes <code>05_processing_modes.py</code> LLM (Local) Mode comparison 06: Export Formats <code>06_export_formats.py</code> VLM CSV, Cypher, JSON 07: Local Inference <code>07_local_inference.py</code> LLM (Local) Offline processing 08: Chunking <code>08_chunking_consolidation.py</code> LLM (Remote) Large documents 09: Batch Processing <code>09_batch_processing.py</code> VLM Multiple documents 10: Multi-Provider <code>10_provider_configs.py</code> LLM (Remote) Provider comparison"},{"location":"usage/cli/cli-recipes/#vlm-from-image","title":"\ud83d\udccd VLM from Image","text":"<p>Python Script: <code>01_quickstart_vlm_image.py</code></p> <p>Use Case: Extract structured data from invoice images</p> <p>CLI Command: <pre><code>docling-graph convert \"docs/examples/data/invoice/sample_invoice.jpg\" \\\n    --template \"docs.examples.templates.billing_document.BillingDocument\" \\\n    --output-dir \"outputs/cli_01\" \\\n    --backend \"vlm\" \\\n    --processing-mode \"one-to-one\" \\\n    --docling-pipeline \"vision\"\n</code></pre></p> <p>When to Use:</p> <ul> <li>\u2705 Single-page forms or invoices</li> <li>\u2705 ID cards, badges, receipts</li> <li>\u2705 Image files (JPG, PNG)</li> <li>\u2705 Structured layouts</li> </ul>"},{"location":"usage/cli/cli-recipes/#llm-from-pdf","title":"\ud83d\udccd LLM from PDF","text":"<p>Python Script: <code>02_quickstart_llm_pdf.py</code></p> <p>Use Case: Extract from multi-page rheology researchs</p> <p>Prerequisites: <pre><code>pip install docling-graph\nexport MISTRAL_API_KEY=\"your-api-key\"\n</code></pre></p> <p>CLI Command: <pre><code>docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --output-dir \"outputs/cli_02\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"mistral\" \\\n    --model \"mistral-large-latest\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking\n</code></pre></p> <p>When to Use:</p> <ul> <li>\u2705 Multi-page documents</li> <li>\u2705 Text-heavy content</li> <li>\u2705 Rheology researchs, reports</li> <li>\u2705 Complex narratives</li> </ul>"},{"location":"usage/cli/cli-recipes/#url-processing","title":"\ud83d\udccd URL Processing","text":"<p>Python Script: <code>03_url_processing.py</code></p> <p>Use Case: Download and process documents from URLs</p> <p>Prerequisites: <pre><code>pip install docling-graph\nexport MISTRAL_API_KEY=\"your-api-key\"\n</code></pre></p> <p>CLI Command: <pre><code>docling-graph convert \"https://arxiv.org/pdf/2207.02720\" \\\n    --template \"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --output-dir \"outputs/cli_03\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"mistral\" \\\n    --model \"mistral-large-latest\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking\n</code></pre></p> <p>When to Use:</p> <ul> <li>\u2705 arXiv papers</li> <li>\u2705 Web-hosted PDFs</li> <li>\u2705 Automated ingestion</li> <li>\u2705 Remote document processing</li> </ul>"},{"location":"usage/cli/cli-recipes/#input-formats","title":"\ud83d\udccd Input Formats","text":"<p>Python Script: <code>04_input_formats.py</code></p> <p>Use Case: Process text, Markdown, and DoclingDocument formats</p> <p>Text File: <pre><code># Create sample text file\necho \"Title: Sample Document\nSummary: This is a test document.\nKey Points:\n- Point 1\n- Point 2\" &gt; sample.txt\n\n# Process text file\ndocling-graph convert \"sample.txt\" \\\n    --template \"docs.examples.templates.simple.SimpleDocument\" \\\n    --output-dir \"outputs/cli_04_text\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"mistral\"\n</code></pre></p> <p>Markdown File: <pre><code># Process markdown file\ndocling-graph convert \"README.md\" \\\n    --template \"docs.examples.templates.simple.SimpleDocument\" \\\n    --output-dir \"outputs/cli_04_markdown\" \\\n    --backend \"llm\"\n</code></pre></p> <p>When to Use:</p> <ul> <li>\u2705 Documentation files</li> <li>\u2705 Plain text content</li> <li>\u2705 Reprocessing (DoclingDocument)</li> <li>\u2705 Skip OCR for speed</li> </ul>"},{"location":"usage/cli/cli-recipes/#processing-modes","title":"\ud83d\udccd Processing Modes","text":"<p>Python Script: <code>05_processing_modes.py</code></p> <p>Use Case: Compare one-to-one vs many-to-one modes</p> <p>Prerequisites: <pre><code>ollama serve\nollama pull llama3:8b\npip install docling-graph\n</code></pre></p> <p>One-to-One Mode: <pre><code>docling-graph convert \"docs/examples/data/id_card/multi_french_id_cards.pdf\" \\\n    --template \"docs.examples.templates.id_card.IDCard\" \\\n    --output-dir \"outputs/cli_05_one_to_one\" \\\n    --backend \"llm\" \\\n    --inference \"local\" \\\n    --provider \"ollama\" \\\n    --model \"llama3:8b\" \\\n    --processing-mode \"one-to-one\" \\\n    --no-use-chunking\n</code></pre></p> <p>Many-to-One Mode: <pre><code>docling-graph convert \"docs/examples/data/id_card/multi_french_id_cards.pdf\" \\\n    --template \"docs.examples.templates.id_card.IDCard\" \\\n    --output-dir \"outputs/cli_05_many_to_one\" \\\n    --backend \"llm\" \\\n    --inference \"local\" \\\n    --provider \"ollama\" \\\n    --model \"llama3:8b\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking\n</code></pre></p>"},{"location":"usage/cli/cli-recipes/#export-formats","title":"\ud83d\udccd Export Formats","text":"<p>Python Script: <code>06_export_formats.py</code></p> <p>Use Case: Generate different export formats for Neo4j</p> <p>CSV Export (Bulk Import): <pre><code>docling-graph convert \"docs/examples/data/invoice/sample_invoice.jpg\" \\\n    --template \"docs.examples.templates.billing_document.BillingDocument\" \\\n    --output-dir \"outputs/cli_06_csv\" \\\n    --backend \"vlm\" \\\n    --export-format \"csv\"\n</code></pre></p> <p>Cypher Export (Script): <pre><code>docling-graph convert \"docs/examples/data/invoice/sample_invoice.jpg\" \\\n    --template \"docs.examples.templates.billing_document.BillingDocument\" \\\n    --output-dir \"outputs/cli_06_cypher\" \\\n    --backend \"vlm\" \\\n    --export-format \"cypher\"\n</code></pre></p> <p>Neo4j Import: <pre><code># CSV bulk import\nneo4j-admin database import full \\\n    --nodes=outputs/cli_06_csv/docling_graph/nodes.csv \\\n    --relationships=outputs/cli_06_csv/docling_graph/edges.csv\n\n# Cypher script\ncat outputs/cli_06_cypher/docling_graph/graph.cypher | \\\n    cypher-shell -u neo4j -p password\n</code></pre></p>"},{"location":"usage/cli/cli-recipes/#local-inference","title":"\ud83d\udccd Local Inference","text":"<p>Python Script: <code>07_local_inference.py</code></p> <p>Use Case: Privacy-focused offline processing</p> <p>Prerequisites: <pre><code>ollama serve\nollama pull llama3:8b\npip install docling-graph\n</code></pre></p> <p>CLI Command: <pre><code>docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --output-dir \"outputs/cli_07\" \\\n    --backend \"llm\" \\\n    --inference \"local\" \\\n    --provider \"ollama\" \\\n    --model \"llama3:8b\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking\n</code></pre></p> <p>When to Use:</p> <ul> <li>\u2705 Privacy-sensitive documents</li> <li>\u2705 Offline processing</li> <li>\u2705 No API costs</li> <li>\u2705 Development and testing</li> </ul>"},{"location":"usage/cli/cli-recipes/#chunking-consolidation","title":"\ud83d\udccd Chunking &amp; Consolidation","text":"<p>Python Script: <code>08_chunking_consolidation.py</code></p> <p>Use Case: Compare consolidation strategies</p> <p>Prerequisites: <pre><code>pip install docling-graph\nexport MISTRAL_API_KEY=\"your-api-key\"\n</code></pre></p> <p>Programmatic Merge (Fast): <pre><code>docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --output-dir \"outputs/cli_08_programmatic\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"mistral\" \\\n    --processing-mode \"many-to-one\" \\\n    --use-chunking\n</code></pre></p>"},{"location":"usage/cli/cli-recipes/#batch-processing","title":"\ud83d\udccd Batch Processing","text":"<p>Python Script: <code>09_batch_processing.py</code></p> <p>Use Case: Process multiple documents efficiently</p> <p>Bash Script: <pre><code>#!/bin/bash\n# Process all invoices in a directory\n\nfor file in docs/examples/data/invoice/*.jpg; do\n    filename=$(basename \"$file\" .jpg)\n    echo \"Processing $filename...\"\n\n    docling-graph convert \"$file\" \\\n        --template \"docs.examples.templates.billing_document.BillingDocument\" \\\n        --output-dir \"outputs/cli_09/$filename\" \\\n        --backend \"vlm\" \\\n        --processing-mode \"one-to-one\"\ndone\n\necho \"Batch processing complete!\"\n</code></pre></p>"},{"location":"usage/cli/cli-recipes/#multi-provider","title":"\ud83d\udccd Multi-Provider","text":"<p>Python Script: <code>10_provider_configs.py</code></p> <p>Use Case: Compare different LLM providers</p> <p>Prerequisites: <pre><code># Set API keys for providers you want to test\nexport OPENAI_API_KEY=\"sk-...\"\nexport MISTRAL_API_KEY=\"...\"\nexport GEMINI_API_KEY=\"...\"\nexport WATSONX_API_KEY=\"...\"\nexport WATSONX_PROJECT_ID=\"...\"\n\npip install docling-graph\n</code></pre></p> <p>OpenAI: <pre><code>docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --output-dir \"outputs/cli_10_openai\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"openai\" \\\n    --model \"gpt-4-turbo-preview\"\n</code></pre></p> <p>Mistral: <pre><code>docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --output-dir \"outputs/cli_10_mistral\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"mistral\" \\\n    --model \"mistral-large-latest\"\n</code></pre></p> <p>Gemini: <pre><code>docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --output-dir \"outputs/cli_10_gemini\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"gemini\" \\\n    --model \"gemini-1.5-pro\"\n</code></pre></p> <p>WatsonX: <pre><code>docling-graph convert \"docs/examples/data/research_paper/rheology.pdf\" \\\n    --template \"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --output-dir \"outputs/cli_10_watsonx\" \\\n    --backend \"llm\" \\\n    --inference \"remote\" \\\n    --provider \"watsonx\" \\\n    --model \"ibm/granite-4-h-small\"\n</code></pre></p>"},{"location":"usage/cli/cli-recipes/#common-options","title":"Common Options","text":""},{"location":"usage/cli/cli-recipes/#visualization","title":"Visualization","text":"<pre><code># View interactive graph\ndocling-graph inspect outputs/cli_01\n\n# Open specific HTML file\nopen outputs/cli_01/docling_graph/graph.html\n</code></pre>"},{"location":"usage/cli/cli-recipes/#debugging","title":"Debugging","text":"<pre><code># Verbose output\ndocling-graph --verbose convert ...\n\n# Check version\ndocling-graph --version\n\n# Get help\ndocling-graph convert --help\n</code></pre>"},{"location":"usage/cli/cli-recipes/#configuration","title":"Configuration","text":"<pre><code># Initialize config file\ndocling-graph init\n\n# Use custom config\ndocling-graph convert --config custom_config.yaml ...\n</code></pre>"},{"location":"usage/cli/cli-recipes/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/cli/cli-recipes/#api-key-issues","title":"\ud83d\udc1b API Key Issues","text":"<pre><code># Check if key is set\necho $MISTRAL_API_KEY\n\n# Set key for current session\nexport MISTRAL_API_KEY=\"your-key\"\n\n# Set permanently (add to ~/.bashrc or ~/.zshrc)\necho 'export MISTRAL_API_KEY=\"your-key\"' &gt;&gt; ~/.bashrc\n</code></pre>"},{"location":"usage/cli/cli-recipes/#ollama-issues","title":"\ud83d\udc1b Ollama Issues","text":"<pre><code># Check if Ollama is running\ncurl http://localhost:11434\n\n# Start Ollama\nollama serve\n\n# List available models\nollama list\n\n# Pull a model\nollama pull llama3:8b\n</code></pre>"},{"location":"usage/cli/cli-recipes/#installation-issues","title":"\ud83d\udc1b Installation Issues","text":"<pre><code># Reinstall\npip install --force-reinstall docling-graph\n\n# Check Python version\npython --version  # Should be 3.10+\n\n# Verify installation\npython -c \"import docling_graph; print(docling_graph.__version__)\"\n</code></pre>"},{"location":"usage/cli/cli-recipes/#next-steps","title":"Next Steps","text":"<ol> <li>Python API \u2192 - Programmatic usage</li> <li>Examples \u2192 - Real-world examples</li> <li>Advanced Topics \u2192 - Custom backends</li> </ol>"},{"location":"usage/cli/convert-command/","title":"convert Command","text":""},{"location":"usage/cli/convert-command/#overview","title":"Overview","text":"<p>The <code>convert</code> command transforms documents into knowledge graphs using configurable extraction pipelines.</p> <p>Key Features:</p> <ul> <li>Multiple backend support (LLM/VLM)</li> <li>Flexible processing modes</li> <li>Configurable chunking</li> <li>Multiple export formats</li> <li>Batch processing support</li> </ul>"},{"location":"usage/cli/convert-command/#basic-usage","title":"Basic Usage","text":"<pre><code>uv run docling-graph convert SOURCE --template TEMPLATE [OPTIONS]\n</code></pre>"},{"location":"usage/cli/convert-command/#required-arguments","title":"Required Arguments","text":"Argument Description <code>SOURCE</code> Path to document (PDF, JPG, PNG, TXT, MD), URL, or DoclingDocument JSON <code>--template</code>, <code>-t</code> Dotted path to Pydantic template"},{"location":"usage/cli/convert-command/#examples","title":"Examples","text":"<pre><code># PDF document\nuv run docling-graph convert invoice.pdf \\\n    --template \"templates.BillingDocument\"\n\n# Text file\nuv run docling-graph convert notes.txt \\\n    --template \"templates.Report\" \\\n    --backend llm\n\n# URL\nuv run docling-graph convert https://example.com/doc.pdf \\\n    --template \"templates.BillingDocument\"\n\n# Markdown file\nuv run docling-graph convert README.md \\\n    --template \"templates.Documentation\" \\\n    --backend llm\n</code></pre>"},{"location":"usage/cli/convert-command/#core-options","title":"Core Options","text":""},{"location":"usage/cli/convert-command/#debug-mode","title":"Debug Mode","text":"<pre><code>--debug\n</code></pre> <p>Enable debug mode to save all intermediate extraction artifacts for debugging and analysis.</p> <p>When to use:</p> <ul> <li>Debugging extraction issues</li> <li>Analyzing extraction quality</li> <li>Performance profiling</li> <li>Development and testing</li> </ul> <p>Output: All debug artifacts saved to <code>outputs/{document}_{timestamp}/debug/</code></p> <p>Example: <pre><code># Enable debug mode\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --debug\n\n# Debug artifacts will be in:\n# outputs/document_pdf_20260206_094500/debug/\n</code></pre></p> <p>See Debug Mode Documentation for details on debug artifacts.</p>"},{"location":"usage/cli/convert-command/#backend-selection","title":"Backend Selection","text":"<pre><code>--backend {llm|vlm}\n</code></pre> <p>LLM (Language Model):</p> <ul> <li>Best for text-heavy documents</li> <li>Supports chunking and consolidation</li> <li>Works with local and remote providers</li> </ul> <p>VLM (Vision-Language Model):</p> <ul> <li>Best for forms and structured layouts</li> <li>Processes images directly</li> <li>Local inference only</li> </ul> <p>Example: <pre><code># Use LLM backend\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm\n\n# Use VLM backend\nuv run docling-graph convert form.jpg \\\n    --template \"templates.IDCard\" \\\n    --backend vlm\n</code></pre></p>"},{"location":"usage/cli/convert-command/#inference-mode","title":"Inference Mode","text":"<pre><code>--inference {local|remote}\n</code></pre> <p>Local:</p> <ul> <li>Run models on your machine</li> <li>Requires GPU for best performance</li> <li>No API costs</li> </ul> <p>Remote:</p> <ul> <li>Use cloud API providers</li> <li>Requires API key</li> <li>Pay per request</li> </ul> <p>Example: <pre><code># Local inference\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --inference local\n\n# Remote inference\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --inference remote\n</code></pre></p>"},{"location":"usage/cli/convert-command/#processing-mode","title":"Processing Mode","text":"<pre><code>--processing-mode {one-to-one|many-to-one}\n</code></pre> <p>many-to-one (recommended):</p> <ul> <li>Merge all pages into single graph</li> <li>Better for multi-page documents</li> <li>Enables consolidation</li> </ul> <p>one-to-one:</p> <ul> <li>Create separate graph per page</li> <li>Better for independent pages</li> <li>Faster processing</li> </ul> <p>Example: <pre><code># Merge all pages\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --processing-mode many-to-one\n\n# Process pages separately\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --processing-mode one-to-one\n</code></pre></p>"},{"location":"usage/cli/convert-command/#model-configuration","title":"Model Configuration","text":""},{"location":"usage/cli/convert-command/#provider-override","title":"Provider Override","text":"<pre><code>--provider PROVIDER\n</code></pre> <p>Available providers:</p> <ul> <li>Local: <code>vllm</code>, <code>ollama</code>, <code>lmstudio</code></li> <li>Remote: <code>mistral</code>, <code>openai</code>, <code>gemini</code>, <code>watsonx</code></li> </ul>"},{"location":"usage/cli/convert-command/#model-override","title":"Model Override","text":"<pre><code>--model MODEL\n</code></pre> <p>Example: <pre><code># Use specific model\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --provider mistral \\\n    --model mistral-large-latest\n</code></pre></p>"},{"location":"usage/cli/convert-command/#llm-connection-overrides","title":"LLM connection overrides","text":"<p>Use <code>--llm-base-url</code> to point to a custom endpoint (e.g. on-prem OpenAI-compatible server). API keys are set via environment variables or <code>config.yaml</code> (<code>llm_overrides.connection</code>), not CLI. See LLM Model Configuration for the full list of overrides and on-prem setup.</p> <p>For LM Studio (<code>--provider lmstudio</code>): override the base URL with <code>LM_STUDIO_API_BASE</code> or <code>--llm-base-url</code>; when the server requires auth, set <code>LM_STUDIO_API_KEY</code> or <code>llm_overrides.connection.api_key</code> in config.</p> <p>For the on-prem flow (openai-compatible), use fixed env vars:</p> <pre><code>export CUSTOM_LLM_BASE_URL=\"https://your-llm.example.com/v1\"\nexport CUSTOM_LLM_API_KEY=\"your-api-key\"\n</code></pre>"},{"location":"usage/cli/convert-command/#extraction-options","title":"Extraction Options","text":""},{"location":"usage/cli/convert-command/#chunking","title":"Chunking","text":"<pre><code>--use-chunking / --no-use-chunking\n</code></pre> <p>Enable chunking for:</p> <ul> <li>Large documents (&gt;5 pages)</li> <li>Documents exceeding context limits</li> <li>Better extraction accuracy</li> </ul> <p>Disable chunking for:</p> <ul> <li>Small documents</li> <li>When full context is needed</li> <li>Faster processing</li> </ul> <p>Example: <pre><code># Enable chunking (default)\nuv run docling-graph convert large_doc.pdf \\\n    --template \"templates.ScholarlyRheologyPaper\" \\\n    --use-chunking\n\n# Disable chunking\nuv run docling-graph convert small_doc.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --no-use-chunking\n</code></pre></p>"},{"location":"usage/cli/convert-command/#staged-extraction-tuning","title":"Staged Extraction Tuning","text":"<p>These flags apply when <code>--extraction-contract staged</code> is used in many-to-one mode.</p> <pre><code>--staged-tuning {standard|advanced}\n--staged-retries INT\n--parallel-workers INT\n--staged-nodes-fill-cap INT\n--staged-id-shard-size INT\n</code></pre> <ul> <li><code>--staged-tuning</code>: preset defaults (<code>standard</code> or <code>advanced</code>).</li> <li><code>--staged-retries</code>: retries per staged pass for invalid JSON responses.</li> <li><code>--parallel-workers</code>: parallel workers for extraction (staged fill pass and delta batch calls).</li> <li><code>--staged-nodes-fill-cap</code>: max node instances per fill-pass call.</li> <li><code>--staged-id-shard-size</code>: max catalog paths per ID-pass call (<code>0</code> disables sharding).</li> </ul> <p>ID pass always runs sequentially across shards for stable skeleton assembly.</p>"},{"location":"usage/cli/convert-command/#delta-extraction-tuning","title":"Delta Extraction Tuning","text":"<p>These flags apply when <code>--extraction-contract delta</code> is used in many-to-one mode (chunking must be enabled). To configure delta resolvers and quality gates interactively, run <code>docling-graph init</code> and choose delta as the extraction contract; the wizard will prompt for resolver enable/mode and optional quality tweaks (see init Command).</p> <pre><code>--llm-batch-token-size INT\n--parallel-workers INT\n--delta-normalizer-validate-paths / --no-delta-normalizer-validate-paths\n--delta-normalizer-canonicalize-ids / --no-delta-normalizer-canonicalize-ids\n--delta-normalizer-strip-nested-properties / --no-delta-normalizer-strip-nested-properties\n--delta-resolvers-enabled / --no-delta-resolvers-enabled\n--delta-resolvers-mode {off|fuzzy|semantic|chain}\n--delta-resolver-fuzzy-threshold FLOAT\n--delta-resolver-semantic-threshold FLOAT\n</code></pre> <ul> <li><code>--llm-batch-token-size</code>: max input tokens per delta batch (default: 1024).</li> <li><code>--parallel-workers</code>: parallel workers for delta batch LLM calls.</li> <li>Delta normalizer flags control path validation, ID canonicalization, and nested property stripping.</li> <li>Resolvers optionally merge near-duplicate entities after merge (<code>fuzzy</code>, <code>semantic</code>, or <code>chain</code>).</li> </ul> <p>Quality gate options (e.g. <code>delta_quality_max_parent_lookup_miss</code>, <code>delta_quality_require_relationships</code>) are not CLI flags; set them in <code>config.yaml</code> under <code>defaults</code> or use the init wizard when selecting delta.</p> <p>See Delta Extraction for full options and quality gate settings.</p>"},{"location":"usage/cli/convert-command/#gleaning-direct-and-delta","title":"Gleaning (direct and delta)","text":"<p>Optional second-pass extraction (\"what did you miss?\") to improve recall. Applies to direct and delta contracts only (not staged). Enabled by default.</p> <pre><code>--gleaning-enabled / --no-gleaning-enabled\n--gleaning-max-passes INT\n</code></pre> <ul> <li><code>--gleaning-enabled</code>: run one extra extraction pass and merge additional entities/relations (default: enabled).</li> <li><code>--gleaning-max-passes</code>: max number of gleaning passes when enabled (default: 1).</li> </ul> <p>Example (delta with gleaning):</p> <pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.ScholarlyRheologyPaper\" \\\n    --processing-mode many-to-one \\\n    --extraction-contract delta \\\n    --gleaning-enabled \\\n    --gleaning-max-passes 1 \\\n    --parallel-workers 2\n</code></pre> <p>Example (basic delta):</p> <pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --processing-mode many-to-one \\\n    --extraction-contract delta \\\n    --use-chunking \\\n    --llm-batch-token-size 2048 \\\n    --parallel-workers 2\n</code></pre> <p>Example (delta with resolvers):</p> <pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --processing-mode many-to-one \\\n    --extraction-contract delta \\\n    --use-chunking \\\n    --delta-resolvers-enabled \\\n    --delta-resolvers-mode fuzzy \\\n    --delta-resolver-fuzzy-threshold 0.9 \\\n    --parallel-workers 2\n</code></pre>"},{"location":"usage/cli/convert-command/#structured-output-mode","title":"Structured Output Mode","text":"<p>Structured output is enabled by default for LLM extraction and enforces schema through LiteLLM <code>response_format=json_schema</code>.</p> <pre><code>--schema-enforced-llm / --no-schema-enforced-llm\n--structured-sparse-check / --no-structured-sparse-check\n</code></pre> <ul> <li>Use <code>--schema-enforced-llm</code> (default) for strict schema-constrained output.</li> <li>Use <code>--no-schema-enforced-llm</code> to fall back to legacy prompt-embedded schema mode.</li> <li>Use <code>--no-structured-sparse-check</code> to disable the sparse structured-result quality guard.</li> <li>When schema mode fails at runtime (unsupported backend/model or malformed request),   Docling Graph logs the error and automatically retries once using legacy prompt-schema mode.</li> <li>Even when schema mode succeeds technically, Docling Graph can trigger the same fallback once   if the structured payload is detected as obviously sparse for the target schema.</li> </ul> <p>Example:</p> <pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --processing-mode many-to-one \\\n    --extraction-contract staged \\\n    --parallel-workers 4 \\\n    --staged-nodes-fill-cap 12 \\\n    --staged-id-shard-size 2\n</code></pre>"},{"location":"usage/cli/convert-command/#docling-configuration","title":"Docling Configuration","text":""},{"location":"usage/cli/convert-command/#pipeline-selection","title":"Pipeline Selection","text":"<pre><code>--docling-pipeline {ocr|vision}\n</code></pre> <p>OCR Pipeline:</p> <ul> <li>Traditional OCR approach</li> <li>Most accurate for standard documents</li> <li>Faster processing</li> </ul> <p>Vision Pipeline:</p> <ul> <li>Uses Granite-Docling VLM</li> <li>Better for complex layouts</li> <li>Handles tables and figures better</li> </ul> <p>Example: <pre><code># Use OCR pipeline (default)\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --docling-pipeline ocr\n\n# Use vision pipeline\nuv run docling-graph convert complex_doc.pdf \\\n    --template \"templates.ScholarlyRheologyPaper\" \\\n    --docling-pipeline vision\n</code></pre></p>"},{"location":"usage/cli/convert-command/#export-options","title":"Export Options","text":""},{"location":"usage/cli/convert-command/#export-format","title":"Export Format","text":"<pre><code>--export-format {csv|cypher}\n</code></pre> <p>CSV:</p> <ul> <li>For Neo4j import</li> <li>Separate nodes.csv and edges.csv</li> <li>Easy to analyze</li> </ul> <p>Cypher:</p> <ul> <li>Direct Neo4j execution</li> <li>Single .cypher file</li> <li>Ready to import</li> </ul> <p>Example: <pre><code># Export as CSV\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --export-format csv\n\n# Export as Cypher\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --export-format cypher\n</code></pre></p>"},{"location":"usage/cli/convert-command/#docling-exports","title":"Docling Exports","text":"<pre><code>--export-docling-json / --no-docling-json\n--export-markdown / --no-markdown\n--export-per-page / --no-per-page\n</code></pre> <p>Example: <pre><code># Export all Docling outputs\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --export-docling-json \\\n    --export-markdown \\\n    --export-per-page\n\n# Minimal exports\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --no-docling-json \\\n    --no-markdown \\\n    --no-per-page\n</code></pre></p>"},{"location":"usage/cli/convert-command/#graph-options","title":"Graph Options","text":""},{"location":"usage/cli/convert-command/#reverse-edges","title":"Reverse Edges","text":"<pre><code>--reverse-edges\n</code></pre> <p>Creates bidirectional relationships in the graph.</p> <p>Example: <pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --reverse-edges\n</code></pre></p>"},{"location":"usage/cli/convert-command/#output-options","title":"Output Options","text":""},{"location":"usage/cli/convert-command/#output-directory","title":"Output Directory","text":"<pre><code>--output-dir PATH\n</code></pre> <p>Default: <code>outputs/</code></p> <p>Example: <pre><code># Custom output directory\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --output-dir \"results/invoice_001\"\n\n# Organize by date\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --output-dir \"outputs/$(date +%Y-%m-%d)\"\n</code></pre></p>"},{"location":"usage/cli/convert-command/#complete-examples","title":"Complete Examples","text":""},{"location":"usage/cli/convert-command/#simple-invoice-vlm","title":"\ud83d\udccd Simple Invoice (VLM)","text":"<pre><code>uv run docling-graph convert invoice.jpg \\\n    --template \"templates.BillingDocument\" \\\n    --backend vlm \\\n    --processing-mode one-to-one \\\n    --output-dir \"outputs/invoice\"\n</code></pre>"},{"location":"usage/cli/convert-command/#rheology-research-remote-llm","title":"\ud83d\udccd Rheology Research (Remote LLM)","text":"<pre><code>export MISTRAL_API_KEY=\"your-key\"\n\nuv run docling-graph convert research.pdf \\\n    --template \"templates.ScholarlyRheologyPaper\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider mistral \\\n    --model mistral-large-latest \\\n    --processing-mode many-to-one \\\n    --use-chunking \\\n    --output-dir \"outputs/research\"\n</code></pre>"},{"location":"usage/cli/convert-command/#debug-mode-enabled","title":"\ud83d\udccd Debug Mode Enabled","text":"<pre><code># Enable debug mode for troubleshooting\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --debug \\\n    --output-dir \"outputs/debug_run\"\n\n# Debug artifacts will be saved to:\n# outputs/debug_run/document_pdf_20260206_094500/debug/\n</code></pre>"},{"location":"usage/cli/convert-command/#local-processing-ollama","title":"\ud83d\udccd Local Processing (Ollama)","text":"<pre><code># Start Ollama server first\nollama serve\n\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --inference local \\\n    --provider ollama \\\n    --model llama3:8b \\\n    --processing-mode many-to-one \\\n    --use-chunking \\\n    --output-dir \"outputs/local\"\n</code></pre>"},{"location":"usage/cli/convert-command/#cypher-export-for-neo4j","title":"\ud83d\udccd Cypher Export for Neo4j","text":"<pre><code>uv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --inference remote \\\n    --export-format cypher \\\n    --output-dir \"outputs/neo4j\"\n\n# Import to Neo4j\ncat outputs/neo4j/graph.cypher | cypher-shell\n</code></pre>"},{"location":"usage/cli/convert-command/#minimal-processing","title":"\ud83d\udccd Minimal Processing","text":"<pre><code>uv run docling-graph convert small_doc.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm \\\n    --inference local \\\n    --no-use-chunking \\\n    --no-docling-json \\\n    --no-markdown \\\n    --output-dir \"outputs/minimal\"\n</code></pre>"},{"location":"usage/cli/convert-command/#batch-processing","title":"Batch Processing","text":""},{"location":"usage/cli/convert-command/#process-multiple-files","title":"Process Multiple Files","text":"<pre><code># Bash loop\nfor pdf in documents/*.pdf; do\n    uv run docling-graph convert \"$pdf\" \\\n        --template \"templates.BillingDocument\" \\\n        --output-dir \"outputs/$(basename $pdf .pdf)\"\ndone\n</code></pre>"},{"location":"usage/cli/convert-command/#parallel-processing","title":"Parallel Processing","text":"<pre><code># Using GNU parallel\nls documents/*.pdf | parallel -j 4 \\\n    uv run docling-graph convert {} \\\n        --template \"templates.BillingDocument\" \\\n        --output-dir \"outputs/{/.}\"\n</code></pre>"},{"location":"usage/cli/convert-command/#batch-script","title":"Batch Script","text":"<pre><code>#!/bin/bash\n# batch_convert.sh\n\nTEMPLATE=\"templates.BillingDocument\"\nINPUT_DIR=\"documents\"\nOUTPUT_BASE=\"outputs\"\n\nfor file in \"$INPUT_DIR\"/*.pdf; do\n    filename=$(basename \"$file\" .pdf)\n    echo \"Processing: $filename\"\n\n    uv run docling-graph convert \"$file\" \\\n        --template \"$TEMPLATE\" \\\n        --output-dir \"$OUTPUT_BASE/$filename\" \\\n        --backend llm \\\n        --inference remote\n\n    echo \"Completed: $filename\"\ndone\n</code></pre>"},{"location":"usage/cli/convert-command/#configuration-priority","title":"Configuration Priority","text":"<p>Options are resolved in this order (highest to lowest):</p> <ol> <li>Command-line arguments</li> <li>config.yaml (from <code>init</code>)</li> <li>Built-in defaults</li> </ol>"},{"location":"usage/cli/convert-command/#example","title":"Example","text":"<pre><code># config.yaml\ndefaults:\n  backend: llm\n  inference: local\n  processing_mode: many-to-one\n</code></pre> <pre><code># This uses remote inference (CLI overrides config)\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --inference remote\n</code></pre>"},{"location":"usage/cli/convert-command/#output-structure","title":"Output Structure","text":"<pre><code>outputs/\n\u251c\u2500\u2500 metadata.json                # Pipeline metadata\n\u251c\u2500\u2500 docling/                     # Docling conversion output\n\u2502   \u251c\u2500\u2500 document.json            # Docling format\n\u2502   \u2514\u2500\u2500 document.md              # Markdown export\n\u2514\u2500\u2500 docling_graph/               # Graph outputs\n    \u251c\u2500\u2500 graph.json               # Complete graph\n    \u251c\u2500\u2500 nodes.csv                # Node data\n    \u251c\u2500\u2500 edges.csv                # Edge data\n    \u251c\u2500\u2500 graph.html               # Interactive visualization\n    \u2514\u2500\u2500 report.md                # Summary report\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"usage/cli/convert-command/#error-handling","title":"Error Handling","text":""},{"location":"usage/cli/convert-command/#configuration-errors","title":"Configuration Errors","text":"<pre><code>[red]Configuration Error:[/red] Invalid backend type: 'invalid'\n</code></pre> <p>Solution: Use <code>llm</code> or <code>vlm</code></p>"},{"location":"usage/cli/convert-command/#extraction-errors","title":"Extraction Errors","text":"<pre><code>[red]Extraction Error:[/red] Template not found: 'templates.Missing'\n</code></pre> <p>Solution: Check template path and ensure it's importable</p>"},{"location":"usage/cli/convert-command/#api-errors","title":"API Errors","text":"<pre><code>[red]Pipeline Error:[/red] API key not found for provider: mistral\n</code></pre> <p>Solution: <pre><code>export MISTRAL_API_KEY=\"your-key\"\n</code></pre></p>"},{"location":"usage/cli/convert-command/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/cli/convert-command/#template-not-found","title":"\ud83d\udc1b Template Not Found","text":"<p>Error: <pre><code>ModuleNotFoundError: No module named 'templates'\n</code></pre></p> <p>Solution: <pre><code># Ensure template is in Python path\nexport PYTHONPATH=\"${PYTHONPATH}:$(pwd)\"\n\n# Or use absolute path\nuv run docling-graph convert document.pdf \\\n    --template \"my_project.templates.BillingDocument\"\n</code></pre></p>"},{"location":"usage/cli/convert-command/#out-of-memory","title":"\ud83d\udc1b Out of Memory","text":"<p>Error: <pre><code>CUDA out of memory\n</code></pre></p> <p>Solution: <pre><code># Enable chunking\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --use-chunking\n\n# Or use smaller model\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --model \"ibm-granite/granite-4.0-1b\"\n</code></pre></p>"},{"location":"usage/cli/convert-command/#slow-processing","title":"\ud83d\udc1b Slow Processing","text":"<p>Solution: <pre><code># Disable chunking for small documents to speed up\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --no-use-chunking\n</code></pre></p>"},{"location":"usage/cli/convert-command/#best-practices","title":"Best Practices","text":""},{"location":"usage/cli/convert-command/#use-configuration-files","title":"\ud83d\udc4d Use Configuration Files","text":"<pre><code># \u2705 Good - Reusable configuration\nuv run docling-graph init\nuv run docling-graph convert document.pdf -t \"templates.BillingDocument\"\n\n# \u274c Avoid - Repeating options\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --backend llm --inference remote --provider mistral\n</code></pre>"},{"location":"usage/cli/convert-command/#organize-outputs","title":"\ud83d\udc4d Organize Outputs","text":"<pre><code># \u2705 Good - Organized by document\nuv run docling-graph convert invoice_001.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --output-dir \"outputs/invoice_001\"\n\n# \u274c Avoid - Overwriting outputs\nuv run docling-graph convert invoice_001.pdf \\\n    --template \"templates.BillingDocument\"\n</code></pre>"},{"location":"usage/cli/convert-command/#use-appropriate-backend","title":"\ud83d\udc4d Use Appropriate Backend","text":"<pre><code># \u2705 Good - VLM for forms\nuv run docling-graph convert id_card.jpg \\\n    --template \"templates.IDCard\" \\\n    --backend vlm\n\n# \u2705 Good - LLM for documents\nuv run docling-graph convert research.pdf \\\n    --template \"templates.ScholarlyRheologyPaper\" \\\n    --backend llm\n</code></pre>"},{"location":"usage/cli/convert-command/#next-steps","title":"Next Steps","text":"<ol> <li>inspect Command \u2192 - Visualize results</li> <li>CLI Recipes \u2192 - Common patterns</li> <li>Examples \u2192 - Real-world examples</li> </ol>"},{"location":"usage/cli/init-command/","title":"init Command","text":""},{"location":"usage/cli/init-command/#overview","title":"Overview","text":"<p>The <code>init</code> command creates a <code>config.yaml</code> file in your current directory through an interactive setup process.</p> <p>Purpose:</p> <ul> <li>Generate configuration files</li> <li>Validate dependencies</li> <li>Guide API key setup</li> <li>Provide next steps</li> </ul>"},{"location":"usage/cli/init-command/#basic-usage","title":"Basic Usage","text":"<pre><code>docling-graph init\n</code></pre> <p>This launches an interactive wizard that guides you through:</p> <ol> <li>Processing mode (one-to-one / many-to-one)</li> <li>Extraction contract (direct / staged / delta)</li> <li>Delta Extraction Tuning (only when delta is selected): resolvers (enable + mode) and optional quality gate tweaks</li> <li>Backend type (LLM / VLM)</li> <li>Inference location (local / remote; skipped for VLM)</li> <li>Docling pipeline and export options</li> <li>Provider and model selection (by backend/inference)</li> <li>Export format</li> <li>Output directory</li> <li>(If remote LLM with custom provider) Use custom endpoint (URL and API key via environment variables)</li> </ol> <p>When custom endpoint is enabled, the wizard expects the fixed env var names <code>CUSTOM_LLM_BASE_URL</code> and <code>CUSTOM_LLM_API_KEY</code>.</p>"},{"location":"usage/cli/init-command/#interactive-setup","title":"Interactive Setup","text":""},{"location":"usage/cli/init-command/#step-1-processing-mode","title":"Step 1: Processing Mode","text":"<pre><code>1. Processing Mode\n How should documents be processed?\n  \u2022 one-to-one: Creates a separate Pydantic instance for each page\n  \u2022 many-to-one: Combines the entire document into a single Pydantic instance\nSelect processing mode (one-to-one, many-to-one) [many-to-one]:\n</code></pre>"},{"location":"usage/cli/init-command/#step-2-extraction-contract","title":"Step 2: Extraction Contract","text":"<pre><code>2. Extraction Contract\n How should LLM extraction prompts/execution be orchestrated?\n  \u2022 direct: Single-pass best-effort extraction (fastest)\n  \u2022 staged: Multi-pass staged extraction for improved small-model quality\n  \u2022 delta: Chunk-based graph extraction for long documents (batches \u2192 merge \u2192 projection)\nSelect extraction contract (direct, staged, delta) [direct]:\n</code></pre>"},{"location":"usage/cli/init-command/#step-3-delta-extraction-tuning-only-when-delta-is-selected","title":"Step 3: Delta Extraction Tuning (only when delta is selected)","text":"<p>If you selected delta, the wizard shows a Delta Extraction Tuning section:</p> <ul> <li>Delta Resolvers \u2014 Enable post-merge duplicate resolution and choose mode (<code>off</code>, <code>fuzzy</code>, <code>semantic</code>, <code>chain</code>). Resolvers merge near-duplicate entities after the graph merge.</li> <li>Delta Quality Gates \u2014 Optionally customize:</li> <li>Max parent lookup misses before failing the quality gate</li> <li>Adaptive parent lookup tolerance</li> <li>Require at least one relationship in the projected graph</li> <li>Require structural attachments (avoid root-only outputs)</li> </ul> <p>These values are written into <code>defaults</code> in your <code>config.yaml</code>. You can override them later in the config file or via the convert command (where applicable). See Delta Extraction for full options.</p>"},{"location":"usage/cli/init-command/#step-4-backend-type","title":"Step 4: Backend Type","text":"<pre><code>Backend Type\n Which AI backend should be used?\n  \u2022 llm: Language Model (text-based)\n  \u2022 vlm: Vision-Language Model (image-based)\nSelect backend type [llm]:\n</code></pre>"},{"location":"usage/cli/init-command/#step-5-inference-location-llm-only","title":"Step 5: Inference Location (LLM only)","text":"<pre><code>Inference Location\n How should models be executed?\n  \u2022 local: Run on your machine\n  \u2022 remote: Use cloud APIs\nSelect inference location [remote]:\n</code></pre> <p>(VLM backend skips this step and uses local inference.)</p>"},{"location":"usage/cli/init-command/#step-6-docling-pipeline-and-export-options","title":"Step 6: Docling Pipeline and Export Options","text":"<p>You choose the Docling pipeline (ocr / vision) and whether to export Docling JSON, markdown, and per-page markdown.</p>"},{"location":"usage/cli/init-command/#step-7-provider-and-model-selection","title":"Step 7: Provider and Model Selection","text":"<p>For Local LLM: <pre><code>Choose local LLM provider:\n1. vLLM (recommended for GPU)\n2. Ollama (recommended for CPU)\n3. LM Studio (OpenAI-compatible local server)\n4. Custom\n\nYour choice [1-4]:\n</code></pre></p> <p>For Remote LLM: <pre><code>Choose remote provider:\n1. Mistral AI\n2. OpenAI\n3. Google Gemini\n4. IBM watsonx\n\nYour choice [1-4]:\n</code></pre></p>"},{"location":"usage/cli/init-command/#step-8-model-selection","title":"Step 8: Model Selection","text":"<pre><code>Select model for &lt;provider&gt; [default]:\n</code></pre>"},{"location":"usage/cli/init-command/#step-9-export-format","title":"Step 9: Export Format","text":"<pre><code>Export Format\n Output format for results\n  \u2022 csv: CSV files (nodes.csv, edges.csv)\n  \u2022 cypher: Cypher script for Neo4j\nSelect export format [csv]:\n</code></pre>"},{"location":"usage/cli/init-command/#step-10-output-directory","title":"Step 10: Output Directory","text":"<p>The wizard then prompts for the output directory (default: <code>outputs</code>).</p>"},{"location":"usage/cli/init-command/#generated-configuration","title":"Generated Configuration","text":""},{"location":"usage/cli/init-command/#example-remote-llm-mistral","title":"Example: Remote LLM (Mistral)","text":"<pre><code># config.yaml\ndefaults:\n  processing_mode: many-to-one\n  backend: llm\n  inference: remote\n  export_format: csv\n\ndocling:\n  pipeline: ocr\n  export:\n    docling_json: true\n    markdown: true\n    per_page_markdown: false\n\nmodels:\n  llm:\n    local:\n      model: ibm-granite/granite-4.0-1b\n      provider: vllm\n    remote:\n      model: mistral-small-latest\n      provider: mistral\n  vlm:\n    local:\n      model: numind/NuExtract-2.0-8B\n      provider: docling\n\noutput:\n  directory: outputs\n</code></pre>"},{"location":"usage/cli/init-command/#example-local-llm-ollama","title":"Example: Local LLM (Ollama)","text":"<pre><code>defaults:\n  processing_mode: many-to-one\n  backend: llm\n  inference: local\n  export_format: csv\n\nmodels:\n  llm:\n    local:\n      model: llama3:8b\n      provider: ollama\n    remote:\n      model: mistral-small-latest\n      provider: mistral\n  vlm:\n    local:\n      model: numind/NuExtract-2.0-8B\n      provider: docling\n\noutput:\n  directory: outputs\n</code></pre>"},{"location":"usage/cli/init-command/#example-local-llm-lm-studio","title":"Example: Local LLM (LM Studio)","text":"<pre><code>defaults:\n  processing_mode: many-to-one\n  backend: llm\n  inference: local\n  export_format: csv\n\nmodels:\n  llm:\n    local:\n      model: llama-3.2-3b-instruct   # Must match model name in LM Studio\n      provider: lmstudio\n    remote:\n      model: mistral-small-latest\n      provider: mistral\n  vlm:\n    local:\n      model: numind/NuExtract-2.0-8B\n      provider: docling\n\noutput:\n  directory: outputs\n</code></pre>"},{"location":"usage/cli/init-command/#example-vlm-local","title":"Example: VLM (Local)","text":"<pre><code>defaults:\n  processing_mode: one-to-one\n  backend: vlm\n  inference: local\n  export_format: csv\n\ndocling:\n  pipeline: vision\n\nmodels:\n  llm:\n    local:\n      model: ibm-granite/granite-4.0-1b\n      provider: vllm\n    remote:\n      model: mistral-small-latest\n      provider: mistral\n  vlm:\n    local:\n      model: numind/NuExtract-2.0-8B\n      provider: docling\n\noutput:\n  directory: outputs\n</code></pre>"},{"location":"usage/cli/init-command/#example-delta-extraction-with-resolvers","title":"Example: Delta extraction with resolvers","text":"<p>When you select delta and enable resolvers (and optionally customize quality), your <code>defaults</code> will include delta options:</p> <pre><code>defaults:\n  processing_mode: many-to-one\n  extraction_contract: delta\n  delta_resolvers_enabled: true\n  delta_resolvers_mode: semantic\n  delta_quality_max_parent_lookup_miss: 4\n  delta_quality_adaptive_parent_lookup: true\n  delta_quality_require_relationships: false\n  delta_quality_require_structural_attachments: false\n  backend: llm\n  inference: remote\n  export_format: csv\n# ... docling, models, output\n</code></pre> <p>You can then run <code>docling-graph convert ... --extraction-contract delta</code> and the config will be used. See Delta Extraction and convert Command \u2014 Delta Extraction Tuning for details.</p>"},{"location":"usage/cli/init-command/#dependency-validation","title":"Dependency Validation","text":"<p>After configuration, <code>init</code> validates required dependencies:</p>"},{"location":"usage/cli/init-command/#all-dependencies-installed","title":"All Dependencies Installed","text":"<pre><code>\u2705 All required dependencies are installed\n</code></pre>"},{"location":"usage/cli/init-command/#missing-dependencies","title":"Missing Dependencies","text":"<pre><code>\u26a0 Missing dependencies for remote inference\nRun: pip install docling-graph\n</code></pre> <p>Dependencies: - <code>pip install docling-graph</code> installs the package with LiteLLM and all core runtime dependencies. If you installed from source, use <code>uv sync</code> instead.</p>"},{"location":"usage/cli/init-command/#next-steps-guidance","title":"Next Steps Guidance","text":""},{"location":"usage/cli/init-command/#remote-provider-setup","title":"Remote Provider Setup","text":"<pre><code>Next steps:\n1. Install (if not already): pip install docling-graph\n\n2. Set your API key:\n   export MISTRAL_API_KEY=\"your-api-key-here\"\n\n   (If you chose custom endpoint, set instead:)\n   export CUSTOM_LLM_BASE_URL=\"https://your-llm.example.com/v1\"\n   export CUSTOM_LLM_API_KEY=\"your-key\"\n\n3. Run your first conversion:\n   docling-graph convert document.pdf \\\n       --template \"templates.BillingDocument\"\n</code></pre>"},{"location":"usage/cli/init-command/#local-provider-setup","title":"Local Provider Setup","text":"<p>If you selected LM Studio: start the Local Server in the LM Studio app; set <code>LM_STUDIO_API_KEY</code> only if your server requires authentication.</p> <pre><code>Next steps:\n1. Install (if not already): pip install docling-graph\n\n2. Start Ollama server (if using Ollama):\n   ollama serve\n\n3. Pull the model (if using Ollama):\n   ollama pull llama3:8b\n\n4. Run your first conversion:\n   docling-graph convert document.pdf \\\n       --template \"templates.BillingDocument\"\n</code></pre>"},{"location":"usage/cli/init-command/#overwriting-configuration","title":"Overwriting Configuration","text":"<p>If <code>config.yaml</code> already exists:</p> <pre><code>A configuration file: 'config.yaml' already exists.\nOverwrite it? [y/N]:\n</code></pre> <ul> <li>y - Replace existing configuration</li> <li>N - Cancel and keep existing file</li> </ul>"},{"location":"usage/cli/init-command/#non-interactive-mode","title":"Non-Interactive Mode","text":"<p>If interactive mode is unavailable (e.g., in CI/CD):</p> <pre><code>docling-graph init\n# Falls back to default configuration\n</code></pre> <p>Default configuration uses: - Processing: <code>many-to-one</code> - Extraction contract: <code>direct</code> - Backend: <code>llm</code> - Inference: <code>local</code> - Provider: <code>vllm</code> - Export: <code>csv</code></p>"},{"location":"usage/cli/init-command/#complete-examples","title":"Complete Examples","text":""},{"location":"usage/cli/init-command/#first-time-setup","title":"\ud83d\udccd First-Time Setup","text":"<pre><code># Install (if not already)\npip install docling-graph\n\n# Initialize configuration\ndocling-graph init\n\n# Follow prompts:\n# 1. Processing mode (e.g. many-to-one)\n# 2. Extraction contract (direct / staged / delta)\n# 3. (If delta) Resolvers and quality tuning\n# 4. Backend (e.g. LLM), inference (e.g. remote)\n# 5. Docling pipeline and export options\n# 6. Provider and model\n# 7. Export format, output directory\n\n# Set API key\nexport MISTRAL_API_KEY=\"your-key\"\n\n# Test conversion\ndocling-graph convert test.pdf \\\n    --template \"templates.BillingDocument\"\n</code></pre>"},{"location":"usage/cli/init-command/#local-development-setup","title":"\ud83d\udccd Local Development Setup","text":"<pre><code># Install (if not already)\npip install docling-graph\n\n# Initialize for local development\ndocling-graph init\n\n# Follow prompts:\n# 1. Processing mode (e.g. many-to-one)\n# 2. Extraction contract (e.g. direct)\n# 3. Backend (LLM), inference (local)\n# 4. Docling pipeline and export options\n# 5. Provider and model\n# 6. Export format, output directory\n\n# Start Ollama\nollama serve\n\n# Pull model\nollama pull llama3:8b\n\n# Test conversion\ndocling-graph convert test.pdf \\\n    --template \"templates.BillingDocument\"\n</code></pre>"},{"location":"usage/cli/init-command/#vlm-setup","title":"\ud83d\udccd VLM Setup","text":"<pre><code># Install (if not already)\npip install docling-graph\n\n# Initialize for VLM\ndocling-graph init\n\n# Follow prompts:\n# 1. Processing mode (e.g. one-to-one)\n# 2. Extraction contract (e.g. direct)\n# 3. Backend (VLM) \u2014 inference is local only\n# 4. Docling pipeline and export options\n# 5. Model, export format, output directory\n\n# Test conversion\ndocling-graph convert form.jpg \\\n    --template \"templates.IDCard\"\n</code></pre>"},{"location":"usage/cli/init-command/#configuration-file-location","title":"Configuration File Location","text":"<p>The <code>config.yaml</code> file is created in your current working directory:</p> <pre><code># Create config in project root\ncd /path/to/project\ndocling-graph init\n\n# Creates: /path/to/project/config.yaml\n</code></pre> <p>Best Practice: Run <code>init</code> from your project root directory.</p>"},{"location":"usage/cli/init-command/#manual-configuration","title":"Manual Configuration","text":"<p>You can also create <code>config.yaml</code> manually:</p> <pre><code># Minimal configuration\ndefaults:\n  backend: llm\n  inference: remote\n\nmodels:\n  llm:\n    remote:\n      model: mistral-small-latest\n      provider: mistral\n</code></pre> <p>Or use the template:</p> <pre><code># Copy template\ncp docling_graph/config_template.yaml config.yaml\n\n# Edit as needed\nnano config.yaml\n</code></pre>"},{"location":"usage/cli/init-command/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/cli/init-command/#interactive-mode-not-available","title":"\ud83d\udc1b Interactive Mode Not Available","text":"<p>Error: <pre><code>Interactive mode not available. Using default configuration.\n</code></pre></p> <p>Solution: - Running in non-interactive environment (CI/CD) - Default configuration will be used - Manually edit <code>config.yaml</code> if needed</p>"},{"location":"usage/cli/init-command/#permission-denied","title":"\ud83d\udc1b Permission Denied","text":"<p>Error: <pre><code>Error saving config: Permission denied\n</code></pre></p> <p>Solution: <pre><code># Check directory permissions\nls -la\n\n# Run from writable directory\ncd ~/projects/my-project\ndocling-graph init\n</code></pre></p>"},{"location":"usage/cli/init-command/#invalid-configuration","title":"\ud83d\udc1b Invalid Configuration","text":"<p>Error: <pre><code>Error creating config: Invalid backend type\n</code></pre></p> <p>Solution: - Restart <code>init</code> command - Choose valid options (llm/vlm) - Check for typos in manual edits</p>"},{"location":"usage/cli/init-command/#best-practices","title":"Best Practices","text":""},{"location":"usage/cli/init-command/#initialize-per-project","title":"\ud83d\udc4d Initialize Per Project","text":"<pre><code># \u2705 Good - One config per project\ncd project1/\ndocling-graph init\n\ncd project2/\ndocling-graph init\n\n# \u274c Avoid - Shared config across projects\ncd ~/\ndocling-graph init\n</code></pre>"},{"location":"usage/cli/init-command/#version-control","title":"\ud83d\udc4d Version Control","text":"<pre><code># \u2705 Good - Track configuration\ngit add config.yaml\ngit commit -m \"Add docling-graph configuration\"\n\n# Add to .gitignore if it contains secrets\necho \"config.yaml\" &gt;&gt; .gitignore\n</code></pre>"},{"location":"usage/cli/init-command/#environment-specific-configs","title":"\ud83d\udc4d Environment-Specific Configs","text":"<pre><code># Development\ncp config.yaml config.dev.yaml\n\n# Production\ncp config.yaml config.prod.yaml\n\n# Use specific config\ncp config.prod.yaml config.yaml\ndocling-graph convert document.pdf -t \"templates.BillingDocument\"\n</code></pre>"},{"location":"usage/cli/init-command/#next-steps","title":"Next Steps","text":"<p>Now that you have a configuration:</p> <ol> <li>convert Command \u2192 - Convert documents</li> <li>CLI Recipes \u2192 - Common patterns</li> <li>Configuration Guide \u2192 - Advanced config</li> </ol>"},{"location":"usage/cli/inspect-command/","title":"inspect Command","text":""},{"location":"usage/cli/inspect-command/#overview","title":"Overview","text":"<p>The <code>inspect</code> command creates interactive HTML visualizations of your knowledge graphs that open in your browser.</p> <p>Key Features: - Interactive node/edge exploration - CSV and JSON import - Self-contained HTML output - Automatic browser opening - Shareable visualizations</p>"},{"location":"usage/cli/inspect-command/#basic-usage","title":"Basic Usage","text":"<pre><code>uv run docling-graph inspect PATH [OPTIONS]\n</code></pre>"},{"location":"usage/cli/inspect-command/#required-arguments","title":"Required Arguments","text":"Argument Description <code>PATH</code> Path to graph data (directory for CSV, file for JSON)"},{"location":"usage/cli/inspect-command/#example","title":"Example","text":"<pre><code># Visualize CSV output\nuv run docling-graph inspect outputs/\n\n# Visualize JSON output\nuv run docling-graph inspect outputs/graph.json --format json\n</code></pre>"},{"location":"usage/cli/inspect-command/#input-formats","title":"Input Formats","text":""},{"location":"usage/cli/inspect-command/#csv-format-default","title":"CSV Format (Default)","text":"<p>For CSV format, provide a directory containing: - <code>nodes.csv</code> - Node data - <code>edges.csv</code> - Edge data</p> <pre><code>uv run docling-graph inspect outputs/\n</code></pre> <p>Directory structure: <pre><code>outputs/\n\u251c\u2500\u2500 nodes.csv\n\u251c\u2500\u2500 edges.csv\n\u2514\u2500\u2500 ... (other files)\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#json-format","title":"JSON Format","text":"<p>For JSON format, provide a file path to the graph JSON:</p> <pre><code>uv run docling-graph inspect outputs/graph.json --format json\n</code></pre>"},{"location":"usage/cli/inspect-command/#options","title":"Options","text":""},{"location":"usage/cli/inspect-command/#input-format","title":"Input Format","text":"<pre><code>--format {csv|json}\n</code></pre> <p>Default: <code>csv</code></p> <p>Example: <pre><code># CSV format (default)\nuv run docling-graph inspect outputs/\n\n# JSON format\nuv run docling-graph inspect outputs/graph.json --format json\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#output-file","title":"Output File","text":"<pre><code>--output PATH\n</code></pre> <p>Specify where to save the HTML visualization.</p> <p>Default: Temporary file</p> <p>Example: <pre><code># Save to specific location\nuv run docling-graph inspect outputs/ \\\n    --output visualization.html\n\n# Save with timestamp\nuv run docling-graph inspect outputs/ \\\n    --output \"viz_$(date +%Y%m%d_%H%M%S).html\"\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#browser-control","title":"Browser Control","text":"<pre><code>--open / --no-open\n</code></pre> <p>Control whether to automatically open the visualization in your browser.</p> <p>Default: <code>--open</code> (opens automatically)</p> <p>Example: <pre><code># Open automatically (default)\nuv run docling-graph inspect outputs/\n\n# Don't open browser\nuv run docling-graph inspect outputs/ \\\n    --no-open \\\n    --output visualization.html\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#complete-examples","title":"Complete Examples","text":""},{"location":"usage/cli/inspect-command/#quick-visualization","title":"\ud83d\udccd Quick Visualization","text":"<pre><code># Convert document\nuv run docling-graph convert invoice.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --output-dir \"outputs/invoice\"\n\n# Visualize immediately\nuv run docling-graph inspect outputs/invoice/\n</code></pre>"},{"location":"usage/cli/inspect-command/#save-for-later","title":"\ud83d\udccd Save for Later","text":"<pre><code># Create visualization without opening\nuv run docling-graph inspect outputs/ \\\n    --output graph_viz.html \\\n    --no-open\n\n# Open later\nopen graph_viz.html  # macOS\nxdg-open graph_viz.html  # Linux\nstart graph_viz.html  # Windows\n</code></pre>"},{"location":"usage/cli/inspect-command/#json-format_1","title":"\ud83d\udccd JSON Format","text":"<pre><code># Visualize JSON graph\nuv run docling-graph inspect outputs/graph.json \\\n    --format json \\\n    --output interactive_graph.html\n</code></pre>"},{"location":"usage/cli/inspect-command/#batch-visualization","title":"\ud83d\udccd Batch Visualization","text":"<pre><code># Create visualizations for multiple outputs\nfor dir in outputs/*/; do\n    name=$(basename \"$dir\")\n    uv run docling-graph inspect \"$dir\" \\\n        --output \"visualizations/${name}.html\" \\\n        --no-open\ndone\n\necho \"Created visualizations in visualizations/\"\n</code></pre>"},{"location":"usage/cli/inspect-command/#share-visualization","title":"\ud83d\udccd Share Visualization","text":"<pre><code># Create self-contained HTML\nuv run docling-graph inspect outputs/ \\\n    --output shared_graph.html \\\n    --no-open\n\n# Share the HTML file\n# The file contains all data and can be opened anywhere\n</code></pre>"},{"location":"usage/cli/inspect-command/#interactive-features","title":"Interactive Features","text":""},{"location":"usage/cli/inspect-command/#node-exploration","title":"Node Exploration","text":"<p>Click on a node to: - View node properties - Highlight connected edges - See relationship details - Filter by node type</p>"},{"location":"usage/cli/inspect-command/#edge-exploration","title":"Edge Exploration","text":"<p>Click on an edge to: - View relationship type - See source and target nodes - View edge properties</p>"},{"location":"usage/cli/inspect-command/#graph-navigation","title":"Graph Navigation","text":"<p>Controls: - Zoom: Mouse wheel or pinch - Pan: Click and drag - Reset: Double-click background - Search: Use search box to find nodes</p>"},{"location":"usage/cli/inspect-command/#layout-options","title":"Layout Options","text":"<p>Available layouts: - Force-directed: Automatic positioning - Hierarchical: Top-down structure - Circular: Nodes in a circle - Grid: Regular grid layout</p>"},{"location":"usage/cli/inspect-command/#output-structure","title":"Output Structure","text":""},{"location":"usage/cli/inspect-command/#html-file-contents","title":"HTML File Contents","text":"<p>The generated HTML file is self-contained and includes: - Complete graph data - Interactive visualization library - Styling and controls - No external dependencies</p> <p>File size: Typically 100KB - 2MB depending on graph size</p>"},{"location":"usage/cli/inspect-command/#sharing","title":"Sharing","text":"<pre><code># Create visualization\nuv run docling-graph inspect outputs/ \\\n    --output graph.html \\\n    --no-open\n\n# Share via email, cloud storage, or web hosting\n# Recipients can open directly in any modern browser\n</code></pre>"},{"location":"usage/cli/inspect-command/#validation","title":"Validation","text":""},{"location":"usage/cli/inspect-command/#csv-validation","title":"CSV Validation","text":"<p>The command validates that required files exist:</p> <pre><code>uv run docling-graph inspect outputs/\n</code></pre> <p>Checks: - Directory exists - <code>nodes.csv</code> exists - <code>edges.csv</code> exists</p> <p>Error if missing: <pre><code>[bold red]Error:[/bold red] nodes.csv not found in outputs/\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#json-validation","title":"JSON Validation","text":"<pre><code>uv run docling-graph inspect graph.json --format json\n</code></pre> <p>Checks: - File exists - File has <code>.json</code> extension - Valid JSON format</p> <p>Error if invalid: <pre><code>[bold red]Error:[/bold red] For JSON format, path must be a .json file\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/cli/inspect-command/#files-not-found","title":"\ud83d\udc1b Files Not Found","text":"<p>Error: <pre><code>[bold red]Error:[/bold red] nodes.csv not found in outputs/\n</code></pre></p> <p>Solution: <pre><code># Check directory contents\nls outputs/\n\n# Ensure convert completed successfully\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --output-dir \"outputs\"\n\n# Then inspect\nuv run docling-graph inspect outputs/\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#browser-doesnt-open","title":"\ud83d\udc1b Browser Doesn't Open","text":"<p>Error: <pre><code>Browser failed to open\n</code></pre></p> <p>Solution: <pre><code># Save to file and open manually\nuv run docling-graph inspect outputs/ \\\n    --output graph.html \\\n    --no-open\n\n# Open manually\nopen graph.html  # macOS\nxdg-open graph.html  # Linux\nstart graph.html  # Windows\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#large-graph-performance","title":"\ud83d\udc1b Large Graph Performance","text":"<p>Visualization is slow with large graphs</p> <p>Solution: <pre><code># Filter graph before visualization\n# Use Python to create smaller subset\n\n# Or use Neo4j for large graphs\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --export-format cypher\n\n# Import to Neo4j and use Neo4j Browser\n</code></pre></p>"},{"location":"usage/cli/inspect-command/#integration-workflows","title":"Integration Workflows","text":""},{"location":"usage/cli/inspect-command/#workflow-1-development-cycle","title":"Workflow 1: Development Cycle","text":"<pre><code># 1. Convert document\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --output-dir \"test_output\"\n\n# 2. Inspect results\nuv run docling-graph inspect test_output/\n\n# 3. Iterate on template\n# Edit templates/billing_document.py\n\n# 4. Re-convert and inspect\nuv run docling-graph convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --output-dir \"test_output\"\n\nuv run docling-graph inspect test_output/\n</code></pre>"},{"location":"usage/cli/inspect-command/#workflow-2-batch-processing-with-visualization","title":"Workflow 2: Batch Processing with Visualization","text":"<pre><code>#!/bin/bash\n# process_and_visualize.sh\n\nINPUT_DIR=\"documents\"\nOUTPUT_BASE=\"outputs\"\nVIZ_DIR=\"visualizations\"\n\nmkdir -p \"$VIZ_DIR\"\n\nfor pdf in \"$INPUT_DIR\"/*.pdf; do\n    name=$(basename \"$pdf\" .pdf)\n    output_dir=\"$OUTPUT_BASE/$name\"\n\n    echo \"Processing: $name\"\n\n    # Convert\n    uv run docling-graph convert \"$pdf\" \\\n        --template \"templates.BillingDocument\" \\\n        --output-dir \"$output_dir\"\n\n    # Visualize\n    uv run docling-graph inspect \"$output_dir\" \\\n        --output \"$VIZ_DIR/${name}.html\" \\\n        --no-open\n\n    echo \"Completed: $name\"\ndone\n\necho \"All visualizations saved to $VIZ_DIR/\"\n</code></pre>"},{"location":"usage/cli/inspect-command/#workflow-3-quality-assurance","title":"Workflow 3: Quality Assurance","text":"<pre><code># Convert with verbose logging\nuv run docling-graph --verbose convert document.pdf \\\n    --template \"templates.BillingDocument\" \\\n    --output-dir \"qa_output\"\n\n# Inspect graph structure\nuv run docling-graph inspect qa_output/\n\n# Check statistics\ncat qa_output/graph_stats.json\n\n# Review markdown report\ncat qa_output/markdown_report.md\n</code></pre>"},{"location":"usage/cli/inspect-command/#comparison-with-other-tools","title":"Comparison with Other Tools","text":""},{"location":"usage/cli/inspect-command/#inspect-vs-neo4j-browser","title":"inspect vs Neo4j Browser","text":"Feature inspect Neo4j Browser Setup No setup required Requires Neo4j installation Sharing Self-contained HTML Requires Neo4j access Performance Good for small/medium graphs Excellent for large graphs Querying Basic filtering Full Cypher queries Best for Quick visualization, sharing Production, complex queries"},{"location":"usage/cli/inspect-command/#when-to-use-inspect","title":"When to Use inspect","text":"<p>\u2705 Use inspect for: - Quick visualization during development - Sharing results with non-technical users - Small to medium graphs (&lt;1000 nodes) - No database setup required</p> <p>\u274c Use Neo4j for: - Large graphs (&gt;1000 nodes) - Complex queries - Production deployments - Team collaboration</p>"},{"location":"usage/cli/inspect-command/#best-practices","title":"Best Practices","text":""},{"location":"usage/cli/inspect-command/#save-important-visualizations","title":"\ud83d\udc4d Save Important Visualizations","text":"<pre><code># \u2705 Good - Save with descriptive name\nuv run docling-graph inspect outputs/ \\\n    --output \"invoice_001_graph.html\" \\\n    --no-open\n\n# \u274c Avoid - Temporary files get lost\nuv run docling-graph inspect outputs/\n</code></pre>"},{"location":"usage/cli/inspect-command/#organize-visualizations","title":"\ud83d\udc4d Organize Visualizations","text":"<pre><code># \u2705 Good - Organized structure\nmkdir -p visualizations/invoices\nuv run docling-graph inspect outputs/invoice_001/ \\\n    --output \"visualizations/invoices/invoice_001.html\" \\\n    --no-open\n\n# \u274c Avoid - Cluttered directory\nuv run docling-graph inspect outputs/ \\\n    --output \"viz1.html\" \\\n    --no-open\n</code></pre>"},{"location":"usage/cli/inspect-command/#use-for-development","title":"\ud83d\udc4d Use for Development","text":"<pre><code># \u2705 Good - Quick feedback loop\nuv run docling-graph convert test.pdf -t \"templates.BillingDocument\" -o \"test\"\nuv run docling-graph inspect test/\n\n# \u2705 Good - Iterate quickly\n# Edit template, re-run, inspect\n</code></pre>"},{"location":"usage/cli/inspect-command/#next-steps","title":"Next Steps","text":"<ol> <li>CLI Recipes \u2192 - Common CLI patterns</li> <li>Visualization Guide \u2192 - Advanced visualization</li> <li>Neo4j Integration \u2192 - Database visualization</li> </ol>"},{"location":"usage/examples/","title":"Examples","text":""},{"location":"usage/examples/#overview","title":"Overview","text":"<p>This section provides complete, end-to-end examples organized by both input format and domain/use case. Each example demonstrates how to process different types of documents through the Docling Graph pipeline.</p> <p>What's Covered: - Complete Pydantic templates - CLI and Python API usage - Expected outputs and graph structures - Troubleshooting tips - Best practices</p>"},{"location":"usage/examples/#quick-navigation","title":"Quick Navigation","text":""},{"location":"usage/examples/#by-input-format","title":"By Input Format","text":"Example Input Type Backend Quickstart PDF/Image VLM/LLM URL Input URL LLM Markdown Input Markdown LLM DoclingDocument Input JSON LLM"},{"location":"usage/examples/#by-domain","title":"By Domain","text":"Example Domain Input Billing Document Extraction Business PDF/Image ID Card Identity Image Insurance Policy Legal PDF Rheology Research Academic PDF Format OCR Required Processing Speed Backend Support Best For PDF \u2705 Yes \ud83d\udc22 Slow LLM + VLM Scanned documents, forms Image \u2705 Yes \ud83d\udc22 Slow LLM + VLM Photos, scans URL Depends \u26a1 Variable LLM + VLM Remote documents Markdown \u274c No \u26a1 Fast LLM only Documentation, notes DoclingDocument \u274c No \u26a1 Very Fast LLM only Reprocessing, experimentation"},{"location":"usage/examples/#choosing-the-right-example","title":"Choosing the Right Example","text":"<p>New to Docling Graph? \u2192 Quickstart</p> <p>By Input Format: - Web documents \u2192 URL Input - Documentation \u2192 Markdown Input - Reprocessing \u2192 DoclingDocument Input</p> <p>By Domain: - Business \u2192 Billing Document Extraction - Identity \u2192 ID Card - Legal \u2192 Insurance Policy - Academic \u2192 Rheology Research</p>"},{"location":"usage/examples/#workflow-1-url-extract-visualize","title":"Workflow 1: URL \u2192 Extract \u2192 Visualize","text":"<pre><code># Download and process in one step\nuv run docling-graph convert \"https://arxiv.org/pdf/2207.02720\" \\\n    --template \"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --processing-mode \"many-to-one\"\n\n# Visualize results\nuv run docling-graph inspect outputs\n</code></pre>"},{"location":"usage/examples/#workflow-2-pdf-doclingdocument-reprocess","title":"Workflow 2: PDF \u2192 DoclingDocument \u2192 Reprocess","text":"<pre><code># Step 1: Initial processing with DoclingDocument export\nuv run docling-graph convert billing_doc.pdf \\\n    --template \"templates.billing_document.BasicBillingDocument\" \\\n    --export-docling-json\n\n# Step 2: Reprocess with different template (no OCR)\nuv run docling-graph convert outputs/billing_doc_docling.json \\\n    --template \"templates.billing_document.DetailedBillingDocument\"\n</code></pre>"},{"location":"usage/examples/#workflow-3-batch-markdown-processing","title":"Workflow 3: Batch Markdown Processing","text":"<pre><code># Process all markdown files\nfor file in docs/**/*.md; do\n    uv run docling-graph convert \"$file\" \\\n        --template \"templates.documentation.Documentation\" \\\n        --backend llm \\\n        --output-dir \"outputs/$(basename $file .md)\"\ndone\n</code></pre>"},{"location":"usage/examples/#template-examples","title":"Template Examples","text":""},{"location":"usage/examples/#simple-entity","title":"Simple Entity","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n    model_config = {'is_entity': True, 'graph_id_fields': ['name']}\n    name: str = Field(description=\"Person's name\")\n</code></pre>"},{"location":"usage/examples/#with-relationships","title":"With Relationships","text":"<pre><code>from docling_graph.utils import edge\n\nclass Organization(BaseModel):\n    name: str\n    employees: list[Person] = edge(\"EMPLOYS\")\n</code></pre> <p>See individual example pages for complete templates.</p>"},{"location":"usage/examples/#additional-resources","title":"Additional Resources","text":""},{"location":"usage/examples/#documentation","title":"Documentation","text":"<ul> <li>Input Formats Guide - Complete input format reference</li> <li>Backend Selection - Choose LLM vs VLM</li> <li>Processing Modes - One-to-one vs many-to-one</li> </ul>"},{"location":"usage/examples/#api-reference","title":"API Reference","text":"<ul> <li>PipelineConfig - Configuration options</li> <li>run_pipeline - Pipeline execution</li> <li>Batch Processing - Process multiple documents</li> </ul>"},{"location":"usage/examples/#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Performance Tuning - Optimize processing</li> <li>Error Handling - Handle failures gracefully</li> <li>Custom Backends - Extend functionality</li> </ul>"},{"location":"usage/examples/#getting-help","title":"Getting Help","text":""},{"location":"usage/examples/#common-issues","title":"Common Issues","text":"<p>\"VLM backend does not support text-only inputs\" \u2192 Use <code>--backend llm</code> for Markdown and text files</p> <p>\"URL download timeout\" \u2192 Increase timeout or download manually first</p> <p>\"Text input is empty\" \u2192 Check file content and encoding</p> <p>\"Invalid DoclingDocument schema\" \u2192 Verify <code>schema_name</code> and <code>version</code> fields</p>"},{"location":"usage/examples/#support","title":"Support","text":"<ul> <li>Documentation: https://ibm.github.io/docling-graph</li> <li>GitHub Issues: https://github.com/docling-project/docling-graph/issues</li> <li>Discussions: https://github.com/docling-project/docling-graph/discussions</li> </ul>"},{"location":"usage/examples/#next-steps","title":"Next Steps","text":"<ol> <li>Explore Input Formats - Learn about all supported formats</li> <li>Read Advanced Topics - Optimize your workflows</li> </ol>"},{"location":"usage/examples/billing-document/","title":"Billing Document Extraction","text":""},{"location":"usage/examples/billing-document/#overview","title":"Overview","text":"<p>Extract complete structured data from billing documents (invoices, credit notes, receipts, etc.) including parties, line items, taxes, and payment information.</p> <p>Document Type: Billing Documents (PDF/JPG) Time: 15 minutes Backend: VLM (recommended) or LLM</p>"},{"location":"usage/examples/billing-document/#prerequisites","title":"Prerequisites","text":"<pre><code># Install\npip install docling-graph\n\n# Verify installation\nuv run docling-graph --version\n</code></pre>"},{"location":"usage/examples/billing-document/#template-reference","title":"Template Reference","text":"<p>The <code>BillingDocument</code> template is a streamlined schema located at: <code>docs/examples/templates/billing_document.py</code></p>"},{"location":"usage/examples/billing-document/#key-features","title":"Key Features","text":"<ul> <li>Multiple Document Types: Invoice, Credit Note, Debit Note, Receipt</li> <li>Simplified Structure: 10 core classes (reduced from 40+)</li> <li>Embedded Fields: Contact info and totals directly in parent classes</li> <li>Clear Extraction Prompts: Each field has \"LOOK FOR\", \"EXTRACT\", and \"EXAMPLES\" sections</li> <li>Essential Tax Handling: VAT, GST, Sales Tax support</li> <li>Payment Methods: Bank transfer, card, cash, direct debit</li> </ul>"},{"location":"usage/examples/billing-document/#root-model","title":"Root Model","text":"<pre><code>from examples.templates.billing_document import BillingDocument\n\n# The root entity with document_number as unique identifier\nclass BillingDocument(BaseModel):\n    \"\"\"Root billing document entity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"document_number\"])\n\n    # Core fields\n    document_number: str  # Primary identifier (e.g., \"INV-2024-001\")\n    document_type: DocumentType  # INVOICE, CREDIT_NOTE, RECEIPT, etc.\n    issue_date: date | None\n    due_date: date | None\n    currency: str | None  # ISO 4217 code (EUR, USD, GBP)\n\n    # Financial totals (embedded)\n    subtotal: float | None\n    discount_total: float | None\n    tax_total: float | None\n    total_amount: float | None\n    balance_due: float | None\n\n    # Relationships (edges)\n    seller: Party  # Who issued the document\n    buyer: Party | None  # Who receives it\n    line_items: List[LineItem]  # Line items\n    taxes: List[Tax]  # Tax breakdown\n    payment: Payment | None  # Payment info\n    delivery: Delivery | None  # Delivery info\n    references: List[DocumentReference]  # Related documents\n</code></pre>"},{"location":"usage/examples/billing-document/#simplified-party-model","title":"Simplified Party Model","text":"<pre><code>class Party(BaseModel):\n    \"\"\"Party with embedded contact and address information.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"name\", \"tax_id\"])\n\n    name: str  # Company/person name\n    tax_id: str | None  # VAT/Tax ID\n\n    # Contact info (embedded)\n    email: str | None\n    phone: str | None\n    website: str | None\n\n    # Address (embedded)\n    street: str | None\n    city: str | None\n    postal_code: str | None\n    country: str | None\n</code></pre>"},{"location":"usage/examples/billing-document/#simplified-lineitem-model","title":"Simplified LineItem Model","text":"<pre><code>class LineItem(BaseModel):\n    \"\"\"Line item with embedded price and quantity.\"\"\"\n    model_config = ConfigDict(graph_id_fields=[\"line_number\", \"item_code\"])\n\n    line_number: str  # Line position\n    description: str | None\n\n    # Quantity and price (embedded)\n    quantity: float | None\n    unit: str | None  # EA, KG, HUR, etc.\n    unit_price: float | None\n    discount_percent: float | None\n    line_total: float | None\n\n    # Relationships\n    item: Item | None  # Product/service reference\n    tax: Tax | None  # Tax for this line\n</code></pre>"},{"location":"usage/examples/billing-document/#usage-examples","title":"Usage Examples","text":""},{"location":"usage/examples/billing-document/#cli-process-image","title":"CLI - Process Image","text":"<pre><code># Process billing document image with VLM\nuv run docling-graph convert \"https://upload.wikimedia.org/wikipedia/commons/9/9f/Swiss_QR-Bill_example.jpg\" \\\n    --template \"docs.examples.templates.billing_document.BillingDocument\" \\\n    --backend vlm \\\n    --processing-mode one-to-one \\\n    --output-dir \"outputs/billing_doc\"\n</code></pre>"},{"location":"usage/examples/billing-document/#cli-process-pdf","title":"CLI - Process PDF","text":"<pre><code># Process PDF with LLM\nuv run docling-graph convert billing_document.pdf \\\n    --template \"docs.examples.templates.billing_document.BillingDocument\" \\\n    --backend llm \\\n    --inference remote \\\n    --output-dir \"outputs/billing_doc\"\n</code></pre>"},{"location":"usage/examples/billing-document/#python-api","title":"Python API","text":"<p>File: <code>process_billing_doc.py</code></p> <pre><code>\"\"\"Process billing document using Python API.\"\"\"\n\nfrom docling_graph import PipelineConfig, run_pipeline\n\nconfig = PipelineConfig(\n    source=\"https://upload.wikimedia.org/wikipedia/commons/9/9f/Swiss_QR-Bill_example.jpg\",\n    template=\"docs.examples.templates.billing_document.BillingDocument\",\n    backend=\"vlm\",\n    inference=\"local\",\n    processing_mode=\"one-to-one\"\n)\n\n# Run extraction\nprint(\"Processing billing document...\")\ncontext = run_pipeline(config)\ngraph = context.knowledge_graph\nprint(f\"\u2705 Complete! Extracted {graph.number_of_nodes()} nodes\")\n</code></pre> <p>Run: <pre><code>uv run python process_billing_doc.py\n</code></pre></p>"},{"location":"usage/examples/billing-document/#expected-output","title":"Expected Output","text":""},{"location":"usage/examples/billing-document/#graph-structure","title":"Graph Structure","text":"<pre><code>BillingDocument (root)\n  \u251c\u2500 ISSUED_BY \u2192 Party (Seller/Supplier)\n  \u2502   \u251c\u2500 name: \"Acme Corp\"\n  \u2502   \u251c\u2500 email: \"contact@acme.com\"\n  \u2502   \u251c\u2500 street: \"123 Main St\"\n  \u2502   \u2514\u2500 city: \"Paris\"\n  \u251c\u2500 BILLED_TO \u2192 Party (Buyer/Customer)\n  \u2502   \u251c\u2500 name: \"Client Inc\"\n  \u2502   \u2514\u2500 email: \"billing@client.com\"\n  \u251c\u2500 CONTAINS_LINE \u2192 LineItem (multiple)\n  \u2502   \u251c\u2500 line_number: \"1\"\n  \u2502   \u251c\u2500 quantity: 10.0\n  \u2502   \u251c\u2500 unit_price: 50.00\n  \u2502   \u251c\u2500 REFERENCES_ITEM \u2192 Item\n  \u2502   \u2514\u2500 HAS_TAX \u2192 Tax\n  \u251c\u2500 HAS_TAX \u2192 Tax (document-level)\n  \u2514\u2500 HAS_PAYMENT_INFO \u2192 Payment\n      \u251c\u2500 method: \"Bank Transfer\"\n      \u251c\u2500 iban: \"FR76...\"\n      \u2514\u2500 due_date: \"2024-02-15\"\n</code></pre>"},{"location":"usage/examples/billing-document/#files-generated","title":"Files Generated","text":"<p>outputs/billing_doc/docling_graph/</p> <ul> <li><code>nodes.csv</code> - All entities and components</li> <li><code>edges.csv</code> - Relationships between nodes</li> <li><code>graph.json</code> - Complete graph structure</li> <li><code>graph.html</code> - Interactive visualization</li> <li><code>report.md</code> - Extraction statistics</li> </ul>"},{"location":"usage/examples/billing-document/#sample-nodescsv","title":"Sample nodes.csv","text":"<pre><code>id,label,type,document_number,document_type,issue_date,total_amount,name,email,city\ndoc_1,BillingDocument,entity,INV-2024-001,Invoice,2024-01-15,1075.00,,,\nparty_1,Party,entity,,,,,Acme Corp,contact@acme.com,Paris\nparty_2,Party,entity,,,,,Client Inc,billing@client.com,London\nline_1,LineItem,entity,1,,,50.00,,,\nitem_1,Item,entity,,,,,Widget Pro,,\n</code></pre>"},{"location":"usage/examples/billing-document/#sample-edgescsv","title":"Sample edges.csv","text":"<pre><code>source,target,label\ndoc_1,party_1,ISSUED_BY\ndoc_1,party_2,BILLED_TO\ndoc_1,line_1,CONTAINS_LINE\nline_1,item_1,REFERENCES_ITEM\nline_1,tax_1,HAS_TAX\ndoc_1,payment_1,HAS_PAYMENT_INFO\n</code></pre>"},{"location":"usage/examples/billing-document/#visualization","title":"Visualization","text":"<pre><code># Open interactive visualization\nuv run docling-graph inspect outputs/billing_doc/\n</code></pre> <p>Features: - Interactive node exploration - Relationship filtering - Property inspection - Export capabilities</p>"},{"location":"usage/examples/billing-document/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/examples/billing-document/#export-as-cypher-for-neo4j","title":"Export as Cypher for Neo4j","text":"<pre><code># Export as Cypher script\nuv run docling-graph convert billing_document.pdf \\\n    --template \"docs.examples.templates.billing_document.BillingDocument\" \\\n    --export-format cypher \\\n    --output-dir \"outputs/neo4j\"\n\n# Import to Neo4j\ncat outputs/neo4j/docling_graph/graph.cypher | cypher-shell -u neo4j -p password\n</code></pre>"},{"location":"usage/examples/billing-document/#batch-processing","title":"Batch Processing","text":"<pre><code>\"\"\"Process multiple billing documents.\"\"\"\n\nfrom pathlib import Path\nfrom docling_graph import PipelineConfig, run_pipeline\n\ndocuments = [\n    \"https://example.com/invoice1.pdf\",\n    \"https://example.com/invoice2.pdf\",\n    \"https://example.com/credit_note1.pdf\",\n]\n\nfor doc in documents:\n    doc_name = Path(doc).stem\n    config = PipelineConfig(\n        source=doc,\n        template=\"docs.examples.templates.billing_document.BillingDocument\",\n        backend=\"llm\"\n    )\n\n    try:\n        run_pipeline(config)\n        print(f\"\u2705 {doc_name}\")\n    except Exception as e:\n        print(f\"\u274c {doc_name}: {e}\")\n</code></pre>"},{"location":"usage/examples/billing-document/#document-types-supported","title":"Document Types Supported","text":"<p>The <code>BillingDocument</code> template supports multiple document types:</p> Type Description Use Case INVOICE Standard invoice Sales, services CREDIT_NOTE Credit memo Returns, corrections DEBIT_NOTE Debit memo Additional charges RECEIPT Payment receipt Proof of payment OTHER Other billing docs Custom types <p>The <code>document_type</code> field automatically normalizes various input formats.</p>"},{"location":"usage/examples/billing-document/#key-fields-reference","title":"Key Fields Reference","text":""},{"location":"usage/examples/billing-document/#core-document-fields","title":"Core Document Fields","text":"<pre><code>document_number: str          # \"INV-2024-001\" (required, unique ID)\ndocument_type: DocumentType   # INVOICE, CREDIT_NOTE, RECEIPT, etc.\nissue_date: date | None       # Document issue date\ndue_date: date | None         # Payment due date\ncurrency: str | None          # \"EUR\", \"USD\", \"GBP\" (ISO 4217)\nnotes: str | None             # General notes or remarks\n</code></pre>"},{"location":"usage/examples/billing-document/#financial-totals-embedded","title":"Financial Totals (Embedded)","text":"<pre><code>subtotal: float | None        # Subtotal before tax and discounts\ndiscount_total: float | None  # Total discount amount\ntax_total: float | None       # Total tax amount\ntotal_amount: float | None    # Final total (including tax)\namount_paid: float | None     # Amount already paid\nbalance_due: float | None     # Remaining balance\n</code></pre>"},{"location":"usage/examples/billing-document/#party-information","title":"Party Information","text":"<pre><code>seller: Party                 # Seller/supplier (required)\nbuyer: Party | None           # Customer/buyer\n</code></pre> <p>Party fields: <pre><code>name: str                     # Company/person name\ntax_id: str | None            # VAT/Tax ID\nemail: str | None             # Email address\nphone: str | None             # Phone number\nwebsite: str | None           # Website URL\nstreet: str | None            # Street address\ncity: str | None              # City\npostal_code: str | None       # Postal/ZIP code\ncountry: str | None           # Country name or code\n</code></pre></p>"},{"location":"usage/examples/billing-document/#line-items","title":"Line Items","text":"<pre><code>line_items: List[LineItem]    # Line items with products/services\n</code></pre> <p>LineItem fields: <pre><code>line_number: str              # Line position (required)\ndescription: str | None       # Item description\nquantity: float | None        # Quantity\nunit: str | None              # Unit of measure (EA, KG, etc.)\nunit_price: float | None      # Price per unit\ndiscount_percent: float | None # Discount percentage\nline_total: float | None      # Total for this line\nitem: Item | None             # Product/service reference\ntax: Tax | None               # Tax for this line\n</code></pre></p>"},{"location":"usage/examples/billing-document/#tax-information","title":"Tax Information","text":"<pre><code>taxes: List[Tax]              # Tax breakdown\n</code></pre> <p>Tax fields: <pre><code>tax_type: TaxType             # VAT, GST, SALES_TAX, OTHER\nrate_percent: float | None    # Tax rate (e.g., 20.0)\ntaxable_amount: float | None  # Amount on which tax is calculated\ntax_amount: float | None      # Calculated tax amount\nexemption_reason: str | None  # Exemption reason if applicable\n</code></pre></p>"},{"location":"usage/examples/billing-document/#payment-information","title":"Payment Information","text":"<pre><code>payment: Payment | None       # Payment details\n</code></pre> <p>Payment fields: <pre><code>method: PaymentMethod         # BANK_TRANSFER, CARD, CASH, etc.\ndue_date: date | None         # Payment due date\nterms: str | None             # Payment terms (e.g., \"Net 30\")\nbank_name: str | None         # Bank name\niban: str | None              # IBAN\nbic: str | None               # BIC/SWIFT code\nreference: str | None         # Payment reference\n</code></pre></p>"},{"location":"usage/examples/billing-document/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/billing-document/#field-descriptions-with-extraction-hints","title":"Field Descriptions with Extraction Hints","text":"<p>The simplified template includes enhanced extraction prompts:</p> <pre><code># \u2705 Good - Specific with visual cues\ndocument_number: str = Field(\n    ...,\n    description=(\n        \"Invoice/document number (primary identifier). \"\n        \"LOOK FOR: Large, bold text in header, 'Invoice No', 'Invoice Number', \"\n        \"'Receipt No', 'Facture No' labels (usually top right). \"\n        \"EXTRACT: Complete number including prefixes/suffixes. \"\n        \"EXAMPLES: 'INV-2024-001', '2024-INV-12345', 'REC-001'\"\n    ),\n    examples=[\"INV-2024-001\", \"2024-INV-12345\", \"REC-001\"],\n)\n\n# \u274c Avoid - Vague\ndocument_number: str = Field(description=\"Document number\")\n</code></pre>"},{"location":"usage/examples/billing-document/#required-vs-optional","title":"Required vs Optional","text":"<pre><code># Required fields\ndocument_number: str          # Always needed for identification\nseller: Party                 # Always present\n\n# Optional fields\nbuyer: Party | None = None    # May not be present\ndue_date: date | None = None  # Not all documents have due dates\npayment: Payment | None = None # Not all documents have payment info\n</code></pre>"},{"location":"usage/examples/billing-document/#validation","title":"Validation","text":"<p>The template includes essential validators:</p> <ul> <li>Currency format validation (ISO 4217)</li> <li>Enum normalization (handles various input formats)</li> <li>Automatic currency symbol conversion (\u20ac \u2192 EUR, $ \u2192 USD, \u00a3 \u2192 GBP)</li> </ul>"},{"location":"usage/examples/billing-document/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/billing-document/#common-issues","title":"Common Issues","text":"<p>\"Field document_number is required\" \u2192 Ensure the document has a visible document number</p> <p>\"Currency must be 3 uppercase letters\" \u2192 Use ISO 4217 codes: EUR, USD, GBP (symbols are auto-converted)</p> <p>\"Cannot normalize enum value\" \u2192 Check DocumentType values match: INVOICE, CREDIT_NOTE, RECEIPT, OTHER</p>"},{"location":"usage/examples/billing-document/#improving-extraction-quality","title":"Improving Extraction Quality","text":"<ol> <li>Use VLM for images - Better layout understanding</li> <li>Provide clear examples - Template includes diverse examples</li> <li>Use vision pipeline - For complex layouts: <code>--docling-config vision</code></li> <li>Enable chunking - For large documents: <code>--use-chunking</code></li> </ol>"},{"location":"usage/examples/billing-document/#template-simplification-v200","title":"Template Simplification (v2.0.0)","text":"<p>The template has been significantly simplified:</p> <ul> <li>Reduced from 2230 lines to 717 lines (68% reduction)</li> <li>Reduced from 40+ classes to 10 core classes</li> <li>Embedded contact info - Email, phone, address directly in Party</li> <li>Embedded totals - Financial totals directly in BillingDocument</li> <li>Simplified line items - Direct fields instead of nested objects</li> <li>Better extraction prompts - Clear \"LOOK FOR\", \"EXTRACT\", \"EXAMPLES\" sections</li> </ul> <p>See <code>BILLING_DOCUMENT_CHANGELOG.md</code> for detailed migration guide.</p>"},{"location":"usage/examples/billing-document/#related-examples","title":"Related Examples","text":"<ul> <li>ID Card Extraction - Identity documents</li> <li>Insurance Policy - Legal documents</li> <li>Batch Processing - Multiple documents</li> </ul>"},{"location":"usage/examples/billing-document/#additional-resources","title":"Additional Resources","text":""},{"location":"usage/examples/billing-document/#documentation","title":"Documentation","text":"<ul> <li>Schema Definition - Template creation guide</li> <li>Graph Management - Working with graphs</li> <li>Neo4j Integration - Database import</li> </ul>"},{"location":"usage/examples/billing-document/#template-source","title":"Template Source","text":"<ul> <li>Full Template: <code>docs/examples/templates/billing_document.py</code></li> <li>717 lines (simplified from 2230)</li> <li>10 core classes with clear extraction prompts</li> <li>Changelog: <code>docs/examples/templates/BILLING_DOCUMENT_CHANGELOG.md</code></li> </ul>"},{"location":"usage/examples/billing-document/#next-steps","title":"Next Steps","text":"<ol> <li>Try the example - Process a sample billing document</li> <li>Customize template - Adapt for your specific needs</li> <li>Integrate with Neo4j - Build a document knowledge base</li> <li>Automate workflows - Set up batch processing pipelines</li> </ol>"},{"location":"usage/examples/docling-document-input/","title":"DoclingDocument Input Example","text":""},{"location":"usage/examples/docling-document-input/#overview","title":"Overview","text":"<p>This example demonstrates how to process pre-converted DoclingDocument JSON files, enabling reprocessing of documents without re-running OCR or document conversion.</p> <p>Time: 10 minutes</p>"},{"location":"usage/examples/docling-document-input/#use-case-billingdocument-reprocessing","title":"Use Case: BillingDocument Reprocessing","text":"<p>Reprocess a previously converted invoice document with a different template or extraction strategy, without re-running expensive OCR operations.</p>"},{"location":"usage/examples/docling-document-input/#document-source","title":"Document Source","text":"<p>File: <code>invoice_docling.json</code></p> <p>Type: DoclingDocument JSON</p> <p>Content: Pre-processed invoice with structure, text, and layout information.</p>"},{"location":"usage/examples/docling-document-input/#creating-doclingdocument-files","title":"Creating DoclingDocument Files","text":""},{"location":"usage/examples/docling-document-input/#method-1-export-from-docling-graph","title":"Method 1: Export from Docling Graph","text":"<pre><code># First run: Convert PDF and export DoclingDocument\nuv run docling-graph convert invoice.pdf \\\n    --template \"templates.billing_document.BillingDocument\" \\\n    --export-docling-json\n\n# This creates: outputs/invoice_docling.json\n</code></pre>"},{"location":"usage/examples/docling-document-input/#method-2-use-docling-directly","title":"Method 2: Use Docling Directly","text":"<pre><code>from docling.document_converter import DocumentConverter\n\n# Convert document with Docling\nconverter = DocumentConverter()\nresult = converter.convert(\"invoice.pdf\")\n\n# Export DoclingDocument\nwith open(\"invoice_docling.json\", \"w\") as f:\n    f.write(result.document.model_dump_json(indent=2))\n</code></pre>"},{"location":"usage/examples/docling-document-input/#method-3-custom-pipeline","title":"Method 3: Custom Pipeline","text":"<pre><code>from docling_core.types.doc import DoclingDocument\nimport json\n\n# Create custom DoclingDocument\ndoc = DoclingDocument(\n    schema_name=\"DoclingDocument\",\n    version=\"1.0.0\",\n    name=\"custom_invoice\",\n    # ... add pages, body, furniture\n)\n\n# Save to JSON\nwith open(\"custom_docling.json\", \"w\") as f:\n    json.dump(doc.model_dump(), f, indent=2)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#template-definition","title":"Template Definition","text":"<p>We'll use an invoice template for this example.</p> <pre><code>from pydantic import BaseModel, Field\nfrom docling_graph.utils import edge\n\nclass Address(BaseModel):\n    \"\"\"Address component.\"\"\"\n    model_config = {'is_entity': False}\n\n    street: str = Field(description=\"Street address\")\n    city: str = Field(description=\"City\")\n    postal_code: str = Field(description=\"Postal code\")\n    country: str = Field(description=\"Country\")\n\nclass Company(BaseModel):\n    \"\"\"Company entity.\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['name']\n    }\n\n    name: str = Field(description=\"Company name\")\n    address: Address = Field(description=\"Company address\")\n    tax_id: str | None = Field(default=None, description=\"Tax ID\")\n\nclass LineItem(BaseModel):\n    \"\"\"Invoice line item.\"\"\"\n    model_config = {'is_entity': False}\n\n    description: str = Field(description=\"Item description\")\n    quantity: float = Field(description=\"Quantity\")\n    unit_price: float = Field(description=\"Unit price\")\n    total: float = Field(description=\"Line total\")\n\nclass BillingDocument(BaseModel):\n    \"\"\"Complete invoice structure.\"\"\"\n    model_config = {'is_entity': True}\n\n    document_no: str = Field(description=\"Invoice number\")\n    date: str = Field(description=\"Invoice date\")\n    issuer: Company = edge(\"ISSUED_BY\", description=\"Issuing company\")\n    client: Company = edge(\"BILLED_TO\", description=\"Client company\")\n    line_items: list[LineItem] = Field(description=\"Invoice line items\")\n    subtotal: float = Field(description=\"Subtotal amount\")\n    tax: float = Field(description=\"Tax amount\")\n    total: float = Field(description=\"Total amount\")\n</code></pre> <p>Save as: <code>templates/billing_document.py</code></p>"},{"location":"usage/examples/docling-document-input/#processing-with-cli","title":"Processing with CLI","text":""},{"location":"usage/examples/docling-document-input/#basic-doclingdocument-processing","title":"Basic DoclingDocument Processing","text":"<pre><code># Process DoclingDocument JSON\nuv run docling-graph convert invoice_docling.json \\\n    --template \"templates.billing_document.BillingDocument\" \\\n    --backend llm \\\n    --inference remote\n</code></pre>"},{"location":"usage/examples/docling-document-input/#reprocess-with-different-template","title":"Reprocess with Different Template","text":"<pre><code># First extraction\nuv run docling-graph convert invoice.pdf \\\n    --template \"templates.billing_document.BasicInvoice\" \\\n    --export-docling-json\n\n# Reprocess with detailed template (no OCR needed)\nuv run docling-graph convert outputs/invoice_docling.json \\\n    --template \"templates.billing_document.DetailedInvoice\" \\\n    --output-dir \"outputs/detailed\"\n</code></pre>"},{"location":"usage/examples/docling-document-input/#batch-reprocessing","title":"Batch Reprocessing","text":"<pre><code># Reprocess multiple DoclingDocument files\nfor file in outputs/*_docling.json; do\n    uv run docling-graph convert \"$file\" \\\n        --template \"templates.billing_document.BillingDocument\" \\\n        --output-dir \"outputs/reprocessed\"\ndone\n</code></pre>"},{"location":"usage/examples/docling-document-input/#processing-with-python-api","title":"Processing with Python API","text":""},{"location":"usage/examples/docling-document-input/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom templates.billing_document import BillingDocument\n\n# Configure pipeline for DoclingDocument input\nconfig = PipelineConfig(\n    source=\"invoice_docling.json\",\n    template=Invoice,\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\"\n)\n\n# Run pipeline (skips document conversion)\ncontext = run_pipeline(config)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#two-stage-processing","title":"Two-Stage Processing","text":"<pre><code>import json\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom templates.billing_document import BasicInvoice, DetailedInvoice\n\n# Stage 1: Initial extraction with basic template\nstage1_config = PipelineConfig(\n    source=\"invoice.pdf\",\n    template=BasicInvoice,\n    backend=\"llm\",\n    inference=\"remote\",\n    export_docling_json=True\n)\nstage1_context = run_pipeline(stage1_config)\n\n# Stage 2: Detailed extraction from DoclingDocument\ndocling_json = json.dumps(stage1_context.docling_document.export_to_dict())\nstage2_config = PipelineConfig(\n    source=docling_json,\n    template=DetailedInvoice,\n    backend=\"llm\",\n    inference=\"remote\"\n)\nrun_pipeline(stage2_config)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#batch-reprocessing_1","title":"Batch Reprocessing","text":"<pre><code>import json\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom templates.billing_document import BillingDocument\n\n# Example: DoclingDocument JSON strings from a datastore\ndocling_documents = [\n    \"...docling_json_1...\",\n    \"...docling_json_2...\",\n]\n\nfor doc_json in docling_documents:\n    print(\"Reprocessing DoclingDocument...\")\n\n    config = PipelineConfig(\n        source=doc_json,\n        template=Invoice,\n        backend=\"llm\",\n        inference=\"remote\"\n    )\n\n    try:\n        run_pipeline(config)\n        print(\"\u2705 Completed\")\n    except Exception as e:\n        print(f\"\u274c Failed: {e}\")\n</code></pre>"},{"location":"usage/examples/docling-document-input/#expected-output","title":"Expected Output","text":""},{"location":"usage/examples/docling-document-input/#graph-structure","title":"Graph Structure","text":"<pre><code>Invoice (root node)\n\u251c\u2500\u2500 ISSUED_BY \u2192 Company (Acme Corp)\n\u2502   \u2514\u2500\u2500 address (embedded)\n\u251c\u2500\u2500 BILLED_TO \u2192 Company (Client Inc)\n\u2502   \u2514\u2500\u2500 address (embedded)\n\u2514\u2500\u2500 line_items (list)\n    \u251c\u2500\u2500 LineItem 1\n    \u251c\u2500\u2500 LineItem 2\n    \u2514\u2500\u2500 LineItem 3\n</code></pre>"},{"location":"usage/examples/docling-document-input/#processing-benefits","title":"Processing Benefits","text":"<p>With DoclingDocument Input: - \u26a1 Faster: Skips OCR and document conversion - \ud83d\udcb0 Cheaper: No OCR processing costs - \ud83d\udd04 Reusable: Process same document with different templates - \ud83c\udfaf Consistent: Same document structure every time</p> <p>Comparison:</p> Operation PDF Input DoclingDocument Input OCR \u2705 Required \u274c Skipped Conversion \u2705 Required \u274c Skipped Extraction \u2705 Yes \u2705 Yes Graph Build \u2705 Yes \u2705 Yes Time ~30s ~5s"},{"location":"usage/examples/docling-document-input/#doclingdocument-structure","title":"DoclingDocument Structure","text":""},{"location":"usage/examples/docling-document-input/#required-fields","title":"Required Fields","text":"<pre><code>{\n  \"schema_name\": \"DoclingDocument\",  // Required\n  \"version\": \"1.0.0\",                // Required\n  \"name\": \"document_name\",\n  \"pages\": {\n    \"0\": {\n      \"page_no\": 0,\n      \"size\": {\"width\": 612, \"height\": 792}\n    }\n  },\n  \"body\": {\n    \"self_ref\": \"#/body\",\n    \"children\": []\n  },\n  \"furniture\": {}\n}\n</code></pre>"},{"location":"usage/examples/docling-document-input/#validation","title":"Validation","text":"<p>The pipeline validates: \u2705 <code>schema_name</code> must be \"DoclingDocument\" \u2705 <code>version</code> field must be present \u2705 Valid JSON structure \u2705 Required fields present</p>"},{"location":"usage/examples/docling-document-input/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/docling-document-input/#invalid-schema","title":"\ud83d\udc1b Invalid Schema","text":"<p>Error: <pre><code>ValidationError: schema_name must be 'DoclingDocument', got 'CustomDocument'\n</code></pre></p> <p>Solution: <pre><code>{\n  \"schema_name\": \"DoclingDocument\",  // Must be exactly this\n  \"version\": \"1.0.0\",\n  ...\n}\n</code></pre></p>"},{"location":"usage/examples/docling-document-input/#missing-version","title":"\ud83d\udc1b Missing Version","text":"<p>Error: <pre><code>ValidationError: Missing required field: version\n</code></pre></p> <p>Solution: <pre><code>{\n  \"schema_name\": \"DoclingDocument\",\n  \"version\": \"1.0.0\",  // Add version field\n  ...\n}\n</code></pre></p>"},{"location":"usage/examples/docling-document-input/#invalid-json","title":"\ud83d\udc1b Invalid JSON","text":"<p>Error: <pre><code>ValidationError: Invalid JSON in DoclingDocument file\n</code></pre></p> <p>Solution: <pre><code># Validate JSON syntax\npython -m json.tool invoice_docling.json\n\n# Or use jq\njq . invoice_docling.json\n</code></pre></p>"},{"location":"usage/examples/docling-document-input/#file-not-found","title":"\ud83d\udc1b File Not Found","text":"<p>Error: <pre><code>ConfigurationError: File not found: invoice_docling.json\n</code></pre></p> <p>Solution: <pre><code># Check file exists\nls -la invoice_docling.json\n\n# Check file path\npwd\n# Use absolute path if needed\nuv run docling-graph convert /full/path/to/invoice_docling.json ...\n</code></pre></p>"},{"location":"usage/examples/docling-document-input/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/docling-document-input/#version-your-doclingdocuments","title":"\ud83d\udc4d Version Your DoclingDocuments","text":"<pre><code># Add version to filename\ndoc_file = f\"invoice_v{version}_docling.json\"\n\n# Or in metadata\ndoc = DoclingDocument(\n    schema_name=\"DoclingDocument\",\n    version=\"1.0.0\",\n    name=f\"invoice_v{version}\",\n    ...\n)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#store-metadata","title":"\ud83d\udc4d Store Metadata","text":"<pre><code>{\n  \"schema_name\": \"DoclingDocument\",\n  \"version\": \"1.0.0\",\n  \"name\": \"invoice_001\",\n  \"metadata\": {\n    \"source_file\": \"invoice.pdf\",\n    \"processed_date\": \"2024-01-15\",\n    \"ocr_engine\": \"docling\",\n    \"template_version\": \"2.0\"\n  },\n  ...\n}\n</code></pre>"},{"location":"usage/examples/docling-document-input/#validate-before-processing","title":"\ud83d\udc4d Validate Before Processing","text":"<pre><code>from docling_graph.core.input.validators import DoclingDocumentValidator\nimport json\n\n# Validate DoclingDocument\nvalidator = DoclingDocumentValidator()\n\nwith open(\"invoice_docling.json\") as f:\n    content = f.read()\n\ntry:\n    validator.validate(content)\n    print(\"\u2705 Valid DoclingDocument\")\nexcept ValidationError as e:\n    print(f\"\u274c Invalid: {e.message}\")\n</code></pre>"},{"location":"usage/examples/docling-document-input/#archive-original-pdfs","title":"\ud83d\udc4d Archive Original PDFs","text":"<pre><code>from pathlib import Path\nimport shutil\n\n# Keep original PDF alongside DoclingDocument\npdf_file = Path(\"invoice.pdf\")\ndocling_file = Path(\"invoice_docling.json\")\narchive_dir = Path(\"archive\")\n\n# Archive structure\narchive_dir.mkdir(exist_ok=True)\nshutil.copy(pdf_file, archive_dir / pdf_file.name)\nshutil.copy(docling_file, archive_dir / docling_file.name)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/examples/docling-document-input/#custom-doclingdocument-creation","title":"Custom DoclingDocument Creation","text":"<pre><code>from docling_core.types.doc import DoclingDocument, Page, Size\nimport json\n\n# Create custom DoclingDocument\ndoc = DoclingDocument(\n    schema_name=\"DoclingDocument\",\n    version=\"1.0.0\",\n    name=\"custom_invoice\",\n    pages={\n        \"0\": Page(\n            page_no=0,\n            size=Size(width=612, height=792)\n        )\n    },\n    body={\n        \"self_ref\": \"#/body\",\n        \"children\": []\n    },\n    furniture={}\n)\n\n# Save\nwith open(\"custom_docling.json\", \"w\") as f:\n    json.dump(doc.model_dump(), f, indent=2)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#merging-multiple-doclingdocuments","title":"Merging Multiple DoclingDocuments","text":"<pre><code>from docling_core.types.doc import DoclingDocument\nimport json\n\n# Load multiple documents\ndocs = []\nfor file in [\"doc1_docling.json\", \"doc2_docling.json\"]:\n    with open(file) as f:\n        docs.append(json.load(f))\n\n# Merge (simplified example)\nmerged = docs[0].copy()\nfor doc in docs[1:]:\n    # Merge pages, body, etc.\n    merged[\"pages\"].update(doc[\"pages\"])\n\n# Save merged document\nwith open(\"merged_docling.json\", \"w\") as f:\n    json.dump(merged, f, indent=2)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#extracting-specific-pages","title":"Extracting Specific Pages","text":"<pre><code>import json\n\n# Load DoclingDocument\nwith open(\"multi_page_docling.json\") as f:\n    doc = json.load(f)\n\n# Extract specific pages\npages_to_keep = [\"0\", \"2\", \"4\"]  # Keep pages 0, 2, 4\ndoc[\"pages\"] = {\n    k: v for k, v in doc[\"pages\"].items()\n    if k in pages_to_keep\n}\n\n# Save filtered document\nwith open(\"filtered_docling.json\", \"w\") as f:\n    json.dump(doc, f, indent=2)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#use-cases","title":"Use Cases","text":""},{"location":"usage/examples/docling-document-input/#1-template-experimentation","title":"1. Template Experimentation","text":"<p>Test different templates without re-running OCR:</p> <pre><code>templates = [\n    \"templates.billing_document.BasicInvoice\",\n    \"templates.billing_document.DetailedInvoice\",\n    \"templates.billing_document.MinimalInvoice\"\n]\n\nfor template in templates:\n    config = PipelineConfig(\n        source=\"invoice_docling.json\",\n        template=template\n    )\n    run_pipeline(config)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#2-ab-testing-extraction-strategies","title":"2. A/B Testing Extraction Strategies","text":"<pre><code># Test different backends\nfor backend in [\"llm\", \"vlm\"]:\n    config = PipelineConfig(\n        source=\"invoice_docling.json\",\n        template=Invoice,\n        backend=backend\n    )\n    run_pipeline(config)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#3-incremental-processing","title":"3. Incremental Processing","text":"<pre><code># Process in stages\nstages = [\n    (\"basic\", BasicTemplate),\n    (\"detailed\", DetailedTemplate),\n    (\"enriched\", EnrichedTemplate)\n]\n\nsource = \"invoice_docling.json\"\nfor stage_name, template in stages:\n    config = PipelineConfig(\n        source=source,\n        template=template\n    )\n    run_pipeline(config)\n</code></pre>"},{"location":"usage/examples/docling-document-input/#next-steps","title":"Next Steps","text":"<ul> <li>Input Formats Guide - Complete input format reference</li> <li>Examples Index - Browse all examples</li> </ul>"},{"location":"usage/examples/id-card/","title":"ID Card Extraction","text":""},{"location":"usage/examples/id-card/#overview","title":"Overview","text":"<p>Extract personal information from ID cards and identity documents using vision-based extraction.</p> <p>Document Type: ID Card (Image) Time: 15 minutes Backend: VLM (recommended)</p>"},{"location":"usage/examples/id-card/#prerequisites","title":"Prerequisites","text":"<pre><code># Install\npip install docling-graph\n</code></pre>"},{"location":"usage/examples/id-card/#template-definition","title":"Template Definition","text":""},{"location":"usage/examples/id-card/#complete-template","title":"Complete Template","text":"<p>File: <code>id_card_template.py</code></p> <pre><code>\"\"\"\nID Card extraction template.\nDemonstrates date parsing, validators, and graph IDs.\n\"\"\"\n\nimport re\nfrom datetime import date\nfrom typing import List\nfrom pydantic import BaseModel, ConfigDict, Field, field_validator\n\ndef edge(label: str, **kwargs):\n    \"\"\"Helper for graph edges.\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- Address Component ---\n\nclass Address(BaseModel):\n    \"\"\"Physical address.\"\"\"\n\n    model_config = ConfigDict(is_entity=False)\n\n    street_address: str | None = Field(\n        None,\n        description=\"Street name and number\",\n        examples=[\"123 Main Street\", \"456 Oak Avenue\"]\n    )\n\n    city: str | None = Field(\n        None,\n        description=\"City name\",\n        examples=[\"New York\", \"Los Angeles\"]\n    )\n\n    state_or_province: str | None = Field(\n        None,\n        description=\"State or province\",\n        examples=[\"NY\", \"California\"]\n    )\n\n    postal_code: str | None = Field(\n        None,\n        description=\"Postal or ZIP code\",\n        examples=[\"10001\", \"90210\"]\n    )\n\n    country: str | None = Field(\n        None,\n        description=\"Country name\",\n        examples=[\"USA\", \"United States\"]\n    )\n\n# --- Person Entity ---\n\nclass Person(BaseModel):\n    \"\"\"Person entity with unique identification.\"\"\"\n\n    # Graph ID: Unique by name + date of birth\n    model_config = ConfigDict(\n        graph_id_fields=[\"given_names\", \"last_name\", \"date_of_birth\"]\n    )\n\n    given_names: List[str] | None = Field(\n        default=None,\n        description=\"List of given names (first names)\",\n        examples=[[\"John\"], [\"Mary\", \"Jane\"], [\"Pierre\", \"Louis\"]]\n    )\n\n    last_name: str | None = Field(\n        None,\n        description=\"Family name (surname)\",\n        examples=[\"Smith\", \"Johnson\", \"Doe\"]\n    )\n\n    alternate_name: str | None = Field(\n        None,\n        description=\"Alternate or maiden name\",\n        examples=[\"Doe\", \"MJ\"]\n    )\n\n    date_of_birth: date | None = Field(\n        None,\n        description=\"Date of birth in YYYY-MM-DD format\",\n        examples=[\"1990-05-15\", \"1985-12-01\"]\n    )\n\n    place_of_birth: str | None = Field(\n        None,\n        description=\"City and/or country of birth\",\n        examples=[\"New York, USA\", \"Paris, France\"]\n    )\n\n    gender: str | None = Field(\n        None,\n        description=\"Gender\",\n        examples=[\"M\", \"F\", \"Male\", \"Female\"]\n    )\n\n    # Relationship\n    lives_at: Address | None = edge(\n        label=\"LIVES_AT\",\n        description=\"Home address\"\n    )\n\n    # --- Validators ---\n\n    @field_validator(\"given_names\", mode=\"before\")\n    @classmethod\n    def ensure_list(cls, v):\n        \"\"\"Ensure given_names is a list.\"\"\"\n        if isinstance(v, str):\n            # Handle comma or space separated\n            if \",\" in v:\n                return [name.strip() for name in v.split(\",\")]\n            return [v]\n        return v\n\n    @field_validator(\"lives_at\", mode=\"before\")\n    @classmethod\n    def parse_address(cls, v):\n        \"\"\"Parse address string into Address object.\"\"\"\n        if v is None or isinstance(v, dict):\n            return v\n\n        if isinstance(v, str):\n            # Simple parsing\n            parts = [p.strip() for p in v.split(\",\")]\n            return {\n                \"street_address\": parts[0] if len(parts) &gt; 0 else None,\n                \"city\": parts[1] if len(parts) &gt; 1 else None,\n                \"country\": parts[-1] if len(parts) &gt; 2 else None\n            }\n        return v\n\n# --- Root Entity: IDCard ---\n\nclass IDCard(BaseModel):\n    \"\"\"Identity document.\"\"\"\n\n    # Graph ID: Unique by document number\n    model_config = ConfigDict(graph_id_fields=[\"document_number\"])\n\n    document_number: str = Field(\n        ...,\n        description=\"Unique document identifier\",\n        examples=[\"A12345678\", \"123456789\", \"AB1234567\"]\n    )\n\n    issuing_country: str | None = Field(\n        None,\n        description=\"Country that issued the document\",\n        examples=[\"USA\", \"France\", \"United Kingdom\"]\n    )\n\n    issue_date: date | None = Field(\n        None,\n        description=\"Date document was issued (YYYY-MM-DD)\",\n        examples=[\"2023-10-20\", \"2020-05-15\"]\n    )\n\n    expiry_date: date | None = Field(\n        None,\n        description=\"Date document expires (YYYY-MM-DD)\",\n        examples=[\"2033-10-19\", \"2030-05-14\"]\n    )\n\n    # Relationship\n    holder: Person = edge(\n        label=\"BELONGS_TO\",\n        description=\"Person this ID belongs to\"\n    )\n</code></pre>"},{"location":"usage/examples/id-card/#processing","title":"Processing","text":""},{"location":"usage/examples/id-card/#using-cli","title":"Using CLI","text":"<pre><code># Process ID card image with VLM\nuv run docling-graph convert id_card.jpg \\\n    --template \"id_card_template.IDCard\" \\\n    --backend vlm \\\n    --processing-mode one-to-one \\\n    --docling-pipeline vision \\\n    --output-dir \"outputs/id_card\"\n</code></pre>"},{"location":"usage/examples/id-card/#using-python-api","title":"Using Python API","text":"<pre><code>\"\"\"Process ID card.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"id_card.jpg\",\n    template=\"id_card_template.IDCard\",\n    backend=\"vlm\",\n    inference=\"local\",  # VLM only supports local\n    processing_mode=\"one-to-one\",\n    docling_config=\"vision\"\n)\n\nprint(\"Processing ID card...\")\nrun_pipeline(config)\nprint(\"\u2705 Complete!\")\n</code></pre>"},{"location":"usage/examples/id-card/#expected-results","title":"Expected Results","text":""},{"location":"usage/examples/id-card/#graph-structure","title":"Graph Structure","text":"<pre><code>IDCard (A12345678)\n\u2514\u2500\u2500 BELONGS_TO \u2192 Person (John Smith, 1990-05-15)\n    \u2514\u2500\u2500 LIVES_AT \u2192 Address (123 Main St, NYC)\n</code></pre>"},{"location":"usage/examples/id-card/#nodes-csv","title":"Nodes CSV","text":"<pre><code>id,label,type,document_number,issuing_country,issue_date,expiry_date\nid_1,A12345678,IDCard,A12345678,USA,2023-10-20,2033-10-19\nperson_1,John Smith,Person,,,,\naddr_1,123 Main St,Address,,,,\n</code></pre>"},{"location":"usage/examples/id-card/#edges-csv","title":"Edges CSV","text":"<pre><code>source,target,type\nid_1,person_1,BELONGS_TO\nperson_1,addr_1,LIVES_AT\n</code></pre>"},{"location":"usage/examples/id-card/#key-features","title":"Key Features","text":""},{"location":"usage/examples/id-card/#1-date-parsing","title":"1. Date Parsing","text":"<pre><code># Pydantic automatically parses dates\ndate_of_birth: date | None = Field(\n    None,\n    description=\"Date in YYYY-MM-DD format\"\n)\n\n# Accepts: \"1990-05-15\", \"1990/05/15\", \"05-15-1990\"\n# Converts to: date(1990, 5, 15)\n</code></pre>"},{"location":"usage/examples/id-card/#2-graph-id-configuration","title":"2. Graph ID Configuration","text":"<pre><code># Person uniquely identified by name + DOB\nmodel_config = ConfigDict(\n    graph_id_fields=[\"given_names\", \"last_name\", \"date_of_birth\"]\n)\n\n# Same person in multiple documents = same node\n</code></pre>"},{"location":"usage/examples/id-card/#3-list-handling","title":"3. List Handling","text":"<pre><code># Validator converts string to list\ngiven_names: List[str] = Field(...)\n\n@field_validator(\"given_names\", mode=\"before\")\n@classmethod\ndef ensure_list(cls, v):\n    if isinstance(v, str):\n        return [v]  # \"John\" \u2192 [\"John\"]\n    return v\n</code></pre>"},{"location":"usage/examples/id-card/#4-address-parsing","title":"4. Address Parsing","text":"<pre><code># Validator parses address string\n@field_validator(\"lives_at\", mode=\"before\")\n@classmethod\ndef parse_address(cls, v):\n    if isinstance(v, str):\n        # \"123 Main St, NYC, USA\" \u2192 Address object\n        parts = v.split(\",\")\n        return {\"street_address\": parts[0], ...}\n    return v\n</code></pre>"},{"location":"usage/examples/id-card/#visualization","title":"Visualization","text":"<pre><code># Interactive visualization\nuv run docling-graph inspect outputs/id_card/\n</code></pre> <p>Features: - View extracted personal information - See address relationships - Verify dates are parsed correctly</p>"},{"location":"usage/examples/id-card/#customization","title":"Customization","text":""},{"location":"usage/examples/id-card/#add-more-fields","title":"Add More Fields","text":"<pre><code>class IDCard(BaseModel):\n    document_number: str\n    issuing_country: str | None\n    issue_date: date | None\n    expiry_date: date | None\n\n    # Add document type\n    document_type: str | None = Field(\n        None,\n        description=\"Type of ID document\",\n        examples=[\"Passport\", \"Driver License\", \"National ID\"]\n    )\n\n    # Add nationality\n    nationality: str | None = Field(\n        None,\n        description=\"Holder's nationality\",\n        examples=[\"American\", \"French\", \"British\"]\n    )\n\n    holder: Person = edge(label=\"BELONGS_TO\")\n</code></pre>"},{"location":"usage/examples/id-card/#add-validation","title":"Add Validation","text":"<pre><code>from pydantic import field_validator\nfrom datetime import date\n\nclass IDCard(BaseModel):\n    issue_date: date | None\n    expiry_date: date | None\n\n    @field_validator(\"expiry_date\")\n    @classmethod\n    def validate_expiry(cls, v, info):\n        \"\"\"Ensure expiry date is after issue date.\"\"\"\n        issue = info.data.get(\"issue_date\")\n        if issue and v and v &lt;= \ud83d\udc1b\n            raise ValueError(\"Expiry date must be after issue date\")\n        return v\n</code></pre>"},{"location":"usage/examples/id-card/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/id-card/#dates-not-parsed","title":"\ud83d\udc1b Dates Not Parsed","text":"<p>Date fields are None or incorrect</p> <p>Solution: <pre><code># Make dates optional and add examples\ndate_of_birth: date | None = Field(\n    None,\n    description=\"Date of birth. Parse formats like DD/MM/YYYY, MM-DD-YYYY, YYYY-MM-DD\",\n    examples=[\"1990-05-15\", \"05/15/1990\", \"15-05-1990\"]\n)\n</code></pre></p>"},{"location":"usage/examples/id-card/#name-parsing","title":"\ud83d\udc1b Name Parsing","text":"<p>Full name extracted as single string</p> <p>Solution: <pre><code># Add validator to split names\n@field_validator(\"given_names\", mode=\"before\")\n@classmethod\ndef split_names(cls, v):\n    if isinstance(v, str):\n        # \"John Paul\" \u2192 [\"John\", \"Paul\"]\n        return v.split()\n    return v\n</code></pre></p>"},{"location":"usage/examples/id-card/#address-not-structured","title":"\ud83d\udc1b Address Not Structured","text":"<p>Address extracted as single string</p> <p>Solution: <pre><code># Use validator to parse\n@field_validator(\"lives_at\", mode=\"before\")\n@classmethod\ndef parse_address(cls, v):\n    if isinstance(v, str):\n        # Extract postal code\n        postal_match = re.search(r'\\b(\\d{5})\\b', v)\n        postal = postal_match.group(1) if postal_match else None\n\n        return {\n            \"street_address\": v.split(\",\")[0] if \",\" in v else v,\n            \"postal_code\": postal\n        }\n    return v\n</code></pre></p>"},{"location":"usage/examples/id-card/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/id-card/#use-vlm-for-images","title":"\ud83d\udc4d Use VLM for Images","text":"<pre><code># \u2705 Good - VLM for image documents\nuv run docling-graph convert id_card.jpg \\\n    --backend vlm\n\n# \u274c Avoid - LLM for images (slower, less accurate)\nuv run docling-graph convert id_card.jpg \\\n    --backend llm\n</code></pre>"},{"location":"usage/examples/id-card/#make-fields-optional","title":"\ud83d\udc4d Make Fields Optional","text":"<pre><code># \u2705 Good - Optional fields for incomplete data\nclass Person(BaseModel):\n    given_names: List[str] | None = Field(default=None)\n    last_name: str | None = Field(default=None)\n    date_of_birth: date | None = Field(default=None)\n\n# \u274c Avoid - Required fields that might be missing\nclass Person(BaseModel):\n    given_names: List[str]  # Fails if not found\n    last_name: str\n</code></pre>"},{"location":"usage/examples/id-card/#provide-date-format-examples","title":"\ud83d\udc4d Provide Date Format Examples","text":"<pre><code># \u2705 Good - Multiple format examples\ndate_of_birth: date | None = Field(\n    None,\n    description=\"Date of birth in various formats\",\n    examples=[\"1990-05-15\", \"05/15/1990\", \"15-05-1990\"]\n)\n</code></pre>"},{"location":"usage/examples/id-card/#next-steps","title":"Next Steps","text":"<ol> <li>Insurance Policy \u2192 - Financial documents</li> <li>Validation Guide \u2192 - Advanced validators</li> <li>VLM Backend \u2192 - Vision models</li> </ol>"},{"location":"usage/examples/insurance-policy/","title":"Insurance Policy Extraction","text":""},{"location":"usage/examples/insurance-policy/#overview","title":"Overview","text":"<p>Extract structured information from insurance policy documents including coverage details, terms, and relationships.</p> <p>Document Type: Insurance Policy (PDF)  Time: 20 minutes Backend: LLM (recommended)</p>"},{"location":"usage/examples/insurance-policy/#prerequisites","title":"Prerequisites","text":"<pre><code># Install\npip install docling-graph\n\n# For remote API (recommended for complex documents)\nexport MISTRAL_API_KEY=\"your_key_here\"\n</code></pre>"},{"location":"usage/examples/insurance-policy/#template-definition","title":"Template Definition","text":""},{"location":"usage/examples/insurance-policy/#complete-template","title":"Complete Template","text":"<p>File: <code>insurance_template.py</code></p> <pre><code>\"\"\"\nInsurance policy extraction template.\nDemonstrates complex relationships and nested structures.\n\"\"\"\n\nfrom datetime import date\nfrom decimal import Decimal\nfrom typing import List\nfrom pydantic import BaseModel, ConfigDict, Field\n\ndef edge(label: str, **kwargs):\n    \"\"\"Helper for graph edges.\"\"\"\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\n# --- Components (is_entity=False) ---\n\nclass Address(BaseModel):\n    \"\"\"Physical address.\"\"\"\n\n    model_config = ConfigDict(is_entity=False)\n\n    street: str | None = Field(None, description=\"Street address\")\n    city: str | None = Field(None, description=\"City\")\n    state: str | None = Field(None, description=\"State or province\")\n    postal_code: str | None = Field(None, description=\"Postal code\")\n    country: str | None = Field(None, description=\"Country\")\n\nclass MonetaryAmount(BaseModel):\n    \"\"\"Money value with currency.\"\"\"\n\n    model_config = ConfigDict(is_entity=False)\n\n    amount: Decimal = Field(..., description=\"Numeric amount\")\n    currency: str = Field(default=\"USD\", description=\"Currency code\")\n\nclass DateRange(BaseModel):\n    \"\"\"Date range for coverage periods.\"\"\"\n\n    model_config = ConfigDict(is_entity=False)\n\n    start_date: date = Field(..., description=\"Start date\")\n    end_date: date = Field(..., description=\"End date\")\n\n# --- Entities ---\n\nclass Person(BaseModel):\n    \"\"\"Person entity.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"full_name\", \"date_of_birth\"])\n\n    full_name: str = Field(..., description=\"Full legal name\")\n    date_of_birth: date | None = Field(None, description=\"Date of birth\")\n    email: str | None = Field(None, description=\"Email address\")\n    phone: str | None = Field(None, description=\"Phone number\")\n\n    # Relationship\n    address: Address | None = edge(\n        label=\"LIVES_AT\",\n        description=\"Residential address\"\n    )\n\nclass Organization(BaseModel):\n    \"\"\"Insurance company or provider.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"name\"])\n\n    name: str = Field(..., description=\"Organization name\")\n    registration_number: str | None = Field(None, description=\"Business registration\")\n    phone: str | None = Field(None, description=\"Contact phone\")\n    email: str | None = Field(None, description=\"Contact email\")\n    website: str | None = Field(None, description=\"Website URL\")\n\n    # Relationship\n    headquarters: Address | None = edge(\n        label=\"LOCATED_AT\",\n        description=\"Main office address\"\n    )\n\nclass Coverage(BaseModel):\n    \"\"\"Insurance coverage details.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"coverage_type\", \"policy_number\"])\n\n    coverage_type: str = Field(\n        ...,\n        description=\"Type of coverage\",\n        examples=[\"Liability\", \"Collision\", \"Comprehensive\", \"Medical\"]\n    )\n\n    policy_number: str = Field(..., description=\"Associated policy number\")\n\n    coverage_limit: MonetaryAmount | None = Field(\n        None,\n        description=\"Maximum coverage amount\"\n    )\n\n    deductible: MonetaryAmount | None = Field(\n        None,\n        description=\"Deductible amount\"\n    )\n\n    premium: MonetaryAmount | None = Field(\n        None,\n        description=\"Premium cost\"\n    )\n\n    description: str | None = Field(\n        None,\n        description=\"Coverage description\"\n    )\n\nclass PolicyTerm(BaseModel):\n    \"\"\"Policy term or condition.\"\"\"\n\n    model_config = ConfigDict(is_entity=True)\n\n    term_type: str = Field(\n        ...,\n        description=\"Type of term\",\n        examples=[\"Exclusion\", \"Condition\", \"Limitation\", \"Requirement\"]\n    )\n\n    description: str = Field(..., description=\"Term description\")\n\n    applies_to: str | None = Field(\n        None,\n        description=\"What this term applies to\"\n    )\n\n# --- Root Entity: InsurancePolicy ---\n\nclass InsurancePolicy(BaseModel):\n    \"\"\"Complete insurance policy document.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"policy_number\"])\n\n    policy_number: str = Field(\n        ...,\n        description=\"Unique policy identifier\",\n        examples=[\"POL-2024-001234\", \"AUTO-12345\"]\n    )\n\n    policy_type: str = Field(\n        ...,\n        description=\"Type of insurance policy\",\n        examples=[\"Auto\", \"Home\", \"Life\", \"Health\", \"Business\"]\n    )\n\n    status: str | None = Field(\n        None,\n        description=\"Policy status\",\n        examples=[\"Active\", \"Pending\", \"Expired\", \"Cancelled\"]\n    )\n\n    effective_period: DateRange = Field(\n        ...,\n        description=\"Policy effective dates\"\n    )\n\n    total_premium: MonetaryAmount | None = Field(\n        None,\n        description=\"Total policy premium\"\n    )\n\n    payment_frequency: str | None = Field(\n        None,\n        description=\"Payment schedule\",\n        examples=[\"Monthly\", \"Quarterly\", \"Annually\"]\n    )\n\n    # Relationships\n    policyholder: Person = edge(\n        label=\"HELD_BY\",\n        description=\"Primary policyholder\"\n    )\n\n    insurer: Organization = edge(\n        label=\"ISSUED_BY\",\n        description=\"Insurance company\"\n    )\n\n    coverages: List[Coverage] = edge(\n        label=\"INCLUDES_COVERAGE\",\n        description=\"Coverage items\"\n    )\n\n    beneficiaries: List[Person] | None = edge(\n        label=\"BENEFITS\",\n        description=\"Policy beneficiaries\",\n        default=None\n    )\n\n    terms: List[PolicyTerm] | None = edge(\n        label=\"HAS_TERM\",\n        description=\"Policy terms and conditions\",\n        default=None\n    )\n</code></pre>"},{"location":"usage/examples/insurance-policy/#processing","title":"Processing","text":""},{"location":"usage/examples/insurance-policy/#using-cli","title":"Using CLI","text":"<pre><code># Process with remote LLM (best for complex documents)\nuv run docling-graph convert insurance_policy.pdf \\\n    --template \"insurance_template.InsurancePolicy\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider mistral \\\n    --model mistral-small-latest \\\n    --processing-mode many-to-one \\\n    --output-dir \"outputs/insurance\"\n</code></pre>"},{"location":"usage/examples/insurance-policy/#using-python-api","title":"Using Python API","text":"<pre><code>\"\"\"Process insurance policy.\"\"\"\n\nfrom docling_graph import run_pipeline, PipelineConfig\n\nconfig = PipelineConfig(\n    source=\"insurance_policy.pdf\",\n    template=\"insurance_template.InsurancePolicy\",\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\",\n    model_override=\"mistral-small-latest\",\n    provider_override=\"mistral\"\n)\n\nprint(\"Processing insurance policy...\")\nrun_pipeline(config)\nprint(\"\u2705 Complete!\")\n</code></pre>"},{"location":"usage/examples/insurance-policy/#expected-results","title":"Expected Results","text":""},{"location":"usage/examples/insurance-policy/#graph-structure","title":"Graph Structure","text":"<pre><code>InsurancePolicy (POL-2024-001234)\n\u251c\u2500\u2500 HELD_BY \u2192 Person (John Smith)\n\u2502   \u2514\u2500\u2500 LIVES_AT \u2192 Address (123 Main St)\n\u251c\u2500\u2500 ISSUED_BY \u2192 Organization (ABC Insurance)\n\u2502   \u2514\u2500\u2500 LOCATED_AT \u2192 Address (456 Corp Plaza)\n\u251c\u2500\u2500 INCLUDES_COVERAGE \u2192 Coverage (Liability)\n\u251c\u2500\u2500 INCLUDES_COVERAGE \u2192 Coverage (Collision)\n\u251c\u2500\u2500 INCLUDES_COVERAGE \u2192 Coverage (Comprehensive)\n\u251c\u2500\u2500 BENEFITS \u2192 Person (Jane Smith)\n\u2514\u2500\u2500 HAS_TERM \u2192 PolicyTerm (Exclusion)\n</code></pre>"},{"location":"usage/examples/insurance-policy/#nodes-csv","title":"Nodes CSV","text":"<pre><code>id,label,type,policy_number,policy_type,status\npolicy_1,POL-2024-001234,InsurancePolicy,POL-2024-001234,Auto,Active\nperson_1,John Smith,Person,,,\nperson_2,Jane Smith,Person,,,\norg_1,ABC Insurance,Organization,,,\ncov_1,Liability,Coverage,,,\ncov_2,Collision,Coverage,,,\nterm_1,Exclusion,PolicyTerm,,,\n</code></pre>"},{"location":"usage/examples/insurance-policy/#edges-csv","title":"Edges CSV","text":"<pre><code>source,target,type\npolicy_1,person_1,HELD_BY\npolicy_1,org_1,ISSUED_BY\npolicy_1,cov_1,INCLUDES_COVERAGE\npolicy_1,cov_2,INCLUDES_COVERAGE\npolicy_1,person_2,BENEFITS\npolicy_1,term_1,HAS_TERM\nperson_1,addr_1,LIVES_AT\norg_1,addr_2,LOCATED_AT\n</code></pre>"},{"location":"usage/examples/insurance-policy/#key-features","title":"Key Features","text":""},{"location":"usage/examples/insurance-policy/#1-complex-nested-structures","title":"1. Complex Nested Structures","text":"<pre><code># Policy contains multiple coverages\ncoverages: List[Coverage] = edge(\n    label=\"INCLUDES_COVERAGE\",\n    description=\"Coverage items\"\n)\n\n# Each coverage has its own details\nclass Coverage(BaseModel):\n    coverage_type: str\n    coverage_limit: MonetaryAmount\n    deductible: MonetaryAmount\n</code></pre>"},{"location":"usage/examples/insurance-policy/#2-financial-data-handling","title":"2. Financial Data Handling","text":"<pre><code># Use Decimal for precise amounts\nclass MonetaryAmount(BaseModel):\n    amount: Decimal  # Not float!\n    currency: str = \"USD\"\n\n# In policy\ntotal_premium: MonetaryAmount = Field(\n    ...,\n    description=\"Total premium with currency\"\n)\n</code></pre>"},{"location":"usage/examples/insurance-policy/#3-date-ranges","title":"3. Date Ranges","text":"<pre><code># Structured date range\nclass DateRange(BaseModel):\n    start_date: date\n    end_date: date\n\n# In policy\neffective_period: DateRange = Field(\n    ...,\n    description=\"Coverage period\"\n)\n</code></pre>"},{"location":"usage/examples/insurance-policy/#4-multiple-relationships","title":"4. Multiple Relationships","text":"<pre><code># One-to-one\npolicyholder: Person = edge(label=\"HELD_BY\")\n\n# One-to-many\ncoverages: List[Coverage] = edge(label=\"INCLUDES_COVERAGE\")\nbeneficiaries: List[Person] = edge(label=\"BENEFITS\")\n</code></pre>"},{"location":"usage/examples/insurance-policy/#visualization","title":"Visualization","text":"<pre><code># Interactive visualization\nuv run docling-graph inspect outputs/insurance/\n</code></pre> <p>Features: - View policy structure - Explore coverage relationships - See beneficiary connections - Review terms and conditions</p>"},{"location":"usage/examples/insurance-policy/#customization","title":"Customization","text":""},{"location":"usage/examples/insurance-policy/#add-vehicle-information","title":"Add Vehicle Information","text":"<pre><code>class Vehicle(BaseModel):\n    \"\"\"Vehicle covered by policy.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"vin\"])\n\n    vin: str = Field(..., description=\"Vehicle identification number\")\n    make: str | None = Field(None, description=\"Manufacturer\")\n    model: str | None = Field(None, description=\"Model name\")\n    year: int | None = Field(None, description=\"Model year\")\n\nclass InsurancePolicy(BaseModel):\n    # ... existing fields ...\n\n    # Add vehicle relationship\n    insured_vehicles: List[Vehicle] | None = edge(\n        label=\"COVERS_VEHICLE\",\n        description=\"Vehicles covered by this policy\",\n        default=None\n    )\n</code></pre>"},{"location":"usage/examples/insurance-policy/#add-claim-history","title":"Add Claim History","text":"<pre><code>class Claim(BaseModel):\n    \"\"\"Insurance claim.\"\"\"\n\n    model_config = ConfigDict(graph_id_fields=[\"claim_number\"])\n\n    claim_number: str = Field(..., description=\"Claim ID\")\n    claim_date: date = Field(..., description=\"Date filed\")\n    claim_amount: MonetaryAmount = Field(..., description=\"Claim amount\")\n    status: str = Field(..., description=\"Claim status\")\n    description: str | None = Field(None, description=\"Claim details\")\n\nclass InsurancePolicy(BaseModel):\n    # ... existing fields ...\n\n    # Add claims relationship\n    claims: List[Claim] | None = edge(\n        label=\"HAS_CLAIM\",\n        description=\"Claims filed under this policy\",\n        default=None\n    )\n</code></pre>"},{"location":"usage/examples/insurance-policy/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/insurance-policy/#coverage-not-extracted","title":"\ud83d\udc1b Coverage Not Extracted","text":"<p>Coverage list is empty</p> <p>Solution: <pre><code># Make coverages optional and add clear examples\ncoverages: List[Coverage] | None = edge(\n    label=\"INCLUDES_COVERAGE\",\n    description=\"List of coverage types. Extract ALL coverages mentioned: Liability, Collision, Comprehensive, Medical, etc.\",\n    examples=[\n        [\n            {\"coverage_type\": \"Liability\", \"coverage_limit\": {\"amount\": 100000, \"currency\": \"USD\"}},\n            {\"coverage_type\": \"Collision\", \"deductible\": {\"amount\": 500, \"currency\": \"USD\"}}\n        ]\n    ],\n    default=None\n)\n</code></pre></p>"},{"location":"usage/examples/insurance-policy/#amounts-not-parsed","title":"\ud83d\udc1b Amounts Not Parsed","text":"<p>MonetaryAmount fields are None</p> <p>Solution: <pre><code># Add validator to parse currency strings\nfrom pydantic import field_validator\nimport re\n\nclass MonetaryAmount(BaseModel):\n    amount: Decimal\n    currency: str = \"USD\"\n\n    @field_validator(\"amount\", mode=\"before\")\n    @classmethod\n    def parse_amount(cls, v):\n        if isinstance(v, str):\n            # Remove currency symbols and commas\n            v = re.sub(r'[$,]', '', v)\n            return Decimal(v)\n        return v\n</code></pre></p>"},{"location":"usage/examples/insurance-policy/#dates-not-recognized","title":"\ud83d\udc1b Dates Not Recognized","text":"<p>Date fields are None</p> <p>Solution: <pre><code># Add multiple date format examples\neffective_period: DateRange = Field(\n    ...,\n    description=\"Policy effective dates. Parse formats like MM/DD/YYYY, YYYY-MM-DD, Month DD, YYYY\",\n    examples=[\n        {\"start_date\": \"2024-01-01\", \"end_date\": \"2025-01-01\"},\n        {\"start_date\": \"01/01/2024\", \"end_date\": \"01/01/2025\"}\n    ]\n)\n</code></pre></p>"},{"location":"usage/examples/insurance-policy/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/insurance-policy/#use-remote-api-for-complex-documents","title":"\ud83d\udc4d Use Remote API for Complex Documents","text":"<pre><code># \u2705 Good - Remote API for multi-page policies\nuv run docling-graph convert policy.pdf \\\n    --backend llm \\\n    --inference remote\n\n# \u26a0\ufe0f Caution - Local models may struggle with complexity\nuv run docling-graph convert policy.pdf \\\n    --backend llm \\\n    --inference local\n</code></pre>"},{"location":"usage/examples/insurance-policy/#use-decimal-for-money","title":"\ud83d\udc4d Use Decimal for Money","text":"<pre><code># \u2705 Good - Decimal for financial precision\nfrom decimal import Decimal\n\nclass MonetaryAmount(BaseModel):\n    amount: Decimal  # Exact precision\n\n# \u274c Avoid - Float for money (rounding errors)\nclass MonetaryAmount(BaseModel):\n    amount: float  # 0.1 + 0.2 = 0.30000000000000004\n</code></pre>"},{"location":"usage/examples/insurance-policy/#make-lists-optional","title":"\ud83d\udc4d Make Lists Optional","text":"<pre><code># \u2705 Good - Optional lists with defaults\nbeneficiaries: List[Person] | None = edge(\n    label=\"BENEFITS\",\n    default=None\n)\n\n# \u274c Avoid - Required lists (fails if empty)\nbeneficiaries: List[Person] = edge(label=\"BENEFITS\")\n</code></pre>"},{"location":"usage/examples/insurance-policy/#provide-clear-examples","title":"\ud83d\udc4d Provide Clear Examples","text":"<pre><code># \u2705 Good - Detailed examples\ncoverage_type: str = Field(\n    ...,\n    description=\"Type of coverage\",\n    examples=[\n        \"Bodily Injury Liability\",\n        \"Property Damage Liability\",\n        \"Collision\",\n        \"Comprehensive\",\n        \"Medical Payments\",\n        \"Uninsured Motorist\"\n    ]\n)\n</code></pre>"},{"location":"usage/examples/insurance-policy/#advanced-multi-document-processing","title":"Advanced: Multi-Document Processing","text":"<p>Process multiple policies:</p> <pre><code># Process all policies in directory\nfor policy in policies/*.pdf; do\n    uv run docling-graph convert \"$policy\" \\\n        -t \"insurance_template.InsurancePolicy\" \\\n        --backend llm \\\n        --inference remote \\\n        --output-dir \"outputs/$(basename \"$policy\" .pdf)\"\ndone\n</code></pre> <p>Or use Python:</p> <pre><code>\"\"\"Process multiple policies.\"\"\"\n\nfrom pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\n\npolicies_dir = Path(\"policies\")\n\nfor policy_file in policies_dir.glob(\"*.pdf\"):\n    print(f\"Processing {policy_file.name}...\")\n\n    config = PipelineConfig(\n        source=str(policy_file),\n        template=\"insurance_template.InsurancePolicy\",\n        backend=\"llm\",\n        inference=\"remote\"\n    )\n\n    run_pipeline(config)\n    print(f\"\u2705 {policy_file.name} complete!\")\n</code></pre>"},{"location":"usage/examples/insurance-policy/#next-steps","title":"Next Steps","text":"<ol> <li>Examples Index - See all examples</li> <li>Graph Analysis \u2192 - Analyze extracted data</li> <li>Neo4j Integration \u2192 - Load into database</li> </ol>"},{"location":"usage/examples/markdown-input/","title":"Markdown Input Example","text":""},{"location":"usage/examples/markdown-input/#overview","title":"Overview","text":"<p>This example demonstrates how to process Markdown documents directly, extracting structured data from formatted text without requiring OCR or visual processing.</p> <p>Time: 10 minutes</p>"},{"location":"usage/examples/markdown-input/#use-case-documentation-analysis","title":"Use Case: Documentation Analysis","text":"<p>Extract structured information from project documentation, including sections, code examples, and metadata.</p>"},{"location":"usage/examples/markdown-input/#document-source","title":"Document Source","text":"<p>File: <code>README.md</code> or <code>DOCUMENTATION.md</code></p> <p>Type: Markdown</p> <p>Content: Project documentation with sections, code blocks, and structured information.</p>"},{"location":"usage/examples/markdown-input/#template-definition","title":"Template Definition","text":"<p>We'll create a template for documentation that captures sections, code examples, and metadata.</p> <pre><code>from pydantic import BaseModel, Field\nfrom docling_graph.utils import edge\n\nclass CodeExample(BaseModel):\n    \"\"\"Code example component.\"\"\"\n    model_config = {'is_entity': False}\n\n    language: str = Field(description=\"Programming language\")\n    code: str = Field(description=\"Code snippet\")\n    description: str = Field(description=\"What the code does\")\n\nclass Section(BaseModel):\n    \"\"\"Documentation section entity.\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['title']\n    }\n\n    title: str = Field(description=\"Section title\")\n    content: str = Field(description=\"Section content\")\n    subsections: list[str] = Field(\n        default_factory=list,\n        description=\"Subsection titles\"\n    )\n\nclass Documentation(BaseModel):\n    \"\"\"Complete documentation structure.\"\"\"\n    model_config = {'is_entity': True}\n\n    title: str = Field(description=\"Document title\")\n    description: str = Field(description=\"Project description\")\n    version: str | None = Field(\n        default=None,\n        description=\"Documentation version\"\n    )\n    sections: list[Section] = edge(\n        \"HAS_SECTION\",\n        description=\"Documentation sections\"\n    )\n    code_examples: list[CodeExample] = Field(\n        default_factory=list,\n        description=\"Code examples\"\n    )\n    requirements: list[str] = Field(\n        default_factory=list,\n        description=\"Project requirements\"\n    )\n</code></pre> <p>Save as: <code>templates/documentation.py</code></p>"},{"location":"usage/examples/markdown-input/#processing-with-cli","title":"Processing with CLI","text":""},{"location":"usage/examples/markdown-input/#basic-markdown-processing","title":"Basic Markdown Processing","text":"<pre><code># Process README.md\nuv run docling-graph convert README.md \\\n    --template \"templates.documentation.Documentation\" \\\n    --backend llm \\\n    --inference remote\n</code></pre> <p>Important: Markdown files require LLM backend (VLM doesn't support text-only inputs).</p>"},{"location":"usage/examples/markdown-input/#with-local-llm","title":"With Local LLM","text":"<pre><code># Use local Ollama\nuv run docling-graph convert DOCUMENTATION.md \\\n    --template \"templates.documentation.Documentation\" \\\n    --backend llm \\\n    --inference local \\\n    --provider ollama \\\n    --model llama3.1:8b\n</code></pre>"},{"location":"usage/examples/markdown-input/#with-chunking","title":"With Chunking","text":"<pre><code># Process large markdown with chunking\nuv run docling-graph convert LARGE_DOC.md \\\n    --template \"templates.documentation.Documentation\" \\\n    --backend llm \\\n    --inference remote \\\n    --use-chunking \\\n</code></pre>"},{"location":"usage/examples/markdown-input/#processing-with-python-api","title":"Processing with Python API","text":""},{"location":"usage/examples/markdown-input/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom templates.documentation import Documentation\n\n# Configure pipeline for Markdown input\nconfig = PipelineConfig(\n    source=\"README.md\",\n    template=Documentation,\n    backend=\"llm\",  # Required for text inputs\n    inference=\"remote\",\n    processing_mode=\"many-to-one\"\n)\n\n# Run pipeline\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/examples/markdown-input/#processing-multiple-markdown-files","title":"Processing Multiple Markdown Files","text":"<pre><code>from pathlib import Path\nfrom docling_graph import run_pipeline, PipelineConfig\nfrom templates.documentation import Documentation\n\n# Process all markdown files in a directory\ndocs_dir = Path(\"docs\")\nmarkdown_files = docs_dir.glob(\"**/*.md\")\n\nfor md_file in markdown_files:\n    print(f\"Processing: {md_file}\")\n\n    config = PipelineConfig(\n        source=str(md_file),\n        template=Documentation,\n        backend=\"llm\",\n        inference=\"remote\",\n        processing_mode=\"many-to-one\"\n    )\n\n    try:\n        run_pipeline(config)\n        print(f\"\u2705 Completed: {md_file}\")\n    except Exception as e:\n        print(f\"\u274c Failed: {md_file} - {e}\")\n</code></pre>"},{"location":"usage/examples/markdown-input/#with-custom-provider","title":"With Custom Provider","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom templates.documentation import Documentation\n\n# Use specific LLM provider\nconfig = PipelineConfig(\n    source=\"API_DOCS.md\",\n    template=Documentation,\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"openai\",\n    model_override=\"gpt-4-turbo\",\n    use_chunking=True\n)\n\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/examples/markdown-input/#expected-output","title":"Expected Output","text":""},{"location":"usage/examples/markdown-input/#graph-structure","title":"Graph Structure","text":"<pre><code>Documentation (root node)\n\u251c\u2500\u2500 HAS_SECTION \u2192 Section (Installation)\n\u2502   \u251c\u2500\u2500 title: \"Installation\"\n\u2502   \u251c\u2500\u2500 content: \"...\"\n\u2502   \u2514\u2500\u2500 subsections: [\"Requirements\", \"Setup\"]\n\u251c\u2500\u2500 HAS_SECTION \u2192 Section (Usage)\n\u2502   \u251c\u2500\u2500 title: \"Usage\"\n\u2502   \u2514\u2500\u2500 content: \"...\"\n\u251c\u2500\u2500 code_examples (list)\n\u2502   \u251c\u2500\u2500 CodeExample 1: Python\n\u2502   \u2514\u2500\u2500 CodeExample 2: Bash\n\u2514\u2500\u2500 requirements: [\"Python 3.10+\", \"uv\"]\n</code></pre>"},{"location":"usage/examples/markdown-input/#csv-export","title":"CSV Export","text":"<p>nodes.csv: <pre><code>node_id,node_type,title,description,version\ndoc_1,Documentation,\"Project Name\",\"Description...\",\"1.0.0\"\n\nnode_id,node_type,title,content\nsection_installation,Section,\"Installation\",\"Installation instructions...\"\nsection_usage,Section,\"Usage\",\"Usage guide...\"\n</code></pre></p> <p>edges.csv: <pre><code>source_id,target_id,edge_type\ndoc_1,section_installation,HAS_SECTION\ndoc_1,section_usage,HAS_SECTION\n</code></pre></p>"},{"location":"usage/examples/markdown-input/#markdown-processing-features","title":"Markdown Processing Features","text":""},{"location":"usage/examples/markdown-input/#what-gets-processed","title":"What Gets Processed","text":"<p>The pipeline extracts: - Headers \u2192 Section titles - Paragraphs \u2192 Content - Code blocks \u2192 Code examples - Lists \u2192 Requirements, features - Links \u2192 References - Tables \u2192 Structured data</p>"},{"location":"usage/examples/markdown-input/#markdown-preservation","title":"Markdown Preservation","text":"<p>The original Markdown formatting is preserved in the extracted content, allowing you to: - Maintain code block syntax - Preserve link references - Keep list structures - Retain emphasis and formatting</p>"},{"location":"usage/examples/markdown-input/#text-only-pipeline","title":"Text-Only Pipeline","text":"<p>Markdown files skip: \u274c OCR (no visual processing needed) \u274c Page segmentation (single text stream) \u2705 Direct LLM extraction \u2705 Semantic chunking (if enabled)</p>"},{"location":"usage/examples/markdown-input/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/markdown-input/#vlm-backend-error","title":"\ud83d\udc1b VLM Backend Error","text":"<p>Error: <pre><code>ExtractionError: VLM backend does not support text-only inputs\n</code></pre></p> <p>Solution: <pre><code># Always use LLM backend for Markdown\nuv run docling-graph convert README.md \\\n    --template \"templates.documentation.Documentation\" \\\n    --backend llm  # Required\n</code></pre></p>"},{"location":"usage/examples/markdown-input/#empty-file","title":"\ud83d\udc1b Empty File","text":"<p>Error: <pre><code>ValidationError: Text input is empty\n</code></pre></p> <p>Solution: <pre><code># Ensure file has content\ncat README.md  # Check file content\nfile README.md  # Verify file type\n\n# If file is empty, add content first\necho \"# Documentation\" &gt; README.md\n</code></pre></p>"},{"location":"usage/examples/markdown-input/#encoding-problems","title":"\ud83d\udc1b Encoding Problems","text":"<p>Error: <pre><code>ValidationError: Failed to read text file: encoding error\n</code></pre></p> <p>Solution: <pre><code># Convert file to UTF-8 first\nwith open(\"README.md\", \"r\", encoding=\"latin-1\") as f:\n    content = f.read()\n\nwith open(\"README_utf8.md\", \"w\", encoding=\"utf-8\") as f:\n    f.write(content)\n\n# Then process\nconfig = PipelineConfig(source=\"README_utf8.md\", ...)\n</code></pre></p>"},{"location":"usage/examples/markdown-input/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/markdown-input/#use-descriptive-section-headers","title":"\ud83d\udc4d Use Descriptive Section Headers","text":"<pre><code>\u2705 Good - Clear hierarchy\n# Installation Guide\n## Requirements\n## Setup Steps\n\n\u274c Bad - Unclear structure\n# Stuff\n## Things\n</code></pre>"},{"location":"usage/examples/markdown-input/#2-include-code-language-tags","title":"2. Include Code Language Tags","text":"<pre><code>\u2705 Good - Language specified\n```python\ndef hello():\n    print(\"Hello\")\n</code></pre> <p>\u274c Bad - No language <pre><code>def hello():\n    print(\"Hello\")\n</code></pre> <pre><code>### 3. Structure Content Logically\n\n```markdown\n\u2705 Good - Logical flow\n# Overview\n# Installation\n# Usage\n# Examples\n# Troubleshooting\n\n\u274c Bad - Random order\n# Examples\n# Overview\n# Troubleshooting\n# Installation\n</code></pre></p>"},{"location":"usage/examples/markdown-input/#4-use-consistent-formatting","title":"4. Use Consistent Formatting","text":"<pre><code>\u2705 Good - Consistent style\n- Item 1\n- Item 2\n- Item 3\n\n\u274c Bad - Mixed styles\n- Item 1\n* Item 2\n+ Item 3\n</code></pre>"},{"location":"usage/examples/markdown-input/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/examples/markdown-input/#processing-markdown-from-string","title":"Processing Markdown from String","text":"<pre><code>from docling_graph import PipelineConfig, run_pipeline\nfrom templates.documentation import Documentation\n\n# Markdown content as string\nmarkdown_content = \"\"\"\n# My Project\n\n## Overview\nThis is a sample project.\n\n## Features\n- Feature 1\n- Feature 2\n\"\"\"\n\n# Process directly (API mode only)\nconfig = PipelineConfig(\n    source=markdown_content,\n    template=Documentation,\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\"\n)\n\nrun_pipeline(config, mode=\"api\")  # mode=\"api\" required for string input\n</code></pre>"},{"location":"usage/examples/markdown-input/#combining-multiple-markdown-files","title":"Combining Multiple Markdown Files","text":"<pre><code>from pathlib import Path\n\n# Combine multiple markdown files\nmd_files = [\"intro.md\", \"guide.md\", \"reference.md\"]\ncombined_content = \"\\n\\n---\\n\\n\".join(\n    Path(f).read_text() for f in md_files\n)\n\n# Save combined file\nPath(\"combined.md\").write_text(combined_content)\n\n# Process combined file\nconfig = PipelineConfig(\n    source=\"combined.md\",\n    template=Documentation,\n    backend=\"llm\",\n    inference=\"remote\"\n)\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/examples/markdown-input/#extracting-specific-sections","title":"Extracting Specific Sections","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass QuickStart(BaseModel):\n    \"\"\"Extract only quickstart section.\"\"\"\n    model_config = {'is_entity': True}\n\n    installation: str = Field(description=\"Installation instructions\")\n    basic_usage: str = Field(description=\"Basic usage example\")\n    next_steps: list[str] = Field(description=\"Next steps\")\n\n# Process with focused template\nconfig = PipelineConfig(\n    source=\"README.md\",\n    template=QuickStart,\n    backend=\"llm\",\n    inference=\"remote\"\n)\n</code></pre>"},{"location":"usage/examples/markdown-input/#comparison-markdown-vs-pdf","title":"Comparison: Markdown vs PDF","text":"Feature Markdown PDF OCR Required \u274c No \u2705 Yes Processing Speed \u26a1 Fast \ud83d\udc22 Slower Backend Support LLM only LLM + VLM Structure Preservation \u2705 Excellent \u26a0\ufe0f Variable Code Blocks \u2705 Native \u26a0\ufe0f Extracted Best For Documentation, Notes Scanned docs, Forms"},{"location":"usage/examples/markdown-input/#next-steps","title":"Next Steps","text":"<ul> <li>DoclingDocument Input \u2192 - Use pre-processed documents</li> <li>Input Formats Guide - Complete input format reference</li> <li>LLM Backend Configuration - Configure LLM settings</li> </ul>"},{"location":"usage/examples/rheology_research/","title":"Rheology Research Extraction","text":""},{"location":"usage/examples/rheology_research/#overview","title":"Overview","text":"<p>Extract complex research data from scientific papers including experiments, measurements, materials, and results.</p> <p>Document Type: Rheology Research (PDF) Time: 30 minutes Backend: LLM with chunking</p>"},{"location":"usage/examples/rheology_research/#prerequisites","title":"Prerequisites","text":"<pre><code># Install with remote API support\npip install docling-graph\n\n# Set API key\nexport MISTRAL_API_KEY=\"your-key\"\n</code></pre>"},{"location":"usage/examples/rheology_research/#template-overview","title":"Template Overview","text":"<p>The rheology research template (<code>rheology_research.py</code>) includes:</p> <ul> <li>Measurements - Flexible value/unit pairs</li> <li>Materials - Granular material properties</li> <li>Geometry - Experimental setup</li> <li>Vibration - Vibration parameters</li> <li>Simulation - DEM simulation details</li> <li>Results - Rheological measurements</li> <li>Experiments - Complete experiment instances</li> <li>Research - Root document model</li> </ul>"},{"location":"usage/examples/rheology_research/#key-components","title":"Key Components","text":"<pre><code># 1. Measurement Model\nclass Measurement(BaseModel):\n    \"\"\"Flexible measurement with value and unit.\"\"\"\n    name: str\n    numeric_value: float | None = None\n    text_value: str | None = None\n    unit: str | None = None\n\n# 2. Enum Types\nclass GeometryType(str, Enum):\n    VANE_RHEOMETER = \"Vane Rheometer\"\n    DOUBLE_PLATE = \"Double Plate\"\n    CYLINDRICAL_CONTAINER = \"Cylindrical Container\"\n\n# 3. Experiment Entity\nclass Experiment(BaseModel):\n    experiment_id: str\n    objective: str\n    granular_material: GranularMaterial = edge(\"USES_MATERIAL\")\n    vibration_conditions: VibrationConditions = edge(\"HAS_VIBRATION\")\n    rheological_results: List[RheologicalResult] = edge(\"HAS_RESULT\")\n\n# 4. Root Model\nclass Research(BaseModel):\n    title: str\n    authors: List[str]\n    experiments: List[Experiment] = edge(\"HAS_EXPERIMENT\")\n</code></pre>"},{"location":"usage/examples/rheology_research/#processing","title":"Processing","text":""},{"location":"usage/examples/rheology_research/#using-cli","title":"Using CLI","text":"<pre><code># Process rheology research with chunking\nuv run docling-graph convert research.pdf \\\n    --template \"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider mistral \\\n    --model mistral-large-latest \\\n    --processing-mode many-to-one \\\n    --use-chunking \\\n    --docling-pipeline vision \\\n    --output-dir \"outputs/research\"\n</code></pre>"},{"location":"usage/examples/rheology_research/#using-python-api","title":"Using Python API","text":"<pre><code>\"\"\"Process rheology research.\"\"\"\n\nimport os\nfrom docling_graph import run_pipeline, PipelineConfig\n\nos.environ[\"MISTRAL_API_KEY\"] = \"your-key\"\n\nconfig = PipelineConfig(\n    source=\"research.pdf\",\n    template=\"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\",\n    backend=\"llm\",\n    inference=\"remote\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n    processing_mode=\"many-to-one\",\n    use_chunking=True,\n    docling_config=\"vision\"  # Better for complex layouts\n)\n\nprint(\"Processing rheology research (may take several minutes)...\")\nrun_pipeline(config)\nprint(\"\u2705 Complete!\")\n</code></pre>"},{"location":"usage/examples/rheology_research/#expected-results","title":"Expected Results","text":""},{"location":"usage/examples/rheology_research/#graph-structure","title":"Graph Structure","text":"<pre><code>Research (Title)\n\u251c\u2500\u2500 HAS_EXPERIMENT \u2192 Experiment 1\n\u2502   \u251c\u2500\u2500 USES_MATERIAL \u2192 GranularMaterial\n\u2502   \u2502   \u2514\u2500\u2500 properties: [Measurement, Measurement]\n\u2502   \u251c\u2500\u2500 HAS_GEOMETRY \u2192 SystemGeometry\n\u2502   \u2502   \u2514\u2500\u2500 dimensions: [Measurement, Measurement]\n\u2502   \u251c\u2500\u2500 HAS_VIBRATION \u2192 VibrationConditions\n\u2502   \u2502   \u251c\u2500\u2500 amplitude: Measurement\n\u2502   \u2502   \u251c\u2500\u2500 frequency: Measurement\n\u2502   \u2502   \u2514\u2500\u2500 confining_pressure: Measurement\n\u2502   \u251c\u2500\u2500 HAS_SIMULATION \u2192 SimulationSetup\n\u2502   \u2502   \u2514\u2500\u2500 parameters: [Measurement, Measurement]\n\u2502   \u2514\u2500\u2500 HAS_RESULT \u2192 RheologicalResult\n\u2502       \u2514\u2500\u2500 measurement: Measurement\n\u2514\u2500\u2500 HAS_EXPERIMENT \u2192 Experiment 2\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"usage/examples/rheology_research/#statistics","title":"Statistics","text":"<pre><code>{\n  \"node_count\": 45,\n  \"edge_count\": 38,\n  \"density\": 0.019,\n  \"node_types\": {\n    \"Research\": 1,\n    \"Experiment\": 3,\n    \"GranularMaterial\": 3,\n    \"SystemGeometry\": 3,\n    \"VibrationConditions\": 3,\n    \"RheologicalResult\": 12,\n    \"Measurement\": 20\n  }\n}\n</code></pre>"},{"location":"usage/examples/rheology_research/#key-features","title":"Key Features","text":""},{"location":"usage/examples/rheology_research/#1-enum-normalization","title":"1. Enum Normalization","text":"<pre><code>class GeometryType(str, Enum):\n    VANE_RHEOMETER = \"Vane Rheometer\"\n    CYLINDRICAL_CONTAINER = \"Cylindrical Container\"\n\n# Validator accepts multiple formats\n@field_validator(\"geometry_type\", mode=\"before\")\n@classmethod\ndef normalize_enum(cls, v):\n    # Accepts: \"Vane Rheometer\", \"vane_rheometer\", \"VANE_RHEOMETER\"\n    return _normalize_enum(GeometryType, v)\n</code></pre>"},{"location":"usage/examples/rheology_research/#2-measurement-parsing","title":"2. Measurement Parsing","text":"<pre><code># Parses strings like \"1.6 mPa.s\", \"2 mm\", \"80-90 \u00b0C\"\ndef _parse_measurement_string(s: str):\n    # Single value: \"1.6 mPa.s\" \u2192 {numeric_value: 1.6, unit: \"mPa.s\"}\n    # Range: \"80-90 \u00b0C\" \u2192 {numeric_value_min: 80, numeric_value_max: 90, unit: \"\u00b0C\"}\n    ...\n</code></pre>"},{"location":"usage/examples/rheology_research/#3-flexible-measurements","title":"3. Flexible Measurements","text":"<pre><code>class Measurement(BaseModel):\n    name: str\n    numeric_value: float | None = None  # Single value\n    numeric_value_min: float | None = None  # Range min\n    numeric_value_max: float | None = None  # Range max\n    text_value: str | None = None  # Qualitative\n    unit: str | None = None\n</code></pre>"},{"location":"usage/examples/rheology_research/#4-nested-relationships","title":"4. Nested Relationships","text":"<pre><code>class Experiment(BaseModel):\n    # Direct edges\n    granular_material: GranularMaterial = edge(\"USES_MATERIAL\")\n\n    # Nested properties (not separate nodes)\n    key_findings: List[str] = Field(default_factory=list)\n</code></pre>"},{"location":"usage/examples/rheology_research/#configuration-tips","title":"Configuration Tips","text":""},{"location":"usage/examples/rheology_research/#for-long-documents","title":"For Long Documents","text":"<pre><code># Enable chunking and consolidation\nuv run docling-graph convert research.pdf \\\n    --template \"templates.ScholarlyRheologyPaper\" \\\n    --use-chunking \\\n    --processing-mode many-to-one\n</code></pre>"},{"location":"usage/examples/rheology_research/#for-complex-layouts","title":"For Complex Layouts","text":"<pre><code># Use vision pipeline for better table/figure handling\nuv run docling-graph convert research.pdf \\\n    --template \"templates.ScholarlyRheologyPaper\" \\\n    --docling-pipeline vision\n</code></pre>"},{"location":"usage/examples/rheology_research/#for-cost-optimization","title":"For Cost Optimization","text":"<pre><code># Use smaller model without consolidation\nuv run docling-graph convert research.pdf \\\n    --template \"templates.ScholarlyRheologyPaper\" \\\n    --model mistral-small-latest \\\n</code></pre>"},{"location":"usage/examples/rheology_research/#customization","title":"Customization","text":""},{"location":"usage/examples/rheology_research/#simplify-for-your-domain","title":"Simplify for Your Domain","text":"<pre><code>\"\"\"Simplified research template.\"\"\"\n\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\ndef edge(label: str, **kwargs):\n    return Field(..., json_schema_extra={\"edge_label\": label}, **kwargs)\n\nclass Measurement(BaseModel):\n    \"\"\"Simple measurement.\"\"\"\n    name: str\n    value: str  # Keep as string for simplicity\n    unit: str | None = None\n\nclass Experiment(BaseModel):\n    \"\"\"Simplified experiment.\"\"\"\n    title: str\n    objective: str\n    methods: str\n    results: str\n    measurements: List[Measurement] = Field(default_factory=list)\n\nclass Research(BaseModel):\n    \"\"\"Simplified rheology research (for demonstration).\n\n    Note: For production use, see the full ScholarlyRheologyPaper template at:\n    docs/examples/templates/rheology_research.py\n\n    The full template includes:\n    - Comprehensive scholarly metadata (authors, affiliations, identifiers)\n    - Detailed formulation specifications (materials, components, amounts)\n    - Batch preparation history (mixing steps, equipment, conditions)\n    - Complete rheometry setup (instruments, geometries, protocols)\n    - Test runs and datasets (curves, measurements, model fits)\n    \"\"\"\n    title: str\n    authors: List[str]\n    abstract: str\n    experiments: List[Experiment] = edge(\"HAS_EXPERIMENT\")\n</code></pre>"},{"location":"usage/examples/rheology_research/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/rheology_research/#extraction-takes-too-long","title":"\ud83d\udc1b Extraction Takes Too Long","text":"<p>Solution: <pre><code># Disable consolidation for faster processing\nuv run docling-graph convert research.pdf \\\n    --template \"templates.ScholarlyRheologyPaper\" \\\n\n# Or use smaller model\n--model mistral-small-latest\n</code></pre></p>"},{"location":"usage/examples/rheology_research/#missing-measurements","title":"\ud83d\udc1b Missing Measurements","text":"<p>Solution: <pre><code># Make measurements optional\nmeasurements: List[Measurement] = Field(\n    default_factory=list,\n    description=\"List of measurements (optional)\"\n)\n</code></pre></p>"},{"location":"usage/examples/rheology_research/#enum-validation-errors","title":"\ud83d\udc1b Enum Validation Errors","text":"<p>Solution: <pre><code># Add OTHER option to enums\nclass GeometryType(str, Enum):\n    VANE_RHEOMETER = \"Vane Rheometer\"\n    OTHER = \"Other\"  # Fallback\n\n# Or make enum optional\ngeometry_type: GeometryType | None = Field(default=None)\n</code></pre></p>"},{"location":"usage/examples/rheology_research/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/rheology_research/#start-simple-add-complexity","title":"\ud83d\udc4d Start Simple, Add Complexity","text":"<pre><code># Phase 1: Basic structure\nclass Research(BaseModel):\n    title: str\n    authors: List[str]\n    abstract: str\n\n# Phase 2: Add experiments\nclass Research(BaseModel):\n    title: str\n    authors: List[str]\n    abstract: str\n    experiments: List[Experiment]\n\n# Phase 3: Add measurements, validations, etc.\n</code></pre>"},{"location":"usage/examples/rheology_research/#use-appropriate-chunking","title":"\ud83d\udc4d Use Appropriate Chunking","text":"<pre><code># For papers &gt; 10 pages\nconfig = PipelineConfig(\n    source=\"long_paper.pdf\",\n    template=\"templates.ScholarlyRheologyPaper\",\n    use_chunking=True,  # Essential\n)\n</code></pre>"},{"location":"usage/examples/rheology_research/#provide-clear-examples","title":"\ud83d\udc4d Provide Clear Examples","text":"<pre><code># \u2705 Good - Domain-specific examples\nviscosity: Measurement = Field(\n    description=\"Effective viscosity measurement\",\n    examples=[\n        {\"name\": \"Effective Viscosity\", \"numeric_value\": 1.6, \"unit\": \"mPa.s\"}\n    ]\n)\n</code></pre>"},{"location":"usage/examples/rheology_research/#next-steps","title":"Next Steps","text":"<ol> <li>ID Card \u2192 - Vision-based extraction</li> <li>Advanced Patterns \u2192 - Complex templates</li> <li>Performance Tuning \u2192 - Optimization</li> </ol>"},{"location":"usage/examples/url-input/","title":"URL Input Example","text":""},{"location":"usage/examples/url-input/#overview","title":"Overview","text":"<p>This example demonstrates how to process documents directly from URLs, showcasing Docling Graph's ability to download and extract data from remote documents without manual file management.</p> <p>Time: 10 minutes</p>"},{"location":"usage/examples/url-input/#use-case-rheology-research-analysis","title":"Use Case: Rheology Research Analysis","text":"<p>Extract structured information from a scientific paper hosted on arXiv, including authors, abstract, methodology, and key findings.</p>"},{"location":"usage/examples/url-input/#document-source","title":"Document Source","text":"<p>URL: <code>https://arxiv.org/pdf/2207.02720</code></p> <p>Type: PDF (Rheology Research on Rheology)</p> <p>Content: Scientific paper with complex structure including authors, abstract, methodology, results, and references.</p>"},{"location":"usage/examples/url-input/#template-definition","title":"Template Definition","text":"<p>We'll use a rheology research template that captures the essential structure of scientific documents.</p> <pre><code>from pydantic import BaseModel, Field\nfrom docling_graph.utils import edge\n\nclass Author(BaseModel):\n    \"\"\"Author entity.\"\"\"\n    model_config = {\n        'is_entity': True,\n        'graph_id_fields': ['name']\n    }\n\n    name: str = Field(description=\"Author's full name\")\n    affiliation: str | None = Field(\n        default=None,\n        description=\"Author's institutional affiliation\"\n    )\n\nclass Methodology(BaseModel):\n    \"\"\"Research methodology component.\"\"\"\n    model_config = {'is_entity': False}\n\n    approach: str = Field(description=\"Research approach or method used\")\n    materials: list[str] = Field(\n        default_factory=list,\n        description=\"Materials or tools used\"\n    )\n    procedure: str = Field(description=\"Experimental or analytical procedure\")\n\nclass Finding(BaseModel):\n    \"\"\"Key research finding.\"\"\"\n    model_config = {'is_entity': False}\n\n    description: str = Field(description=\"Description of the finding\")\n    significance: str = Field(description=\"Significance or implication\")\n\nclass Research(BaseModel):\n    \"\"\"Complete rheology research structure.\"\"\"\n    model_config = {'is_entity': True}\n\n    title: str = Field(description=\"Paper title\")\n    abstract: str = Field(description=\"Paper abstract\")\n    authors: list[Author] = edge(\n        \"AUTHORED_BY\",\n        description=\"Paper authors\"\n    )\n    methodology: Methodology = Field(description=\"Research methodology\")\n    key_findings: list[Finding] = Field(\n        default_factory=list,\n        description=\"Key research findings\"\n    )\n    conclusion: str = Field(description=\"Paper conclusion\")\n</code></pre> <p>Save as: <code>templates/research.py</code></p>"},{"location":"usage/examples/url-input/#processing-with-cli","title":"Processing with CLI","text":""},{"location":"usage/examples/url-input/#basic-url-processing","title":"Basic URL Processing","text":"<pre><code># Process rheology research from URL\nuv run docling-graph convert \"https://arxiv.org/pdf/2207.02720\" \\\n    --template \"docs.examples.templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --processing-mode \"many-to-one\" \\\n    --backend llm \\\n    --inference remote\n</code></pre>"},{"location":"usage/examples/url-input/#with-custom-output","title":"With Custom Output","text":"<pre><code># Process with custom output directory\nuv run docling-graph convert \"https://arxiv.org/pdf/2207.02720\" \\\n    --template \"templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --processing-mode \"many-to-one\" \\\n    --output-dir \"outputs/research_paper\" \\\n    --export-format json\n</code></pre>"},{"location":"usage/examples/url-input/#with-specific-model","title":"With Specific Model","text":"<pre><code># Use specific LLM model\nuv run docling-graph convert \"https://arxiv.org/pdf/2207.02720\" \\\n    --template \"templates.rheology_research.ScholarlyRheologyPaper\" \\\n    --processing-mode \"many-to-one\" \\\n    --backend llm \\\n    --inference remote \\\n    --provider openai \\\n    --model gpt-4-turbo\n</code></pre>"},{"location":"usage/examples/url-input/#processing-with-python-api","title":"Processing with Python API","text":""},{"location":"usage/examples/url-input/#basic-usage","title":"Basic Usage","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom templates.rheology_research import ScholarlyRheologyPaper\n\n# Configure pipeline for URL input\nconfig = PipelineConfig(\n    source=\"https://arxiv.org/pdf/2207.02720\",\n    template=Research,\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\"\n)\n\n# Run pipeline\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/examples/url-input/#with-custom-settings","title":"With Custom Settings","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom templates.rheology_research import ScholarlyRheologyPaper\n\n# Advanced configuration\nconfig = PipelineConfig(\n    source=\"https://arxiv.org/pdf/2207.02720\",\n    template=Research,\n    backend=\"llm\",\n    inference=\"remote\",\n    processing_mode=\"many-to-one\",\n    provider_override=\"mistral\",\n    model_override=\"mistral-large-latest\",\n    use_chunking=True,\n    export_format=\"json\"\n)\n\n# Run pipeline\nrun_pipeline(config)\n</code></pre>"},{"location":"usage/examples/url-input/#error-handling","title":"Error Handling","text":"<pre><code>from docling_graph import run_pipeline, PipelineConfig\nfrom docling_graph.exceptions import ValidationError, ExtractionError\nfrom templates.rheology_research import ScholarlyRheologyPaper\n\ntry:\n    config = PipelineConfig(\n        source=\"https://arxiv.org/pdf/2207.02720\",\n        template=Research,\n        backend=\"llm\",\n        inference=\"remote\",\n        processing_mode=\"many-to-one\"\n    )\n    run_pipeline(config)\n\nexcept ValidationError as e:\n    print(f\"URL validation failed: {e.message}\")\n    if e.details:\n        print(f\"Details: {e.details}\")\n\nexcept ExtractionError as e:\n    print(f\"Extraction failed: {e.message}\")\n    # Handle extraction errors (e.g., retry with different model)\n</code></pre>"},{"location":"usage/examples/url-input/#expected-output","title":"Expected Output","text":""},{"location":"usage/examples/url-input/#graph-structure","title":"Graph Structure","text":"<pre><code>Research (root node)\n\u251c\u2500\u2500 AUTHORED_BY \u2192 Author (John Doe)\n\u251c\u2500\u2500 AUTHORED_BY \u2192 Author (Jane Smith)\n\u251c\u2500\u2500 methodology (embedded)\n\u2502   \u251c\u2500\u2500 approach: \"Experimental rheology\"\n\u2502   \u251c\u2500\u2500 materials: [\"Polymer samples\", \"Rheometer\"]\n\u2502   \u2514\u2500\u2500 procedure: \"...\"\n\u251c\u2500\u2500 key_findings (list)\n\u2502   \u251c\u2500\u2500 Finding 1: \"...\"\n\u2502   \u2514\u2500\u2500 Finding 2: \"...\"\n\u2514\u2500\u2500 conclusion: \"...\"\n</code></pre>"},{"location":"usage/examples/url-input/#csv-export","title":"CSV Export","text":"<p>nodes.csv: <pre><code>node_id,node_type,title,abstract,conclusion\nresearch_1,Research,\"Paper Title\",\"Abstract text...\",\"Conclusion text...\"\n\nnode_id,node_type,name,affiliation\nauthor_john_doe,Author,\"John Doe\",\"University X\"\nauthor_jane_smith,Author,\"Jane Smith\",\"Institute Y\"\n</code></pre></p> <p>edges.csv: <pre><code>source_id,target_id,edge_type\nresearch_1,author_john_doe,AUTHORED_BY\nresearch_1,author_jane_smith,AUTHORED_BY\n</code></pre></p>"},{"location":"usage/examples/url-input/#json-export","title":"JSON Export","text":"<pre><code>{\n  \"nodes\": [\n    {\n      \"id\": \"research_1\",\n      \"type\": \"Research\",\n      \"properties\": {\n        \"title\": \"Paper Title\",\n        \"abstract\": \"Abstract text...\",\n        \"conclusion\": \"Conclusion text...\"\n      }\n    },\n    {\n      \"id\": \"author_john_doe\",\n      \"type\": \"Author\",\n      \"properties\": {\n        \"name\": \"John Doe\",\n        \"affiliation\": \"University X\"\n      }\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"research_1\",\n      \"target\": \"author_john_doe\",\n      \"type\": \"AUTHORED_BY\"\n    }\n  ]\n}\n</code></pre>"},{"location":"usage/examples/url-input/#url-processing-features","title":"URL Processing Features","text":""},{"location":"usage/examples/url-input/#automatic-download","title":"Automatic Download","text":"<p>The pipeline automatically: 1. Downloads the PDF from the URL 2. Saves to temporary location 3. Detects content type (PDF) 4. Routes to appropriate processing pipeline 5. Cleans up temporary files</p>"},{"location":"usage/examples/url-input/#content-type-detection","title":"Content Type Detection","text":"<p>Supported URL content types: - PDF documents \u2192 Full document pipeline - Images (PNG, JPG) \u2192 Full document pipeline - Text files \u2192 Text-only pipeline (LLM backend required) - Markdown files \u2192 Text-only pipeline (LLM backend required)</p>"},{"location":"usage/examples/url-input/#configuration-options","title":"Configuration Options","text":"<pre><code>from docling_graph.core.input.handlers import URLInputHandler\n\n# Custom URL handler settings\nhandler = URLInputHandler(\n    timeout=60,      # Download timeout in seconds\n    max_size_mb=100  # Maximum file size in MB\n)\n</code></pre>"},{"location":"usage/examples/url-input/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/examples/url-input/#url-download-timeout","title":"\ud83d\udc1b URL Download Timeout","text":"<p>Error: <pre><code>ValidationError: URL download timeout after 30 seconds\n</code></pre></p> <p>Solution: <pre><code># Increase timeout for large files\nfrom docling_graph.core.input.handlers import URLInputHandler\n\nhandler = URLInputHandler(timeout=120)  # 2 minutes\n</code></pre></p>"},{"location":"usage/examples/url-input/#file-too-large","title":"\ud83d\udc1b File Too Large","text":"<p>Error: <pre><code>ValidationError: File size (150MB) exceeds maximum size (100MB)\n</code></pre></p> <p>Solution: <pre><code># Increase size limit or download manually\nhandler = URLInputHandler(max_size_mb=200)\n\n# Or download manually first\nimport requests\nresponse = requests.get(url)\nwith open(\"document.pdf\", \"wb\") as f:\n    f.write(response.content)\n\n# Then process local file\nconfig = PipelineConfig(source=\"document.pdf\", ...)\n</code></pre></p>"},{"location":"usage/examples/url-input/#unsupported-url-scheme","title":"\ud83d\udc1b Unsupported URL Scheme","text":"<p>Error: <pre><code>ValidationError: URL must use http or https scheme\n</code></pre></p> <p>Solution: <pre><code># Only HTTP/HTTPS URLs are supported\n# For FTP or other protocols, download manually first\nwget ftp://example.com/file.pdf\nuv run docling-graph convert file.pdf --template \"...\"\n</code></pre></p>"},{"location":"usage/examples/url-input/#best-practices","title":"Best Practices","text":""},{"location":"usage/examples/url-input/#use-https-when-available","title":"\ud83d\udc4d Use HTTPS When Available","text":"<pre><code># \u2705 Good - Secure connection\nsource = \"https://arxiv.org/pdf/2207.02720\"\n\n# \u26a0\ufe0f Avoid - Insecure connection\nsource = \"http://example.com/document.pdf\"\n</code></pre>"},{"location":"usage/examples/url-input/#handle-network-errors","title":"\ud83d\udc4d Handle Network Errors","text":"<pre><code>from docling_graph.exceptions import ValidationError\n\ntry:\n    run_pipeline(config)\nexcept ValidationError as e:\n    if \"timeout\" in str(e).lower():\n        print(\"Network timeout - retrying with longer timeout\")\n        # Retry logic\n    elif \"failed to download\" in str(e).lower():\n        print(\"Download failed - check URL and network connection\")\n</code></pre>"},{"location":"usage/examples/url-input/#verify-url-before-processing","title":"\ud83d\udc4d Verify URL Before Processing","text":"<pre><code>import requests\n\ndef verify_url(url: str) -&gt; bool:\n    \"\"\"Verify URL is accessible before processing.\"\"\"\n    try:\n        response = requests.head(url, timeout=10)\n        return response.status_code == 200\n    except:\n        return False\n\nif verify_url(url):\n    config = PipelineConfig(source=url, ...)\n    run_pipeline(config)\nelse:\n    print(f\"URL not accessible: {url}\")\n</code></pre>"},{"location":"usage/examples/url-input/#cache-downloaded-files","title":"\ud83d\udc4d Cache Downloaded Files","text":"<pre><code>from pathlib import Path\nimport hashlib\n\ndef get_cache_path(url: str) -&gt; Path:\n    \"\"\"Generate cache path for URL.\"\"\"\n    url_hash = hashlib.md5(url.encode()).hexdigest()\n    return Path(f\"cache/{url_hash}.pdf\")\n\ncache_path = get_cache_path(url)\nif cache_path.exists():\n    # Use cached file\n    config = PipelineConfig(source=str(cache_path), ...)\nelse:\n    # Download from URL\n    config = PipelineConfig(source=url, ...)\n</code></pre>"},{"location":"usage/examples/url-input/#next-steps","title":"Next Steps","text":"<ul> <li>Markdown Input \u2192 - Process markdown documents</li> <li>DoclingDocument Input \u2192 - Use pre-processed documents</li> <li>Input Formats Guide - Complete input format reference</li> </ul>"}]}